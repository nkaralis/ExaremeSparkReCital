{"id":"oai:arXiv.org:q-bio/0601020","text":"arXiv:q-bio/0601020v1  [q-bio.BM]  14 Jan 2006\nComputation of protein geometry and its applications: Packing and\nfunction prediction\nJie Liang\nFebruary 9, 2008\nContents\n6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n6.2 Theory and Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n6.2.1 The idealized ball model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n6.2.2 Surface models: Lee-Richards and Connolly?s surfaces . . . . . . . . . . . . . . . . . . 2\n6.2.3 Geometric constructs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n6.2.4 Topological structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n6.2.5 Metric measurement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n6.3 Computation and software . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n6.4 Applications: Packing analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n6.5 Applications: Protein function prediction from structures. . . . . . . . . . . . . . . . . . . . . 13\n6.6 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n6.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n6.8 Further reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n6.9 Acknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n6.1 Introduction\nThree-dimensional atomic structures of protein molecules provide rich information for understanding how\nthese working molecules of a cell carry out their biological functions. With the amount of solved protein\nstructures rapidly accumulating, computation of geometric properties of protein structure becomes an indis-\npensable component in studies of modern biochemistry and molecular biology. Before we discuss methods for\ncomputing the geometry of protein molecules, we first briefly describe how protein structures are obtained\nexperimentally.\nThereareprimarilythree experimentaltechniques for obtainingprotein structures: X-raycrystallography,\nsolution nuclear magnetic resonance (NMR), and recently freeze-sample electron microscopy (cryo-EM). In\nX-ray crystallography, the diffraction patterns of X-ray irradiation of a high quality crystal of the protein\nmolecule are measured. Since the diffraction is due to the scattering of X-rayby the electrons of the molecules\nin the crystal, the position, the intensity, and the phase of each recorded diffraction spot provide information\nfor the reconstruction of an electron density map of atoms in the protein molecule. Based on independent\ninformation of the amino acid sequence, a model of the protein conformation is then derived by fitting model\nconformations of residues to the electron density map. An iterative process called refinement is then applied\nto improve the quality of the fit of the electron density map. The final model of the protein conformation\nconsists of the coordinates of each of the non-hydrogen atoms [1].\nThe solution NMR technique for solving protein structure is based on measuring the tumbling and\nvibrating motion of the molecule in solution. By assessing the chemical shifts of atomic nuclei with spins due\nto interactions with other atoms in the vicinity, a set of estimated distances between specific pairs of atoms\ncan be derived from NOSEY spectra. When a large number of such distances are obtained, one can derive\na set of conformations of the protein molecule, each is consistent with all of the distance constraints [2].\nAlthough determining conformations from either X-ray diffraction patterns or NMR spectra is equivalent to\nsolving an ill-posed inverse problem, technique such as Bayesian Markov chain Monte Carlo with parallel\n1\ntempering has been shown to be effective in obtaining protein structures from NMR spectra [3]. The cryo-EM\ntechnique for obtaining protein structure is described in more details in Chapter 11.\n6.2 Theory and Model\n6.2.1 The idealized ball model\nThe shape of a protein molecule is complex. The chemical properties of atoms in a molecule are determined\nby their electron charge distribution. It is this distribution that generates the scattering patterns of the\nX-ray diffraction. Chemical bonds between atoms lead to transfer of electronic charges from one atom to\nanother, and the resulting isosurfaces of the electron density distribution depend not only on the location of\nindividual nuclei but also on interactions between atoms. This results in an overall complicated isosurface\nof electron density [4].\nThe geometric model of macromolecule amenable to convenient computation is an idealized model, where\nthe shapes of atoms are approximated by three-dimensional balls. The shape of a protein or a DNA molecule\nconsisting of many atoms is then the space-filling shape taken by a set of atom balls. This model is often\ncalled the interlocking hard-sphere model, the fused ball model, the space filling model [5?8], or the union\nof ball model [9]. In this model, details in the distribution of electron density, e.g., the differences between\nregions of covalent bonds and non-covalent bonds, are ignored. This idealization is quite reasonable, as it\nreflects the fact that the electron density reaches maximum at a nucleus, and its magnitude decays almost\nspherically away from the point of the nucleus. Despite possible inaccuracy, this idealized model has found\nwide acceptance, because it enables quantitative measurement of important geometric properties (such as\narea and volume) of molecules. Insights gained from these measurements correlate well with experimental\nobservations [5,8,10?13].\nIn this idealization, the shape of each atom is that of a ball, and its size parameter is the ball radius.\nThere are many possible choices for the parameter set of atomic radii [14,15]. Frequently, atomic radii are\nassigned the values of their van der Waals radii [16]. Among all these atoms, hydrogen atom has the smallest\nmass, and has a much smaller radius than those of other atoms. For simplification, the model of united\natom is often employed to approximate the union of a heavy atom and the hydrogen atoms connected by a\ncovalent bond. In this case, the radius of the heavy atom is increased to approximate the size of the union of\nthe two atoms. This practice significantly reduces the total number of atom balls in the molecule. However,\nthis approach has been questioned for possible inadequacy [17].\nThe mathematical model of this idealized model is that of the union of balls [9]. For a molecule M of n\natoms, the i-th atom is modeled as a ball bi, whose center is located at zi ? R3, and the radius of this ball\nis ri ? R, namely, we have bi ? {x|x ? R3,||x?zi|| ? ri} parameterized by (zi,ri). The molecule M is\nformed by the union of a finite number n of such balls defining the set B:\nM =\nuniondisplay\nB =\nnuniondisplay\ni=1\n{bi}.\nIt creates a space-filling body corresponding to the union of the excluded volumes vol(uniontextni=1 bi) [9]. When\nthe atoms are assigned the van der Waals radii, the boundary surface ?uniontextB of the union of balls is called\nthe van der Waals surface.\n6.2.2 Surface models: Lee-Richards and Connolly?s surfaces\nProtein folds into native three-dimensional shape to carry out its biological functional roles. The interac-\ntions of a protein molecule with other molecules (such as ligand, substrate, or other protein) determine its\nfunctional roles. Such interactions occur physically on the surfaces of the protein molecule.\nThe importance of protein surface was recognized very early on. Lee and Richards developed the widely\nused solvent accessible surface (SA) model, which is also often called the Lee-Richards surface model [5].\n2\nba c\nFigure 6.1: Geometric models of protein surfaces. (a) The solvent accessible surface (SA surface) is shown\nin the front. The van der Waals surface (beneath the SA surface) can be regarded as a shrunken version\nof the SA surface by reducing all atomic radii uniformly by the amount of the radius of the solvent probe\nrs = 1.4?A. The elementary pieces of the solvent accessible surface are the three convex spherical surface\npieces, the three arcs, and the vertex where the three arcs meet. (b) The molecular surface (MS, beneath\nthe SA surface) also has three types of elementary pieces: the convex spheric pieces, which are shrunken\nversion of the corresponding pieces in the solvent accessible surface, the concave toroidal pieces, and concave\nspheric surface. The latter two are also called the re-entrant surface. (c) The toroidal surface pieces in the\nmolecular surface, correspond to the arcs in the solvent accessible surface, and the concave spheric surface\nto the vertex. The set of elements in one surface can be continuously deformed to the set of elements in the\nother surface.\nIntuitively, this surface is obtained by rolling a ball of radius rs everywhere along the van der Waals surface of\nthe molecule. The center of the solvent ball will then sweep out the solvent accessible surface. Equivalently,\nthe solvent accessible surface can be viewed as the boundary surface ?uniontextBrs of the union of a set of inflated\nballs Brs, where each ball takes the position of an atom, but with an inflated radius ri + rs (Fig. 6.1a).\nThe solvent accessible surface in general has many sharp crevices and sharp corners. In hope of obtaining\na smoother surface, one can take the surface swept out by the front instead of the center of the solvent ball.\nThis surface is the molecular surface (MS model), which is often called the Connolly?s surface after Michael\nConnolly who developed the first algorithm for computing molecular surface [11]. Both solvent accessible\nsurface and molecular surface are formed by elementary pieces of simpler shape.\nElementary pieces. For the solvent accessible surface model, the boundary surface of a molecule consists\nof three types of elements: the convex spherical surface pieces, arcs or curved line segments (possibly a\nfull circle) formed by two intersecting spheres, and a vertex that is the intersection point of three atom\nspheres. The whole boundary surface of the molecules can be thought of as a surface formed by stitching\nthese elements together.\nSimilarly, the molecular surface swept out by the front of the solvent ball can also be thought of as being\nformed by elementary surface pieces. In this case, they are the convex spherical surface pieces, the toroidal\nsurface pieces, and the concave or inverse spherical surface pieces (Fig. 6.1b) . The latter two types of surface\npieces are often called the ?re-entrant surfaces? [8,11].\nThe surface elements of the solvent accessible surface and the molecular surface are closely related.\nImagine a process where atom balls are shrunk or expanded. The vertices in solvent accessible surface\nbecomes the concave spherical surface pieces, the arcs becomes the toroidal surfaces, and the convex surface\npieces become smaller convex surface pieces (Fig. 6.1c). Because of this mapping, these two type of surfaces\nare combinatorically equivalent and have similar topological properties, i.e., they are homotopy equivalent.\nHowever, the SA surface and the MS surface differ in their metric measurement. In concave regions of a\nmolecule, often the front of the solvent ball can sweep out a larger volume than the center of the solvent ball.\nA void of size close to zero in solvent accessible surface model will correspond to a void of the size of a solvent\nball (4pir3s/3). It is therefore important to distinguish these two types of measurement when interpreting the\nresults of volume calculations of protein molecules. The intrinsic structures of these fundamental elementary\n3\nvoid\na cb\nFigure 6.2: Geometry of a simplified two dimensional model molecule, to illustrate the geometric constructs\nand the procedure mapping the Voronoi diagram to the Delaunay triangulation. (a) The molecule formed by\nthe union of atom disks of uniform size. Voronoi diagram is in dashed lines. (b) The shape enclosed by the\nboundary polygon is the convex hull. It is tessellated by the Delaunay triangulation. (c) The alpha shape of\nthe molecule is formed by removing those Delaunay edges and triangles whose corresponding Voronoi edges\nand Voronoi vertices do not intersect with the body of the molecule. A molecular void is represented in the\nalpha shape by two empty triangles.\npieces are closely related to several geometric constructs we describe below.\n6.2.3 Geometric constructs\nVoronoi diagram. Voronoi diagram (Fig 6.2a), also known as Voronoi tessellation, is a geometric construct\nthat has been used for analyzing protein packing in the early days of protein crystallography [6,18,19]. For\ntwo dimensional Voronoi diagram, we consider the following analogy. Imagine a vast forset containing a\nnumber of fire observation towers. Each fire ranger is responsible for putting out any fire closer to his/her\ntower than to any other tower. The set of all trees for which a ranger is responsible constitutes the Voronoi\ncell associated with his/hertower, and the map of rangerresponsibilities, with towersand boundariesmarked,\nconstitutes the Voronoi diagram.\nWe formalize this for three dimensional space. Consider the point set S of atom centers in three dimen-\nsional space R3. The Voronoi region or Voronoi cell Vi of an atom bi with atom center zi ? R3 is the set of\nall points that are at least as close to zi than to any other atom centers in S:\nVi = {x ?R3|||x?zi|| ? ||x?zj||,zj ? S}. (6.1)\nWe can have an alternative view of the Voronoi cell of an atom bi. Considering the distance relationship of\natom center zi with the atom center zk of another atom bk. The plane bisecting the line segment connecting\npoints zi and zk divides the full R3 space into two half spaces, where points in one half space is closer to\nzi than to zk, and points in the other allspice is closer to zk than to zi. If we repeat this process and take\nzk in turn from the set of all atom centers other than zi, we will have a number of halfspaces where points\nare closer to zi than to each of the atom center zk. The Voronoi region Vi is then the common intersections\nof these half spaces, which is convex. When we consider atoms of different radii, we replace the Euclidean\ndistance ||x?zi|| with the power distance defined as: pii(x) ? ||x?zi||2 ?r2i .\nDelaunay tetrahedrization. Delaunay triangulation in R2 or Delaunay tetrahedrization in R3 is a geo-\nmetric construct that is closely related to the Voronoi diagram (Fig 6.2b). In general, it uniquely tessellates\nor tile up the space of the convex hull of the atom centers in R3 with tetrahedra. Convex hull for a point\n4\nset is the smallest convex body that contains the point set 1. The Delaunay tetrahedrization of a molecule\ncan be obtained from the Voronoi diagram. Consider that the Delaunay tetrahedrization is formed by gluing\nfour types of primitive elements together: vertices, edges, triangles, and tetrahedra. Here vertices are just\nthe atom centers. We obtain a Delaunay edge by connecting atom centers zi and zj if and only if the\nVoronoi regions Vi and Vj have a common intersection, which is a planar piece that may be either bounded\nor extend to infinity. We obtain a Delaunay triangle connecting atom centers zi, zj, and zk if the common\nintersection of Voronoi regions Vi,Vj and Vk exists, which is either a line segment, or a half-line, or a line\nin the Voronoi diagram. We obtain a Delaunay tetrahedra connecting atom centers zi,zj,zk and zl if and\nonly if the Voronoi regions Vi,Vj,Vk and Vl intersect at a point.\n6.2.4 Topological structures\nDelaunay complex. The structures in both Voronoi diagram and Delaunay tetrahedrization are better\ndescribed with concepts from algebraic topology. We focus on the intersection relationship in the Voronoi\ndiagram and introduce concepts formalizing the primitive elements. In R3, between two to four Voronoi re-\ngions may have common intersections. We use simplices of various dimensions to record these intersection or\noverlap relationships. We have vertices ?0 as 0-simplices, edges ?1 as 1-simplices, triangles ?2 as 2-simplices,\nand tetrahedra ?3 as 3-simplices. Each of the Voronoi plane, Voronoi edge, and Voronoi vertices corresponds\nto a 1-simplex (Delaunay edge), 2-simplex (Delaunay triangle), and 3-simplex (Delaunay tetrahedron), re-\nspectively. If we use 0-simplices to represent the Voronoi cells, and add them to the simplices induced by\nthe intersection relationship, we can think of the Delaunay tetrahedrization as the structure obtained by\n?glueing? these simplices properly together. Formally, these simplices form a simplicial complex K:\nK = {?|I|?1|\nintersectiondisplay\ni?I\nVi negationslash= ?}, (6.2)\nwhere I is an index set for the vertices representing atoms whose Voronoi cells overlap, and |I|? 1 is the\ndimension of the simplex.\nAlpha shape and protein surfaces. Imagine we can turn a knob to increase or decrease the size of all\natoms simultaneously. We can then have a model of growing balls and obtain further information from the\nDelaunay complex about the shape of a protein structure. Formally, we use a parameter ? ? R to control\nthe size of the atom balls. For an atom ball bi of radius ri, we modified its radius ri at a particular ? value\nto ri(?) = (r2i +?)1/2. When ?ri < ? < 0, the size of an atom is shrunk. The atom could even disappear if\n? < 0 and |?| > ri. We start to collect the simplices at different ? value as we increase ? from ?? to +?\n(see Fig 6.3 for a two-dimensional example). At the beginning, we only have vertices. When ? is increased\nsuch that two atoms are close enough to intersect, we collect the corresponding Delaunay edge that connects\nthese two atom centers. When three atoms intersect, we collect the correspondingDelaunay triangle spanning\nthese three atom centers. When four atoms intersect, we collect the corresponding Delaunay tetrahedron.\nAt any specific ? value, we have a dual simplicial complex or alpha complex K? formed by the collected\nsimplices. If all atoms take the incremented radius of ri +rs and ? = 0, we have the dual simplicial complex\nK0 of the protein molecule. When ? is sufficiently large, we have collected all simplices and we get the full\nDelaunay complex. This series of simplicial complexes at different ? value form a family of shapes (Fig 6.3),\ncalled alpha shapes, each faithfully represents the geometric and topological property of the protein molecule\nat a particular resolution parametrized by the ? value.\nAn equivalent way to obtain the alpha shape at ? = 0 is to take a subset of the simplices, with the\nrequirement that the corresponding intersections of Voronoi cells must overlap with the body of the union\n1For a two dimensional toy molecule, we can imagine that we put nails at the locations of the atom centers, and tightly wrap\na rubber band around these nails. The rubber band will trace out a polygon. This polygon and the region enclosed within\nis the convex hull of the set of points corresponding to the atom centers. Similarly, imagine if we can tightly wrap a tin-foil\naround a set of points in three dimensional space, the resulting convex body formed by the tin-foil and space enclosed within\nis the convex hull of this set of points in R3.\n5\na b c\nd e f\nFigure 6.3: The family of alpha shapes or dual simplicial complexes for a two-dimensional toy molecule.\n(a) We collect simplices from the Delaunay triangulation as atoms grow by increasing the ? value. At the\nbeginning as ? grows from ??, atoms are in isolation and we only have vertices in the alpha shape. (b) and\n(c) When ? is increased such that some atom pairs start to intersect, we collect the corresponding Delaunay\nedges. (d) When three atoms intersect as ? increases, we collect the corresponding Delaunay triangles.\nWhen ? = 0, the collection of vertices, edges, and triangles form the dual simplicial complex K0, which\nreflecting the topological structure of the protein molecule. (e) More edges and triangles from the Delaunay\ntriangulation are now collected as atoms continue to grow. (d) Finally, all vertices, edges, and triangles are\nnow collected as atoms are grown to large enough size. We get back the full original Delaunay complex.\nof the balls. We obtain the dual complex or alpha shape K0 of the molecule at ? = 0 (Fig 6.2c):\nK0 = {?|I|?1|\nintersectiondisplay\ni?I\nVi ?\nuniondisplay\nB negationslash= ?}. (6.3)\nAlpha shape provides a guide map for computing geometric properties of the structures of biomolecules.\nTake the molecular surface as an example, the re-entrant surfaces are formed by the concave spherical patch\nand the toroidal surface. These can be mapped from the boundary triangles and boundary edges of the\nalpha shape, respectively [20]. Recall that a triangle in the Delaunay tetrahedrization corresponds to the\nintersection of three Voronoi regions, i.e., a Voronoi edge. For a triangle on the boundary of the alpha shape,\nthe corresponding Voronoi edge intersects with the body of the union of balls by definition. In this case,\nit intersects with the solvent accessible surface at the common intersecting vertex when the three atoms\noverlap. This vertex corresponds to a concave spherical surface patch in the molecular surface. For an\nedge on the boundary of the alpha shape, the corresponding Voronoi plane coincides with the intersecting\nplane when two atoms meet, which intersect with the surface of the union of balls on an arc. This line\nsegment corresponds to a toroidal surface patch. The remaining part of the surface are convex pieces, which\ncorrespond to the vertices, namely, the atoms on the boundary of the alpha shape.\nThe numbers of toroidal pieces and concave spherical pieces are exactly the numbers of boundary edges\nand boundary triangles in the alpha shape, respectively. Because of the restriction of bond length and the\nexcluded volume effects, the number of edges and triangles in molecules are roughly in the order of O(n)\n[21].\n6.2.5 Metric measurement\nWe have described the relationship between the simplices and the surface elements of the molecule. Based\non this type of relationship, we can compute efficiently size properties of the molecule. We take the problem\n6\nof volume computation as an example.\nConsider a grossly incorrect way to compute the volume of a protein molecule using the solvent accessible\nsurface model. We could define that the volume of the molecule is the summation of the volumes of individual\natoms, whose radii are inflated to account for solvent probe. By doing so we would have significantly inflated\nthe value of the true volume, because we neglected to consider volume overlaps. We can explicitly correct\nthis by following the inclusion-exclusion formula: when two atoms overlap, we subtract the overlap; when\nthree atoms overlap, we first subtract the pair overlaps, we then add back the triple overlap, etc. This\ncontinues when there are four, five, or more atoms intersecting. At the combinatorial level, the principle\nof inclusion-exclusion is related to the Gauss-Bonnet theorem used by Connolly [11]. The corrected volume\nV (B) for a set of atom balls B can then be written as:\nV (B) =\nsummationdisplay\nvol(intersectiontext T)>0\nT?B\n(?1)dim(T)?1 vol(\nintersectiondisplay\nT), (6.4)\nwhere vol(intersectiontextT) represents volume overlap of various degree, T ? B is a subset of the balls with non-zero\nvolume overlap: vol(intersectiontextT) > 0.\nHowever, the straightforward application of this inclusion-exclusion formula does not work. The degree\nof overlap can be very high: theoretical and simulation studies showed that the volume overlap can be up\nto 7-8 degrees [22,23]. It is difficult to keep track of these high degree of volume overlaps correctly during\ncomputation, and it is also difficult to compute the volume of these overlaps because there are many different\ncombinatorial situations, i.e., to quantify how large is the k-volume overlap of which one of the parenleftbig7kparenrightbig or parenleftbig8kparenrightbig\noverlapping atoms for all of k = 2,??? ,7 [23]. It turns out that for three-dimensional molecules, overlaps\nof five or more atoms at a time can always be reduced to a ?+? or a ??? signed combination of overlaps\nof four or fewer atom balls [9]. This requires that the 2-body, 3-body, and 4-body terms in Eqn 6.4 enter\nthe formula if and only if the corresponding edge ?ij connecting the two balls (1-simplex), triangles ?ijk\nspanning the three balls (2-simplex), and tetrahedron ?ijkl cornered on the four balls (3-simplex) all exist in\nthe dual simplicial complex K0 of the molecule [9,21]. Atoms corresponding to these simplices will all have\nvolume overlaps. In this case, we have the simplified exact expansion:\nV (B) =\nsummationdisplay\n?i?K\nvol(bi)?\nsummationdisplay\n?ij?K\nvol(bi ?bj)\n+\nsummationdisplay\n?ijk?K\nvol(bi ?bj ?bk)?\nsummationdisplay\n?ijkl?K\nvol(bi ?bj ?bk ?bl).\nThe same idea is applicable for the calculation of surface area of molecules.\nAn example. An example of area computation by alpha shape is shown in Fig 6.4. Let b1,b2,b3,b4 be the\nfour disks. To simplify the notation we write Ai for the area of bi, Aij for the area of bi ?bj, and Aijk for\nthe area of bi ?bj ?bk. The total area of the union, b1 ?b2 ?b3 ?b4, is\nAtotal = (A1 + A2 + A3 + A4)\n? (A12 + A23 + A24 + A34)\n+ A234.\nWe add the area of bi if the corresponding vertex belongs to the alpha complex (Fig 6.4), we subtract the\narea of bi ?bj if the corresponding edge belongs to the alpha complex, and we add the area of bi ?bj ?bk if\nthe corresponding triangle belongs to the alpha complex. Note without the guidance of the alpha complex,\nthe inclusion-exclusion formula may be written as:\nAtotal = (A1 + A2 + A3 + A4)\n? (A12 + A13 + A14 + A23 + A24 + A34)\n+ (A123 + A124 + A134 + A234)\n? A1234.\n7\nb1\nb2\nb3\nb4\nA\nb1\nb2\nb3\nb4\nB\nFigure 6.4: An example of analytical area calculation. (a) Area can be computed using the direct inclusion-\nexclusion. (b) The formula is simplified without any redundant terms when using alpha shape.\nThis contains 6 canceling redundant terms: A13 = A123, A14 = A124, and A134 = A1234. Computing these\nterms would be wasteful. Such redundancy does not occur when we use the alpha complex: the part of the\nVoronoi regions contained in the respective atom balls for the redundant terms do not intersect. Therefore,\nthe corresponding edges and triangles do not enter the alpha complex. In two dimensions, we have terms of at\nmost three disk intersections, corresponding to triangles in the alpha complex. Similarly, in three dimensions\nthe most complicated terms are intersections of four spherical balls, and they correspond to tetrahedra in\nthe alpha complex.\nVoids and pockets. Voids and pockets represent the concave regions of a protein surface. Because shape-\ncomplementarity is the basis of many molecular recognition processes, binding and other activities frequently\noccur in pocket or void regions of protein structures. For example, the majority of enzyme reactions take\nplace in surface pockets or interior voids.\nThe topological structure of the alpha shape also offers an effective method for computing voids and\npockets in proteins. Consider the Delaunay tetrahedra that are not included in the alpha shape. If we\nrepeatedly merge any two such tetrahedra on the condition that they share a 2-simplex triangle, we will\nend up with discrete sets of tetrahedra. Some of them will be completely isolated from the outside, and\nsome of them are connected to the outside by triangle(s) on the boundary of the alpha shape. The former\ncorresponds to voids (or cavities) in proteins, the latter corresponds to pockets and depressions in proteins.\nA pocket differs from a depression in that it must have an opening that is at least narrower than one\ninterior cross-section. Formally, the discrete flow [24] explains the distinction between a depression and a\npocket. In a two dimensional Delaunay triangulation, the empty triangles that are not part of the alpha\nshape can be classified into obtuse triangles and acute triangles. The largest angle of an obtuse triangle is\nmore than 90 degrees, and the largest angle of an acute triangle is less than 90 degrees. An empty obtuse\ntriangle can be regarded as a ?source? of empty space that ?flows? to its neighbor, and an empty acute\ntriangle a ?sink? that collects flow from its obtuse empty neighboring triangle(s). In Figure 6.5a, obtuse\ntriangles 1, 3, 4 and 5 flow to the acute triangle 2, which is a sink. Each of the discrete empty spaces on\nthe surface of protein can be organized by the flow systems of the corresponding empty triangles: Those\nthat flow together belong to the same discrete empty space. For a pocket, there is at least one sink among\nthe empty triangles. For a depression, all triangles are obtuse, and the discrete flow goes from one obtuse\ntriangle to another, from the innermost region to outside the convex hull. The discrete flow of a depression\ntherefore goes to infinity. Figure 6.5b gives an example of a depression formed by a set of obtuse triangles.\nOnce voids and pockets are identified, we can apply the inclusion-exclusion principle based on the sim-\nplices to compute the exact size measurement (e.g., volume and area) of each void and pocket [24,25].\nThe distinction between voids and pockets depends on the specific set of atomic radii and the solvent\n8\n1\n2 34\n5\n1\n345\nInfinity\n2\na b\nFigure 6.5: Discrete flow of empty space illustrated for two dimensional disks. (a) Discrete flow of a pocket.\nTriangles 1, 3, 4 and 5 are obtuse. The free volume flows to the ?sink? triangle 2, which is acute. (b) In a\ndepression, the flow is from obtuse triangles to the outside.\nradius. When a larger solvent ball is used, the radii of all atoms will be inflated by a larger amount. This\ncould lead to two different outcomes. A void or pocket may become completely filled and disappear. On the\nother hand, the inflated atoms may not fill the space of a pocket, but may close off the opening of the pocket.\nIn this case, a pocket becomes a void. A widely used practice in the past was to adjust the solvent ball\nand repeatedly compute voids, in the hope that some pockets will become voids and hence be identified by\nmethods designed for cavity/void computation. The pocket algorithm [24] and tools such as CastP [26,27]\noften makes this unnecessary.\n6.3 Computation and software\nComputing Delaunay tetrahedrization and Voronoi diagram. It is easier to discuss the computation\nof tetrahedrization first. The incremental algorithm developed in [28] can be used to compute the weighted\ntetrahedrization for a set of atoms of different radii. For simplicity, we sketch the outline of the algorithm\nbelow for two dimensional unweighted Delaunay triangulation.\nThe intuitive idea of the algorithm can be traced back to the original observation of Delaunay. For the\nDelaunay triangulation of a point set, the circumcircle of an edge and a third point forming a Delaunay\ntriangle must not contain a fourth point. Delaunay showed that if all edges in a particular triangulation\nsatisfy this condition, the triangulation is a Delaunay triangulation. It is easy to come up with an arbitrary\ntriangulation for a point set. A simple algorithm to covert this triangulation to the Delaunay triangulation is\ntherefore to go through each of the triangles, and make corrections using ?flips? discussed below if a specific\ntriangle contains an edge violating the above condition. The basic ingredients for computing Delaunay\ntetrahedrization are generalizations of these observations. We discuss the concept of locally Delaunay edge\nand the edge-flip primitive operation below.\nLocally Delaunay edge. We say an edge ab is locally Delaunay if either it is on the boundary of the convex\nhull of the point set, or if it belongs to two triangles abc and abd, and the circumcircle of abc does not contain\nd (e.g., edge cd in Fig 6.6a).\nEdge-flip. If ab is not locally Delaunay (edge ab in Fig 6.6a), then the union of the two triangles abc?abd\nis a convex quadrangle acbd, and edge cd is locally Delaunay. We can replace edge ab by edge cd. We call\nthis an edge-flip or 2-to-2 flip, as two old triangles are replaced by two new triangles.\nWe recursively check each boundary edge of the quadrangle abcd to see if it is also locally Delaunay after\nreplacing ab by cd. If not, we recursively edge-flip it.\nIncremental algorithm for Delaunay triangulation. Assume we have a finite set of points (namely, atom\ncenters) S = {z1,z2,??? ,zi,??? ,zn}. We start with a large auxiliary triangle that contains all these points.\nWe insert the points one by one. At all times, we maintain a Delaunay triangulation Di upto insertion of\n9\n1?to?3 flip\nb\n2?to?2 flip\na\nb\nc\nd\na\nb\nc\nd\na\nFigure 6.6: An illustration of locally Delaunay edge and flips. (a) For the quadrilateral abcd, edge ab is not\nlocally Delaunay, as the circumcircle passing through edge ab and a third point c contains a fourth point d.\nEdge cd is locally Delaunay, as b is outside the circumcircle adc. An edge-flip or 2-to-2 flip replaces edge ab\nby edge cd, and replace the original two triangles abc and adb with two new triangles acd and bcd. (b) When\na new vertex is inserted, we replace the old triangle containing this new vertex with three new triangles.\nThis is called 1-to3 flips.\npoint zi.\nAfter inserting point zi, we search for the triangle ?i?1 that contains this new point. We then add zi to\nthe triangulation and split the original triangle ?i?1 into three smaller triangles. This split is called 1-to-3\nflip, as it replaces one old triangle with three new triangles. We then check if each of the three edges in ?i?1\nstill satisfies the locally Delaunay requirement. If not, we perform a recursive edge-flip. This algorithm is\nsummarized in Algorithm 1.\nAlgorithm 1 Delaunay triangulation\nObtain random ordering of points {z1,??? ,zn};\nfor i = 1 to n do\nfind ?i?1 such zi ? ?i?1;\nadd zi, and split ?i?1 into three triangles (1-to-3 flip);\nwhile any edge ab not locally Delaunay do\nflip ab to other diagonal cd (2-to-2 edge flip);\nend while\nend for\nIn R3, the algorithm of tetrahedrization becomes more complex, but the same basic ideas apply. In this\ncase, we need to locate a tetrahedron instead of a triangle that contains the newly inserted point. The\nconcept of locally Delaunay is replaced by the concept of locally convex, and there are flips different than the\n2-to-2 flip in R3 [28]. Although an incremental approach, i.e., sequentially adding points, is not necessary\nfor Delaunay triangulation in R2, it is necessary in R3 to avoid non-flippable cases and to guarantee that\nthe algorithm will terminate. This incremental algorithm has excellent expected performance [28].\nThe computation of Voronoi diagram is conceptually easy once the Delaunay triangulation is available.\nWe can take advantage of the mathematical duality and compute all of the Voronoi vertices, edges, and\nplanar faces from the Delaunay tetrahedra, triangles, and edges. Because one point zi may be an vertex of\nmany Delaunay tetrahedra, the Voronoi region of zi therefore may contain many Voronoi vertices, edges,\nand planar faces. The efficient quad-edge data structure can be used for software implementation [29].\nVolume and area computation. Let V and A denote the volume and area of the molecule, respectively,\nK? for the alpha complex, ? for a simplex in K, i for a vertex, ij for an edge, ijk for a triangle, and ijkl for\na tetrahedron. The algorithm for volume and area computation can be written as Algorithm 2. Additional\ndetails of volume and area computation can be found in [20,21].\nSoftware. The software package Delcx for computing weighted Delaunay tetrahedrization, Mkalf for\ncomputing the alpha shape, Volbl for computing volume and area of both molecules and interior voids\n10\nAlgorithm 2 Volume and area measurement\nV := A := 0.0;\nfor all ? ? K do\nif ? is a vertex i then\nV := V +vol(bi); A := A+area(bi);\nend if\nif ? is an edge ij then\nV := V ?vol(bi ?bj); A := A?area(bi ?bj);\nend if\nif ? is a triangle ijk then\nV := V +vol(bi ?bj ?bk); A := A +area(bi ?bj ?bk);\nend if\nif ? is a tetrahedron ijkl then\nV := V ?vol(bi ?bj ?bk ?bl); A := A?area(bi ?bj ?bk ?bl);\nend if\nend for\nand be found at www.alphashape.org. The CastP webserver for pocket computation can be found at\ncast.engr.uic.edu. There are other studies that compute or use Voronoi diagrams of protein structures\n[30?32], although not all computes the weighted version which allows atoms to have different radii.\nIn this short description of algorithm, we have neglected many details important for geometric compu-\ntation. For example, the problem of how to handle geometric degeneracy, namely, when three points are\nco-linear, or when four points are co-planar. Interested readers should consult the excellent monograph by\nEdelsbrunner for a detailed treatise of these and other important topics in computational geometry [33].\n6.4 Applications: Packing analysis.\nAn important application of the Voronoi diagram and volume calculation is the measurement of protein\npacking. Tight packing is an important feature of protein structure [6,10], and is thought to play important\nroles in protein stability and folding dynamics [34]. The packing density of a protein is measured by the\nratio of its van der Waals volume and the volume of the space it occupies. One approach is to calculate the\npacking density of buried residues and atoms using Voronoi diagram [6,10]. This approach was also used to\nderive radii parameters of atoms [15].\nBased on the computation of voids and pockets in proteins, a detailed study surveying major represen-\ntatives of all known protein structural folds showed that there is a substantial amount of voids and pockets\nin proteins [35]. On average, every 15 residues introduces a void or a pocket (Fig 6.7a). For a perfectly\nsolid three-dimensional sphere of radius r, the relationship between volume V = 4pir3/3 and surface area\nA = 4pir2 is: V ? A3/2. In contrast, Figure 6.7b shows that the van der Waals volume scales linearly with\nthe van der Waals surface areas of proteins. The same linear relationship holds irrespective of whether we\nrelate molecular surface volume and molecular surface area, or solvent accessible volume and solvent acces-\nsible surface area. This and other scaling behavior point out that protein interior is not packed as tight as\nsolid [35]. Rather, packing defects in the form of voids and pockets are common in proteins.\nIf voids and pockets are prevalent in proteins, an interesting question is what is then the origin of the\nexistence of these voids and pockets. This question was studied by examining the scaling behavior of packing\ndensity and coordination number of residues through the computation of voids, pockets, and edge simplices\nin the alpha shapes of random compact chain polymers [36]. For this purpose, a 32-state discrete state\nmodel was used to generate a large ensemble of compact self-avoiding walks. This is a difficult task, as it is\nvery challenging to generate a large number of independent conformations of very compact chains that are\nself-avoiding. The results in [36] showed that it is easy for compact random chain polymers to have similar\nscaling behavior of packing density and coordination number with chain length. This suggests that proteins\n11\nNumber of Residues\nNum of Voids and Pockets\n0 200 600 1000\n0\n50\n100\n150\nA x 1000\nV x 1000\n0 200 400 600 800\n0\n100\n300\n500\nFigure 6.7: Voids and pockets for a set of 636 proteins representing most of the known protein folds, and\nthe scaling behavior of the geometric properties of proteins. (a) The number of voids and pockets detected\nwith a 1.4 ?A probe is linearly correlated with the number of residues in a protein. Only proteins with\nless than 1,000 residues are shown. Solid triangles and empty circles represent the pockets and the voids,\nrespectively. (b) The van der Waals (vdw) volume and van der Waals area of proteins scale linearly with\neach other. Similarly, molecular surface (ms) volume also scales linearly with molecular surface area using\na probe radius of 1.4?A. (Data not shown. Figure adapted after [35])\n12\nare not optimized by evolution to eliminate voids and pockets, and the existence of many pockets and voids is\nrandom in nature, and is due to the generic requirement of compact chain polymers. The frequent occurrence\nand the origin of voids and pockets in protein structures raise a challenging question: How can we distinguish\nvoids and pockets that perform biological functions such as binding from those formed by random chance?\nThis question is related to the general problem of protein function prediction.\n6.5 Applications: Protein function prediction from structures.\nConservation of protein structures often reveals very distant evolutionary relationship, which are otherwise\ndifficult to detect by sequence analysis [37]. Comparing protein structures can provide insightful ideas about\nthe biochemical functions of proteins (e.g., active sites, catalytic residues, and substrate interactions) [38?40].\nA fundamental challenge in inferring protein function from structure is that the functional surface of\na protein often involves only a small number of key residues. These interacting residues are dispersed in\ndiverse regions of the primary sequences and are difficult to detect if the only information available is the\nprimary sequence. Discovery of local spatial motifs from structures that are functionally relevant has been\nthe focus of many studies.\nGraph based methods for spatial patterns in proteins. To analyze local spatial patterns in proteins.\nArtymiuk et al developed an algorithm based on subgraph isomorphism detection [41]. By representing\nresidue side-chains as simplified pseudo-atoms, a molecular graph is constructed to represent the patterns of\nside-chain pseudo-atoms and their inter-atomic distances. A user defined query pattern can then be searched\nrapidly against the Protein Data Bank for similarity relationship. Another widely used approach is the\nmethod of geometric hashing. By examining spatial patterns of atoms, Fischer et al developed an algorithm\nthat can detect surface similarity of proteins [42,43]. This method has also been applied by Wallace et al for\nthe derivation and matching of spatial templates [44]. Russell developed a different algorithm that detects\nside-chain geometric patterns common to two protein structures [45]. With the evaluation of statistical\nsignificance of measured root mean square distance, several new examples of convergent evolution were\ndiscovered, where common patterns of side-chains were found to reside on different tertiary folds.\nThese methods have a number of limitations. Most require a user-defined template motif, restricting their\nutility for automated database-wide search. In addition, the size of the spatial pattern related to protein\nfunction is also often restricted.\nPredicting protein functions by matching pocket surfaces. Protein functional surfaces are frequently\nassociated with surface regions of prominent concavity [26,46]. These include pockets and voids, which can\nbe accurately computed as we have discussed. Computationally, one wishes to automatically identify voids\nand pockets on protein structures where interactions exist with other molecules such as substrate, ions,\nligands, or other proteins.\nBinkowski et al. developed a method for predicting protein function by matching a surface pocket or void\non a protein of unknown or undetermined function to the pocket or void of a protein of known function\n[47,48]. Initially, the Delaunay tetrahedrization and alpha shapes for almost all of the structures in the\nPDB databank are computed [27]. All surface pockets and interior voids for each of the protein structure\nare then exhaustively computed [24,25]. For each pocket and void, the residues forming the wall are then\nconcatenated to form a short sequence fragment of amino acid residues, while ignoring all intervening residues\nthat do not participate in the formation of the wall of the pocket or void. Two sequence fragments, one\nfrom the query protein and another from one of the proteins in the database, both derived from pocket or\nvoid surface residues, are then compared using dynamic programming. The similarity score for any observed\nmatch is assessed for statistical significance using an empirical randomization model constructed for short\nsequence patterns.\nFor promising matches of pocket/void surfaces showing significant sequence similarity, we can further\nevaluate their similarity in shape and in relative orientation. The former can be obtained by measuring\nthe coordinate root mean square distance (rmsd) between the two surfaces. The latter is measured by\n13\nfirst placing a unit sphere at the geometric center z0 ? R3 of a pocket/void. The location of each residue\nz = (x,y,z)T is then projected onto the unit sphere along the direction of the vector from the geometric\ncenter: u = (z ?z0)/||z ?z0||. The projected pocket is represented by a collection of unit vectors located\non the unit sphere, and the original orientation of residues in the pocket is preserved. The rmsd distance of\nthe two sets of unit vectors derived from the two pockets are then measured, which is called the ormsd for\norientation rmsd [47]. This allows similar pockets with only minor conformational changes to be detected\n[47].\nThe advantage of the method of Binkowski et al is that it does not assume prior knowledge of functional\nsite residues, and does not require a priori any similarity in either the full primary sequence or the backbone\nfold structures. It has no limitation in the size of the spatially derived motif and can successfully detect\npatterns small and large. This method has been successfully applied to detect similar functional surfaces\namong proteins of the same fold but low sequence identities, and among proteins of different fold [47,49].\nFunction prediction through models of protein surface evolution. To match local surfaces such as\npockets and voids and to assess their sequence similarity, an effective scoring matrix is critically important.\nIn the original study of Binkowski et al, Blosum matrix was used. However, this is problematic, as Blosum\nmatrices were derivedfrom analysisof precomputed large quantities of sequences, while the information of the\nparticular protein of interest has limited or no influence. In addition, these precomputed sequences include\nburied residues in protein core, whose conservation reflects the need to maintain protein stability rather\nthan to maintain protein function. In reference [50,51], a continuous time Markov process was developed\nto explicitly model the substitution rates of residues in binding pockets. Using a Bayesian Markov chain\nMonte Carlo method, the residue substitution rates at functional pocket are estimated. The substitution\nrates are found to be very different for residues in the binding site and residues on the remaining surface of\nproteins. In addition, substitution rates are also very different for residues in the buried core and residues\non the solvent exposed surfaces.\nThese rates are then used to generate a set of scoring matrices of different time intervals for residues\nlocated in the functional pocket. Application of protein-specific and region-specific scoring matrices in\nmatching protein surfaces result in significantly improved sensitivity and specificity in protein function\nprediction [50,51].\nIn a large scale study of predicting protein functions from structures, a subset of 100 enzyme families are\ncollected from the total of 286 enzyme families containing between 10?50 member protein structures with\nknown Enzyme Classification (E.C.) labels. By estimating the substitution rate matrix for residues on the\nactive site pocket of a query protein, a series of scoring matrices of different evolutionary time is derived. By\nsearching for similar pocket surfaces from a database of 770,466 pockets derived from the CastP database\n(with the criterion that each must contain at least 8 residues), this method can recover active site surfaces\non enzymes similar to that on the query structure at an accuracy of > 92%. Fig 6.8 shows the Receiver\nOperating Characteristic Curve of this study. An example of identifying human amylase using template\nsurfaces from B. subtilis and from barley is shown in Fig 6.9.\nThe method of surface matching based on evolutionary model is also especially effective in solving the\nchallenging problems of protein function prediction of orphan structures of unknown function (such as those\nobtained in structural genomics projects), which have only sequence homologs that are themselves hypothet-\nical proteins with unknown functions.\n6.6 Discussion\nA major challenge in studying protein geometry is to understand our intuitive notions of various geometric\naspects of molecular shapes, and to quantify these notions with mathematical models that are amenable to\nfast computation. The advent of the union of ball model of protein structures enabled rigorous definition\nof important geometric concepts such as solvent accessible surface and molecular surface. It also led to\nthe development of algorithms for area and volume calculations of proteins. Deep understanding of the\ntopological structure of molecular shapes is also based on the idealized union of ball model [9]. A success\n14\n0.0 0.2 0.4 0.6 0.8 1.0\n0.75\n0.80\n0.85\n0.90\nnewy\nTrue Positive Rate(sensitivity)\nFalse Positve Rate(1?specificity)\nFigure 6.8: A large scale study of protein function prediction from structures by matching similar func-\ntional surfaces for 100 protein families. A correct prediction is made if the matched surface comes from a\nprotein structure with the same Enzyme Classification (E.C.) number (upto the 4-th digit) as that of the\nquery protein. The x-axis of the Receiver Operating Characteristics curve reflects the false positive rate\n(1?specificity) at different statistical significance p-value by cRMSD measurement, and the y-axis reflects\nthe true positive rate (sensitivity).\nin approaching these problems is exemplified in the development of the pocket algorithm [24]. Another\nexample is the recent development of a rigorous definition of protein-protein binding or interaction interface\nand algorithm for its computation [52].\nPerhaps a more fundamental problem we face is to identify important structural and chemical features\nthat are the determinants of biological problems of interest. For example, we would like to know what are the\nshape features that has significant influences on protein solvation, protein stability, ligand specific binding,\nand protein conformational changes. It is not clear whether our current geometric intuitions are sufficient,\nor are the correct or the most relevant ones. There may still be important unknown shape properties of\nmolecules that elude us at the moment.\nAn important application of geometric computation of protein structures is to detect patterns important\nfor protein function. The shape of local surface regions on a protein structure and their chemical texture are\nthe basis of its binding interactions with other molecules. Proteins fold into specific native structure to form\nthese local regions for carrying out various biochemical functions. The geometric shape and chemical pattern\nof the local surface regions, and how they change dynamically are therefore of fundamental importance in\ncomputational studies of proteins.\nAnother important application is the development of geometric potential functions. Potential functions\nare important for generating conformations, for distinguishing native and near native conformations from\nother decoy conformations in protein structure predictions [53?56] and in protein-protein docking [57]. They\nare also important for peptide and protein design [57,58]. Chapter 4 describes in details the development of\ngeometric potential and applications in decoy discrimination and in protein-protein docking prediction.\nWe havenot described in detail the approachof studying protein geometryusing graphtheory. In addition\nto side-chain pattern analysis briefly discussed earlier, graph based protein geometric model also has lead to\na number of important insights, including the optimal design of model proteins formed by hydrophobic and\npolar residues [59], and methods for optimal design of side-chain packing [60,61]. Another important topic\nwe did not touch upon is the analysis of the topology of protein backbones. Based on concepts from knot\ntheory, R?gen and Bohr developed a family of global geometric measures for protein structure classification\n[62]. These measures originate from integral formulas of Vassiliev knot invariants. With these measures,\nR?gen and Fain further constructed a system that can automatically classify protein chains into folds [63].\n15\nFigure 6.9: Protein function prediction as illustrated by the example of alpha amylases. Two template\nbinding surfaces are used to search database of protein surfaces to identify protein structures that are of\nsimilar functions. (a) The phylogenetic tree for the template Pdb structure 1bag from B. subtilis. (b)\nThe template binding pocket of alpha amylase on 1bag. (c) A matched binding surface on a different\nprotein structure (1b2y from human, full sequence identity 22%) obtained by querying with 1bag. (d) The\nphylogenetic tree for the template structure 1bg9 from H. vulgare. (e) The template binding pocket on 1bg9.\n(f) A matched binding surface on a different protein structure (1u2y from human, full sequence identity\n23%) obtained by querying with 1bg9 (Adapted from [51]).\nThis system can reproduce the Cath classification system that requires explicit structural alignment as well\nas human curation.\nFurther development of descriptions of geometric shape and topological structure, as well as algorithms\nfor their computation will provide a solid foundation for studying many important biological problems. The\nother important tasks are then to show how these descriptors may be effectively used to deepen our biological\ninsights and to develop accurate predictive models of biological phenomena. For example, in computing\nprotein-protein interfaces, a challenging task is to discriminate surfaces that are involved in protein binding\nfrom other non-binding surface regions, and to understand in what fashion this depends on the properties\nof the binding partner protein.\nUndoubtedly, evolution plays central roles in shaping up the function and stability of protein molecules.\nThe method of analyzing residue substitution rates using a continuous time Markov models [50,51], and\nthe method of surface mapping of conservation entropy and phylogeny [64,65] only scratches the surface of\n16\nthis important issue. Much remains to be done in incorporating evolutionary information in protein shape\nanalysis for understanding biological functions.\n6.7 Summary\nThe accumulation of experimentally solved molecular structures of proteins provides a wealth of information\nfor studying many important biological problems. With the development of a rigorous model of the structure\nof protein molecules, various shape properties, including surfaces, voids, and pockets, and measurements of\ntheir metric properties can be computed. Geometric algorithms have found important applications in protein\npacking analysis, in developing potential functions, in docking, and in protein function prediction. It is\nlikely further development of geometric models and algorithms will find important applications in answering\nadditional biological questions.\n6.8 Further reading\nThe original work of Lee and Richards surface can be found in [5], where they also formulated the molecular\nsurface model [8]. Michael Connolly developed the first method for the computation of the molecular surface\n[11]. Tsai et al. described a method for obtaining atomic radii parameter [15]. The mathematical theory of\nthe union of balls and alpha shape was developed by Herbert Edelsbrunner and colleague [9,66]. Algorithm\nfor computing weighted Delaunay tetrahedrization can be found in [28], or in a concise monograph with\nin-depth discussion of geometric computing [33]. Details of area and volume calculations can be found in\n[20,21,25]. The theory of pocket computation and applications can be found in [24,26]. Richards and Lim\noffered a comprehensive review on protein packing and protein folding [12]. A detailed packing analysis of\nproteins can be found in [35]. The study on inferring protein function by matching surfaces is described in\n[47]. The study of the evolutionary model of protein binding pocket and its application in protein function\nprediction can be found in [51].\n6.9 Acknowledgments\nThis work is supported by grants from the National Science Foundation (CAREER DBI0133856), the Na-\ntional Institute of Health (GM68958), the Office of Naval Research (N000140310329), and the Whitaker\nFoundation (TF-04-0023). The author thanks Jeffrey Tseng for help in preparing this chapter.\n17\nBibliography\n[1] G. Rhodes. Crystallography Made Crystal Clear: A Guide for Users of Macromolecular Models. Aca-\ndemic Press, 1999.\n[2] G. M. Crippen and T. F. Havel. Distance Geometry and Molecular Conformation. J. Wiley & Sons,\n1988.\n[3] W. Rieping, M. Habeck, and M. Nilges. Inferential structure determination. Science, 309(5732):303?6,\n2005.\n[4] R.F.W. Bader. Atoms in Molecules: A Quantum Theory. The international series of mongraphs on\nchemistry, No. 22. Oxford University Press, 1994.\n[5] B. Lee and F. M. Richards. The interpretation of protein structures: estimation of static accessibility.\nJ. Mol. Biol., 55:379?400, 1971.\n[6] F. M. Richards. The interpretation of protein structures: total volume, group volume distributions and\npacking density. J. Mol. Biol., 82:1?14, 1974.\n[7] T. J. Richmond. Solvent accessible surface area and excluded volume in proteins: analytical equations\nfor overlapping spheres and implications for the hydrophobic effect. J. Mol. Biol., 178:63?89, 1984.\n[8] F. M. Richards. Calculation of molecular volumes and areas for structures of known geometries. Methods\nin Enzymology, 115:440?464, 1985.\n[9] H. Edelsbrunner. The union of balls and its dual shape. Discrete Comput. Geom., 13:415?440, 1995.\n[10] F. M. Richards. Areas, volumes, packing, and proteinstructures. Ann. Rev. Biophys. Bioeng., 6:151?176,\n1977.\n[11] M. L. Connolly. Analytical molecular surface calculation. J. Appl. Cryst., 16:548?558, 1983.\n[12] F. M. Richards and W. A. Lim. An analysis of packing in the protein folding problem. Q. Rev. Biophys.,\n26:423?498, 1994.\n[13] M. Gerstein and F. M Richards. Protein Geometry: Distances, Areas, and Volumes, volume F, chap-\nter 22. International Union of Crystallography, 1999.\n[14] F. M. Richards. The interpretation of protein structures: total volume, group volume distributions and\npacking density. J. Mol. Biol., 82:1?14, 1974.\n[15] J. Tsai, R. Taylor, C. Chothia, and M. Gerstein. The packing density in proteins: standard radii and\nvolumes. J Mol Biol, 290(1):253?66, 1999.\n[16] A. Bondi. VDW volumes and radii. J. Phys. Chem., 68:441?451, 1964.\n[17] J.M. Word, S.C. Lovell, J.S. Richardson, and D.C. Richardson. Asparagine and glutamine: using\nhydrogen atom contacts in the choice of side-chain amide orientation. J Mol Biol, 285(4):1735?47, 1999.\n18\n[18] J. L. Finney. Volume occupation, environment and accessibility in proteins. The problem of the protein\nsurface. J. Mol. Biol., 96:721?732, 1975.\n[19] B. J. Gellatly and J.L. Finney. Calculation of protein volumes: an alternative to the Voronoi procedure.\nJ. Mol. Biol., 161:305?322, 1982.\n[20] H. Edelsbrunner, M. Facello, P. Fu, and J. Liang. Measuring proteins and voids in proteins. In Proc.\n28th Ann. Hawaii Int?l Conf. System Sciences, volume 5, pages 256?264, Los Alamitos, California, 1995.\nIEEE Computer Scociety Press.\n[21] J. Liang, H. Edelsbrunner, P. Fu, P. V. Sudhakar, and S. Subramaniam. Analytical shape computing\nof macromolecules I: Molecular area and volume through alpha-shape. Proteins, 33:1?17, 1998.\n[22] K. W. Kratky. Intersecting disks (and spheres) and statistical mechanics. I. mathematical basis. J. Stat.\nPhys., 25:619?634, 1981.\n[23] M. Petitjean. On the analytical calculation of van der waals surfaces and volumes: some numerical\naspects. J. Comput. Chem., 15:507?523, 1994.\n[24] H. Edeslbrunner, M. Facello, and J. Liang. On the definition and the construction of pockets in macro-\nmolecules. Disc. Appl. Math., 88:18?29, 1998.\n[25] J. Liang, H. Edelsbrunner, P. Fu, P. V. Sudhakar, and S. Subramaniam. Analytical shape computing\nof macromolecules II: Identification and computation of inaccessible cavities inside proteins. Proteins,\n33:18?29, 1998.\n[26] J. Liang, H. Edelsbrunner, and C. Woodward. Anatomy of protein pockets and cavities: Measurement\nof binding site geometry and implications for ligand design. Protein Sci, 7:1884?1897, 1998.\n[27] T. A. Binkowski, S. Naghibzadeh, and J. Liang. CASTp: Computed atlas of surface topography of\nproteins. Nucleic Acids Res., 31:3352?3355, 2003.\n[28] H. Edelsbrunner and N.R. Shah. Incremental topological flipping works for regular triangulations.\nAlgorithmica, 15:223?241, 1996.\n[29] L. Guibas and J. Stolfi. Primitives for the manipulation of general subdivisions and the computation of\nVoronoi diagrams. ACM Transactions on Graphiques, 4:74?123, 1985.\n[30] S. Chakravarty, A. Bhinge, and R. Varadarajan. A procedure for detection and quantitation of cavity\nvolumes proteins. application to measure the strength of the hydrophobic driving force in protein folding.\nJ Biol Chem, 277(35):31345?53, 2002.\n[31] A. Goede, R. Preissner, and C. Frommel. Voronoi cell: New method for allocation of space among\natoms: Elimination of avoidable errors in calculation of atomic volume and density. J. Comput. Chem.,\n18:1113?1123, 1997.\n[32] Y. Harpaz, M. Gerstein, and C. Chothia. Volume changes on protein folding. Structure, 2(7):641?9,\n1994.\n[33] H. Edelsbrunner. Geometry and Topology for Mesh Generation. Cambridge University Press, 2001.\n[34] M. Levitt, M. Gerstein, E. Huang, S. Subbiah, and J. Tsai. Protein folding: the endgame. Annu Rev\nBiochem, 66:549?579, 1997.\n[35] J. Liang and K. A. Dill. Are proteins well-packed? Biophys. J., 81:751?766, 2001.\n[36] J. Zhang, R. Chen, C. Tang, and J. Liang. Origin of scaling behavior of protein packing density: A\nsequential monte carlo study of compact long chain polymers. J. Chem. Phys., 118:6102?6109, 2003.\n19\n[37] A. E. Todd, C. A. Orengo, and J. M. Thornton. Evolution of function in protein superfamilies, from a\nstructural perspective. J. Mol. Biol., 307:1113?1143, 2001.\n[38] L. Holm and C. Sander. New structure: Novel fold? Structure, 5:165?171, 1997.\n[39] A. C. R. Martin, C. A. Orengo, E. G. Hutchinson, A. D. Michie, A. C. Wallace, M. L. Jones, and J. M.\nThornton. Protein folds and functions. Structure, 6:875?884, 1998.\n[40] C. A. Orengo, A. E. Todd, and J. M. Thornton. From protein structure to function. Curr. Opinion\nStructural Biology, 9(4):374?382, 1999.\n[41] P. J. Artymiuk, A. R. Poirrette, H. M. Grindley, D.W. Rice, and P. Willett. A graph-theoretic approach\nto the identification of three-dimensional patterns of amino acid side-chains in protein structure. J. Mol.\nBiol., 243:327?344, 1994.\n[42] D. Fischer, R. Norel, H. Wolfson, and R. Nussinov. Surface motifs by a computer vision technique:\nsearches, detection, and implications for protein- ligand recognition. Proteins: Structure, Function and\nGenetics, 16:278?292, 1993.\n[43] R. Norel, D. Fischer, H. J. Wolfson, and R. Nussinov. Molecualr surface recognition by computer\nvision-based technique. Protein Eng., 1994.\n[44] A. C. Wallace, N. Borkakoti, and J. M. Thornton. TESS: a geometric hashing algorithm for deriving\n3d coordinate templates for searching structural databases. Application to enzyme active sites. Protein\nSci., 6:2308?2323, 1997.\n[45] R. Russell. Detection of protein three-dimensional side-chain patterns: New examples of convergent\nevolution. J. Mol. Biol., 279:1211?1227, 1998.\n[46] R. A. Laskowski, N. M. Luscombe, M. B. Swindells, and J. M. Thornton. Protein clefts in molecular\nrecognition and function. Protein Sci., 5:2438?2452, 1996.\n[47] T. A. Binkowski, L. Adamian, and J. Liang. Inferring functional relationship of proteins from local\nsequence and spatial surface patterns. J. Mol. Biol., 332:505?526, 2003.\n[48] T.A. Binkowski, A. Joachimiak, and J. Liang. Protein surface analysis for function annotation in\nhigh-throughput structural genomics pipeline. Protein Sci, 14(12):2972?81, 2005.\n[49] T.A. Binkowski, P. Freeman, and J. Liang. pvSOAR: Detecting similar surface patterns of pocket and\nvoid surfaces of amino acid residues on proteins. Nucleic Acid Research, 32:W555?W558, 2004.\n[50] Y.Y. Tseng and J. Liang. Estimating evolutionary rate of local protein binding surfaces: a bayesian\nmonte carlo approach. Proceedings of 2005 IEEE-EMBC Conference, 2005.\n[51] Y.Y. Tseng and J. Liang. Estimation of amino acid residue substitution rates at local spatial regions\nand application in protein function inference: A Bayesian Monte Carlo approach. Mol. Biol. Evol.,\n23:421?436, 2006.\n[52] Y. Ban, H. Edelsbrunner, and J. Rudolph. Interface surfaces for protein-protein complexes. In RE-\nCOMB, pages 205?212, 2004.\n[53] R. K.Singh, A. Tropsha, and I. I. Vaisman. Delaunaytessellationof proteins: fourbody nearest-neighbor\npropensities of amino-acid residues. J. Comp. Bio., 3:213?221, 1996.\n[54] W. Zheng, S. J. Cho, I. I. Vaisman, and A. Tropsha. A new approach to protein fold recognition based\non Delaunay tessellation of protein structure. In R.B. Altman, A.K. Dunker, L. Hunter, and T.E. Klein,\neditors, Pacific Symposium on Biocomputing?97, pages 486?497, Singapore, 1997. World Scientific.\n20\n[55] X. Li, C. Hu, and J. Liang. Simplicial edge representation of protein structures and alpha contact\npotential with confidence measure. Proteins, 53:792?805, 2003.\n[56] X. Li and J. Liang. Geometric cooperativity and anticooperativity of three-body interactions in native\nproteins. Proteins, 60(1):46?65, 2005.\n[57] X. Li and J. Liang. Computational design of combinatorial peptide library for modulating protein-\nprotein interactions. Pac Symp Biocomput, pages 28?39, 2005.\n[58] C. Hu, X. Li, and J. Liang. Developing optimal nonlinear scoring function for protein design. Bioinfor-\nmatics, 20:3080?3098, 2004.\n[59] J. Kleinberg. Efficient algorithms for protein sequence design and the analysis of certain evolutionary\nfitness landscapes. In RECOMB, pages 205?212, 2004.\n[60] J. Xu. Rapid protein side-chain packing via tree decomposition. In RECOMB, pages 423?439, 2005.\n[61] A. Leaver-Fay, B. Kuhlman, and J. Snoeyink. An adaptive dynamic programming algorithm for the\nside chain placement problem. In Pacific Symposium on Biocomputing, pages 17?28, 2005.\n[62] P. R?gen and H. Bohr. A new family of global protein shape descriptors. Math Biosci, 182(2):167?81,\n2003.\n[63] P. R?gen and B. Fain. Automatic classification of protein structure by using gauss in tegrals. Proc Natl\nAcad Sci U S A, 100(1):119?24, 2003.\n[64] O. Lichtarge, H.R. Bourne, and F.E. Cohen. An evolutionary trace method defines binding surfaces\ncommon to protein families. J Mol Biol, 257(2):342?58, 1996.\n[65] F. Glaser, T. Pupko, I. Paz, R.E. Bell, D. Shental, E. Martz, and N. Ben-Tal. Consurf: identifica-\ntion of functional regions in proteins by surface-mapping of phylogenetic information. Bioinformatics,\n19(1):163?4, 2003.\n[66] H. Edelsbrunner and E.P. M?ucke. Three-dimensional alpha shapes. ACM Trans. Graphics, 13:43?72,\n1994.\n21\n"}
{"id":"oai:arXiv.org:q-bio/0601020","text":"arXiv:quant-ph/0610192v1  23 Oct 2006\nICMPA-MPA/2006/20\nCP3-06-13\n(p,q)-Deformations and (p,q)-Vector Coherent States\nof the Jaynes-Cummings Model\nin the Rotating Wave Approximation\nJoseph Ben Geloun?, Jan Govaerts?,?,1 and M. Norbert Hounkonnou?\n?International Chair in Mathematical Physics and Applications (ICMPA-UNESCO)\n072 B.P. 50 Cotonou, Republic of Benin\nE-mail: jobengeloun@yahoo.fr, norbert?hounkonnou@cipma.net\n?Department of Theoretical Physics, School of Physics\nThe University of New South Wales, Sydney NSW 2052, Australia\nE-mail: Jan.Govaerts@fynu.ucl.ac.be\nFebruary 1, 2008\nAbstract\nClasses of (p,q)-deformations of the Jaynes-Cummings model in the rotating wave ap-\nproximation are considered. Diagonalization of the Hamiltonian is performed exactly, leading\nto useful spectral decompositions of a series of relevant operators. The latter include ladder\noperators acting between adjacent energy eigenstates within two separate infinite discrete\ntowers, except for a singleton state. These ladder operators allow for the construction of\n(p,q)-deformed vector coherent states. Using (p,q)-arithmetics, explicit and exact solutions\nto the associated moment problem are displayed, providing new classes of coherent states\nfor such models. Finally, in the limit of decoupled spin sectors, our analysis translates into\n(p,q)-deformations of the supersymmetric harmonic oscillator, such that the two supersym-\nmetric sectors get intertwined through the action of the ladder operators as well as in the\nassociated coherent states.\n1On sabbatical leave from the Center for Particle Physics and Phenomenology (CP3), Institute of Nuclear\nPhysics, Catholic University of Louvain, 2, Chemin du Cyclotron, B-1348 Louvain-la-Neuve, Belgium.\n1 Introduction\nIn recent years, quantum algebras and groups [1] which appear as a generalization of the sym-\nmetry concept [2] and the basics of so-called noncommutative theories, have been the subject of\nintensive research interest in both mathematics and physics. The q- and more generally (p,q)-\ndeformation of a pre-defined algebraic structure [3, 4, 5] proves to be a powerful tool widely used\nin the representation theory of quantum groups. The field of ?q-mathematics? has a long history\n[6, 7] dating back to over 150 years, and includes several famous names such as Cauchy, Jacobi\nand Heine to mention just a few. Its possible relation to physics has been considerably reinforced\nduring the last thirty years [3, 8]. In particular, great attention has been devoted to deformations\nof the bosonic Fock-Heisenberg algebra. The most commonly studied deformed bosons, with\nannihilation and creation operators a and a?, respectively, satisfy the q-commutation relation\n[3] (also called quommutation)\naa??qa?a = I, (1)\nor some variant forms of such a relation [4, 9]. Still more general deformations, which include in\nspecific limits the above standard q-deformed case and which also provides consistent extensions\nof the harmonic oscillator algebra, proceed from the two parameter deformation of the Fock\nalgebra introduced by Chakrabarty and Jagannathan [5], namely the so-called (p,q)-oscillator\nquantum algebras generated by three operators a, a? and N which obey [5, 10]\n[N,a] =?a, [N,a?] = a?, aa??qa?a = p?N, aa??p?1a?a = qN. (2)\nHere, p and q are free parameters, which henceforth are chosen to be both real and such that\np > 1, 0 < q < 1 and pq < 1. Clearly, one recovers the ordinary Fock algebra of the harmonic\noscillator algebra in the double limit p,q?1, with then [a,a?] = I and N = a?a. Furthermore,\nthese q- and (p,q)-deformed algebras have found a number of relevant applications and provide\nalgebraic interpretations of various q- and (p,q)-special functions [9, 10, 11].\nThe harmonic oscillator algebra is central in the construction of a number of models in\nphysics, among which the Jaynes?Cummings model (JCm) plays a significant role. Indeed ever\nsince Jaynes and Cummings? historical work [12], the JCm has been at the basis of many in-\nvestigations. This system belongs to a class of physically relevant models widely used in atomic\nphysics and quantum optics. As far as we know, a great deal of analytically solvable models of\nthis type have been studied in the rotating wave approximation (r.w.a.) within the framework\nof non-deformed commutative theories (see [12]?[17] and references therein). TheJCm has also\nbeen considered in the context of generalized intensity dependent oscillator algebras including\nnonlinear dynamical supersymmetry[18] or using shapeinvariance techniques [19, 20]. Compara-\ntively, much fewer papers have dealt with generalizations of these models including deformations.\nAmong the latter and mainly based on the generalized intensity-dependent coupling of Buck and\nSukumar [21], one may mention, on the one hand, the work by Chaichan et al. [22], and on the\nother hand, that by Chang [23], both dealing with a generalized q-deformed intensity-dependent\ninteraction Hamiltonian of theJCm given by the Holstein-Primakoff suq(1,1) or suq(2) quantum\nalgebra realizations of the Hamiltonian field operators and the related Peremolov, Glauber or\nBarut-Girardello group theoretical construction of coherent states. In the same vein, the paper\nby Naderi et al. considers the dynamical properties of a two-level atom in three variants of the\ntwo-photon q-deformedJCm [24]. In this latter work, the authors focused their attention onto\nthe time evolution of atomic properties including population inversion and quantum fluctuations\nof the atomic dipole variables. However, it is not clear to us how the main issues related to the\nmoment problem as well as the mathematical foundation of the coherent and squeezed states\nwhich they use and on which a great part of their analysis rests in a crucial way, are solved.\n1\nIn a recent publication [14], Hussin and Nieto have performed an interesting systematic\nsearch of different types of ladder operators for theJCm model in the r.w.a. and constructed\nassociated coherent states. In the present work, and in line with that investigation, we provide\na generalization of that analysis to (p,q)-deformations of the same model.\nThe outline of the paper is the following. In Section 2, we briefly recall the main results\nrelevant to theJCm in the r.w.a. in the non-deformed situation [14]. Section 3 then introduces\n(p,q)-deformations of the same model. By providing an explicit diagonalization of the (p,q)-\ndeformed Hamiltonian, the spectrum and its eigenstates are exactly identified. As in the non-\ndeformed case [14], except for a singleton state, all other energy eigenstates are organized into\ntwo separate discrete towers, for which ladder operators transforming states into one another\nwithin each tower separately may be introduced. Using properties of these ladder operators, in\nSection 4 we introduce general classes of (p,q)-deformed vector coherent states. The freedom\nafforded in their construction is fixed from two alternative points of view, discussed in Section 5,\nwhich in the ordinary case of the non-deformed Fock algebra coincide. However at all stages of\nour discussion, the double limit p,q?1 reproduces the corresponding results of [14]. Section 5\nalso briefly considers the situation in the uncoupled limit of theJCm, while Section 6 presents\nsome concluding remarks. An Appendix collects useful facts in connection with properties of\n(p,q)-deformed algebras and related functions.\n2 The Ordinary JCm in the Rotating Wave Approximation\nThe JCm describes the interaction between one mode of the quantized electromagnetic field\nand a two-level model of an atomic system [12, 14]?[16]. It has proved to be a theoretical\nlaboratory of great relevance to many topics in atomic physics and quantum optics, as well\nas in the study of ion traps, cavity QED theory and quantum information processing [13, 14].\nFurthermore, the spin-orbit interaction term which appears in the JCm is essentially the so-\ncalled Dresselhaus spin-orbit term [25]. The model is thus also widely used in condensed matter\nphysics for its relevance in spintronics [26] which exploits the electron spin rather than its charge\nto develop a new generation of electronic devices [27, 28]. The solution of the completeJCm is\nnot yet known in a closed form [14]. However, in the r.w.a., although the Hamiltonian remains\nnonlinear, the model becomes exactly solvable in closed form with explicit expressions for its\neigenenergy states. In this Section, we briefly recall, in a streamlined presentation, the main\nresults in the non-deformed case (see [14, 15] and references therein) of relevance to our analysis\nof (p,q)-deformations hereafter.\nIn the r.w.a., the reduced dimensionlessJCm Hamiltonian reads [15]\nHred = 1planckover2pi1?\n0\nH= (1+?)\nparenleftbigg\na?a+ 12\nparenrightbigg\n+ 12?3 +?\nparenleftBig\na??? +a?+\nparenrightBig\n, (3)\nwhere a and a? are the usual photon annihilation and creation operators, respectively, obeying\nthe ordinary Fock algebra, and (?1,?2,?3) are the Pauli matrices with ?? = ?1?i?2. The r.w.a.\nis related to the detuning parameter ? which is such that|?|?1, with ?0 being the fixed atomic\nfrequency and ? = ?0(1 + ?) the actual field mode frequency. The r.w.a. is reliable provided\n|???0|??,?0. Finally, ? is the reduced spin-orbit coupling modelling the interaction strength\nbetween the radiation field and the atom.\n2\nThe Hilbert spaceV of the system is the tensor product of the Fock space representation\nof the Fock algebra (a,a?) and the 2-dimensional representation of the SU(2) algebra associated\nto the Pauli matrices. A basis of the former is provided by the number operator, N = a?a,\northonormalized eigenstates |n? = (1/?n!)(a?)n|0? (n = 0,1,2,???), with a|n? = ?n|n?1?,\na?|n?=?n+ 1|n + 1?and N|n?= n|n?, while a basis of the latter spin sector is the orthonor-\nmalized set {|+?,|??} such that ?3|??=?|??. The tensor product space is thus spanned by\nthe states|n,??=|n??|??.\nThe diagonalization of the Hamiltonian (3) is readily achieved. The orthonormalized\nenergy eigenspectrum consists of a ?singleton? state|E??,\nHred|E??= E?|E??, (4)\nwith\nE? = 12?, |E??=|0,??, (5)\nand two infinite discrete towers of states |E?n? such that Hred|E?n? = E?n|E?n? for all n =\n0,1,2,???, expressed as [14]\n|E+n? = sin?(n)|n,+?+ cos?(n)|n+ 1,??, (6)\n|E?n? = cos?(n)|n,+??sin?(n)|n+ 1,??, (7)\nwhere, given Q(n+ 1) =radicalbig?2/4 +?2(n+ 1), the mixing angle ?(n) is such that\nsin?(n) = sign(?)\nradicalBigg\nQ(n+ 1)??/2\n2Q(n + 1) , cos?(n) =\nradicalBigg\nQ(n+ 1) +?/2\n2Q(n+ 1) , (8)\nwhile the energy eigenvalues are\nE?n = (1 +?)(n+ 1)?Q(n+ 1). (9)\nConsequently, one has the spectral decomposition of the reduced Hamiltonian (3),\nHred =|E??E??E?| +\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|. (10)\nIt proves useful to introduce the following notations. Let V0 be the (complex) one-\ndimensional subspace of the Hilbert space V spanned by the state |0,?? = |E??, and V be\nits complement in the Hilbert spaceV, spanned by{|E?n?,n?N}. We thus haveV=V0?V.\nFurthermore let us introduce [14] operatorsU andU? defined through their action on the\nabove two sets of basis vectors, for all n?N,\nU|n,??=|E?n?; U?|E??= 0, U?|E?n?=|n,??, (11)\nnamely\nU =\n?summationdisplay\nn=0,?\n|E?n??n,?|, U? =\n?summationdisplay\nn=0,?\n|n,???E?n|. (12)\nClearly we have\nUV =V; U?V =V, U?V=V. (13)\n3\nNote that even though neither U nor U? is unitary on the full Hilbert space V, they are the\nadjoint of one another, hence the notation.\nIt is of interest to apply these operators onto the quantum Hamiltonian (3). One obtains\nHred =U?HredU =\n?summationdisplay\nn=0,?\n|n,??E?n ?n,?|, (14)\nand conversely,\nUHredU? =\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|=Hred ?|E??E??E?|. (15)\nThe energy eigenstates spanning V may be organized into two subspaces referred to as\n?towers?, namely {|E+n?,n?N} and {|E?n?,n?N}. The states in the tower {|E+n?,n?N}\nare associated to strictly increasing eigenvalues so that they constitute a nondegenerate set\nof eigenstates. The second group does not necessarily possess the same feature depending\non the values for the parameters ? and ?. It is possible [16] to identify a range of values\nfor these parameters such that {|E?n?,n?N} only contains nondegenerate states of strictly\nincreasing eigenvalues with n. Some of the considerations discussed hereafter may require a\nnondegenerate spectrum, which may always be achieved by properly ?detuning? the parameters\n? and ? away from a degenerate case, but not necessarily a strictly increasing spectrum in the\nlabel n?N. Whatever the case may be though, bounded from below spectra such that E?n > E?0\nfor n = 1,2,???are always assumed implicitly.\nIt is possible to consider ladder operators acting between successive energy eigenstates\nwithin each of the above two towers, irrespective of whether the spectral values are strictly\nincreasing or not1. Namely, let us first consider operators M? and M+ given as\nM? =\n?summationdisplay\nn=0,?\n|n?1,??K?(n)?n,?|; M+ =\n?summationdisplay\nn=0,?\n|n+ 1,??K??(n+ 1)?n,?|, (16)\nwhere K?(n) are, at this stage, arbitrary complex coefficients such that K?(0) = 0. Then,\nintroduce the ladder operators\nM? =UM?U? =\n?summationdisplay\nn=0,?\n|E?n?1?K?(n)?E?n|; M+ =UM+U? =\n?summationdisplay\nn=0,?\n|E?n+1?K??(n+ 1)?E?n|,\n(17)\nwhich are thus such that, for all n = 0,1,2,???,\nM?|E??= 0, M?|E?n?= K?(n)|E?n?1?; M+|E??= 0, M+|E?n?= K??(n+ 1)|E?n+1?.\n(18)\nNote thatM? andM+ are adjoint of one another but in effect only act on the subspaceV.\nGeneral vector coherent states (VCS) may then be introduced [29]?[32] on the space V\nas eigenstates of the lowering operator M? with as eigenvalue an arbitrary complex number\nz?C. Furthermore, these VCS are also parametrized by two real quantities ?? which account\nfor their stability under time evolution generated by the operator expbraceleftbig?i?0tHredbracerightbig, as well as\nthe two spherical coordinates (?,?)?[0,?]?[0,2?[ parametrizing a unit vector in the 2-sphere\n1We differ on this point with [14], where strictly increasing energy spectra in each tower are required.\n4\nS2 (hence the name of ?vector? coherent states). Explicitly, one has [14]\n|z;??;?,?? = N+(|z|)cos?\n?summationdisplay\nn=0\nzn\nK+(n)!e\n?i?0?+E+n |E+\nn?\n+ N?(|z|)ei? sin?\n?summationdisplay\nn=0\nzn\nK?(n)!e\n?i?0??E?n |E?\nn?, (19)\nwhere K?(n)! =producttextnk=1 K?(k) (with, by convention, K?(0)! = 1), while the normalization factors\nare defined as\nN?(|z|) =\nbracketleftBigg ?summationdisplay\nn=0\n|z|2n\n|K?(n)!|2\nbracketrightBigg?1/2\n(20)\nin order that the VCS be of unit norm. The smallest value, R, of the two convergence radii of\nthese two series in |z| also defines the disk DR in z ?C for which these VCS are well defined.\nThese states are clearly such that\nM?|z;??;?,??= z|z;??;?,??, e?i?0tHred|z;??;?,??=|z;t +??;?,??. (21)\nFurther restrictions are necessary to finally specify in a unique fashion the factors K?(n),\nand then solve the moment problem implied by the requirement of overcompleteness overV for\nthe VCS (19) given a choice of a SU(2) matrix-valued integration measure over C?S2 [30]-[32].\nDifferent choices are available [14], each leading to a different set of VCS. Furthermore, taking\nthe limit case ??0 or the zero-detuning limit (resonance case) ??0, different models arise\nwith their associated VCS.\nFor the sake of illustration, let us consider one such choice explicitly [14]. The factors\nK?(n) may be restricted for example by requiring that the ladder operatorsM? andM+ obey\nthe usual Fock algebra of annihilation and creation operators on the spaceV,\nbracketleftbigM?,M+bracketrightbig=M?M+ ?M+M? = I\nV =\n?summationdisplay\nn=0,?\n|E?n??E?n|. (22)\nFrom the expressions in (18) and the initial conditions K?(0) = 0, it follows that the quantities\nK?(n) are now determined up to arbitrary phase factors ??(n) as\nK?(n) = ei??(n)?n, n = 0,1,2,???. (23)\nConsequently, one has N?(|z|) = e?|z|2/2, which is well-defined for all z?C. Hence so are then\nall the VCS|z;??;?,??.\n3 The (p,q)-Deformed JCm in the Rotating Wave Approxima-\ntion\nLet us now introduce a (p,q)-deformation of the JCm Hamiltonian (3), namely (p,q)-JCm\nmodels. The eigenstates and spectrum are first identified, before considering the construction\nof ladder operators following the same rationale as in Section 2. A study of the associated VCS\nand examples of exactly solvable reduced models is differed to Section 4.\n5\n3.1 Energy spectrum and eigenstates\nGiven the (p,q)-deformation (2) of the ordinary Fock algebra (see the Appendix for further\ndetails and identities pertaining to such deformations), we now consider (p,q)-deformations of\nthe Hamiltonian (3) of the form2\nHred = (1 +?)\nbraceleftbigg\nh(p,q)[N] + 12\nbracerightbigg\n+ 12?3 +?\nparenleftBig\na??? +a?+\nparenrightBig\n, (24)\nwhere [N] = (p?N ?qN)/(p?1?q), and h(p,q) is some arbitrary positive function of the real\nparameters p > 1 and 0 < q < 1 (with pq < 1) such that limp,q?1 h(p,q) = 1 in order to recover\n(3) in the non-deformed case.\nThe Hilbert space V of quantum states of the model is again the tensor product of the\n(p,q)-deformed Fock space spanned by the states3 |n?(n?N) such as a|n?= radicalbig[n]|n?1?and\na?|n?=radicalbig[n+ 1]|n+1?(see the Appendix), with the 2-dimensional representation of the SU(2)\nalgebra associated to the Pauli matrices ?i (i = 1,2,3). Hence the diagonalization of (24) is\nreadily achieved in the same way as in the non-deformed case, on the basis|n,??=|n??|??of\nV.\nFor any n?N, let us introduce the following quantities,\nE([n+1]) = (1+?)h(p,q)\nparenleftBig\n[n+1]?[n]\nparenrightBig\n?1, Q([n+1]) =\nradicalbigg\n1\n4E\n2([n +1]) + ?2 [n+1], (25)\nas well as the mixing angles ?([n]) defined by\nsin?([n]) = sign(?)\nradicalBigg\nQ([n+ 1])?E([n + 1])/2\n2Q([n + 1]) , cos?([n]) =\nradicalBigg\nQ([n + 1]) +E([n+ 1])/2\n2Q([n +1]) .\n(26)\nThe energy eigenspectrum of (24) is then obtained as follows. First, there exists a singleton\nstate|E??=|0,??such that\nHred|E??= E?|E??, E? = 12?, (27)\nwith an eigenvalue which is thus independent of the deformation parameters p and q. Next, one\nalso finds two infinite discrete towers of states for all n?N such that\n|E+n? = sin?([n])|n,+? + cos?([n])|n + 1,??, (28)\n|E?n? = cos?([n])|n,+?? sin?([n])|n + 1,??, (29)\nwith\nHred|E?n?= E?n |E?n?, E?n = 12 (1 +?)\nbraceleftBig\nh(p,q)\nparenleftBig\n[n+ 1] + [n]\nparenrightBig\n+1\nbracerightBig\n? Q([n+ 1]). (30)\nNote that the energy spectrum of these states is deformed by the parameters p and q as compared\nto the ordinary case. In particular, the Zeeman spin splitting ?En = E+n ?E?n = 2Q([n + 1]),\n2Make no mistake that henceforth, all quantities correspond to the (p,q)-deformed analysis even though the\nnotations used coincide with those of Section 2 and do not make explicit the fact that all expressions correspond\nnow to the deformed case. When wanting to make the difference explicit, notations such as for instance [N] ?\n[N](p,q) = (p?N ?qN)/(p?1 ?q) and [n] ? [n](p,q) = (p?n ?qn)/(p?1 ?q) are used.\n3Once again, the states |n? = |n?(p,q) are not to be confused with the number operator eigenstates of the\nordinary Fock algebra as in Section 2, in spite of an identical notation.\n6\nproportional to the Rabi frequency, is function of the values for p and q. In terms of these\nresults, the reduced Hamiltonian (24) possesses the spectral resolution\nHred =|E??E??E?| +\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|. (31)\nLet us again introduce the following notations and operators. LetV0 denote the subspace\nof the Hilbert space V spanned by the singleton state |E??= |0,??, and V its complement in\nV, namely the subspace spanned by{|E?n?,n?N}, with of courseV=V0?V. Acting on these\nspaces, let us consider the operators\nU =\n?summationdisplay\nn=0,?\n|E?n??n,?|; U? =\n?summationdisplay\nn=0,?\n|n,???E?n|, (32)\nsuch that, for all n = 0,1,2,???,\nU|n,??=|E?n?; U?|E??= 0, U?|E?n?=|n,??, (33)\nand thus\nUV=V; U?V=V, U?V =V. (34)\nHence once again the operators U and U?, even though non unitary on V, are adjoint of one\nanother. More specifically, one has\nU?U =\n?summationdisplay\nn=0,?\n|n,???n,?|= IV, UU? =\n?summationdisplay\nn=0,?\n|E?n??E?n|= IV. (35)\nApplying these operators to the reduced Hamiltonian, one finds\nHred =U?HredU =\n?summationdisplay\nn=0,?\n|n,??E?n ?n,?|, (36)\nand conversely,\nUHredU? =\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|=Hred ?|E??E??E?|. (37)\nSome remarks on the spectrum are in order. First, as in the ordinary JCm, except\nfor the singleton state |E?? = |0,??, the spectrum is the direct sum of two towers of states\n{|E?n?,n?N}. However, in contradistinction to the non-deformed case or even the q-deformation\nwith p = 1, the (p,q)-basic numbers [n] = [n](p,q) are not strictly increasing as a function of\nn?N when p > 1, 0 < q < 1 and pq < 1. There always exists a finite positive value n0 ?N\nsuch that [n] decreases once n > n0. Hence, depending on the values for the parameters ? and ?\nas well as the positive function h(p,q), parts of the spectrum E?n may turn negative or present\nsome degeneracies (as in [16]). Without exploring this issue any further in the present work,\nhenceforth we shall assume that parameter values are such that no degeneracies occur and that\nthe spectrum E?n remains bounded from below (E+n is obviously positive). The definition of the\nladder operators to be considered next does not require a strictly increasing spectrum, while it\nis only for one of possible choices leading to vector coherent states to be discussed hereafter that\nthe condition of non degeneracy in E?n > E?0 , for n?1, becomes relevant. Since it has been\n7\nshown [16] that such conditions may be met in the non-deformed case for appropriate ranges\nof values for the available parameters, through an argument of continuity in the deformation\nparameters p and q, similar ranges ought to exist also for the (p,q)-deformed realizations of the\nJCm model.\nAnother feature of potential interest related to these facts, and which will also not be\npursued here, is the possibility that through the (p,q)-deformation of theJCm, the levels E+n\nand E?n+1 cross one another. Such a property may lead to effects similar to the phenomenon\nof resonant spin-Hall conductance at the Fermi level recently observed in spintronics [27, 28].\nNote that this (p,q)-dependent crossing phenomenon is expected since the Zeeman splitting\n?En is also modified as a function of p and q. This remark is also in line with the recent\nsuggestion [33, 34, 35] that (p,q)-deformed or space noncommutative realizations of exactly\nsolvable systems may provide useful model approximations to more realistic complex interacting\ndynamics of collective phenomena.\n3.2 Ladder operators\nIn order to construct ladder operators mapping each of the successive states |E?n? into one\nanother separately within each of the towers, let us first introduce the following operators acting\nonV,\nA? =\n?summationdisplay\nn=0,?\n|n?1,??K?([n])?n,?|; A+ =\n?summationdisplay\nn=0,?\n|n+ 1,??K??([n +1])?n,?|, (38)\nwhere K?([n]) are arbitrary complex quantities such that K?([0]) = K?(0) = 0. Note that A?\nand A+ are adjoint of one another onV.\nThen the relevant ladder operators are obtained as\nA? =UA?U? =\n?summationdisplay\nn=0,?\n|E?n?1?K?([n])?E?n|; A+ =UA+U? =\n?summationdisplay\nn=0,?\n|E?n+1?K??([n+ 1])?E?n|.\n(39)\nConsequently, we have indeed, for all n?N,\nA?|E??= 0, A?|E?n?= K?([n])|E?n?1?; A+|E??= 0, A+|E?n?= K??([n+ 1])|E?n+1?.\n(40)\nNote thatA? andA+ are adjoint of one another, but that in effect they act only on the subspace\nV.\nIt is of course possible to express these ladder operators in the|n,??basis. In the case of\nthe lowering operator, one finds\nA? = summationtext?n=0 |n,+?A?++(n)?n+ 1,+| + summationtext?n=0 |n,+?A?+?(n)?n+ 2,?|\n+ summationtext?n=0 |n,??A??+(n)?n,+| + summationtext?n=0 |n,??A???(n)?n+ 1,?|\n(41)\nwhere\nA?++(n) = sin?([n]) sin?([n+ 1])K+([n + 1]) + cos?([n]) cos?([n+ 1])K?([n + 1]),\nA?+?(n) = sin?([n]) cos?([n+ 1])K+([n + 1]) ? cos?([n]) sin?([n+ 1])K?([n + 1]),\n8\nA??+(n) = cos?([n?1]) sin?([n])K+([n]) ? sin?([n?1]) cos?([n])K?([n]),\nA???(n) = cos?([n?1]) cos?([n])K+([n]) + sin?([n?1]) sin?([n])K?([n]). (42)\nLikewise for the raising operator,\nA+ = summationtext?n=0 |n+ 1,+?parenleftbigA?++(n)parenrightbig? ?n,+| + summationtext?n=0 |n,+?parenleftbigA??+(n)parenrightbig? ?n,?|\n+ summationtext?n=0 |n+ 2,??parenleftbigA?+?(n)parenrightbig? ?n,+| + summationtext?n=0 |n+ 1,??parenleftbigA???(n)parenrightbig? ?n,?|.\n(43)\nNote that we haveA??+(0) = 0 =A???(0), since K?([0]) = 0.\nThe quantities K?([n]) parametrize the freedom available in the choice of such ladder\noperators. Further restrictions arise when considering first the possible existence of vector\ncoherent states meeting a series of general conditions charateristic of such states [30]-[32], starting\nwith one involving the lowering operatorA? itself.\n4 (p,q)-Vector Coherent States for the (p,q)-JCm\nBy considering the action of the lowering operatorA?, we are able to construct an overcomplete\nset of vectors in V, so-called vector coherent states [30]-[32] for the (p,q)-JCm. Since these\nstates are associated to unit vectors in the 2-sphere S2 [29], they are referred to as (p,q)-vector\ncoherent states ((p,q)-VCS). As in Section 2, these (p,q)-VCS are parametrized by a complex\nvariable z ?C, two real parameters ?? to track a stable time evolution of the (p,q)-VCS, and\nfinally the spherical angle coordinates (?,?) on S2,|z;??;?,??. In the double limit that p,q?1,\nthese (p,q)-VCS reduce to those of [14] discussed in Section 2. The dependence of the (p,q)-VCS\non all these quantities is introduced as follows, according to the discussion in [30].\n4.1 Identifying (p,q)-VCS\nAs a slight extension of the analysis so far, given two real parameters ? and ?, let us consider\nthe operator\nQV =|E???E?| +\n?summationdisplay\nn=0,?\n|E?n?\nparenleftbiggq?\np?\nparenrightbiggn\n?E?n|. (44)\nHence, the energy eigenstates of the (p,q)-JCm are also eigenstates of this operator QV, with\neigenvalues given through the above spectral decomposition.\nWe are now in a position to successively identify the dependence of the (p,q)-VCS to be\nconstructed on each of the parameters of which they are functions, first z, then ??, and finally,\n? and ?. Having defined both the operatorsA? and QV, let us consider the following eigenvalue\nproblem in z for the (p,q)-VCS,\nA?|z;??;?,??= zQV|z;??;?,?? (45)\nwhich generalizes to a two-level system the definition of coherent states as advocated in [30]-\n[32]. The particular case ? = 0 = ? yields also a consistent definition of (p,q)-VCS viewed as\nthe limit ?,? ?0 of the present definition (note that their domain of definition in z, required\n9\nfor the convergence of the infinite series to be considered hereafter, may have to be adapted\naccordingly).\nBy expanding the (p,q)-VCS in the Hamiltonian eigenstate basis as\n|z;??;?,??= C?(z)|E??+\n?summationdisplay\nn=0,?\nC?n (z)|E?n?, (46)\nwhere C?(z) and C?n (z) are complex continuous functions of z to be specified presently, the\ncondition (45) then requires, for all n?N,\nC?(z) = 0, C?n+1(z)K?([n+ 1]) = z q\n?n\np?n C\n?\nn (z), (47)\nof which the solution is\nC?n (z) =\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK?([n])! C\n?\n0 (z), (48)\nwhere C?0 (z) are arbitrary complex functions of z, while we defined K?([n])! = producttextnk=1 K?([k])\nwith, by convention, K?([0])! = 1. Hence, the general solution to (45) defines states lying only\nwithin the subspaceV, of the form\n|z;??;?,??=\n?summationdisplay\nn=0,?\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK?([n])! C\n?\n0 (z)|E\n?\nn?. (49)\nNote that the eigenvalue problem (45) is singular at the particular value z = 0, since its solution\nis an arbitrary superposition of the three states|E??and|E?0 ?. Nevertheless, we shall consider\nthe (p,q)-VCS associated to z = 0, |z = 0;??;?,??, as being defined through the continuous\nlimit in z?0 of the construction in (49), namely|z = 0;??;?,??= C+0 (0)|E+0 ?+C?0 (0)|E?0 ?.\nLet us now turn to the issue of the stability of the (p,q)-VCS under time evolution gener-\nated by the Hamiltonian (24). Namely, we now require furthermore that (p,q)-VCS are trans-\nformed into one another under time evolution according to the following dependence on the real\nparameters ??, for all t?R,\ne?i?0tHred|z;??;?,??=|z;t +??;?,??. (50)\nSince one has, for all n?N,\ne?i?0tHred|E?n?= e?i?0tE?n |E?n?, (51)\none needs to factor out their complex phases from the quantities K?([n]),\nK?([n]) = ei??([n])K0?([n]), (52)\nwhere K0?([n]) > 0 are now real positive scalars. The stability condition (50) is then solved by\nchoosing, for all n = 1,2,???,\n??([n]) = ?0??bracketleftbigE?n ?E?n?1bracketrightbig, (53)\nand redefining\nC?0 (z) =C?0 (z)e?i?0??E?0 , (54)\n10\nwhereC?0 (z) are new complex functions of z. Hence,\n|z;??;?,??=\n?summationdisplay\nn=0,?\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK0?([n])!C\n?\n0 (z)e\n?i?0??E?n |E?\nn?. (55)\nHaving identified both the z and ?? dependences of the coherent states, finally let us\naccount for their (?,?) dependence and S2 vector character implicit so far through the two\nfunctionsC?0 (z). The latter are now chosen to be given as\nC+0 (z) = N+(|z|) cos?, C?0 (z) = N?(|z|)ei? sin?, (56)\nN?(|z|) being factors such that the constructed (p,q)-VCS be of unit norm,\nN?(|z|) =\nbraceleftBigg ?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2\nbracerightBigg?1/2\n. (57)\nThe convergence radii R? of these two series in z,\nR? = limn??\nbraceleftBig\n(q?p??)?(n?1) K0?([n])\nbracerightBig\n, (58)\ndepend on the choice of functions K0?([n]) as well as on (?,?) possibly. Specific cases are\nconsidered hereafter.\nConsequently, the (p,q)-VCS constructed here are properlydefined provided z?DR where\nDR denotes the disk in the complex plane centered at z = 0 and of radius R = min(R+,R?).\nTheir general structure is thus of the form\n|z;??;?,?? = N+(|z|) cos?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK0+([n])! e\n?i?0?+ E+n |E+\nn?\n+ N?(|z|)ei? sin?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK0?([n])! e\n?i?0??E?n |E?\nn?. (59)\nOnly the real positive functions K0?([n]) still need to be specified. They parametrize the remain-\ning freedom in the construction. Particular examples will be considered hereafter by imposing\nfurther requirements on these (p,q)-VCS. Note that the double limit p,q?1 yields the VCS of\nthe non-deformedJCm as obtained by Hussin and Nieto [14], briefly described in Section 2.\n4.2 Some expectation values\nBefore dealing with further requirements on the family of (p,q)-VCS, among which their over-\ncompleteness in the space V, let us consider some relevant expectation values for these states.\nGiven (59), the mean value ofHred for any of the (p,q)-VCS is simply\n?Hred? = |N+(|z|)|2 cos2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n+([n])!\nparenrightbig2 E+n\n+|N?(|z|)|2 sin2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2 E?n . (60)\n11\nLikewise for the ?number? operator associated to the ladder operators A? and A+, one finds\nthe expectation value\n?A+A?? = |z|2\nbraceleftBigg\n|N+(|z|)|2 cos2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n+1) |z|2n\nparenleftbigK0\n+([n])!\nparenrightbig2\n+|N?(|z|)|2 sin2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n+1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2\nbracerightBigg\n. (61)\nFinally, the average atomic spin time evolution ??3(t)? = ?U?1(t)?3U(t)?, with U(t) =\nexp{?i?0tHred}being the time evolution operator, has the form\n??3(t)?= 12\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1)\n|z|2nE([n+ 1])Q([n+ 1])\nbraceleftBigg\n?|N\n+(|z|)|2\nparenleftbigK0\n+([n])!\nparenrightbig2 cos2 ? + |N\n?(|z|)|2\nparenleftbigK0\n?([n])!\nparenrightbig2 sin2 ?\nbracerightBigg\n+?N+(|z|)N?(|z|)sin2?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nK0+([n])!K0?([n])!\n[n+ 1]\nQ([n+ 1]) cos?n(t), (62)\nwith\n?n(t) = ?0bracketleftbig(t+?+)E+n ? (t +??)E?nbracketrightbig + ? = ?0?En t + ?0bracketleftbig?+E+n ???E?nbracketrightbig+?. (63)\nAs is the case in the non-deformed model, the explicit time dependence which arises for the\natomic inversion ??3(t)? is due to the mixed state sector, namely the fact that the mixed-spin\nmatrix elements of the Heisenberg picture operator ?3(t) do not vanish when ? negationslash= 0. Hence,\nthe proposition which states that the time dependence of atomic inversion consists of Rabi\noscillations when a system is prepared in a coherent state of the radiation field [17] extends to\n(p,q)-VCS. However, in the limit where ??0, no such oscillations occur. Let us also point out\nthat the time dependence of??3(t)?diplays chaotic behaviour for appropriate values of the model\nparameters, as was previously mentioned for the q-deformation of the model, with 0 < q < 1, in\nthe work by Naderi et al. [24].\n4.3 Overcompleteness and the moment problem\nAn important property that coherent states ought to meet is that of overcompleteness in the\nspace over which they are defined [30]. In the present case, this means that the (p,q)-VCS in\n(59) must also provide a resolution of the identity operator over the subspaceV, namely\nIV = IV0 + IV =|E???E?| + IV, (64)\nwhile\nIV =\n?summationdisplay\nn=0,?\n|E?n??E?n|=\nintegraldisplay\nDR?S2\nd?(z;?,?)|z;??;?,???z;??;?,?|, (65)\nwhere d?(z;?,?) is some SU(2) matrix-valued integration measure over DR?S2 to be determined\nfrom the above requirement.\nLet us thus consider the following parametrization of that measure,\nd?(z;?,?) = d2zd? sin?d?\nbraceleftBigg\nW+(|z|)\n?summationdisplay\nn=0\n|E+n??E+n| + W?(|z|)\n?summationdisplay\nn=0\n|E?n??E?n|\nbracerightBigg\n, (66)\n12\nin terms of real weight functions W?(|z|) to be identified. Using the radial parametrization\nz = rei? and d2z = drrd? where r ? [0,?[ and ? ? [0,2?[, a direct substitution in (65)\nleads to the moment problem associated to the overcompleteness relation (65). In terms of the\nfunctions h?(r2) defined through\nh+(r2) = 4?\n2\n3 |N\n+(r)|2W+(r), h?(r2) = 8?2\n3 |N\n?(r)|2W?(r), (67)\nthe following two infinite sets of moment identities must be met, for all n?N,\nintegraldisplay R2\n0\nduun h?(u) =\nparenleftbiggq?\np?\nparenrightbigg?n(n?1) parenleftbig\nK0?([n])!parenrightbig2 . (68)\nIn conclusion, the resolution of the identity operator over V in terms of the (p,q)-VCS\nis achieved provided the Stieljes moment problem (68) can be solved [36, 37]. This requires a\nchoice of functions K0?([n]) > 0 such that not only the conditions (68) may all be met, but also\nsuch that the normalization factors N?(|z|) converge in a non-empty disc of the complex plane.\nAs a result of this analysis, a priori there may exist a large number of sets of (p,q)-VCS\nwhich fulfill all the above properties, namely continuity in the complex parameter z, temporal\nstability through a simple additive time dependence in the real parameters ??, a unit vector\nvalued characterization on the sphere S2 in terms of the spherical coordinates ? and ?, and the\ncompleteness propertyof a resolution of the unit operator with a SU(2) matrix-valued integration\nmeasure over these spaces. These sets of (p,q)-VCS are distinguished from one another by\ndifferent choices of real positive weight factors K0?([n]), in agreement with the considerations\ndeveloped in [30, 38]. The above construction of (p,q)-VCS is general, but can admit explicit\nexact solutions to the moment problem(68) for particular cases. Concrete examples are discussed\nin Section 5..\n4.4 Action-angle variables\nOne of the useful properties that general coherent states constructed according to the arguments\nof [38] possess, is that action-angle variables are readily identified in relation to the continuous\nparameters ensuring stability of the coherent states under time evolution. In the present case,\ncanonical reduced action-angle variables (J?(t),??(t)) are such that for the previously evaluated\nexpectation values of the reduced Hamiltonian (24) in the (p,q)-VCS, one has\n?Hred?= J+ ?+ + J? ?? =\nsummationdisplay\n?\nJ? ??, (69)\nin relation to the action-angle variational principle of the form\nintegraldisplay\ndt\nsummationdisplay\n?\nbracketleftbiggd?\n?\ndt J? ? ??J?\nbracketrightbigg\n??\nintegraldisplay\ndt\nbracketleftbigg\n? i?\n0\nd\ndt???H\nred?\nbracketrightbigg\n, (70)\nwhere ?? are two constant factors to be chosen appropriately. Consequently\nd??\ndt =\n??Hred?\n?J? = ??,\ndJ?\ndt =?\n??Hred?\n??? = 0. (71)\n13\nGiven the time evolution, ??(t) = t + ??(0), one simply finds ?? = 1. From the expression in\n(60), one then has the identifications\nJ+ = |N+(|z|)|2 cos2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n+([n])!\nparenrightbig2 E+n ,\nJ? = |N?(|z|)|2 sin2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2 E?n . (72)\nAs a final remark, let us mention that the saturated Heisenberg uncertainty relations\nwhich are obeyed by q- and (p,q)-coherent states are also well-known in q-mechanics (see for\ninstance [39]). Such minimal uncertainties may be characterized through small corrections to\ncanonical commutation relations defined in [39, 40]. Such properties in the case of the (p,q)-VCS\nconstructed here are deferred to a later study.\n5 Explicit Solutions\nIn order to completely specify the quantities K0?([n]), one last set of conditions needs to be\nimplemented. In the present Section, two such choices are discussed, one of which allows for an\nexact and explicit solution to the moment problem, hence the construction of a set of (p,q)-VCS.\nFirst, in line with the illustrative example of Section 2, we consider restricting the algebra of the\nladder operatorsA?. Then as a second and independent possibility, we apply a final additional\ncriterion developed in [30] in order to uniquely characterize a set of coherent states which meet\nalready all the requirements considered heretofore and having led to the representation (59),\neven though the moment problem remains unsolved for that choice.\n5.1 Constraining the ladder operator algebra\nIn order to uniquely identify the set of functions K0?([n]) > 0, let us consider the possibility\nthat this may be achieved by restricting the algebraic properties of the ladder operators. In line\nwith the general (p,q)-deformations of the Fock algebra in (2), let us constrain the algebra of\nthe operators A? acting onV to be such that\nA?A+ ? q0A+A? = p?N0 =\n?summationdisplay\nn=0,?\n|n,??p?n0 ?n,?|,\nA?A+ ? p?10 A+A? = qN0 =\n?summationdisplay\nn=0,?\n|n,??qn0 ?n,?|, (73)\nwhere p0 and q0 are again two real parameters such that p0 > 1, 0 < q0 < 1 and p0q0 < 1, which\nmay or may not be identical to p and q. For instance, we could have p0 = 1 and q0 = 1 thus\ncorresponding to an ordinary Fock algebra, or else p0 = p and q0 = q, but also more generally\np0 = p? and q0 = q?, ? being some real constant. As a matter of fact, exact solutions to the\nmoment problem are presented hereafter in all these situations.\nIn terms of the ladder operatorsA? =UA?U? acting on the subspaceV, the associated\nalgebraic constraint reads\nA?A+ ? q0A+A? =\n?summationdisplay\nn=0,?\n|E?n?p?n0 ?E?n|,\n14\nA?A+ ? p?10 A+A? =\n?summationdisplay\nn=0,?\n|E?n?qn0 ?E?n|. (74)\nWhether in terms of (73) or (74), these algebraic constraints translate into the following identi-\nties, for all n?N,\nparenleftbigK0\n?([n+ 1])\nparenrightbig2 ? q\n0\nparenleftbigK0\n?([n])\nparenrightbig2 = p?n\n0 ,\nparenleftbigK0\n?([n+ 1])\nparenrightbig2 ? p?1\n0\nparenleftbigK0\n?([n])\nparenrightbig2 = qn\n0. (75)\nGiven the initial values K0?([0]) = 0, the solution to these recursion relations is simply\nK0?([n]) =\nradicalBig\n[n](p0,q0) =\nradicalBig\n[n](q?1\n0 ,p\n?1\n0 )\n, (76)\nwhere4\n[n](p0,q0) = p\n?n\n0 ?qn0\np?10 ?q0 =\nparenleftbigq?1\n0\nparenrightbig?n?parenleftbigp?1\n0\nparenrightbign\nparenleftbigq?1\n0\nparenrightbig?1?parenleftbigp?1\n0\nparenrightbig = [n](q?10 ,p?10 ). (77)\nGiven this solution, the normalization factors are defined by the series\n|N?(|z|)|?2 =\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\n[n](p0,q0)!, (78)\nof which the convergence radius is\nR = limn??\nbracketleftBiggparenleftbigg\nq?\np?\nparenrightbigg?2(n?1) p?n\n0 ?qn0\np?10 ?q0\nbracketrightBigg1/2\n= limn??\nbracketleftbiggparenleftbig\np0p?2?q2?parenrightbig?(n?1) 1?(p0q0)\nn\n1?(p0q0)\nbracketrightbigg1/2\n. (79)\nProvided p0p?2?q2? < 1, a condition which we shall henceforth assume to be satisfied5, this\nradius of convergence is infinite, R =?, and the moment problem (68) then becomes, for all\nn?N, integraldisplay\n?\n0\nduun h?(u) =\nparenleftbiggq?\np?\nparenrightbigg?n(n?1) parenleftbig\n[n](p0,q0)!parenrightbig. (80)\nIn order to solve these equations, the Ramanujan integral (121) discussed in the Appendix\nsuggests itself quite naturally, through a simple but appropriate rescaling of its arguments in\nthe form of (123).\nAfter a little moment?s thought one comes to the conclusion that a solution to (80) based\non (123) is possible for the following choice of parameters,\n? = 12, ? = 0, p0 = p, q0 = q, (81)\nin which case p0p?2?q2? = pq < 1, hence corresponding indeed to an infinite radius of conver-\ngence. For this choice, one has (for definitions of the (p,q)-exponential functions appearing in\nthese expressions, see the Appendix),\nh?parenleftbig|z|2parenrightbig=\nparenleftbigp?1?qparenrightbig\nqlog(1/pq) e(p,q)\nparenleftBig\n?|z|2 p?1/2q?1parenleftbigp?1?qparenrightbig\nparenrightBig\n, (82)\n4Incidentally, it is because of this identity, corresponding to the exchange p0 ? q?1\n0 , that the two solutions to\nthe above two recursion relations are consistent, as are the two algebraic restrictions in (73) and (74).\n5If p0p?2?q2? = 1, the radius of convergence is finite with R = (1?p0q0)?1/2, while when p0p?2?q2? > 1 the\nradius of convergence vanishes, implying that (p,q)-VCS cannot be constructed in such a case.\n15\nas well as6\nparenleftbigK0\n?([n])\nparenrightbig2 = [n], |N?(|z|)|?2 =E(1/2,0)\n(p,q)\nparenleftBig\n|z|2q?1/2parenleftbigp?1?qparenrightbig\nparenrightBig\n, (83)\nwith for the weight functions W?(|z|) in the integration measure (66) of the overcompleteness\nrelation (65),\nW+ (|z|) = 34?2 |N+ (|z|)|?2 h+parenleftbig|z|2parenrightbig, W?(|z|) = 38?2 |N?(|z|)|?2 h?parenleftbig|z|2parenrightbig. (84)\nExplicit expressions for all previously computed quantities readily follow, beginning with the\ndefinition of the associated (p,q)-VCS which then meet all thenecessary requirements expected of\ncoherent states. Note that up to the coefficients 3/(2?) and 3/(4?), the reduced weights obtained\nare compatible with that of the q-shape invariant harmonic oscillator [20]. Furthermore, (82)\nis a (p,q)-generalization of the q-harmonic oscillator coherent state moment problem solution\nconstructed in [41]. Finally, in the double limit p,q?1, the results of [14] are recovered.\nThe functions (82) thus provide a complete and explicit solution to the moment problem of\nthe (p,q)-VCS for the (p,q)-JCm such that the ladder operatorsA? obey the same (p,q)-Fock\nalgebra as the original modes a and a? of the initial Hamiltonian (24), namely with the choice\np0 = p and q0 = q. It is also possible to construct an explicit solution when the ladder operators\nA? are constrained to rather obey the ordinary non-deformed Fock algebra onV, corresponding\nto the choice p0 = 1 and q0 = 1. One then has to consider7, for all n?N,\nK0?([n]) =?n,\nintegraldisplay ?\n0\nduun h?(u) =\nparenleftbiggq?\np?\nparenrightbigg?n(n?1)\n(n!), p??q??1. (85)\nAn obvious solution to this moment problem is obtained when ? = 0 = ?, in which case the\ncondition for an infinite radius of convergence is saturated. One then has\nh?parenleftbig|z|2parenrightbig= e?|z|2, |N? (|z|)|?2 = e|z|2, W+ (|z|) = 34?2, W?(|z|) = 38?2. (86)\nIn fact, the above two explicit solutions belong to a general class of solutions obtained\nby taking (p0,q0) = (p?,q?) with ? a positive real parameter, ? > 0, such that p??2?q2? < 1\nin order to ensure an infinite radius of convergence8 in z ?C. Once again based on (123), an\nexplicit solution to the moment problem (80) is achieved for the following choice of parameters,\n? = 12?, ? = 0, p0 = p?, q0 = q?, (87)\nfor which the radius of convergence is indeed infinite, p??2?q2? = (pq)? < 1. One then has\nh?parenleftbig|z|2parenrightbig= (p\n???q?)\nq? log(1/p?q?) e(p?,q?)\nparenleftBig\n?|z|2 p??/2q??parenleftbigp???q?parenrightbig\nparenrightBig\n, (88)\nwith\n|N?(|z|)|?2 =E(1/2,0)(p?,q?)\nparenleftBig\n|z|2q??/2parenleftbigp???q?parenrightbig\nparenrightBig\n, (89)\nleading finally to the weight functionsW?(|z|) given in terms of the latter two quantities through\nthe same relations as in (84). In the limits that ? ? 1 or ? ? 0, the previous two explicit\nsolutions are then recovered as particular cases.\n6Restricting to p0 = p and q0 = q but keeping ? and ? arbitrary such that p1?2?q2? < 1 in order to retain an\ninfinite radius of convergence, one has parenleftbigK0?([n])parenrightbig2 = [n] and |N? (|z|)|?2 = E(?,?)(p,q) parenleftbig|z|2 p? q??parenleftbigp?1 ?qparenrightbigparenrightbig, hence\nalso all other previous expressions given accordingly.\n7Leading to |N? (|z|)|?2 = e(?,?)\n(p,q)\nparenleftbig|z|2 p? q??parenrightbig, which converges for all |z| < ? provided p??q? ? 1.\n8Leading to |N? (|z|)|?2 = E(?/?,?/?)\n(p?,q?)\nparenleftbig|z|2p?q??(p?? ?q?)parenrightbig.\n16\n5.2 The action identity constraint\nAn alternative to fixingthe factors K0?([n]) through conditions on the algebra ofladder operators,\nis to consider the action identity constraint discussed in [30] as the one last requirement which\nsingles out coherent states uniquely. In the case of the ordinary Fock algebra, this action\nidentity constraint is equivalent to requiring that the ladder operators obey themselves the Fock\nalgebra as well. We shall establish that this is not the case for the (p,q)-VCS of the (p,q)-JCm\nconstructed above.\nGiven the relations (72), in the present model the action identity constraint is of the form\nJ+ = cos2 ?parenleftbig|z|2 +E+0 parenrightbig, J? = sin2 ?parenleftbig|z|2 +E?0 parenrightbig. (90)\nBy direct substitution into these constraints of the relations (72), the identification of the suc-\ncessive powers in|z|2 leads to the following solution for the factors K0?([n]),\nK0?([n]) =\nparenleftbiggq?\np?\nparenrightbigg(n?1) radicalBig\nE?n ? E?0 . (91)\nThese positive real quantities are thus well-defined provided one has E?n > E?0 for all n ? 1,\nas is implicitly assumed. It is noteworthy that, as (p,q) ? (1+,1?), these factors reduce to\nexactly those obtained in [16] by the factorization method. On the other hand, since the present\nsolution for K0?([n]) cannot be brought into the form of (76) for some choice of constants p0 and\nq0 meeting our assumptions for these quantities, it follows indeed that for the (p,q)-JCm the\naction identity constraint is not equivalent to requiring an algebraic constraint on the ladder\noperators of the (p0,q0)-deformed Fock algebra type.\nThis choice also allows for the factorization of the Hamiltonian in (36) in the form\nHred = A+\nparenleftbiggq?\np?\nparenrightbigg?2N\nA +\n?summationdisplay\nn=0,?\n|n,??E?0 ?n,?|, (92)\nextending a similar expression in [14].\nGiven this solution for the factors K0?([n]), the general moment problem (68) reduces to\nthe following conditions,\nintegraldisplay R2\n0\ndu h?(u) = 1;\nintegraldisplay R2\n0\nduun h?(u) =\nnproductdisplay\nk=1\nparenleftbigE?\nk ?E\n?\n0\nparenrightbig, n = 1,2,3,???, (93)\nwhere the radius of convergence R is given as\nR = min (R+,R?), R? = limn?+?\nradicalBig\nE?n ?E?0 . (94)\nIn the absence of a detailed analysis of the energy spectra E?n as functions of the parameters p,\nq, ? and ? and the function h(p,q), nothing more explicit may be said concerning this moment\nproblem. Since when p > 1 the quantities [n] always possess a turn-around behaviour as func-\ntions of n for n sufficiently large, it is to be expected generally that the radius of convergence\nR, hence the moment problem as well, are associated to a finite disk DR in the complex plane.\nNevertheless, one conclusion of the present discussion is that indeed for the (p,q)-VCS consid-\nered in this work, the action identity constraint leads to coherent states different from those\nconstructed in Section 5.1 and for which explicit solutions to the moment problem have been\ngiven.\n17\n5.3 The spin decoupled limit ? = 0\nIn the limit that ? = 0, the two spin sectors of the model are decoupled, and the (p,q)-JCm\nreduces to the supersymmetric harmonic oscillator [43, 44, 18] with a (p,q)-deformation. Diago-\nnalization of the reduced Hamiltonian (24) is then of course straightforward in the ?3-eigenbasis,\nwith, for n = 0,1,2,???,\nHred?=0|n,??= ??n |n,??, ??n = (1 +?)h(p,q)[n] + 12(1 +?)?12. (95)\nFrom that point of view, one thus has two decoupled (p,q)-deformed Fock bases, for which\none could consider the usual (p,q)-coherent states in each spin sector separately. However, such\ncoherent states do not coincide with any of those constructed in this paper and obtained in the\nlimit ? = 0, because of the distinguished role played by the singleton state |E?? = |0,?? and\nthe S2 unit vector character of the (p,q)-VCS. In particular the ladder operators A? acting\nwithin each of the towers |E?n? do not coincide with the annihilation and creation operators a\nand a? defining the Hamiltonian (24), even in the decoupled limit ? = 0. As a matter of fact,\nthe action of the ladder operatorsA? may switch between the two spin sectors as a function of\nn depending on the sign of the quantityE([n+ 1]).\nMore specifically, let us introduce the notation\nsn = signE([n+ 1]), n?N. (96)\nIn the limit that ? = 0, one has Q([n + 1]) =|E([n + 1])|/2, so that the mixing angle ?([n]) is\nnow such that, for all n?N,\n? = 0 : sin?([n]) = 12(1?sn)(sign?), cos?([n]) = 12(1 +sn). (97)\nConsequently, the towers of energy eigenstates|E?n?are then given as follows, for all n?N,\nIf sn = +1 : |E+n??=0 =|n+1,??, |E?n??=0 =|n,+?;\nIf sn =?1 : |E+n??=0 = (sign?)|n,+?, |E?n??=0 =?(sign?)|n + 1,??,\n(98)\nwhile the energy eigenvalues are given as\nIf sn = +1 : E+n (? = 0) = (1 +?)h(p,q)[n +1] + 12(1 +?) ? 12,\nE?n (? = 0) = (1 +?)h(p,q)[n] + 12(1 +?) + 12;\nIf sn =?1 : E+n (? = 0) = (1 +?)h(p,q)[n] + 12(1 +?) + 12,\nE?n (? = 0) = (1 +?)h(p,q)[n +1] + 12(1 +?) ? 12.\n(99)\nThese spectra do indeed coincide with those in (95), once the singleton state|E??=|0,??with\nE? = ?/2 is included as well.\nThese expressions show how, even in the decoupled spin limit ? = 0, the (p,q)-VCS\nconstructed here are not simply the juxtaposition of two separate (p,q)-coherent states of the\n(p,q)-deformed Fock algebra in each of the two spin sectors. Since the spectrum of the system\nis discrete infinite, by leaving aside the singleton state|0,??, all the remaining states still allow\nfor similar types of constructions of coherent states, but in such a way that different spin sectors\nare getting superposed, leading to the SU(2) vector coherent states of the type studied here. All\nthe expressions detailed in the previous sections for the (p,q)-VCS may readily be particularized\nto the limit ??0.\n18\n6 Conclusion\nIn this work, we considered (p,q)-deformations of the Jaynes-Cummings model in the rotating\nwave approximation, extending recent developments on this topic in the non-deformed case [14].\nHaving introduced (p,q)-deformed versions of the model, first its energy eigenspectrum has been\nidentified, enabling the definition of different relevant operators acting on Hilbert space and the\ncharacterization of the spectrum in terms of two separate infinite discrete towers and a singleton\nstate. Among these operators, ladder operators acting within each of the two towers separately\nmay be considered, defined up to some arbitrary normalization factors.\nSuch a structure sets the stage for the introduction of vector coherent states for the (p,q)-\ndeformed Jaynes-Cummings model, following the approach of [14] and the rationale outlined\nin [30]. These (p,q)-VCS are parametrized by elements of C?S2, and enjoy temporal sta-\nbility through a further action-angle identification. The moment problem associated to the\novercompleteness property of these (p,q)-VCS involves SU(2)-valued matrix weight functions.\nUsing (p,q)-arithmetic techniques, some explicit and exact solutions to the moment problem\nhave been displayed, hence characterizing specific classes of such (p,q)-VCS. All these solutions\nprovide (p,q)-extensions to the non-deformed vector coherent states of theJCm considered in\n[14]. These explicit solutions are obtained by requiring that specific algebraic constraints of the\n(p,q)-deformed Fock algebra type be obeyed by the ladder operators. However, in contradis-\ntinction to [14], we have not been able to display an explicit and exact solution to the moment\nproblem in the generic case by imposing an action identity constraint.\nFinally, the spin decoupled limit of these models was considered, corresponding to a (p,q)-\nsupersymmetric oscillator of which the two sectors are intertwined in a manner depending on\nthe sign of the energy level spacing between the two decoupled spin sectors as function of the\nexcitation level. In the non-deformed limit (p,q) = (1,1), this feature disappears, reproducing\nthe ordinary supersymmetric oscillator. Our results thus provide new classes of generalized\nversions of theJCm in the rotating wave approximation [20, 18]. Finally, the (p,q)-VCS built\nhere extend the q-coherent states obtained by other techniques involving supersymmetric shape\ninvariance and self-similar potential formalisms applied to the harmonic oscillator [20, 45].\nAcknowledgements\nJ. B. G. is grateful to the Abdus Salam International Centre for Theoretical Physics (ICTP,\nTrieste, Italy) for a Ph.D. fellowship under the grant Prj-15. M. N. H. is particularly indebted\nto V. Hussin for discussions relating to the JCm as well as for provided references during his\nstay at the Centre de Recherches Math?ematiques, Universit?e de Montr?eal, Canada. The ICMPA\nis in partnership with the Daniel Iagoniltzer Foundation (DIF), France.\nJ. G. acknowledges a visiting appointment as Visiting Professor in the School of Physics\n(Faculty of Science) at the University of New South Wales. He is grateful to Prof. Chris Hamer\nand the School of Physics for their hospitality during his sabbatical leave, and for financial sup-\nport through a Fellowship of the Gordon Godfrey Fund. His stay in Australia is also supported\nin part by the Belgian National Fund for Scientific Research (F.N.R.S.) through a travel grant.\nJ. G. acknowledges the Abdus Salam International Centre for Theoretical Physics (ICTP,\nTrieste, Italy) Visiting Scholar Programme in support of a Visiting Professorship at the ICMPA.\nHis work is also supported by the Belgian Federal Office for Scientific, Technical and Cultural\nAffairs through the Interuniversity Attraction Pole (IAP) P5/27.\n19\nAppendix\nThis appendix lists some useful facts related to the (p,q)-boson algebra and associated functions.\nThe (p,q)-deformed oscillator algebra introduced in [5] is generated by operators a, a? and N\nobeying the relations\n[N,a] =?a, [N,a?] = a?,\naa??qa?a = p?N, aa??p?1a?a = qN. (100)\nThroughout the text, we assume the real parameters p and q are such that p > 1, 0 < q < 1\nand pq < 1. The limit p ? 1+ yields the q-oscillator of Arik and Coon [3] while p = q gives\nthe q-deformed oscillator algebra of Biedenharn and MacFarlane [4]. Finally, the algebra (100)\nreduces to the ordinary harmonic oscillator Fock algebra as q ? 1 for p = 1+ or p = q. At\nany stage of the discussion, the (p,q)-deformed model readily reduces to its usual counterpart\nas (p,q)?(1,1).\nThe associated (p,q)-deformed Fock-Hilbert space representation is spanned by the vac-\nuum|0?annihilated by a and the orthonormalized states|n?, such that\na|0?= 0, ?0|0?= 1, |n?= 1radicalBig\n[n](p,q)!\nparenleftBig\na?\nparenrightBign\n|0?,\na|n?=\nradicalBig\n[n](p,q)|n?1?, a?|n?=\nradicalBig\n[n+ 1](p,q)|n+ 1?, N|n?= n|n?, (101)\nwhere the symbol [n](p,q) = (p?n?qn)/parenleftbigp?1?qparenrightbigis called (p,q)-basic number with, by conven-\ntion, [0](p,q) = 0, and its (p,q)-factorial is defined through [n](p,q)! = [n](p,q)parenleftbig[n?1](p,q)!parenrightbig and\nthe convention [0](p,q)! = 1. There exists a formal (p,q)-number operator denoted by [N](p,q), or\nsimply by [N] when no confusion arises. As a matter of fact, from the second pair of relations\nin (100), it follows that [N] = a?a as well as [N + 1] = aa?. One has of course [N]|n?= [n]|n?.\nHence, (101) provides a well defined Fock-Hilbert representation space of the algebra (100).\nThe following relations hold for any function f ?f(N) and consequently for any function\nof [N],\naf(N?1) = f(N)a, a?f(N) = f(N?1)a?. (102)\nLet us define q-shifted products and factorials and their (p,q)-analogues. Using the nota-\ntions of [46], for any quantity x, (x;q)? is constructed as follows,\n(x;q)0 = 1, (x;q)? = (x;q)?(xq?;q)\n?\n, (x;q)? =\n?productdisplay\nn=0\n(1?xqn). (103)\nFurthermore, in the notations of [10], (p,q)-shifted products and factorials are defined as follows,\nfor any real quantities a and b such that anegationslash= 0,\n[a,b;p,q]0 = 1, [a,b;p,q]? = [a,b;p,q]?[ap?,bq?;p,q]\n?\n, [a,b;p,q]? =\n?productdisplay\nn=0\nparenleftbigg 1\napn ?bq\nn\nparenrightbigg\n. (104)\nFor ? = n?N, we have\n[p?,q?;p,q]n =\nparenleftbigg 1\np? ?q\n?\nparenrightbiggparenleftbigg 1\np?+1 ?q\n?+1\nparenrightbigg\n...\nparenleftbigg 1\np?+n?1 ?q\n?+n?1\nparenrightbigg\n20\n= p??n?n(n?1)/2(p?q?;pq)n. (105)\nThis identity is a central formula since it defines a bridge between q- and (p,q)-analogue quan-\ntities and functions.\nLet us now introduce q-analogues of the ordinary exponential funtion. There exist many\ntypes of q-deformations of the exponential function ez, z ?C (see, for instance, [9]). For any\n(z,?)?C?R, the (?,q)-exponential is the complex function [9]\nE(?)q (z) =\n?summationdisplay\nn=0\nq?n2\n(q;q)nz\nn. (106)\nThis series has an infinite radius of convergence for ? > 0. For ? = 0 its domain of definition\nreduces to the unit disk, |z| < 1, while it is nowhere convergent in C for ? < 0. Rescaling\nz?z(1?q) and taking the limit limq?1 E?q (z(1?q)), one recovers ez. For some specific values\nof ?, (106) reproduces some standard q-exponentials [9, 11],\nE(0)q (z) = eq(z) = 1(z;q)\n?\n=\n?summationdisplay\nn=0\nzn\n(q;q)n, |z|< 1, (107)\nE(1/2)q (z) = Eq(q1/2z) = (?q1/2z;q)?, z?C, (108)\nwhere\nEq(z) =\n?summationdisplay\nn=0\nqn(n?1)/2zn\n(q;q)n , z?C, (109)\nis known as the Jackson q-exponential [6]. Note that whereas E(?)q (z) is defined in the entire\ncomplex plane, |z| < ?, for any ? > 0, its reduction eq(z) is only defined on the unit disc.\nFinally, it is also well established that [11]\nEq(?z)eq(z) = 1. (110)\n(p,q)-analogues of the usual exponential function ez, z?C may also be introduced (see,\nfor instance, [10]). Given any (z,?,?)?C?R?R, consider the (?,?,p,q)-exponential function\nE(?,?)(p,q) (z) =\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn2 zn\n[p,q;p,q]n. (111)\nKeeping in mind the condition pq < 1, the radius of convergence R of this series is such that\nR1 =\n?\n?\n?\n?, if q2?p1?2? < 1;\np??1q??, if q2?p1?2? = 1;\n0, if q2?p1?2? > 1.\n(112)\nThus the functionE(?,?)(p,q) (z) exists only provided q2?p1?2? ?1.\nIn order to recover the usual exponential function, one has to rescale z?z(p?1?q), for\nexample, and then take the limit lim(p,q)?(1,1)E?,?(p,q)(z(p?1?q)) = ez. For particular values of\nthe parameters ? and ?, (111) reproduces known (p,q)-exponentials,\nE(1/2,1/2)(p,q) (z) = E(p,q)\nparenleftBiggparenleftbigg\nq\np\nparenrightbigg1/2\nz\nparenrightBigg\n=\n?summationdisplay\nn=0\nparenleftbiggq\np\nparenrightbiggn2/2 zn\n[p,q;p,q]n, (113)\n21\nwhere\nE(p,q)(z) =\n?summationdisplay\nn=0\nparenleftbiggq\np\nparenrightbiggn(n?1)/2 zn\n[p,q;p,q]n. (114)\nThe function E(p,q) may be found in [10]. Note that (114) coincides with (109) as p?1. In the\nsame limit, (111) reproduces the (?,q)-deformed exponential map E(?)q (z) [9]. If ? = 0 = ? the\nseries (111) is not defined since then R = 0, unless one has taken p = 1 in which case the radius\nof convergence is unity. A (p,q)-analogue of (107) is given by\ne(p,q)(z) =\n?summationdisplay\nn=0\n1\npn2/2\nzn\n[p,q;p,q]n, |z|< p\n?1/2, (115)\nwhich reproduces exactly eq(z) converging in the unit disc as p ? 1+. Furthermore, we have\nfrom (105)\ne(p,q)(z) =\n?summationdisplay\nn=0\n(p1/2z)n\n(pq;pq)n = epq(p\n1/2z). (116)\nUsing (105) and (109), we may also write\nE(p,q)(z) =\n?summationdisplay\nn=0\nparenleftbiggq\np\nparenrightbiggn(n?1)/2 zn\np?n(n+1)/2(pq;pq)n\n=\n?summationdisplay\nn=0\nqn(n?1)/2 (zp)\nn\n(pq;pq)n = Epq(pz). (117)\nThen taking into account (110), (116) and (117), a (p,q)-analogue of (110) is given by\nEpq(?pz)epq(pz) = E(p,q)(?z)e(p,q)(p1/2z) = 1. (118)\nFinally, consider\ne(?,?)(p,q)(z) =\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn2 zn\nn!. (119)\nTherefore, e(?,?)(p,q)(z), which converges to ez as (p,q) ? (1,1), provides a (p,q)-deformed ex-\nponential analogue to the q-function used by Penson and Solomon [42] which coincides with\ne(1,?)(1,q)(q?1/2z). The radius of convergence of (119) is given as\nR2 =\nbraceleftbigg ?, if q?p?? ?1;\n0, if q?p?? > 1. (120)\nFinally, consider the Ramanujan integral [7, 19], valid for any integer n?N,\nintegraldisplay ?\n0\ndttn eq(?t) =? (q;q)nqn(n+1)/2 logq. (121)\nThrough the change of variables\nq?pq, t??0 p?1/2 t, ?0 > 0, (122)\nand using once again (105), the following identity is obtained, for any n?N,\nintegraldisplay ?\n0\ndttn e(p,q)\nparenleftBig\n??0p?1/2t\nparenrightBig\n= [p,q;p,q]n?n+1\n0 qn(n+1)/2\nlog\nparenleftbigg 1\npq\nparenrightbigg\n. (123)\nThis result is indeed a (p,q)-analogue of the Ramanujan integral (121).\n22\nReferences\n[1] S. Majid, Quantum Groups (Cambridge Univ. Press, Cambridge, 1995);\nV. G. Drinfeld, Quantum Groups, Lecture Notes in Mathematics, Ed. P. P. Kulish (Springer,\nBerlin, 1992).\n[2] See for example,\nJ. Wess and B. Zumino, Nucl. Phys. B (Proceedings Supplements) 18, 302-312 (1991);\nA. Lorek and J. Wess, Z. Phys. C 67, 671-680 (1995).\n[3] M. Arik and D. D. Coon, J. Math. Phys. 17, 524-527 (1976).\n[4] A. J. Macfarlane, J. Phys. A: Math. Gen. 22, 4581-4588 (1989);\nL. C. Biedenharn, J. Phys A: Math. Gen. 22, L873-L878 (1989).\n[5] R. Chakrabarti and R. Jagannathan, J. Phys. A: Math. Gen. 26, L711-L719 (1991).\n[6] F. Jackson, Mess. Math. 38, 57 (1909).\n[7] S. Ramanujan, Mess. Math. 44, 10-18 (1915).\n[8] H. Exton, q-Hypergeometric Functions and Application (John Wiley and Sons, New York,\n1983).\n[9] F. Floreanini and L. Vinet, Lett. Math. Phys. 22, 45-54 (1991);\nF. Floreanini, J. LeTourneux and L. Vinet, J. Phys. A: Math. Gen. 28, L287-L239 (1995).\n[10] R. Floreanini, L. Lapointe and L. Vinet, J. Phys. A: Math. Gen. 26, L611-L614 (1993).\n[11] R. Koekoek and R. F. Swarttouw, The Askey-scheme of hypergeometric orthogonal polyno-\nmials and its q-analogue, Delft University Technology, Report 94-05 (1994).\n[12] E. T. Jaynes and F. Cummings, FW Proc. IEEE 51, 89-109 (1963).\n[13] P. Meystre and E. M. Wright, Phys. Rev. A 37, 2524 (1988).\n[14] V. Hussin and L. M. Nieto, J. Math. Phys. 46, 122102 (2005).\n[15] Y. B?erub?e-Lauziere, V. Hussin and L. M. Nieto, Phys. Rev. A 50, 1725 (1994).\n[16] L. Dello Sbarba and V. Hussin, in Group of Theoretical Methods in Physics: Proceeding\nof the XXV International Colloqium on Group Theoretical Methods in Physics, Institute\nof Physics Conferences Series, Vol. 185, Eds. G. S. Pogosyan, L. E. Vincent and K. B. Wolf\n(IOP, Bristol, 2005).\n[17] M. Daoud and V. Hussin, J. Phys. A: Math. Gen. 35, 7381-7402 (2002).\n[18] M. Daoud and J. Douari, Int. J. Mod. Phys. B 17, 2473-2486 (2003).\n[19] A. B. Balantekin, To be published in the Proceedings of ?Computational And Group The-\noretical Methods In Nuclear Physics: Symposium In Honor Of Jerry P. Draayer?s 60th\nBirthday, 18-21 Feb 2003, Playa del Carmen, Mexico?; e-print arXiv:nucl-th/0309038.\n23\n[20] A. N. F. Aleixo, A. B. Balantekin and M. A. Candido Ribeiro, J. Phys. A: Math. Gen. 35,\n9063-9070 (2002);\nA. N. F. Aleixo, A. B. Balantekin and M. A. Candido Ribeiro, J. Phys. A: Math. Gen. 36,\n11631-11642 (2003);\nA. N. F. Aleixo and A. B. Balantekin, J. Phys. G 30, 1225-1230 (2004).\n[21] B. Buck and C. V. Sukumar, Phys. Lett. A 81, 132 (1981).\n[22] M. Chaichan, D. Ellinas and P. Kulish, Phys. Rev. Lett. 65, 980-983 (1990).\n[23] Z. Chan, Phys. Rev. A 47, 5017-5023 (1993).\n[24] M. H. Naderi, M. Soltanolkotabi and R. Roknizadeh, Journal of the Physical Society of\nJapan 73, 2413-2423 (2004).\n[25] G. Dresselhaus, Phys. Rev. 100, 580 (1955).\n[26] For a recent review on spintronics, see\nJ. Schliemann, e-print arXiv:cond-mat/0602330.\n[27] S-Q. Shen, Y-J Bao, M. Ma, X. C. Xie and F. C. Zhang, Phys. Rev. B 71, 155316 (2005).\n[28] S-Q. Shen, M. Ma, X. C. Xie and F. C. Zhang, Phys. Rev. Lett. 92, 256603 (2004).\n[29] S. T. Ali and F. Bagarello, J. Math. Phys. 46, 053518 (2004).\n[30] J-P. Gazeau and J. R. Klauder, J. Phys. A: Math. Gen. 32, 123 (1999).\n[31] J-P. Antoine, J-P. Gazeau, P. Monceau, J. R. Klauder and K. A. Penson, J. Math. Phys.\n42, 2349 (2001).\n[32] S. T. Ali, J-P. Antoine and J-P. Gazeau, Coherent States, Wavelets and their Generaliza-\ntions (Springer-Verlag, Berlin, 2000).\n[33] F. G. Scholtz, B. Chakraborty, S. Gangopadhyay and J. Govaerts, J. Phys. A: Math. Gen.\n38, 9849-9858 (2005).\n[34] F. G. Scholtz, B. Chakraborty, S. Gangopadhyay and A. Ghosh Hazra, Phys. Rev. D 71,\n085005 (2005).\n[35] J. Ben Geloun, J. Govaerts and M. N. Hounkonnou, A (p,q)-deformed Landau problem\nin a spherical harmonic well: spectrum and noncommuting coordinates, preprint ICMPA-\nMPA/2006/22, CP3-06-12, e-print arXiv:hep-th/0609120, submitted to J. Phys. A: Math.\nGen.\n[36] M. N. Hounkonnou and K. Sodoga, J. Phys. A: Math. Gen. 38, 7851-7862 (2005).\n[37] For an exhaustive dicussion on the moment problem, see for instance\nB. Simon, Adv. Math. 137, 82-203 (1998).\n[38] J. R. Klauder, Contribution to the 7th ICSSUR Conference, June 2001, e-print\narXiv:quant-ph/0110108.\n[39] A. Kempf, J. Math. Phys. 35, 4483 (1994);\nH. Hinrichsen and A. Kempf, J. Math. Phys. 37, 2121 (1996).\n24\n[40] C. Quesne, K. A. Penson and V. M. Tkachuk, Phys. Lett. A 313, 29-36 (2003).\n[41] C. Quesne, J. Phys. A: Math. Gen. 35, 9213-9226 (2002).\n[42] K. A. Penson and A. I. Solomon, J. Math. Phys. 40, 2354 (1999).\n[43] C. Aragone and F. Zypman, J. Phys. A: Math. Gen. 19, 2267-2279 (1986).\n[44] M. Orszag and S. Salamo, J. Phys. A: Math. Gen. 21, L1059-L1064 (1988).\n[45] F. Cooper, A. Khare and U. Sukhatme, Supersymmetry in Quantum Mechanics 2nd Ed.\n(World Scientific, Singapore, 2004).\n[46] G. Gasper and M. Rahman, Basic Hypergeometric Series (Cambridge Univ. Press, Cam-\nbridge, 1990).\n25\n"}
{"id":"oai:arXiv.org:q-bio/0601020","text":"arXiv:quant-ph/0602178v2  17 May 2006\nDuality, Phase Structures and Dilemmas in Symmetric Quantum Games\nTsubasa Ichikawa and Izumi Tsutsui\nHigh Energy Accelerator Research Organization (KEK), Tsukuba, Ibaraki 305-0801, Japan\n(Dated: February 22, 2006)\nSymmetric quantum games for 2-player, 2-qubit strategies are analyzed in detail by using a scheme\nin which all pure states in the 2-qubit Hilbert space are utilized for strategies. We consider two\ndifferent types of symmetric games exemplified by the familiar games, the Battle of the Sexes (BoS)\nand the Prisoners? Dilemma (PD). These two types of symmetric games are shown to be related by a\nduality map, which ensures that they share common phase structures with respect to the equilibria\nof the strategies. We find eight distinct phase structures possible for the symmetric games, which\nare determined by the classical payoff matrices from which the quantum games are defined. We\nalso discuss the possibility of resolving the dilemmas in the classical BoS, PD and the Stag Hunt\n(SH) game based on the phase structures obtained in the quantum games. It is observed that\nquantization cannot resolve the dilemma fully for the BoS, while it generically can for the PD and\nSH if appropriate correlations for the strategies of the players are provided.\nPACS numbers: 02.50.Le, 03.67.-a, 87.23.Ge\nKeywords: quantum mechanics, game theory, entanglement\nI. INTRODUCTION\nQuantum game theory has attracted much attention\nin recent years as an interesting attempt to expand the\nscope of the conventional (classical) game theory, which\nis now a standard tool in various fields, most notably in\neconomics, for analyzing decision making processes. The\nmain thrust in the investigation of quantum game has\ncome from the remarkable observation by Eisert et al. [1]\nthat the famous dilemma in the Prisoners?Dilemma (PD)\ngame can be resolved if the players resort to strategies\navailable in quantum theory. Subsequently, Marinatto\nand Weber [2] examined the dilemma in the Battle of\nthe Sexes (BoS) game, another typical dilemma in game\ntheory, and observed that this, too, could be resolved\nby adopting a quantum strategy involving a maximally\nentangled state. Application of quantum strategies to\nvarious other games, such as the Stag Hunt (SH) or the\nSamaritan?s Dilemma game, has also been discussed in\n[3].\nThese studies of the quantum games presented in [1, 3]\nand [2] employ different schemes of quantum strategies,\nand it has turned out that the outcome of the analysis is\nhighly dependent on the scheme used. In fact, it has been\npointed out in [4, 5, 6] that in the scheme used in [1, 3]\nthe dilemma in PD can be resolved only if the strategic\nspace is restricted artificially, while a more recent study\n[7] shows that there exists a new scheme in which the\ndilemma can be resolved even with a full strategic space.\nSimilarly, the resolution of the dilemma in the BoS has\nbeen argued using different reasonings depending on the\nschemes [3, 8, 9] (for a generalized scheme, with no analy-\nsis on dilemmas, see [10]), casting a doubt on the genuine\nnature of the resolution and, more importantly, the uni-\nversality of the outcomes of quantum game in general.\nThe distinction among these schemes can be found in\nthe definitions of quantum strategy, the strategic space\nwhich the players can exploit, and the way the quan-\ntum correlation (entanglement) is furnished. These dif-\nferences are crucial, because (as observed in [4, 5, 6])\ndifferent strategic spaces admit different stable solutions,\nand moreover the amount of entanglement required to\nresolve the dilemma will depend on the stage in the pro-\ncess it is measured. Despite of this scheme-dependence,\nwe have found in [7] an intriguing phase structure for the\nquantum PD game, which is reminiscent of the ?phase\ntransition? of equilibrium solutions discovered earlier in\n[11] in a different scheme. This suggests that the phase\nstructures may exhibit a scheme-independent, intrinsic\nfeatures of quantum games under consideration.\nThe aim of the present paper is to support this idea by\nproviding a convenient tool to analyze quantum games\nin general terms. We consider 2-player, 2-qubit strategy\ngames, which are the simplest nontrivial and yet have not\nbeen fully analyzed. Using the scheme introduced in [7],\nwe study in detail two types of ?symmetric games?, exem-\nplified by the BoS and PD games, respectively. We show\nthat these two types of games are actually related by a\nduality map, which brings a game in one symmetric type\ninto a game in the other symmetric type without chang-\ning the payoff in effect. This is convenient because then\nwe can use the outcome of the analysis of the BoS for the\nstudy of the PD, for instance. A quantum game may be\nregarded as a family of games provided by quantum cor-\nrelations which are absent in classical settings, and our\ngeometric picture used to portray the correlation-family\nin this paper turns out to be quite convenient, espe-\ncially for analyzing the phase structures of the game. We\nshall then see that symmetric games admit eight differ-\nent types of phase structures with regard to the possible\nstable strategies (related to classical strategies) preferred\nby the players, and that these types are determined by\nthe original classical games. With these phase structures,\nwe find that the dilemma in the BoS cannot be resolved\nfully in our scheme, albeit alleviated to some extent [2],\nirrespective of the amount of entanglement provided. In\n2\ncontrast, the dilemma of the PD game can be resolved if\na certain amount of correlationsare introduced. An anal-\nogous conclusion will also be drawn for the SH game, for\nwhich we find rather intricate phase structures for the full\nstable strategies compared to the BoS and PD games.\nThe plan of the paper is as follows. We first introduce\nour scheme of quantum gamein section II and present the\nduality map between the two types of symmetric games.\nThe phase structures of the symmetric games are studied\nin section III. Section IV is devoted to the analysis of the\nBoS, PD and SH games, where we examine the resolution\nof the dilemmas based on the results obtained in section\nIII. Finally, we give our conclusion and discussions in\nsection V.\nII. QUANTUM GAME AND DUALITY FOR\nSYMMETRIC GAMES\nTo begin with, we first recapitulate the classical 2-\nplayer, 2-strategy game and then introduce its quantum\nversion following [7]. Let i = 0,1, j = 0,1 be the la-\nbels of the strategies available for the players, Alice and\nBob, respectively, and let also Aij and Bij be their pay-\noffs when their joint strategy is (i,j). In classical game\ntheory, the game is said to be ?symmetric? if Bji = Aij,\nthat is, if their payoffs coincide when their strategies are\nswapped (i,j) ? (j,i). To make a distinction from the\nother symmetry discussed shortly, we call such a game\nS-symmetric in this paper. The PD and other famil-\niar games such as the SH and the Chicken game (see,\ne.g., [3, 12]) are S-symmetric games. Similarly, we call\nthe game T-symmetric if B1?j,1?i = Aij, that is, if the\npayoff matrices coincide when the strategies of the two\nplayers are ?twisted? as (i,j) ? (1 ? j,1 ? i). The BoS\nis an example of T-symmetric games with the additional\nproperty A01 = A10. The payoffs in these S-symmetric\nand T-symmetric games are displayed in the form of the\nbi-matrix (Aij,Bij) in Table I.\nGiven a payoff matrix, each player tries to maximize\nhis/her payoff by choosing the best possible strategy, and\nif there exists a pair of strategies in which no player can\nbring him/her in a better position by deviating from it\nunilaterally, we call it a Nash equilibrium (NE) of the\ngame. The players will be happy if the NE is unique\nand fulfills certain conditions attached to the game (e.g.,\nPareto-optimality or risk-dominance as mentioned later).\nEven when there are more than one NE, the players will\nstill be satisfied if a particular NE can be selected over\nthe other upon using some reasonings. Otherwise, the\nplayers may face a dilemma, as they do in the case of the\nBoS and the PD.\nTo introduce a quantum version of the classical game,\nwe first regard Alice?s strategies i as vectors in a Hilbert\nspace HA of a qubit. Namely, corresponding to the clas-\nsical strategies i we consider vectors |i?A for i = 0 and 1\nwhich are orthonormal in HA. A general quantum strat-\negyavailablefor Alice is then representedbya normalized\nS-symmetric:\nstrategy Bob 0 Bob 1\nAlice 0 (A00,A00) (A01,A10)\nAlice 1 (A10,A01) (A11,A11)\nT-symmetric:\nstrategy Bob 0 Bob 1\nAlice 0 (A00,A11) (A01,A01)\nAlice 1 (A10,A10) (A11,A00)\nTABLE I: Payoff bi-matrices (Aij,Bij) of the S-symmetric\ngame (above) and the T-symmetric game (below).\nvector |??A (with the overall phase ignored, i.e., a unit\nray) in HA. Bob?s strategy is similarly represented by\na normalized vector |??B in another qubit Hilbert space\nHB spanned by orthonormal vectors |j?B for j = 0 and\n1 in HB. The strategies of the players can thus be ex-\npressed in the linear combinations,\n|??A =\nsummationdisplay\ni\n?i(?)|i?A ,\n|??B =\nsummationdisplay\nj\n?j(?)|j?B ,\n(2.1)\nusing the bases |i?A, |j?B which correspond to the clas-\nsical strategies, with complex coefficients ?i(?), ?j(?)\nwhich are functions of the parameters ? and ? normal-\nized as summationtexti|?i|2 = summationtextj |?j|2 = 1. The strategies of the\nindividual players are, therefore, realized by local actions\nimplemented by the players independently.\nThe joint strategy of the players, on the other hand,\nis given by a vector in the direct product Hilbert space\nH = HA ?HB. Here lies one of the crucial differences\nbetween the classical and quantum games: in quantum\ngame theory, the joint strategy is specified not just by the\nchoice of the strategies of the players but also by furnish-\ning the quantum correlation (essentially the entangle-\nment) between the individual strategies. Consequently,\nthe outcome of a quantum game rests also on a third\nparty (or referee) that determines the correlation. To be\nmore explicit, using the product vector|?,?? = |??A|??B\nwhich is uniquely specified by the individual strategies,\na vector in the total strategy space H is written as\n|?,?;?? = J(?)|?,?? = J(?)|??A|??B , (2.2)\nwhere J(?) is a unitary operator providing the quantum\ncorrelation between the individual strategies. The corre-\nlation factor J(?) with the parameter set ? is designed to\nexhaust all possible joint strategies available in H. The\npayoffs for Alice and Bob are then given by the expecta-\ntion values of some appropriate self-adjoint operators A\nand B, respectively:\n?A(?,?;?) = ??,?;?|A|?,?;??,\n?B(?,?;?) = ??,?;?|B|?,?;??. (2.3)\nTo sum up, a quantum game is defined formally by the\ntriplet {H,A,B}.\n3\nTo choose the payoff operators A and B, we require\nthat, in the absence of quantum correlations J(?) = I\n(I is the identity operator in H), the payoff values re-\nduce to the classical ones when the players choose the\n?semiclassical (pure) strategies? |i,j? = |i?A|j?B,\n?i?,j?|A|i,j? = Aij?i?i?j?j,\n?i?,j?|B|i,j? = Bij?i?i?j?j. (2.4)\nAdopting, for simplicity, the value ? = 0 for the refer-\nence point at which J(?) = I holds, we find that, for\nthe uncorrelated product strategies |?,?;0? = |?,??, the\npayoffs (2.3) become\n?A(?,?;0) = ??,?;0|A|?,?;0? =\nsummationdisplay\ni,j\nxiAijyj,\n?B(?,?;0) = ??,?;0|B|?,?;0? =\nsummationdisplay\ni,j\nxiBijyj,\n(2.5)\nwhere xi = |?i|2, yj = |?j|2 represent the probability\nof realizing the strategies |i?A, |j?B under the general\nchoice |??A, |??B (see (2.1)). This ensures the exis-\ntence of a classical limit at which the quantum game\nreduces to the classical game defined by the payoff ma-\ntrix Aij, where now Alice and Bob are allowed to adopt\nmixed strategies (see, e.g., [13]) with probability distri-\nbutions xi, yj (summationtextxi = summationtextyj = 1) for strategies i, j.\nWe thus see that the quantum game is an extension of\nthe classical game, in which the correlation parameter ?\nplays a role similar to the Planck constant planckover2pi1 in quantum\nphysics in the technical sense that the classical limit is\nobtained by their vanishing limit. Note that, since the set\n{|i,j?, i,j = 0,1} forms a basis set in the entire Hilbert\nspace H, the payoff operators A and B are uniquely de-\ntermined from the classical payoff matrices by (2.4); in\nother words, our quantization is unique.\nThe aforementioned symmetries in classical game can\nalso be incorporated into quantum game by using cor-\nresponding appropriate symmetry operators. Indeed, by\nintroducing the swap operator\nS|i,j? = |j,i?, (2.6)\nwe see immediately that in the classical limit the game\nis S-symmetric, ?B(?,?;0) = ?A(?,?;0), provided that\nthe payoff operators A and B fulfill\nB = SAS. (2.7)\nAnalogously, if we introduce the notation ?i = 1 ? i for\ni = 0,1 (i.e., ?0 = 1 and ?1 = 0) and thereby the twist\noperator,\nT|i,j? = |?j,?i?, (2.8)\nand the twisted states,\nvextendsinglevextendsingle??, ??angbracketrightbig := T |?,?? = summationdisplay\ni,j\n?i(?)?j(?)|?j,?i?, (2.9)\nwe find that in the classial limit the game is T-symmetric,\n?B(??, ??;0) = ?A(?,?;0), provided that the operators\nfulfill\nB = T AT. (2.10)\nThe symmetries can be elevated to the full quantum\nlevel if we adopt the correlation factor in the form [7],\nJ(?) = ei?1S/2ei?2T/2, (2.11)\nwith real parameters ?i ? [0,2pi) for i = 1,2 [17]. In fact,\none can readily confirm, using [S,T] = ST ? TS = 0,\nthat under (2.10) the game is S-symmetric\n?B(?,?;?) = ?A(?,?;?), (2.12)\neven in the presence of the correlation (2.11). Similarly,\nthe game is T-symmetric\n?B(??, ??;?) = ?A(?,?;?), (2.13)\nif (2.10) is fulfilled. Since the correlation parameters in\n? are arbitrary, the properties (2.12), (2.13) imply that\na symmetric quantum game consists of a (?-parameter)\nfamily of games with the (S or T) symmetry exhibited\nfor each ?.\nIt is interesting to observe that these two types of sym-\nmetric games are actually related by unitary transforma-\ntions. To see this, let us introduce the operator CA which\nimplements the conversion for Alice?s strategies,\nCA|i,j? = |?i,j?. (2.14)\nNote that CA satisfies\nCA SCA = T, CA T CA = S. (2.15)\nConsider then the transformation of strategy by unilat-\neral conversion by Alice,\n|?,?;??? CA|?,?;??. (2.16)\nOn account of the relation (2.14) and the form of the\ncorrelation (2.11), we find\nCA|?,?;?? = |??,?;???, (2.17)\nwith ?? given by\n(??1,??2) = (?2,?1). (2.18)\nIn addition, one may also consider the transformation\non the payoff operators,\nA ? ?A = CA ACA, B ? ?B = CA BCA. (2.19)\nOne then observesthat, if the game is S-symmetricfulfill-\ning (2.7), the game defined by the transformed operators\nbecomes T-symmetric,\n?B = T ?AT. (2.20)\n4\nAnalogously, if the game is T-symmetric fulfilling (2.10),\nthen the transformed operators define an S-symmetric\ngame,\n?B = S ?AS. (2.21)\nThis shows that the conversion CA in (2.14) provides\na one-to-one correspondence, or duality, between an S-\nsymmetric game and a T-symmetric game. Some quan-\ntities in quantum game are invariant under the duality\nmap while other are not. For instance, the trace of the\npayoff,\nTrA =\nsummationdisplay\ni,j\nAij = A00 +A01 +A10 +A11, (2.22)\nremains invariant TrA ? Tr ?A = TrA, whereas the al-\nternate trace defined by\n?(A) =\nsummationdisplay\ni,j\n(?)i+jAij = A00 ?A01 ?A10 +A11, (2.23)\nchanges the sign ?(A) ? ?( ?A) = ??(A).\nIn formal terms, the two games given by {H,A,B}and\n{H, ?A, ?B} are dual to each other in the sense that the\npayoff under the strategy |?,?;?? in one game is equiva-\nlent to the payoff under the dual strategy CA|?,?;?? =\n|??,?;??? in the other. In particular, if the former\ngame happens to be S-symmetric, then the latter is T-\nsymmetric, and vice versa. This allows us to regard any\ntwo games as ?identical? if their payoff operators are re-\nlated by the duality map (2.19).\nEvidently, the other conversionofthe strategiesby Bob\nCB|i,j? = |i,1?j? can also be used to provide a similar\nbut different duality. Besides, their combination,\nC = CA ?CB, (2.24)\nimplements the renaming of the strategies 0 ? 1 for both\nof the players, and yields a duality map which does not\nalter the type of symmetries of the game. These dual-\nity maps CA, CB and C are used later to identify games\ndefined from different classical payoff matrices. We men-\ntion that these dualities are actually a special case of the\nmore general ?gauge symmetry? in quantum game the-\nory, which is that the two games defined by {H,A,B}\nand {H,UAU?,UBU?} with some unitary operator U\nare dual to each other under the corresponding strategies\n|?,?;?? and U|?,?;??. Thus the identification of games\ncan be extended to those which are unitarily equivalent.\nIII. CLASSIFICATION OF T-SYMMETRIC\nGAMES\nThe foregoing argument suggeststhat in order to study\nthe two types of symmetric games it is sufficient to con-\nsider either one of the two. Moreover, even if the two\ngames are of the same symmetric type, a further identi-\nfication may be possible using the full conversion C. In\nview of this, in the following we choose the T-symmetric\ngames and analyze the pattern of the allowed equilibria\nthere. To start with, we furnish the definition of an equi-\nlibrium which corresponds to the NE in classical game\n[18]. A joint strategy |??,??? is called quantum Nash\nequilibrium (QNE), if it satisfies\n?A(??,??;?) ? ?A(?,??;?), (3.1)\nfor all ?, and also\n?B(??,??;?) ? ?B(??,?;?), (3.2)\nfor all ?. Note that the QNE is defined for a given ?\ntreated as a set of external parameters. Below, we study\nthe conditions for ? under which a QNE appears.\nTo evaluate the payoffs explicitly, we write the strate-\ngies as\n|??A = cos(?1/2)|0?A + sin(?1/2)ei?2|1?A,\n|??B = cos(?1/2)|0?B + sin(?1/2)ei?2|1?B, (3.3)\nwith angle parameters ?1,?1 ? [0,pi] and ?2,?2 ? [0,2pi).\nFor convenience, we henceforth adopt both of the ket\nnotations |?? and |i? with the convention that |0? and |1?\nrefer always to the latter notations. Using (3.3) we find\nthat, for a T-symmetric game fulfilling (2.10), the payoff\nfor Alice reads\n?A(?,?;?) = 14{TrA+?(A)cos?1 cos?1\n+I?+(?)cos?1 +I??(?)cos?1\n?I+(?)sin?1 sin?1 sin?2 cos?2\n?I?(?)sin?1 sin?1 cos?2 sin?2},\n(3.4)\nwhere we have defined\nI?(?) = G+(?)?G?(?),\nI??(?) = G?+(?)?G??(?), (3.5)\nwith\nG+(?) = (A00 ?A11)sin?2,\nG?+(?) = (A00 ?A11)cos?2,\nG?(?) = (A01 ?A10)sin?1,\nG??(?) = (A01 ?A10)cos?1.\n(3.6)\nThe payoff ?B(?,?;?) for Bob is readily obtained from\n(3.4) using the relation (2.13). The conditions for QNE\n(3.1) and (3.2) imply\n??i?A(?,??;?)|?? = 0,\n??i?B(??,?;?)|?? = 0, (3.7)\nfor i = 1,2. Besides, the Hessian matrices PA and PB\ngiven by\nPA(?,?;?)ij = ??i??j?A(?,?;?),\nPB(?,?;?)ij = ??i??j?B(?,?;?), (3.8)\n5\n|??,??? Hessian conditions ?A(??,??;?)\n|0,0? H+ > 0, H? > 0 [TrA+?(A)+ 2G?+]/4\n|0,1? H? < 0 [TrA??(A)+ 2G??]/4\n|1,0? H+ < 0 [TrA??(A)? 2G??]/4\n|1,1? H+ > 0, H? > 0 [TrA+?(A)? 2G?+]/4\nTABLE II: Hessian conditions and Alice?s payoffs for edge\nstrategies in T-symmetric games. Bob?s payoffs can be ob-\ntained from ?B(??,??;?) = ?A(???, ???;?).\nmust be both negative semi-deifinite,\nPA(??,??;?) ? 0, PB(??,??;?) ? 0. (3.9)\nUsing (3.4) we obtain, for example,\n??2?A(?,??;?)|?? = ???2?B(??,?;?)|??\n= 14 sin??1 sin??1 [I?(?)sin??2 sin??2\n?I+(?)cos??2 cos??2]. (3.10)\nThese conditions (3.7) and (3.9) will now be analyzed in\ndetail.\nA. Edge strategies\nFrom (3.10) we see that an obvious set of solutions for\n(3.7) are obtained if\nsin??1 = sin??1 = 0. (3.11)\nThese have solutions given by the semiclassical pure\nstrategies |i,j? for i,j = 0,1, i.e., the four ?edge? strate-\ngies,\n|0,0?, |1,1?, |0,1?, |1,0?, (3.12)\nwhich correspond to classical pure strategies (i,j). Note,\nhowever, that these quantum edge strategies differ from\nthe classical counterparts because the joint strategy is\ndetermined with the additional correlation factor J(?).\nNote also that on the edge strategies the unitary opera-\ntion J(?) yields only a one-parameter family of correla-\ntions for joint states |i,j;?? in (2.2), since one of the two\nfactors in (2.11) gives merely an overall phase.\nFor the edge states to become QNE, they also need to\nobey the Hessian conditions (3.9), which pose different\nrequirements for the states as\n|0,0? : H+(?) > 0, H?(?) > 0,\n|0,1? : H?(?) < 0,\n|1,0? : H+(?) < 0,\n|1,1? : H+(?) > 0, H?(?) > 0,\n(3.13)\nwhere we have used\nH?(?) = ?(A)?I?+(?), (3.14)\nlabel QNE characteristics\nBoS |0,0? and |1,1? none\nPD |1,0? or |0,1? not Pareto optimal\nSH |1,0? and |0,1? either payoff or risk dominant\nTABLE III: QNE and their characteristics in the domains\non the G?+-G?? plane classified by the labels of the classi-\ncal games. Both PD and SH games are mapped to their T-\nsymmetric dual versions.\nand ignored the cases of equalities for brevity. These con-\nditions and the payoffs for the edge solutions are sum-\nmarized in Table II. To see when these conditions are\nfulfilled for different ?, it is convenient to consider the\nplane coordinated by (G?+,G??) with G?? given in (3.6).\nOne then sees that, as shown in Figure 1, the entire pa-\nrameter region of ? is mapped to a rectangular area in\nthe centre of the G?+-G?? plane with the horizontal length\nLh and the vertical length Lv given by\nLh = 2|A00 ?A11|, Lv = 2|A01 ?A10|. (3.15)\nIt is worth noting that, at each of the midpoints of\nthe four edges, the operation J(?) can yield a maximally\nentangled joint strategy state. For instance, for A01 >\nA10 the midpoint (G?+,G??) = (0,Lv/2) corresponds\nto J(pi/2,0) under which the edge state |01? becomes\n(|01? + i|10?)/?2. Similarly, for A00 > A11 the mid-\npoint (G?+,G??) = (Lh/2,0) corresponds to J(0,pi/2) un-\nder which the edge state |00? becomes (|00?+i|11?)/?2.\nThe four corners of the rectangle, on the other hand, cor-\nrespond to J(mpi,npi) for m,n = 0,1, which are S, T, C,\nand I operations, and hence the resultant joint strategies\nare all unentangled. On the G?+-G?? plane, the Hessian\nconditions determine the domains of allowed edge QNE\nwhich are separated by the parallel lines H?(?) = 0 (see\nFigure 1). Observe that the allowed edge QNE are differ-\nent depending onthe domains, and that the combinations\nof the QNE change when the sign of ?(A) is reversed.\nNote that for ?(A) > 0 all edge strategies in (3.12) could\narise as a QNE for some ?, whereas for ?(A) < 0 only\n|0,1? and/or |1,0? become QNE.\nAs will be seen shortly, as long as the edge strategies\nareconcerned our quantum gameis simulated by classical\ngames possessing the corresponding NE. In view of this,\nwe may characterize the domains on the G?+-G?? plane\nby the typical classical games sharing the same NE. We\ndo this by using the BoS, PD and SH as the representa-\ntives (see Table III). Here, the label ?BoS? is chosen to\ndesignate the domain of games possessing two edge QNE\nat |0,0? and |1,1?, which is an obvious choice because\nthe classical BoS game is T-symmetric and has the cor-\nresponding NE at (i,j) = (0,0) and (1,1). None of these\nNE admits better payoffs to both of the players, simulta-\nneously, leading to the dilemma that they cannot decide\non which strategy the should choose. The domain ?BoS?\narises only for ?(A) > 0 and the required conditions are\nBoS : H+ < 0, H? < 0. (3.16)\n6\nG?+\nG??\n? > 0\nH? = 0H+ = 0\n|0,1?\n|1,0?\nBoS\nPD\nPD\nG?+\nG??\n? < 0\nH+ = 0H? = 0\n|0,1?\n|1,0?\nSH\nSH\nPD\nPD\nFIG. 1: Phase structures of QNE in terms of edge strategies: ?(A) > 0 (above), ?(A) < 0 (below). The names of the domains\nare borrowed from the classical games sharing the same characteristic dilemmas (see Table III). Games in the domains without\nnames are free from dilemmas within edge strategies and possess a single stable strategy |1,0? or |0,1? among at most two QNE.\nThe correlation family of a quantum game forms a rectangle on the plane, as shown by the dotted line for the case ?(A) > 0.\nThe domain fulfilling these forms a diagonal strip be-\ntween the parallel lines H? = 0 on the G?+-G?? plane\n(see Figure 1).\nTo justify the assignment of the other labels, recall\nthat the classical PD game is an S-symmetric game and\nhas a NE at (1,1) which is unique. The problem of the\ngame is that the NE is not Pareto optimal, i.e., there\nexists another strategy which improves the payoffs for\nthe two players, simultaneously, and this constitutes the\ndilemma. Upon quantization, the quantum PD, in the\nclassical limit, will have one edge QNE at |1,1?, which\nturns into |0,1? by the duality map (2.14) when it is\nemployed to convert the PD into the T-symmetric dual\nversion. For this reason, we use ?PD? to label the do-\nmain of those T-symmetric games possessing the edge\nQNE at |0,1? which is not Pareto optimal. The Pareto\noptimality can be examined by comparing the payoff val-\nues with other strategies, and in the present case this\nis done essentially by comparing the payoffs between the\ntwo strategies|1,0? and |0,1?. From Table II, we see that\nthis situation occurs when\nPD : H+ > 0, H? < 0, G?? < 0. (3.17)\nWe also use the same label ?PD? for the domain of games\npossessing a QNE at |1,0? which is not Pareto optimal,\nsince thoseareidentified bythe full conversionC in (2.24)\nwith the standard quantum PD. This is the case when\nwe have\nPD : H+ < 0, H? > 0, G?? > 0. (3.18)\nAs shown in Figure 1, the domains of PD appear both\nfor ?(A) > 0 and ?(A) < 0.\nThe classical SH game, on the other hand, is an S-\nsymmetric game which has two NE at (0,0) and (1,1),\nin which (0,0) is payoff dominant (i.e., better than (1,1)\nin the payoff) and (1,1)is risk dominant (i.e., better than\n(0,0) in the ?average? over the choice of the other player).\nThe dilemma is that, while (0,0) is Pareto optimal, (1,1)\nis preferable for the minimal risk, which makes the play-\ners uncertain to decide which to choose. Now, after the\nquantization and the application of the duality map to\nget the T-symmetric quantum version of the game, we\nwill have two edge QNE at |1,0? and |0,1? in the classi-\ncal limit, with payoff dominant |1,0? and risk dominant\n|0,1?. We therefore use the label ?SH? to name the do-\nmain in which the games possess the same QNE with the\nabove property. In the presence of correlations, we find\nfrom Table II that the payoff dominance of |1,0? requires\nG?? < 0. The risk dominance of |0,1? demands that the\naverage payoff Alice receives under the choice |0?A be\nlarger than that obtained under the choice |1?A, which\nis ensured if G?+ + G?? > 0. As in the case of the PD,\nthe label ?SH? is also used for the domain of games pos-\nsessing the two QNE with payoff dominant |0,1? and risk\ndominant |1,0? for Alice, which are possible if G?? > 0\nand G?+ + G?? < 0. These domains ?SH? are allowed\nonly for ?(A) < 0 where |1,0? and |0,1? arise as QNE\nbetween the two parallel lines H? = 0 on the G?+-G??\nplane. Combined with the above additional conditions,\nthe SH domains are characterized by\nSH : H+ > 0, H? > 0, G??(G?+ +G??) < 0. (3.19)\nAs shown in Figure 1, the classification of the games\nleavesunlabeled domains on the G?+-G?? plane for each of\nthe cases ?(A) > 0 and ?(A) < 0. For ?(A) > 0, we find\ntwo separate domains which contain games possessing a\nunique QNE, either at |0,1? or |1,0?. These QNE are\nPareto optimal, and hence the games are free from the\ndilemma of the PD type. For ?(A) < 0, we have two ad-\nditional domains of games possessing QNE at |0,1? and\n|1,0?, which are free from the dilemma of the SH. This\nresult suggests that, if the game under consideration can\nbe driven to lie in these unlabeled domains by adjusting\nthe correlations appropriately, then the original dilemma\nmay be resolved under these correlations, at least within\nthe realm of edge strategies. In this respect, the phase\ndiagram given by Figure 1 provides a convenient basis to\nexamine the problem of optimality of strategies in quan-\ntum games.\nSince the correlation-family of a symmetric quantum\ngame is mapped to a rectangle on the G?+-G?? plane, we\ncan classify quantum games in terms of the patterns of\nthe rectangle formed on the plane. As shown in Figure\n7\nFIG. 2: Four patterns of rectangles which are possible in re-\nlation to the parallel lines H? = 0 provide distinct phase\nstructures for symmetric quantum games. The rectangle may\nreduce to a line as we see in the case of the BoS later.\n2, there are four types of rectangles, determined from\nthe values of Lh and Lv in (3.15), which are different\nin position with respect to the parallel lines H?(?) = 0\nappearing in Figure 1. Combining the two cases ?(A) > 0\nand?(A) < 0 whichoffer different structuresfor domains,\nwe find that there are altogether eight classes of quantum\ngames which have distinct phase structures of QNE in\nterms of edge strategies.\nOne of the advantages of the present quantization\nscheme is that it allows us to establish the connection\nbetween the classical and quantum games in a simple\nmanner and thereby examine how ?quantum? the game\nactually is. To see this, let us introduce the correlated\npayoff matrices\nA(?) = J?(?)AJ(?), B(?) = J?(?)BJ(?). (3.20)\nWith these, the payoffs (2.3) are expressed in terms of\nseparable (uncorrelated) states\n?A(?,?;?) = ??,?|A(?)|?,??,\n?B(?,?;?) = ??,?|B(?)|?,??. (3.21)\nOne may decompose each of the correlated payoffs into\n?pseudo-classical? and ?interference? terms as\nA(?) = Apc(?)+Ain(?), (3.22)\nwith\nApc(?) = cos2 ?12 A+ (cos2 ?22 ?cos2 ?12 )SAS\n+ sin2 ?22 C AC,\n(3.23)\nwhere C is given in (2.24) and\nAin(?) = i2 sin?1 [A,S] + i2 sin?2[A,T]. (3.24)\nThe pointis thatthe pseudo-classicalpartApc isdiagonal\nand hence for separable strategies it can be interpreted\nas a classical payoff matrix. In contrast, the interference\npart Apc is non-diagonal and represents a non-classical\ncontribution. Accordingly, the payoff for Alice in a T-\nsymmetric game is decomposed into the sum ?A = ?pcA +\n?inA, where we have\n?inA(?,?;?) = 0, (3.25)\nfor edge strategies. This observation confirms that our\nquantum game with edge strategies are, in effect, equiv-\nalent to the classical game with the payoff matrices Apc\nand Bpc (the latter can be defined analogously for the\ncorrelated payoff B(?)). Possible game theoretical inter-\npretations of the pseudo-classical payoff based on altru-\nism and value-conversion have been noted in Ref.[7].\nB. Non-edge strategies\nTo discuss QNE beyond the edge strategies (3.12), we\nrecall (2.13) and seek solutions which are T-symmetric,\n|??,??? = |???, ????. In the representation (3.3) of the\nstate (which is defined up to an overall phase), this trans-\nlates into\n??1 ???1 = pi, ??2 +??2 = pi. (3.26)\nUnder the T-symmetric ansatz and the non-edge require-\nment sin??1 negationslash= 0, the conditions in (3.7) imply\ncos??1 [?(A)?G?(?)sin2??2]?I?+(?) = 0,\nG?(?)cos2??2 +G+(?) = 0. (3.27)\nBesides, the Hessian condition (3.9) implies\nG? sin2??2 ? 0. (3.28)\nBefore analyzing the solutions in detail, we observe\nthat at the classical limit ? = 0 the above conditions are\nsimplified to the single condition,\ncos??1 = ?+(A)?(A) , (3.29)\nwith ?+(A) defined as\n??(A) = (A00 ?A11)?(A01 ?A10). (3.30)\nThe condition (3.29) has a solution when |?(A)| ?\n|?+(A)|, which is equivalent to\nA00 ? A10 and A11 ? A01, or\nA00 ? A10 and A11 ? A01. (3.31)\nThe solution for (3.29) corresponds to the NE for mixed\nstrategies in classical games with x?1 = y?1 = cos2(??1/2),\nand (3.31) agrees precisely with the conditions for such\nnontrivial NE to arise. It is important to note, how-\never, that the non-edge QNE in quantum game and the\nmixed NE in classical game are completely different in\nthe meaning of strategies. Namely, the NE in classical\ngame is relevant only for the situation where the games\n8\nFIG. 3: Possible patterns of allowed regions by (3.33) in the\nrectangle of the game under Lh < Lv (left), Lh = Lv (middle)\nand Lh > Lv (right). These regions are shaded, and the dot\nin the centre represents the origin of the G?+-G?? plane.\nare repeated many times in which the players can con-\nsider probability distributions in choosing their strategies\n? the mixed NE and pure NE belong to different cate-\ngories conceptually. In contrast, the non-edge QNE in\nquantum game is a pure strategy and meaningful with-\nout repeating the game ? it belongs to the same category\nas the edge QNE.\nTo discuss solutions for generic ?, we notice first that\nthe second condition in (3.27) determines ??2, which can\nbe used to determine ??1 in the first condition. In terms\nof ?(?) :=\nradicalBig\nG2? ?G2+ for which we have\n?2 = (G?+)2 ?(G??)2 ??+ ??, (3.32)\nthe condition for the existence of ??2 reads\n? ? 0. (3.33)\nNotice that ?+ ?? = (L2h ?L2v)/4 measures the squared\ndifference in length between the two edges of the rectan-\ngle of the game. It follows that the regions allowed by\n(3.33) are those enclosed by the two hyperbolae ?2 = 0\nand the edges of the rectangle, which vary depending on\nthe types of the rectangle (see Figure 3).\nOn the other hand, by combining the two conditions\nin (3.27) and (3.28) we see that the solution for ??1 exists\nif\n(H+ + ?)(H? + ?) ? 0. (3.34)\nUsing (3.32), one can readily depict the regions where\n(3.34) is fulfilled on the G?+-G?? plane. The games be-\nlonging to the overlapped areas of the above two regions\nadmit non-edge QNE, and this is indeed possible if the\npayoff A meets certain conditions, as illustrated by the\nSH game later. When this happens, the non-edge QNE,\nwhich we denote by |??,??;?? = |?ne,?ne;??, offers the\nsame payoff (as ensured by the T-symmetry) for Alice\nand Bob,\n?A(?ne,?ne;?) = ?B(?ne,?ne;?)\n= 14\nbracketleftbigg\nTrA+ ?(A)?(?)??+(A)??(A)?(A) + ?(?)\nbracketrightbigg\n. (3.35)\nIn particular, at the classical limit the payoff becomes\n?A(?ne,?ne;0) = A00A11 ?A01A10A\n00 +A11 ?A01 ?A10\n, (3.36)\nwhich is the familiar payoff expression for the mixed NE\nin classicalT-symmetricgames. This showsthat the non-\nedge QNE are actually an extension of the classicalmixed\nNE. In fact, at the classical limit, we find from ?(0) = 0\nthat the condition (3.33) is trivially fulfilled, and that\n(3.34) reduces to\nH+(0)H?(0) = 4(A00 ?A10)(A11 ?A01) ? 0, (3.37)\nwhich is exactly the condition for mixed NE (3.31). In\nother words, if the classical game admits a mixed NE,\nthen the quantum game defined from the classical game\nadmits a QNE for a certain range of correlations includ-\ning the classical limit.\nTo summarize, non-edge QNE may exist as an exten-\nsion of mixed NE under various correlations in quantum\ngame theory, and their existence can be examined from\nthe rectangle of the game specified from the classical pay-\noff matrix Aij. Game theoretical analysis, including the\nresolution of dilemma in classical game, should be made\nbased on the combination of edge and non-edge QNE.\nIV. DILEMMAS IN BOS, PD AND SH\nHaving obtained the phase structures of symmetric\nquantum games for edge QNE as well as the conditions\nfor non-edgeQNE,we nowexamineif andhowthe typical\ndilemmas familiar in classical game theory ? the dilem-\nmas in the BoS, the PD and the SH game ? can be re-\nsolved in quantum game theory. All of the dilemmas\nin these cases are intrinsically different, and there is no\nunique criterion for the resolution. We thus consider the\nresolution based on the conventional requirements which\nare attached to the respective classical games, and find\nthat the quantization of the games lead to considerably\ndifferent outcomes for the three cases.\nA. Battle of the Sexes\nThe BoS game is a special case of the T-symmetric\ngame specified by the payoff matrix,\nA00 > A11 > A01 = A10. (4.1)\nThe degeneracy A01 = A10 provides the T-symmetric\ngame with an extra symmetry between the payoff matri-\nces, that is,\nB = T AT = C AC. (4.2)\nOnaccountofthe degeneracy,we haveG?(?) = G??(?) =\n0, which implies that the parameter ?1 drops out from\nour consideration of QNE. Notice that the BoS defined\nby (4.1) has ?(A) > 0 and that, as shown in Figure 4, the\nrectangle of the game in the G?+-G?? plane is smashed to\na line on the G?+-axis with length Lh. Notice also from\nA00 > A11 that the classical limit is found at the right\n9\nend of the line. Now, an important point to observe is\nthat since\n?(A)?(A00 ?A11) = 2(A11 ?A01) > 0, (4.3)\nthe line segment of the game lies entirely within the BoS\ndomain (see Figure 4). This shows that, so far as the edge\nstrategies are concerned, even in the presence of the cor-\nrelation J(?), the dilemma in the BoS does not disappear\nin quantum game. Using (3.21) and (3.23), Alice finds\nher payoff ?A(i,i;?) at the edge QNE |??,??? = |i,i? for\ni = 0,1 as\n?A(i,i;?) = cos2 ?22 Aii + sin2 ?22 A?i?i. (4.4)\nNote that the correlationinterpolates between the largest\ntwo payoff values A00 and A11, and hence ?A(i,i;?) ?\nA11 for both of the edge QNE, i = 0,1.\nTo see if the dilemma can be resolved by taking non-\nedge QNE into account, we first observe that for BoS the\nconditions (3.27) are fulfilled for ?2 = 0, pi with arbitrary\n?1. For that non-edge QNE, the payoff ?A(?ne,?ne;?) in\n(3.35) reduces to (3.36) with A01 = A10. At ?1 = 0 this\nnon-edge QNE corresponds to the known mixed strategy\nNE in classical BoS, which cannot resolve the dilemma\nsince the payoffs are strictly less than those obtained un-\nder the two edge QNE for both of the players. The situa-\ntion doesnot improveevenfor?1 negationslash= 0, because the payoffs\nare independent of ?1 for all strategies. Moreover, on the\ngeneral basis of the assignments (4.1) (i.e., without mak-\ning use of the ansatz (3.26)), one can confirm by looking\nat the Hessian condition (3.9) that there is no non-edge\nQNE for BoS except for the one mentioned above. Thus\nwe find that under any correlations ? for the non-edge\nQNE we have ?A(?ne,?ne;?) < A11 and hence\n?A(i,i;?) > ?A(?ne,?ne;?), for i = 0,1. (4.5)\nAlthough the dilemma does not disappear even in\nquantum BoS, one may argue that the problem is some-\nwhat mitigated at?2 = pi/2 wherethe joint strategystate\nis maximally entangled. Indeed, under this correlation\nthe payoffs for the two edge QNE (4.18) for i = 0,1 coin-\ncide and hence the choice of strategies becomes irrelevant\nfor the players. The dilemma still remains in essence [16],\nhowever, because the players, who cannot communicate,\nmay inadvertently end up with a wrong strategy, |0,1? or\n|1,0?, yielding the worst payoff ?A = ?B = A01 (for all\n?). A similar conclusion has been drawn for BoS in [2, 8]\nusing a different quantization scheme with mixed quan-\ntum states, while a way out is suggested in an extended\nscheme [9]. The analysis [3] made in the scheme of [1]\nyields a considerably different outcome, with infinitely\nmany QNE with the payoffs lower than those of our edge\nQNE, indicating that the dilemma is unresolved unless\nsome subtle reasoning (focal point effect) is invoked.\nG?+\nG??\nCL\nME\nFIG. 4: Phase structure of edge QNE in the BoS game. The\nrectangle of the game is smashed to a line segment lying at the\ncentre as shown by the dotted line, which is entirely contained\nin the BoS domain. The right end point CL is the classical\nlimit and the middle point ME represents the point where the\nmaximally entangled correlation is realized.\nB. Prisoners? Dilemma\nThe PD game can also be analyzed in our scheme by\nconverting it to a dual T-symmetric game using the map\n(2.19). The general S-symmetric PD in classical game\ntheory may be defined by the payoff matrix for Alice Aij\nsatisfying\nA10 > A00 > A11 > A01, (4.6)\ntogether with Bob?s payoff given by Bij = Aji. Supple-\nmental conditions (which is inessential for the following\nargument),\n2A00 > A01 +A10 > 2A11, (4.7)\nmay also be imposed in order to render the strategies\n(i,j) = (0,0) and (1,1) the best and the worst of all\npossible strategies with respect to the sum of the payoffs\n[13]. The quantum PD is obtained by considering the\nself-adjointoperatorsA, B fulfilling (2.4), and the duality\nmap (2.19) yieldsthe T-symmetricversionof the PD with\nthe payoff operator ?A possessing the diagonal (classical)\nvalues\n( ?A00, ?A01, ?A10, ?A11) = (A10,A11,A00,A01). (4.8)\nIn terms of the converted payoff values, the conditions\n(4.6) and (4.7) turn out to be\n?A00 > ?A10 > ?A01 > ?A11, (4.9)\nand\n2 ?A10 > ?A00 + ?A11 > 2 ?A01. (4.10)\nNote that under the duality map for strategies (2.16) the\nparameters of the states (3.3) acquire the change\n(??1, ??2) = (?1 +pi, pi ??2). (4.11)\nIn addition, the duality relation in the correlation (2.18)\namounts to ?1 ? ?2 in G? and G??. To accommodate\nthese changes caused by the duality map, we use nota-\ntions such as\n?G? = G?|A? ?A,????, ?H? = H?|A? ?A,????, (4.12)\n10\nG?+\nG??\nCL\nG?+\nG??\nCL\nFIG. 5: Phase structure of edge QNE in the (T-symmetrized)\nPD game for the cases ?( ?A) > 0 (left) and ?( ?A) < 0 (right).\nFor both of the cases, the rectangle of the game, whose edges\nare shown by dotted lines, extends to domains of no dilemmas.\nfor our discussion of T-symmetric games.\nTo examine the possible phase structures of the game,\nwe observe that neither of the conditions (4.9) and (4.10)\ndetermines the sign of ?( ?A). However, since (4.9) implies\nthat the classical limit ? = 0 locates at the lower right\ncorner of the rectangle of the game, the inequalities\n?H+(0) = 2( ?A00 ? ?A10) > 0,\n?H?(0) = 2( ?A11 ? ?A10) < 0, (4.13)\nobtained at the classical limit ? = 0 from (4.9) are suf-\nficient to specify where the corner lies on the G?+-G??\nplane. The phase structures of the quantum PD game\nare then determined from the patterns of the rectangle\nin both of the cases ?( ?A) > 0 and ?( ?A) < 0, as illustrated\nin Figure 5. The outcome indicates that the correlation-\nfamily given by the rectangle does extend to domains of\nno dilemmas. It follows that, as long as edge QNE are\nconcerned, the quantum PD can be made dilemma-free\nwhen the correlations are furnished appropriately.\nFor a full resolution of the dilemma, we need to see\nwhether a non-edge QNE, if any, alters our conclusion\ndrawn from the edge QNE. This can be examined from\nthe analysis given in the previous section. We then learn\nthat, since the condition (3.31) is violated for (4.9), there\nis no non-edge QNE at the classical limit. We also re-\nalize that, for generic ?, the existence of non-edge QNE\nis dependent on the actual classical values of Aij, and\nthat for a wide range of payoff values centered at the\nstandard ones (A10,A00,A11,A01) = (5,3,1,0) used in\nthe literature (e.g., [1]), there exists no region fulfilling\n(3.33) and (3.34) simultaneously, and hence no non-edge\nQNE. Thus, our conclusion concerning the resolution of\nthe dilemma does not change in these standard settings\nof the PD game.\nC. Stag Hunt\nThe classical SH game is an S-symmetric game in\nwhich the payoff matrix for Alice fulfills the conditions,\nA00 > A10 ? A11 > A01, (4.14)\nwhich ensure that the strategies (0,0) and (1,1) are clas-\nsical NE. Among them, (0,0) is payoff dominant while\nG?+\nG??\nCL\nH+ + ? = 0\nH? + ? = 0\nFIG. 6: Phase structures of edge QNE (left) and non-edge\nQNE (right) in the (T-symmetrized) SH game. For edge\nQNE, the rectangle of the game extends to domains of no\ndilemmas. For non-edge QNE, the allowed regions by (3.33)\nare of the third type in Figure 3, and the two narrow regions\noverlapped with (3.34) shown in thick gray indicate the do-\nmains where a non-edge QNE appears.\nthe other (1,1) becomes risk dominant if\nA10 +A11 > A00 +A01. (4.15)\nAnalogously to the PD, we quantize the SH according to\n(2.4) and then T-symmetrizeit by the duality map (2.19).\nThis yields the payoffoperator ?A with the diagonalvalues\n(4.8) obeying\n?A10 > ?A00 ? ?A01 > ?A11, (4.16)\nand\n?A00 + ?A01 > ?A10 + ?A11. (4.17)\nNote that (4.16) implies ?( ?A) < 0. It also shows that\nthe classical limit is at the lower right corner of the rect-\nangle of the game, and that we have ?H?(0) < 0. From\nthis we can determine the position of the rectangle on the\nG?+-G?? plane as shown in Figure 6. The phase structure\nof the quantum SH game then suggests that, as in PD,\nthe correlation-family given by the rectangle extends to\ndomains without dilemmas. Within the edge strategies,\nthe dilemma of the SH can therefore be resolved in quan-\ntum game, if one adjusts the correlations appropriately.\nThe payoffs ?A(i,?i;?) at the edge QNE |??,??? = |i,?i?\nfor i = 0,1 read\n?A(i,?i;?) = cos2 ?12 ?Ai?i + sin2 ?12 ?A?ii, (4.18)\nwhich fall within the range of the payoffs of the two clas-\nsical NE, ?A10 ? ?A(i,?i;?) ? ?A01.\nThe classical SH game admits a mixed NE, and ac-\ncordingly the quantum SH admits a non-edge QNE for\na range of correlations including the classical limit, as\ncan be confirmed explicitly by examining the condition\n(3.37). To see where such correlations occur on the G?+-\nG?? plane, we consider the lines of equality H? + ? = 0\ndetermined by the condition (3.34), which are rewritten\nas\nG?+ = ?G?? ? ?\n2 +?+??\n2(G?? ??). (4.19)\n11\nCL:\nstrategy Bob |0? Bob |1? Bob |?ne?\nAlice |0? (3,0) (3,3) (3,3/4)\nAlice |1? (4,4) (0,3) (3,15/4)\nAlice |?ne? (15/4,3) (3/4,3) (3,3)\nME:\nstrategy Bob |0? Bob |1? Bob |?ne?\nAlice |0? (3,0) (7/2,7/2) (3,0)\nAlice |1? (7/2,7/2) (0,3) (7/2,7/2)\nAlice |?ne? (7/2,7/2) (0,3) (7/2,7/2)\nTABLE IV: Quantum payoff bi-matrices (?A,?B) of the SH\ngame for edge QNE and non-edge QNE. We used the values\n?A10 = 4, ?A00 = ?A01 = 3 and ?A11 = 0 (obtained from those\nmentioned in the text) to evaluate the payoffs at the classi-\ncal limit CL and the maximally entangled point ME, which\nare given by (G?+,G??) = (3,?1) and (3,0), respectively. The\npresence of the non-edge QNE worsens the risk balance be-\ntween the two edge QNE as we increase the amount of en-\ntanglement, but the dilemma disappears at ME where their\npayoffs become identical, for which the non-edge QNE does\nnot contribute.\nFor the SH we find ?2+?+?? > 0 from (4.16) and (4.17).\nThe domains where the non-edge QNE arise are then\nfound to be surrounded by the hyperbolae ? = 0 and\nthe curves (4.19), both of which come in contact at\n(G?+,G??) = ? 12? parenleftbig?2 +?+??,?2 ??+??parenrightbig. (4.20)\nAs illustrated in Figure 6, these domains are given by\ntwo narrow regions along the left and right edges of the\nrectangle of the game, indicating that under generic cor-\nrelations the non-edge QNE does not spoil the resolution\nof the dilemma in terms of edge QNE. It is, however,\nconceivable that the non-edge QNE, in the region where\nit is allowed, could alter the nature of the dilemmas, that\nis, the non-edge QNE could be both payoff and risk dom-\ninant under some particular correlations in the domains\nof SH, or it could pose a new dilemma in the domains\nwhere there was no dilemma originally. These possibili-\nties should be examined for the actual values of the payoff\nmatrix (4.16), but the analysis with the standard values\n(A00,A10,A11,A01) = (4,3,3,0) given in Table IV sug-\ngests that these are not likely to occur unless the payoff\nvalues are fine-tuned.\nV. CONCLUSION AND DISCUSSIONS\nIn this paper, we studied the phase structures of sym-\nmetric quantum games with respect to the stable strate-\ngies (QNE) available by pure states in quantum mechan-\nics. For quantization of classical games we adopted the\nscheme [7] which defines a unique correlation-family of\nquantum games from a classical game, allowing for all\npossible strategies realized by pure states, entangled or\nnot. The correlation-family is projected onto a rectangu-\nlar area in the G?+-G?? plane, where the phase structures\nof both the edge and non-edge QNE in the game can\nreadily be recognized. We have found that for symmet-\nric games there arise altogether eight different classes of\nphase structures for edge QNE depending on the payoff\nmatrices of the classical game we started with. This re-\nsult gives a more detailed account of the phase structures\nmentioned in [1] and discussed later in [5, 11].\nThe symmetric games considered in this paper consist\nof two types, T-symmetric and S-symmetric. We have\npresented a unified framework to treat them by means\nof a duality map, which enables us to use the results\nof the analysis of T-symmetric games for studying S-\nsymmetric games and vice versa. As an example of the\nT-symmetric game, we studied the BoS which is known\nto be a?icted with a dilemma classically. We have found\nthat the dilemma in the BoS cannot be resolved fully\n(albeit it can be alleviated) with strategies given by pure\nstates, even if we go over to quantum game where arbi-\ntrarily entangled states are utilized. Thus, the previous\nobservation made in [2, 8] remains essentially unchanged\neven in our enlarged scheme of quantum game, while the\noutcome is considerably different from those obtained in\nother schemes [3, 9]. As for the S-symmetric game, we\nexamined the PD and the SH to observe that for both of\nthe games the correlation-family contains a phase which\nis free from dilemmas under edge QNE. Since the stan-\ndard PD does not admit non-edge QNE, we concluded\nthat for the PD the classical dilemma disappears after\nquantization. For the SH, on the other hand, there ex-\nists a non-edge QNE which does not affect the resolution\nrealized by the edge QNE, generically. In short, quantum\nentanglement can resolve classical dilemmas for certain\ngames, and the games for which this is possible can be\njudged from the classical payoff matrices. We remark\nthat entanglement is necessary for the resolution of the\ndilemmas in our scheme, and that this is so in any other\nschemes of quantum games in which the resolution is pos-\nsible and the classical games are recovered in the limit\nwhere the joint strategies become separable as in (2.5).\nHowever, the actual amount of entanglement required de-\npends on the scheme used (because the class of families\nconsidered may be scheme-dependent) as well as on the\nvalues of the classical payoffs.\nCompared to most other schemes proposed so far, our\nscheme of quantum game is distinguished in the specifica-\ntion of strategies and correlations which are expressed in\nthe ordering of operations implementing them. Namely,\nin our scheme the players first make their choice of strate-\ngies independently, by performing the corresponding lo-\ncal unitary transformations on a fixed separable state,\nbefore a third party furnishes a correlation for the local\nstates. The player?s strategy is represented by a quantum\nstate, not by the local unitary transformation as consid-\nered in [1]. The advantage for this is that different pure\nstates used to specify the strategies yield different out-\ncomes of the payoff in general, while this is not ensured\nif unitary transformations are regarded as strategies. In\n12\nfact, it has been pointed out [6] that unitary transfor-\nmations become redundant (i.e., different unitary oper-\nations give the same quantum states) when the strate-\ngies are maximally entangled. Obviously, the choice of\nquantization scheme is directly related to the question of\nthe role of the third party which provides the quantum\ncorrelation in the game, and this has not been fully ex-\nplored yet. In this regard, we have found here a number\nof interesting features of quantum games which are com-\nmonly observed in various different schemes, in the phase\nstructures of the QNE and the resolution of dilemmas in\nsome of the familiar games. We hope that these findings\nwill help uncover the core elements ? independent of the\nscheme employed ? in quantum games, which are crucial\nfor laying a solid foundation of quantum game theory.\nAcknowledgments\nWe thank T. Cheon for helpful discussions. This work\nis supported by the Grant-in-Aid for Scientific Research,\nNo.13135206and No.16540354,ofthe JapaneseMinistry\nof Education, Science, Sports and Culture.\n[1] J. Eisert, M. Wilkens and M. Lewenstein, Quantum\ngames and quantum strategies, Phys. Rev. Lett. 83\n(1999) 3077-3080.\n[2] L. Marinatto and T. Weber, A quantum approach to\nstatic games of complete information, Phys. Lett. A272\n(2000) 291-303.\n[3] J. Shimamura, S. K. ?Ozdemir, F. Morikoshi and N.\nImoto, Quantum and classical correlations between play-\ners in game theory, Int.Journ. Quant.Inf.2(2004) 79-89.\n[4] J. Eisert and M. Wilkens, Quantum Games, J. Mod. Opt.\n47 (2000) 2543-2556.\n[5] J. Du, X. Xu, H. Li, X. Zhou and R. Han, Playing Pris-\noner?s Dilemma with Quantum Rules, Fluct. and Noise\nLett. 2 (2002) 189-203.\n[6] S. C. Benjamin and P. M. Hayden, Comment on ?Quan-\ntum Games and Quantum Strategies?, Phys. Rev. Lett.\n87 (2001) 069801.\n[7] T. Cheon and I. Tsutsui, Classical and Quantum Con-\ntents of Solvable Game Theory on Hilbert Space, Phys.\nLett. A348 (2006) 147-152\n[8] L. Marinatto and T. Weber, Reply to ?Comment on: A\nQuantum Approach to Static Games of Complete Infor-\nmation?, Phys. Lett. A277 (2000) 183-184.\n[9] A. Nawaz and A. H. Toor, Dilemma and Quantum Battle\nof Sexes, J. Phys. A: Math. Gen. 37 (2004) 4437-4443.\n[10] A. Nawaz and A. H. Toor, Generalized Quantization\nScheme for Two-Person Non-Zero-Sum Games, J. Phys.\nA: Math. Gen. 37 (2004) 11457-11463.\n[11] J. Du, X. Xu, H. Li, X. Zhou and R. Han, Experimental\nrealization of quantum games on a quantum computer,\nPhys. Rev. Lett. 88 (2002) 137902.\n[12] A. P. Flitney and D. Abbott, Advantage of a quantum\nplayer over a classical one in 2x2 quantum games, Poc\n.R. Soc. (London) A459 (2003) 2463-2474.\n[13] E. Rasmusen, An Introduction to Game Theory, Cam-\nbridge Univ. Press, Cambridge, 1989.\n[14] J. F. Nash, Equilibrium points in N-person games, Proc.\nNat. Acad. Sci. U.S.A. 36 (1950) 48-49.\n[15] C. F. Lee and N. Johnson, Quantum Game Theory, Phys.\nRev. A67 (2003) 022311.\n[16] S. C. Benjamin, Comment on ?A quantum approach to\nstatic games of complete information?, Phys. Lett. A277\n(2000) 180-182.\n[17] Apart from the irrelevant freedoms concerning the over-\nall phase and the normalization, the dimensionality of the\njoint strategy space is dimH ? 2 = 6 in real variables.\nSince the individual strategies |??A and |??B are specified\nby 2 + 2 = 4 parameters (e.g., see (3.3)), the correlation\nfactor must have another 2 parameters to cover the full\njoint strategy space. The actual construction of the cor-\nrelation factor is far from unique, and our form (2.11) is\nadopted based on the convenience for the duality map.\n[18] In the present paper, we consider quantum joint strate-\ngies given by pure states only. The space of pure states is\nnot convex, and hence the Nash theorem [14], which en-\nsures the existence of NE for a classical game with mixed\nstrategies, is no longer available. The existence of QNE\nin quantum game is, therefore, non-trivial [15].\n"}
{"id":"oai:arXiv.org:q-bio/0601020","text":"arXiv:hep-ph/0610379v2  12 Jul 2007\nDirect detection of neutralino dark matter in non-standard\ncosmologies\nGraciela B. Gelmini,1, ? Paolo Gondolo,2, ? Adrian Soldatenko,1, ? and Carlos E. Yaguna1, ?\n1Department of Physics and Astronomy, UCLA,\n475 Portola Plaza, Los Angeles, CA 90095, USA\n2Department of Physics, University of Utah,\n115 S 1400 E # 201, Salt Lake City, UT 84112, USA\nAbstract\nWe compute the neutralino direct detection rate in non-standard cosmological scenarios where\nneutralinos account for the dark matter of the Universe. Significant differences are found when\nsuch rates are compared with those predicted by the standard cosmological model. For bino-\nlike neutralinos, the main feature is the presence of additional light (m? lessorsimilar 40 GeV) and heavy\n(m? greaterorsimilar 600 GeV) neutralinos with detection rates within the sensitivity of future dark matter\nexperiments. For higgsino- and wino-like neutralinos lighter than m? ? 1 TeV, enhancements of\nmore than two orders of magnitude in the largest detection rates are observed. Thus, if dark matter\nis made up of neutralinos, the prospects for their direct detection are in general more promising\nthan in the standard cosmology.\n?Electronic address: gelmini@physics.ucla.edu\n?Electronic address: paolo@physics.utah.edu\n?Electronic address: asold@physics.ucla.edu\n?Electronic address: yaguna@physics.ucla.edu\n1\nI. INTRODUCTION\nThe Large Hadron Collider is now in its final preparation stages and may soon be search-\ning for supersymmetric particles. Among them, the lightest neutralino in the minimal su-\npersymmetric standard model plays a distinctive role as a dark matter candidate [1]. It is\nneutral, weakly interacting, and stable (provided it is the lightest supersymmetric particle).\nIf evidence for low energy supersymmetry is found, it will strongly support the idea that\nneutralinos constitute the dark matter of the Universe. A logical next step would then be\nthe use of neutralinos as cosmological probes of the early Universe. Neutralinos could, in\nparticular, test the standard cosmological model well before big bang nucleosynthesis. Being\nan observable sensitive to the conditions in the early Universe, the neutralino direct detec-\ntion rate provides a plausible way of discriminating between different cosmological models,\nand therefore an indirect way of testing the standard scenario. Most studies on the direct\ndetection of neutralinos already assume the standard cosmology so it is not known what to\nexpect in a more general cosmological framework.\nThe vastness of the supersymmetric parameter space is the most compelling reason to\nassume the standard cosmological model. In a general setup, neither the neutralino mass\nor gauge composition nor its interaction rate, for example, can be determined a priori. To\nreduce such uncertainties, the dark matter constraint is usually imposed on supersymmetric\nmodels. That is, the neutralino relic density is computed within the standard cosmological\nmodel and only models with ?std < ?DM are considered (here ?std is the neutralino density\nin the standard cosmological model, and ?DM is the cold dark matter density, both in units\nof the critical density). This bound, it turns out, is very effective in restricting the parameter\nspace of supersymmetric models. In minimal supergravity models (mSUGRA), for instance,\nthe neutralino typically has a small annihilation rate in the early Universe, thus its relic\ndensity tends to be larger than observed. At the end, the requirement ?std < ?DM is found\nto be satisfied only along four narrow regions: the ?bulk? (with a light neutralino and tight\naccelerator constraints), the ?coannihilation region? (where the stau is almost degenerate\nwith the neutralino and coannihilation effects suppress the relic density), the ?funnel region?\n(where m? ?mA/2 and resonance effects enhance the ?-? annihilation rate) and the ?focus\npoint region? (where the neutralino acquires a non-negligible higgsino fraction). Accounting\nfor the dark matter provides, in fact, the most stringent constraint on supersymmetric\n2\nmodels, well over precision data or accelerator searches (see e.g. [2]).\nThough useful in reducing the supersymmetric parameter space, the dark matter con-\nstraint should not be taken for granted, as it relies on untested assumptions about the early\nUniverse. In particular, it postulates that the entropy of matter and radiation is conserved\nand that the Universe is radiation dominated at high temperatures (T ? m?). Several sce-\nnarios where such assumptions do not hold and, more generally, where the evolution of the\nUniverse before big bang nucleosynthesis deviates from the standard cosmological model,\nhave been studied in the literature. They are generically known as non-standard cosmolo-\ngies and include models with gravitino [3], moduli [4] or Q-ball decay [5], thermal inflation\n[6], the Brans-Dicke-Jordan [7] cosmological model, models with anisotropic expansion [8]\nor quintessence domination [9]. Non-standard cosmological models are viable alternatives\nagainst which the predictions of the standard scenario may be compared.\nIn non-standard cosmological scenarios, the neutralino relic density ?? may be larger or\nsmaller than ?std [11]-[20]. Smaller densities are usually the result of an episode of entropy\nproduction that dilutes the neutralino abundance. Larger densities are due either to ad-\nditional contributions to the expansion rate of the Universe, or to non-thermal neutralino\nproduction mechanisms. Usually these scenarios contain additional parameters that can be\nadjusted to modify the neutralino relic density. A distinctive feature of non-standard\ncosmologies is that the new physics they incorporate does not manifest in ac-\ncelerator or detection experiments. That is certainly the case, for instance, for\nthe several models mentioned above. Neutralino scattering rates, therefore, are\nnot affected by the cosmological model.\nA prototype non-standard cosmological model is that of a scalar field ? with\ncouplings of gravitational strength whose late decay reheats the Universe to\na low reheating temperature. The reheating temperature in this scenario can\nbe lower than the standard neutralino freeze-out temperature without spoiling\nprimordial nucleosynthesis [10]. Such scalar fields are common in superstring\nmodels where they appear as moduli fields. In these models, the decay of ?\ninto radiation increases the entropy, diluting the neutralino number density.\nInstead, the decay of ? into supersymmetric particles, which eventually decay\ninto neutralinos, increases the neutralino number density. In this non-standard\ncosmological model it has been shown that practically all neutralinos can have\n3\nthe density of the dark matter, provided the right combination of two parameters\ncan be achieved in the high energy theory: the reheating temperature, and\nthe ratio of the number of neutralinos produced per ? decay over the ? field\nmass [19, 20].\nIn this paper, we compute the neutralino direct detection rate in generic cosmological\nscenarios where neutralinos constitute the dark matter of the Universe. That is, we assume\nthat, independently of the supersymmetric spectrum, the parameters of the non-standard\ncosmological model can always be chosen so that ?? = ?DM. By randomly scanning the\nsupersymmetric parameter space, we obtain a large sample of models and compute their\ndetection rates in non-standard cosmologies. These predictions are then compared with\nthose obtained within the standard cosmological model. Our goal is twofold. First, we\nexplore the possibility of using the neutralino direct detection rate as a test of the standard\ncosmological model. Second, we establish the potential of future dark matter detectors in\nprobing the parameter space of supersymmetric models in a cosmology-independent setup.\nII. THE SUPERSYMMETRIC MODELS\nIn the MSSM, neutralinos are linear combinations of the fermionic partners of the neutral\nelectroweak bosons, called bino ( ?B0) and wino ( ?W03), and of the fermionic partners of the\nneutral Higgs bosons, called higgsinos ( ?H0u, ?H0d). We assume that the lightest neutralino, ?,\nis the dark matter candidate. Its composition can be parameterized as\n? = N11 ?B0 +N12 ?W03 +N13 ?H0d +N14 ?H0u . (1)\nBecause the neutralino interactions are determined by its gauge content, it is useful to\ndistinguish between bino-like (N211 > N212, N213 + N214), wino-like (N212 > N211, N213 + N214),\nand higgsino-like (N213 + N214 > N211, N212) neutralinos according to the hierarchy of terms\nin (1). This classification implies that even so-called mixed neutralinos, those with two or\nmore comparable components, are considered as either binos, winos or higgsinos.\nBino-like neutralinos annihilate mainly into fermion-antifermion pairs through sfermion\nexchange. Such annihilation cross-section is helicity suppressed and gives rise to a standard\nrelic density that is usually larger than observed. Agreement with the observed dark matter\nabundance can still be achieved in standard cosmological scenarios but only in restricted\n4\nregions of the parameter space where special mechanisms such as coannihilations or resonant\nannihilations help reduce the relic density. Owing to the gaugino unification condition, bino-\nlike neutralinos are a generic prediction of minimal supergravity models.\nWino-like andhiggsino-like neutralinos annihilate mostly into gaugebosons (W+W?, ZZ,\nif kinematically allowed) through neutralino or chargino exchange; otherwise they annihilate\ninto fermions. Due to coannihilations with the lightest chargino (and, for higgsinos, with the\nnext-to-lightest neutralino), their standard relic density is rather small. Neutralino masses\nas large as 1 TeV for higgsinos or 2 TeV for winos are required to bring their thermal density\nwithin the observed range. Wino-like and higgsino-like neutralinos can be obtained in models\nwith non-universal gaugino masses; models with anomaly mediated supersymmetry breaking\n(AMSB) [21], for instance, feature a wino-like neutralino.\nWe consider a general class of MSSM models defined in terms of the parameter set M3,\nM2, M1, mA, ?, tan?, m?q, m?? At, and Ab. Here Mi are the three gaugino masses, mA\nis the mass of the pseudoscalar higgs boson, and tan? denotes the ratio v2/v1. The soft\nbreaking scalar masses are defined through the simplifying ansatz MQ = MU = MD = m?q\nand ME = ML = m??, whereas the trilinear couplings are given by AU = diag(0,0,At),\nAD = diag(0,0,Ab), and AE = 0. All these parameters are defined at the weak scale.\nSpecific realizations of supersymmetry breaking such as mSUGRA, mAMSB [21] or split-\nSUSY [22] are similar to - though not necessarily coincide with - particular examples of these\nmodels.\nWe performed a random scan of such parameter space within the following ranges\n10 GeV < M1,M2,M3 < 50 TeV (2)\n40 GeV < mA,?,m?q,m?? < 50 TeV (3)\n?3m0 < At,Ab < 3m0 (4)\n1 < tan? < 60 (5)\nA logarithmic distribution was used for Mi, mA, ?, m?q and m??, and a linear one for At, Ab,\nand tan?; the sign of ? was randomly chosen. After imposing accelerator constraints, as\ncontained in DarkSUSY version 4.1 [23], a sample of about 105 viable models was obtained.\nThe following analysis is based on such a sample of supersymmetric models.\n5\n10 100 1000 10000\nNeutralino mass (GeV)\n0.0001\n0.01\n1\n100\n10000\n1e+06\n?h\n2\nBinos\nWinos\nHiggsinos\nFIG. 1: The standard neutralino relic density as a function of the neutralino mass for our sample\nof models. The models are differentiated according to the bino, wino, or higgsino character of the\nlightest neutralino. The horizontal band indicates the dark matter range.\nIII. RESULTS\nFigure 1 shows the standard relic density as a function of the neutralino mass for our\nsample of models. Each cell -triangle, circle or dot- represents a small region around which at\nleast one model was found. The models are classified as binos, winos, or higgsinos, according\nto the gauge composition of the lightest neutralino. The horizontal band corresponds to\nthe observed dark matter density ?stdh2 = ?dmh2 = 0.109+0.003?0.006, obtained for a ?CDM\nmodel with scale-invariant primordial perturbation spectrum through a global fit of cosmic\nmicrowave background, supernovae, and large scale structure data [24]. Several observations\ncan be made from this figure. Models with bino-like neutralinos are spread over a wide area\nand usually give a rather large relic density. Models with wino- and higgsino-like neutralinos,\non the contrary, are concentrated over narrow bands and their relic density exceeds the dark\nmatter density only for large masses, m? greaterorsimilar 1 TeV. Finally, notice that in our sample the\n6\nneutralino relic density varies between 106 and 10?4.\nWe now want to compute, for our set of models, the neutralino interaction rates in generic\ncosmologies where the neutralino accounts for the dark matter and compare them with those\nobtained in the standard cosmology. Since spin-dependent searches are harder than spin-\nindependent ones, we will focus on the latter. The neutralino interaction rate in direct\ndark matter detection experiments is proportional to the product of the spin-independent\nneutralino-nucleus cross section ?SI and the number density of neutralinos passing through\nthe detector, f. We assume that, as expected for collisionless cold dark matter, f = ??/?dm.\n?SI is determined only by the supersymmetric spectrum but ?? is sensitive to the cosmo-\nlogical setup. Thus, the neutralino detection rate depends on the cosmology only through\nf.\nIf the standard cosmological model is assumed, then all models above the horizontal band\nin figure 1 are rejected. They have a standard relic density larger than the observed dark\nmatter density (?std > ?DM) and therefore are considered incompatible with cosmological\nobservations. Models with a relic density below the dark matter density are still viable,\nthough neutralinos make up only a fraction of the dark matter. They have f < 1, so their\ndetection rate is typically suppressed. Finally, those models with a neutralino relic density\nwithin the observed dark matter range are viable and have f = 1. They have been the focus\nof the large majority of studies on neutralino direct detection.\nIn non-standard cosmologies, ?? = ?DM may be ensured and the previous picture is\nmodified in two important ways. On the one hand, the viable parameter space is different. In\nfact, overdense models, those with ?std > ?DM, canno longer be rejected. On theother hand,\nunderdense models, those with ?std < ?DM, no longer will have the f < 1 suppression factor\nin the detection rate. Hence, in non-standard cosmologies, we expect more viable models\nand larger detection rates. A priori, however, it is not possible to predict the detection rate\nfor the new viable models or to know whether the enhanced detection rates are within the\nsensitivity of future dark matter detection experiments. Thus, a careful analysis is required\nto establish the implications of non-standard cosmologies for dark matter searches. In the\nfollowing, such an analysis will be carried out.\nFigure 2 displays the detection rate in standard and non-standard cosmologies for bino-\nlike neutralinos as a function of the neutralino mass. As before, the figure has been divided\ninto a rectangular grid and each occupied cell denotes the existence of at least one model\n7\n10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 2: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM for bino-like neutralinos in the standard and non-standard cosmological\nmodels. The solid line indicates the CDMS II present limit [25]. The dashed lines show sensitivity\nlimits for -from top to bottom on the right- CDMS II,ZEPLINIV , XENON-1Ton, and SuperCDMS\nphase C [26].\naround it. For comparison, we also show the current limit from the CDMS II experiment [25]\naswell asthe expected sensitivity of CDMS II, ZEPLIN IV , XENON-1Ton, andSuperCDMS\nphase C [26]. In the standard scenario, both the lower and the upper limit on the bino\nmass are set by the relic density constraint. That is why the range of neutralino masses\nextends to lower and higher values in non-standard cosmologies. They yield many more\nviable models, though most of them have rather small detection rates. This fact is not\nentirely surprising. Small annihilation rates, as those associated with bino-like neutralinos,\nare generically correlated with small scattering rates. Regarding dark matter searches, the\nmost remarkable difference observed in the figure is the existence of new viable models with\nneutralino masses not allowed in the standard cosmology and detection rates within the\nreach of future experiments. Such models feature either m? lessorsimilar 40 GeV or m? greaterorsimilar 600 GeV\n8\n10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 3: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM for higgsino-like neutralinos in the standard and non-standard cosmological\nmodels. The solid line indicates the CDMS II present limit [25]. The dashed lines show sensitivity\nlimits for -from top to bottom on the right- CDMS II,ZEPLINIV , XENON-1Ton, and SuperCDMS\nphase C [26].\nand may be detected in ZEPLIN IV, XENON-1Ton, or SuperCDMS phase C.\nThe detection rate for higgsino-like neutralinos is shown in figure 3 as a function of\nthe neutralino mass in standard and non-standard cosmologies. The lower limit on the\nhiggsino mass is now set by the experimental constraint on the chargino mass and is therefore\nindependent of the cosmological scenario. Two features clearly distinguish the standard and\nthe non-standard cosmologies. One of them is the existence of viable models with heavy\nneutralinos, m? greaterorsimilar 1 TeV. A sizable fraction of them has detection rates large enough\nto be observed in ZEPLINIV, XENON-1Ton, or SuperCDMS phase C. The other feature\nis the significant enhancement in the detection rate of neutralinos lighter than lessorsimilar 1 TeV.\nIn the standard scenario, such neutralinos are usually underdense (see figure 1) and have\nsuppressed detection rates. From the figure we see that non-standard cosmologies yield an\n9\n10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 4: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM for wino-like neutralinos in the standard and non-standard cosmological\nmodels. The solid line indicates the CDMS II present limit [25]. The dashed lines show sensitivity\nlimits for -from top to bottom on the right- CDMS II,ZEPLINIV , XENON-1Ton, and SuperCDMS\nphase C [26].\nenhancement of up to two orders of magnitude for the neutralinos with the largest detection\nrates. Some of them are already ruled out by the present limit and many more will be within\nthe expected sensitivity of the CDMSII experiment.\nA compelling signature of non-standard cosmologies would be the detection of a wino-\nlike neutralino by the CDMSII experiment, as revealed in figure 4. Indeed, in the standard\nscenario, winos with m? lessorsimilar 1-2 TeV are usually underdense and therefore their detection rate\nis suppressed by the factor f = ?std/?DM. In non-standard cosmologies, such suppression\nis nonexistent and light winos have larger detection rates. The enhancement in the largest\ndetection rates are typically larger than for higgsinos, amounting in some cases to three\norders of magnitude. As for higgsinos, the lower bound on m? is not set by the dark matter\nbound but rather by the experimental constraint on the chargino mass, so no additional\n10\n1 10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 5: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM in the standard cosmological model and in the late decaying scalar field\nmodel. Here the lower limit of M1 in Eq. (2) has been lowered to 0.1 MeV The solid upper line\nindicates the CDMS II present limit [25] and the lower solid line the XENON limit [27]. The\ndashed lines show sensitivity limits for -from top to bottom on the right- CDMS II, ZEPLIN IV ,\nXENON-1Ton, and SuperCDMS phase C [26].\nmodels are found at low neutralino masses. For m? greaterorsimilar 2 TeV we do find new viable models\ncorresponding to overdense neutralinos in the standard cosmology. Most of them, however,\nhave small scattering rates, lying below the sensitivity of future detection experiments.\nFigure 5 summarizes the potential increase in neutralino candidates in the\nmodels studied in references [19] and [20]. For this figure the lower limit on M1 in\nEq. (2) has been lowered to 0.1 GeV (which is compatible with all experimental\nlimits (while no assumption is made on the relation between M1 and M2). In the\nlate decaying scalar field scenario most neutrinos can be brought to have the\ndark matter density (provided the value of the two relevant parameters of the\nphysics at the high scale can be suitably arranged). One exception is that of\n11\nvery light neutralinos which would be very overdense in the standard cosmology.\nRequiring the reheating temperature to be above 4 MeV [10], in order not to\nmodify nucleosynthesis, from the equations of reference [19] it is immediate to\nsee that neutralinos of mass m? should have a standard density smaller than\nthe dark matter density times (m?/120MeV)4 for it to be possible to bring their\ndensity to be that of the dark matter in the late decaying scalar field scenario.\nThis constraint is included in figure 5 where it is clearly shown the increase\nin potential neutralino candidates in the particular non-standard cosmological\nmodel considered with respect to the standard cosmological model.\nIV. CONCLUSION\nTo summarize, in this paper we computed the direct detection rate of MSSM neutralinos\nin generic cosmological scenarios where they constitute the dark matter of the Universe.\nWhen compared with the predictions of the standard cosmology, considerable differences\nwere encountered. If the neutralino is bino-like, as in msugra models, additional light m? lessorsimilar\n40 GeV and heavy m? greaterorsimilar 600 GeV neutralinos with non-negligible detection rates were found.\nThey could be detected in a variety of dark matter experiments such as ZEPLINIV, XENON-\n1Ton, or SuperCDMS phase C. For higgsino-like neutralinos, we found enhancements of up\nto two orders of magnitude in the largest detection rates as well as new viable models with\nheavy m? greaterorsimilar 1 TeV neutralinos. Both effects yielding detection rates within the sensitivity\nof future experiments. Wino-like neutralinos provide the clearest signature of non-standard\ncosmologies. Their detection rates may be enhanced by up to three orders of magnitude and\nthey could be detected in CDMSII. Thus, the prospects for the direct detection of neutralinos\nin non-standard cosmologies are significantly more promising than in the standard scenario.\nAcknowledgments\nWe thank Oleg Kalashev for allowing us to use the graphreader program. G.G., A.S. and\nC.Y. were supported in part by the US Department of Energy Grant DE-FG03-91ER40662,\nTask C and G.G. also by NASA grants NAG5-13399 and ATP03-0000-0057 at UCLA. P.G.\n12\nwas supported in part by the NFS grant PHY-0456825 at the University of Utah.\n[1] K. Griest and M. Kamionkowski, Phys. Rept. 333 (2000) 167.\n[2] J. R. Ellis, K. A. Olive, Y. Santoso and V. C. Spanos, Phys. Lett. B 565, 176 (2003).\n[3] T. Moroi, M. Yamaguchi and T. Yanagida, Phys. Lett.B 342,105 (1995); M Kawasaki, T.\nMoroi and T. Yanagida, Phys. Lett.B 370,52 (1996).\n[4] T. Moroi and L. Randall, Nucl. Phys. B570, 455 (2000).\n[5] M. Fujii, K. Hamaguchi, Phys. Rev. D 66, 083501 (2002); M. Fujii, M. Ibe, Phys. Rev. D 69,\n035006 (2004).\n[6] D. H. Lyth, E.D. Stewart, Phys. Rev. D 53, 1784 (1996).\n[7] M. Kamionkowski and M. S. Turner, Phys. Rev. D 42, 3310 (1990).\n[8] J. D. Barrow, Nucl. Phys. B 208, 501 (1982).\n[9] P. Salati, Phys. Lett. B 571, 121 (2003) [arXiv:astro-ph/0207396]; S. Profumo and P. Ullio,\nJCAP 0311, 006 (2003) [arXiv:hep-ph/0309220]. S. Profumo and C. E. Yaguna,\nPhys. Rev. D 70, 095004 (2004)\n[arXiv:hep-ph/0407036].\n[10] M. Kawasaki, K. Kohri, and N. Sugiyama, Phys. Rev. Lett. 82, 4168 (1999); Phys. Rev. D\n62, 023506 (2000); S. Hannestad, Phys. Rev. D 70, 043506 (2004).\n[11] M. Kamionkowski, M. Turner, Phys. Rev. D 42 3310 (1990); R. Jeannerot, X. Zhang, R.\nBrandenberger, JHEP 12, 003 (1999); W. B. Lin, D. H. Huang, X. Zhang, R. Brandenberger,\nPhys. Rev. Lett. 86 954 (2001).\n[12] T. Moroi, M. Yamaguchi and T. Yanagida, Phys. Lett.B 342,105 (1995); M Kawasaki, T.\nMoroi and T. Yanagida, Phys. Lett.B 370,52 (1996).\n[13] D. J.H. Chung, E. W. Kolb and A. Riotto, Phys. Rev. D60, 063504 (1999).\n[14] G. F. Giudice, E. W. Kolb and A. Riotto, Phys. Rev. D64, 023508 (2001).\n[15] R. Allahverdi and M. Drees, Phys. Rev. Lett. 89, 091302 (2002) and Phys. Rev. D66, 063513\n(2002).\n[16] S. Khalil, C. Mu?noz and E. Torrente-Lujan, New Journal of Physics 4, 27 (2002); E. Torrente-\nLujan, hep-ph/0210036 (2002).\n[17] N. Fornengo, A. Riotto, and S. Scopel, Phys. Rev. D67, 023514 (2003).\n13\n[18] C. Pallis, Astrop. Phys. 21, 689 (2004).\n[19] G. B. Gelmini and P. Gondolo, Phys. Rev. D 74, 023510 (2006)\n[20] G. Gelmini, P. Gondolo, A. Soldatenko and C. E. Yaguna, Phys. Rev. D 74, 083514 (2006).\n[21] L. Randall and R. Sundrum, Nucl. Phys. B 557, 79 (1999) [arXiv:hep-th/9810155].\nG. F. Giudice, M. A. Luty, H. Murayama and R. Rattazzi, JHEP 9812, 027 (1998)\n[arXiv:hep-ph/9810442].\n[22] N. Arkani-Hamed, S. Dimopoulos, G. F. Giudice and A. Romanino, Nucl. Phys. B 709,\n3 (2005) [arXiv:hep-ph/0409232]. G. F. Giudice and A. Romanino, Nucl. Phys. B 699, 65\n(2004) [Erratum-ibid. B 706, 65 (2005)] [arXiv:hep-ph/0406088].\n[23] P. Gondolo, J. Edsjo, P. Ullio, L. Bergstrom, M. Schelke and E. A. Baltz, JCAP 0407, 008\n(2004).\n[24] D.N. Spergel et al. Astrophys. J., Suppl. Ser. 148, 175 (2003); D.N.\nSpergel it et al., astro-ph/0603449 (2006); http:// lambda.gsfc.nasa.gov/ prod-\nuct/map/current/parameters.cfm.\n[25] D. S. Akerib et al. [CDMS Collaboration], Phys. Rev. Lett. 96, 011302 (2006)\n[arXiv:astro-ph/0509259].\n[26] R. J. Gaitskell, Ann. Rev. Nucl. Part. Sci. 54, 315 (2004).\n[27] D. N. McKinsey [XENON Collaboration], AIP Conf. Proc. 870 (2006) 202; J. Angle et al.\n[XENON Collaboration], arXiv:0706.0039 [astro-ph].\n14\n"}
{"id":"oai:arXiv.org:q-bio/0601020","text":"arXiv:hep-ph/0612309v1  22 Dec 2006\nProbing the octant of ?23 with very long baseline neutrino\noscillation experiments: a global look\nGuey-Lin Lina,b? and Yoshiaki Umedaa?\naInstitute of Physics, National Chiao-Tung University, Hsinchu 300, Taiwan\nbPhysics Division, National Center for Theoretical Sciences, Hsinchu 300, Taiwan\n(Dated: February 7, 2008)\nAbstract\nWe investigate the baseline range in which the ?23 degeneracy in neutrino oscillation probabilities\nis absent for fixed values of ?13 and CP violation phase ?CP. We begin by studying sensitivities\nof neutrino oscillation probabilities to ?13, ?23 and ?CP for very-long-baseline neutrino oscillations.\nWe show contour graphs of the muon-neutrino survival probability P(?? ? ??) and the appearance\nprobability P(?e ? ??) on the cos2?23?sin2?13 plane for baseline lengths L = 1000, 5000, 10000,\nand 12000 km. For each baseline length, it is found that P(?? ? ??) is more sensitive to sin2?13 at\nenergies around its local maximum while it is more sensitive to cos2?23 at energies around its local\nminimum. On the other hand, the appearance probability P(?e ? ??) is sensitive to sin2?13 and\ncos2?23 only near its local maximum. We observe that the ?23 degeneracy in P(?? ? ??) is absent\nat energies around the local maximum of this probability, provided ?13 is sufficiently large. The\n?23 degeneracy is also absent in general near the local maximum of P(?e ? ??). Using analytic\napproximations for neutrino oscillation probabilities, we demonstrate that the above observations\nfor L = 1000, 5000, 10000, and 12000 km are in fact valid for all distances. The implications of\nthese results on probing the octant of ?23 are discussed in details.\nPACS numbers: 14.60.Pq, 13.15.+g, 14.60.Lm\n? E-mail: glin@cc.nctu.edu.tw\n? E-mail: umeda@faculty.nctu.edu.tw\n1\nI. INTRODUCTION\nThe understanding of neutrino masses and mixing matrix is crucial to unveil the mystery\nof lepton flavor structures. The updated SK analysis of the atmospheric neutrino data gives\n[1]\n1.5?10?3 eV2 < |?m231| < 3.4?10?3 eV2, sin2 2?23 > 0.92. (1)\nThis is a 90%C.L. range with the best fit values given by sin2 2?23 = 1 and ?m231 =\n2.1?10?3 eV2 respectively. An earlier result based upon L/E analysis gives [2]\n1.9?10?3 eV2 < |?m231| < 3.0?10?3 eV2, sin2 2?23 > 0.9. (2)\nat 90%C.L. where the best fit values are given by sin2 2?23 = 1 and ?m231 = 2.4?10?3 eV2\nrespectively. The scenario of ?? ? ?? oscillation for atmospheric neutrinos has been con-\nfirmed by the K2K experiment [3, 4]. Furthermore the results in the solar neutrino oscillation\nmeasurements are also confirmed by KamLAND reactor measurements [5, 6]. Combining\nthese measurements, the LMA solution of the solar neutrino problem is established and the\nupdated 2? parameter ranges are given by [7]\n7.21?10?5 eV2 < ?m221 < 8.63?10?5 eV2, 0.267 < sin2 ?12 < 0.371, (3)\nwith the best fit values ?m221 = 7.92?10?5 eV2 and sin2 ?12 = 0.314.\nDespite the achievements so far in measuring the neutrino mixing parameters, the sign\nof ?m231, the mixing angle ?13 and the CP violating parameter ?CP in the mixing matrix\nremain to be determined. Furthermore, one is keen to resolve the octant degeneracy of ?23\n[8].\nThe mixing angle ?13 is constrained by the reactor experiments [9, 10]. The CHOOZ\nexperiment [9] gives a more stringent constraint on ?13 with sin2 2?13 < 0.1 for a large\n?m231 (90% C.L.). A recent global fit based upon three-flavor neutrino oscillation gives the\n2? upper bound, sin2 2?13 < 0.124 [7]. It is well known that the mixing angle ?13 can be\nenhanced by the matter effect in Earth. The appearance oscillations ?? ? ?e, ?e ? ??,\nand the survival mode ?? ? ?? performed in a very-long baseline have been proposed\n[11] to probe the angle ?13 and the sign of ?m231. Furthermore, the aforementioned very\nlong baseline neutrino experiments as well as future atmospheric neutrino experiments are\nproposed to determine the deviation of ?23 to maximality [12]. In this work, we focus on\n2\nthe mixing angle ?23. We shall provide a global survey on ideal neutrino energies in the\nGeV range and baseline lengths from 103 km to 104 km for probing the octant of the mixing\nangle ?23. The muon neutrino survival probability P(?? ? ??) ? P?? and electron neutrino\nappearance probability P(?e ? ??) ? Pe? are both studied for this purpose. We observe\nthat the muon neutrino survival probability P?? has complementary dependencies on mixing\nangles ?13 and ?23 as the neutrino energy varies. This property is established by studying\nthe dependencies of P?? on cos2?23 and sin2?13 while keeping other parameters fixed. The\nchoice of the parameter cos2?23 is appropriate as\n1\n2 cos2?23 =\n1\n2 ?sin\n2 ?23, (4)\nwhich is a probe to the deviation of ?23 to the best-fit value pi/4. We find that the de-\npendencies of P?? on cos2?23 and sin2?13 at energies near local maxima of this probability\ndiffer drastically from those at energies near local maxima of the same probability. In the\nformer case, the probability P?? is always more sensitive to sin2?13. Furthermore, the ?23\ndegeneracy is absent in this case. In the latter case, the probability P?? is more sensitive to\ncos2?23 while the ?23 degeneracy is generally present. Such information is useful for probing\nthe octant of ?23. We also study sensitivities of the probability Pe? to cos2?23 and sin2?13\nwith other parameters fixed. We only focus on energies near the local maximum of Pe? as\nthis probability is not sensitive to mixing parameters for energies near its local minimum.\nThis paper is organized as follows. In Section II, we compare results on the oscillation\nprobability Pe? obtained by the full calculation with those obtained by various analytic\napproximations. This comparison is essential since analytic approximations will be employed\nfor discussions in later sessions. To set up the analytic approximation, we introduce the\nconcept of average density which varies with the total neutrino path-length inside the Earth.\nApplying full calculations and the two-layer analytic approximations [13], we identify the\nenergy values for local maxima and local minima of neutrino oscillation probabilities P?? and\nPe? for baseline lengths 1000 ? L/km ? 12000. It is found that the two-layer approximation\nis quite satisfactory compared to the full calculation for computing these energy values. In\nSection III, we first present the dependencies of P?? and Pe? on the CP violation phase\n?CP. It will be shown that, unlike Pe?, P?? is not sensitive to the CP violation phase ?CP.\nWe study numerically the effect of CP violation phase to the appearance probability Pe?.\nThe result confirms the so-called magic baseline [14, 15, 16] at L ? 7600 km where Pe? is\n3\nrather insensitive to the CP violation phase. After discussions on the CP violation phase,\nwe present the contour graphs of probabilities P?? and Pe? on cos2?23 ?sin2?13 plane for\nbaseline lengths L = 1000, 5000, 10000, and 12000 km. At all these baseline lengths, we\nshall see that P?? is more sensitive to sin2?13 at energies around its local maximum while\nit is more sensitive to cos2?23 at energies around its local minimum. Such observations\nare then justified by using the two-layer analytic approximations for neutrino oscillation\nprobabilities. With this approximation, the baseline lengths and neutrino energies allowing\nan unambiguous determination of ?23 through measuring P?? are identified. In Section IV,\nwe discuss the prospects of probing the ?23 octant via measuring Pe? and P??. We then\nconclude in the same section.\nII. THE COMPARISON OF FULL CALCULATIONSAND ANALYTICAPPROX-\nIMATIONS\nWe begin the discussions with the relation connecting flavor and mass eigenstates of\nneutrinos, ?? =summationtexti U?i?i, with U the Maki-Nakagawa-Sakata mixing matrix [17] given by\nU =\n?\n??\n??\nc12c13 s12c13 s13e?i?CP\n?s12c23 ?c12s13s23ei?CP c12c23 ?s12s13s23ei?CP c13s23\ns12s23 ?c12s13c23ei?CP ?c12s23 ?s12s13c23ei?CP c13c23\n?\n??\n?? , (5)\nwhere sij and cij denote sin?ij and cos?ij, respectively. The value for the Dirac type CP-\nphase ?CP ranges from 0 to 2pi. The evolutions of neutrino flavor eigenstates are governed\nby the equation\ni ddt|?(t)? =\n?\n????\n????\n1\n2E?U\n?\n??\n??\n0 0 0\n0 ?m221 0\n0 0 ?m231\n?\n??\n??U? +\n?\n??\n??\nV 0 0\n0 0 0\n0 0 0\n?\n??\n??\n?\n????\n????|?(t)?, (6)\nwhere |?(t)? = (?e(t),??(t),??(t))T, ?m2ij ? m2i ?m2j is the mass-squared difference between\nthe i-th and j-th mass eigenstates, and V ? ?2GFNe is the effegtive potential arising\nfrom the charged current interaction between ?e and electrons in the medium with Ne the\nelectron number density. Numerically V = 7.56?10?14 (?/[g/cm3])Ye [eV] with Ye denoting\nthe number of electrons per nucleon. We take Ye ? 0.5 in our calculations. One solves\nEq. (6) by diagonalizing the Hamiltonian on its right hand side. This amounts to writing\n4\n0 5000 10000\nbaseline length L[km]\n0\n5\n10\n? [g/cm\n3 ]\naverage density\ndensity in the mantle\ndensity in the core\naverage density\nFIG. 1: The average Earth density along the path traversed by the neutrino as a function of the\npath length L.\nthe right hand side of Eq. (6) as U?H?U??|?(t)? with U? the neutrino mixing matrix in the\nmatter and H? ? diag(E1,E2,E3) the Hamiltonian after diagonalization. To obtain various\noscillation probabilities described later, we have used the parametrization in [18] for the\nEarth density profile.\nFor analytic calculations, we employ the two-layer approximation for the Earth density\nprofile [13]. Given a path-length L for a neutrino traversing the Earth medium, one can\ndivide L into the sum L = L1 + L2 + ???Ln with each Li corresponding to a region with\na specific matter density. The average density for this path-length is then given by ? =\n(?1L1 + ?2L2 + ????nLn)/L. The Earth medium can be categorized as the Earth mantle\nand the Earth core. If a neutrino only traverses the Earth mantle, we shall use the one-\ndensity approximation for the analytic calculation with the density defined by the above\nprescription. However, if a neutrino traverses both the Earth mantle and the Earth core,\none should write the total neutrino path-length as L = 2Lm + Lc with\nLm = R\nparenleftBigg\ncos?n ?\nradicalbigg\nr2c\nR2 ?sin\n2 ?n\nparenrightBigg\n,\nLc = 2R\nradicalbigg\nr2c\nR2 ?sin\n2 ?n, (7)\n5\nwhere R = 6371 km and rc = 3480 km are the radii of the entire Earth and the Earth core\nrespectively while ?n is the incident Nadir angle of the neutrino. We note that the critical\nNadir angle for a neutrino to pass the Earth core is 33.17? corresponding to L = 10674 km.\nFor L > 10674 km, one separately defines average densities within the path-length Lm and\nthe path-length Lc respectively. The average densities as functions of the neutrino path-\nlength is shown in Fig. 1. For L ? 10674 km, there is only one curve for the average density,\nwhich is represented by the solid line in the figure. Beyond this distance, one can define the\naverage density in the core and the average density in the mantle, which are represented\nby dashed and dotted lines respectively. Alternatively, one can also define single average\ndensity for L > 10674 km by ignoring the distinction between the mantle and the core. This\nis seen from the solid line for L > 10674 km. However, in our analytic calculations, we shall\nadopt the two-density approach for L > 10674 km.\nFor analytic calculations, we only compute oscillation probabilities up to the lowest order\nin ? ? ?m221/?m231. In other words, we set ?m221=0 in analytic calculations and conse-\nquently the mixing angle ?12 and the CP phase ?CP dropout fromthe oscillation probabilities.\nThe probabilities P?? and Pe? in the two-layer approximations are given by[19, 20, 21, 22, 23]:\nP?? = cos4 ?23 +parenleftbigu2 + v2parenrightbigsin4 ?23 + 2cos2 ?23 sin2 ?23 (ucost+ vsint),\nPe? = sin2 ?23parenleftbig1?u2 ?v2parenrightbig. (8)\nThe quantities u, v and t are defined as\nu = cos(2?m)cos(?c)?cos(2?c13 ?2?m13)sin(2?m)sin(?c),\nv = ?cos(2?m13)[sin(?c)cos(2?m)cos(2?c13 ?2?m13) + cos(?c)sin(2?m)]\n+sin(2?m13)sin(?c)sin(2?c13 ?2?m13),\nt = (M\n2\n13)\nm + (m2\n13)\nm\n4E ?2L\nm + (M\n2\n13)\nc + (m2\n13)\nc\n4E ?L\nc, (9)\nwhere\n?m(c) = ?\nm(c)\n31\n4E L\nm(c),\n(M213)m(c) = (?m231 + Am(c)e + ?m(c)31 )/2,\n(m213)m(c) = (?m231 + Am(c)e ??m(c)31 )/2, (10)\nwith\n?m(c)31 =\nradicalBig\n(?m231 sin2?13)2 + (Am(c)e ??m231 cos2?13)2. (11)\n6\n0 5 10\nE [GeV]\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nP e?\nFull\nTwo-Layer\nOne-Layer\n(First order)\nOne-Layer\n(Second order)\nFull (?m212 =0)\nPe? for L=11400 km, sin2?13=0.3, cos2?23=0\nFIG. 2: A comparison of Pe? obtained by the full numerical calculation and various approximations.\nThe thick solid curve denotes the result by the full numerical calculation. The dotted-dashed\ncurve denotes the result by setting ?m221 = 0 in the full numerical calculation. The dashed\ncurve represents the result obtained by the two-layer approximation in the leading order of ? ?\n?m221/?m231. The dotted curve denotes the result obtained by one-density approximation in the\nleading order of ? while the thin solid curve is that obtained by the one-density approximation in\nthe next-to-leading order of ?.\nThe superscripts m and c denote quantities defined in the Earth mantle and the Earth\ncore respectively. For neutrinos traversing only the Earth mantle, one simply sets Lc =\n0, 2Lm = L in the above equations and recovers well known expressions for P?? and Pe? in\nthe one-density approximation [24].\nThe accuracy of two-layer approximation is shown in Fig. 2 with a comparison of this\napproximation to the full numerical calculation and other approximations. In the calcula-\ntions, we have assumed the normal mass hierarchy and taken sin2?13 = 0.3, cos2?23 = 0,\n?CP = 0, ?m231 = 2.4?10?3 eV2, ?m221 = 8.2?10?5 eV2, and tan2 ?12 = 0.39 [25]. This\nset of parameters will be adopted for later calculations unless specific mentioning of other\nchoices. This set of parameters differ from the most updated best-fit values quoted right\nafter Eq. (3). However, both set of parameters give undistinguishable results on Pe? and P??\n7\n0 5000 10000\nbaseline length L[km]\n0\n5\n10\n15\nenergy [GeV]\nFull calculation\nTwo-Layer\nThe energy at local maximum of Pe?\nmax1\nmax2\n0 5000 10000\nbaseline length L[km]\n0\n5\n10\n15\n20\nenergy [GeV]\nFull calculation\nTwo-Layer calculation\nThe energies at local maximum and local minimum of P??\nmin2\nmax1\nmin1\nmax2\nFIG. 3: Left panel: the energy at the local maximum of Pe?, as a function of L. Right panel:\nenergies at local maxima and local minima of P??, as functions of L.\nin the energy range concerned here. A comparison made at L = 11400 km has two purposes.\nFirst of all, it is known that the series expansion in the parameter ? is valid for L/E? ? 104\n(km/GeV) [24, 26]. Hence analytic calculations performed at this baseline length test the\nmarginal region of the condition L/E? ? 104 (km/GeV). Secondly this path-length implies\nthat the neutrino traverses both the Earth mantle and the Earth core. Therefore it is also\na good test to the two-layer approximation. It is seen that the two-layer approximation,\nunlike the one-layer approximation, reproduces well the peak energies of Pe?, while it gives\npeak probabilities deviating from those obtained from the full calculation by 15% ?20%.\nWe also see that the two-layer approximation agrees well with the full calculation in the\nlimit ?m221 = 0.\nFor later analysis, we compute energies at local maxima of Pe? and those at local maxima\nand local minima of P?? for the baseline range 1000 ? L/km ? 12000. The results are\ndepicted in Fig. 3. We do not study local minima of Pe? since their values are not sensitive\nto mixing angles ?13 and ?23. It is seen that the analytic approximation is satisfactory for\ncomputing energies at local maxima and local minima of neutrino oscillation probabilities.\nWe point out that the energy curves in Fig. 3 are calculated with sin2?13 = 0.3 and cos2?23 =\n0. It is found that these curves are not sensitive to the values of sin2?13 and cos2?23.\n8\n0 1 2 3 4 5\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n(P ??\n)\n?CP=0\n?CP=0.5pi\n?CP=pi\n?CP=1.5pi\nP?? and Pe? for L=1000 km, sin2?13=0.3, cos2?23=0\nPe?P??\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=5000 km, sin2?13=0.3, cos2?23=0\n0 5 10 15 20\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=10000 km, sin2?13=0.3, cos2?23=0\n0 5 10 15 20\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=12000 km, sin2?13=0.3, cos2?23=0\nFIG. 4: The CP phase dependencies of P?? and Pe? for L = 1000 km, 5000 km, 10000 km and\n12000 km respectively. The probability P?? is described by the thick curve while Pe? is described\nby the thin curve.\nIII. CONDITIONS FOR THE ABSENCE OF ?23 DEGENERACY IN P?? AND Pe?\nAT DIFFERENT ENERGIES\nA. The dependencies of P?? and Pe? on ?CP\nBefore concentrating on ?13 and ?23 dependencies of neutrino oscillation probabilities,\nwe first study the CP phase dependencies with the full numerical calculations. It is easily\nseen from Fig. 4 that P?? is not sensitive to the CP phase for all distances displayed. On\nthe other hand, Pe? is rather sensitive to the CP phase for L = 1000 km and 5000 km.\nIn order to quantify the CP phase dependence of Pe?, we study peak values of Pe?, which\noccur at energies described by the curve max1 in Fig. 3 for different baseline lengths. This\npeak value for a specific baseline length depends on the CP violation phase ?CP and we\n9\n0 2000 4000 6000 8000 10000\nbaseline length L [km]\n0\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\nP e?max\n?  P\ne?min\nPe?max ?  Pe?min,  sin2?13=0.3, cos2?23=0\n0 2000 4000 6000 8000 10000\nbaseline length L [km]\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nP e?min\n/  P\ne?max\nPe?min /  Pe?max,  sin2?13=0.3, cos2?23=0\nFIG. 5: The difference and the ratio of Pmaxe? and Pmine? as functions of the baseline length.\ndenote the maximum and the minimum of this value as Pmaxe? and Pmine? respectively. The\ndifference and the ratio of these two values as functions of the baseline length L are shown\nin Fig. 5. It is interesting to note that the ratio Pmine? /Pmaxe? increases monotonically with the\nbaseline length until L = 7600 km. The ratio begins to decrease for a larger baseline but\nremains larger than 90%. In fact, one can see that Pmaxe? and Pmine? differ by less than 10%\nfor L ? 6500 km. We point out that 1?Pmine? /Pmaxe? reaching to minimum at L = 7600 km\nconfirms the so-called magic baseline for the probability Pe? [14, 15, 16].\nB. The dependencies of P?? and Pe? on mixing angles ?13 and ?23\nHaving studied CP phase dependencies of oscillation probabilities, we now focus on ?13\nand ?23 dependencies. In this study we set the CP phase ?CP equal to zero. The results\nare presented in Fig. 6. It is easily seen that the values of P?? at its local maximum and\nlocal minimum depend on mixing angles ?13 and ?23 while only the local maximum of Pe?\ndepends on these parameters. This confirms our earlier comments concerning the left panel\nof Fig. 3. We point out that the differences between solid and dotted curves in Fig. 6 reflect\nthe effect of sin2?13; while the differences between solid and dashed curves there reflect the\neffect of cos2?23.\nWe now present contour graphs of P?? and Pe? on the cos2?23 ? sin2?13 plane. The\nrange for cos2?23 is chosen such that sin2?23 > 0.9 [2], i.e., ?0.316 < cos2?23 < 0.316; while\nsin2 2?13 is chosen to be less than 0.1, i.e., sin2?13 < 0.316. The contour graphs of P?? at\n10\n0 1 2 3 4 5\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nsin2?13=0.3,   cos2?23=0\nsin2?13=0.15, cos2?23=0\nsin2?13=0.3,   cos2?23=0.3\nsin2?13=0.3,   cos2?23=?0.3\nP?? and Pe? for L=1000 km\nPe?P??\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=5000 km\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=10000 km\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=12000 km\nFIG. 6: The ?13 and ?23 dependencies of P?? and Pe? for L = 1000 km, 5000 km, 10000 km and\n12000 km respectively. The probability P?? is described by the thick curve while Pe? is described\nby the thin curve.\ndifferent baseline lengths are presented in Fig. 7. Except for L = 1000 km, we have shown\ncontours of P?? for energies in the vicinity of both local maximum and local minimum of\nthis probability. The contour for the local maximum of P?? at L = 1000 km is not shown\nsince P?? at this energy and baseline length is not sensitive to mixing angles ?13 and ?23. For\nL = 5000 km, 10000 km and 12000 km, it is seen that the contours at local maxima of P??\nand those at local minima of P?? behave rather differently. The former are in general more\nparallel to the cos2?23-axis while the latter are generally more parallel to the sin2?13-axis.\nWe note that the local maximum (max2) of P?? at L = 12000 km can vary from 0.9 to a\nmuch smaller value, 0.45, which is a result of significant matter effects. Similarly, due to\nlarge matter effects, the local minimum (min2) of P?? at L = 10000 km can vary from 0\nto a much larger value, 0.4. We also notice that, at this baseline length, the ?23 degeneracy\n11\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=1.39-2.39 GeV (min1), L=1000 km\n0.065\n0.08\n0.08\n0.1\n0.1\n0.13\n0.13\n0.16\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=4.25-5.25 GeV (max1, solid)\nand E=8.74-9.74 GeV (min1, dashed), L= 5000 km\n0.005\n0.02\n0.02\n0.05\n0.05\n0.08\n0.08\n0.12\n0.96 0.93 0.9 0.85\n0.8\n0.75\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=8.71-9.71 GeV (max1, solid)\nand E=5.74-6.74 GeV (min2, dashed), L=10000 km\n0.06\n0.05\n0.3\n0.04\n0.1\n0.1\n0.15 0.40.2\n0.93\n0.982 0.97\n0.95\n0.9\n0.87\n0.84\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=5.00-6.00 GeV (max2, solid)\nand E=6.65-7.65 GeV (min2, dashed), L=12000 km\n0.12\n0.09\n0.450.15\n0.15\n0.6\n0.18\n0.7\n0.86\n0.86\n0.8\n0.06\n0.03\n0.18\nFIG. 7: The contour graphs of the muon neutrino survival probability P?? on the cos2?23?sin2?13\nplane. At L = 1000 km, the local minimum of P?? on the curve min1 occurs at E = 1.89 GeV. We\nplot the contour graph of P?? by averaging this probability over an 1 GeV energy range centered\nat the above local minimum. At L = 5000 km, the local maximum of P?? on the curve max1\noccurs at E = 4.75 GeV while the local minimum of this probability on the curve min1 occurs at\nE = 9.24 GeV. We plot the contour graphs of P?? in the energy range 4.25 ? E/GeV ? 5.25 for\nthe former case and 8.74 ? E/GeV ? 9.74. The same type of convention applies to L = 10000 km\nand 12000 km.\nis absent for P?? > 0.1. In general, such a degeneracy is also absent for energies near local\nmaxima of P??. However, the probabilities are not sensitive to cos2?23 in those cases. For\ncomparisons, we also present contour graphs for the appearance probability Pe? at different\nbaseline lengths. It is clearly seen that Pe? is only sensitive to sin2?13 for most cases. The\nsensitivity to cos2?23 only occurs at very long baseline lengths and large values of sin2?13.\n12\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=1.39-2.39 GeV (max1), L=1000 km\n0.002\n0.01 0.02\n0.03 0.04\n0.06\n0.08\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=5.31-6.31 GeV (max1), L=5000 km\n0.01 0.05\n0.1\n0.15\n0.2\n0.25\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=5.49-6.49 GeV (max1), L=10000 km\n0.03 0.1 0.2\n0.4\n0.5\n0.3\n0.6\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=2.64-3.64 GeV (max1), L=12000 km\n0.01 0.1 0.2\n0.4\n0.5\n0.3\nFIG. 8: The contour graphs for the oscillation probability Pe? on the cos2?23 ?sin2?13 plane. We\nplot contours of Pe? at energies near the local maximum (max1) of this probability.\nFor example, at L = 10000 km, Pe? becomes sensitive to cos2?23 as sin2?13 approaches 0.3.\nAt L = 12000 km, Pe? becomes sensitive to cos2?23 when sin2?13 is greater than 0.2.\nC. A global look at the absence of ?23 degeneracy\nIn this subsection, we focus on ?23 dependencies of P?? and Pe? for general baseline\nlengths. The two-layer analytic approximations for P?? and Pe? will be employed for our\ndiscussions, and observations in the previous subsection shall be justified. It is instructive\nto rewrite Eq. (8) in polynomials of cos2?23:\nf(y,z) = ??y2 + (? + ?)y + (1??),\ng(y,z) = ??(y ?1), (12)\n13\n2000 4000 6000 8000 10000 12000\nbaseline length L [km]\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n?+?\nsin2?13=0.1\nsin2?13=0.2\nsin2?13=0.3\nFIG. 9: The coefficient ?(z) + ?(z) calculated along the energy curve max1 in the left panel of\nFig. 3. The values of sin2?13 are taken to be 0.1, 0.2 and 0.3 respectively.\nwith f(y,z) ? P??, g(y,z) ? Pe?, y ? cos2?23 and z ? sin2?13. Furthermore,\n? = ?14bracketleftbig(u?cost)2 + (v?sint)2bracketrightbig,\n? = 12parenleftbig1?u2 ?v2parenrightbig+ 14bracketleftbig(u?cost)2 + (v ?sint)2bracketrightbig,\n? = 12parenleftbig1?u2 ?v2parenrightbig. (13)\nWe note that the sin2?13 dependencies of P?? and Pe? reside in quantities u, v, cost and\nsint. These quantities also depend on the baseline length L and the neutrino energy E.\nHence the coefficients ?, ? and ? also depend on the baseline length L and the neutrino\nenergy E. It is interesting to note that ? + ? = ?. Therefore we have\nP?? = ?parenleftbigy2 ?1parenrightbig, (14)\nusing P?e +P?? +P?? = 1 and P?e = Pe? with our choice of ?CP = 0. The contour structure\nof Pe? is straightforward as g(y,z) is only a linear function of y. Hence no ?23 degeneracy\npresents in the contour graphs depicted in Fig. 8. Additionally, the sensitivity of Pe? to\ncos2?23 is dg(y,z)/dy = ?(?(z) + ?(z)). The coefficient ? + ? evaluated along the energy\ncurve max1 in the left panel of Fig. 3 are plotted in Fig. 9 for sin2?13 = 0.1, 0.2 and 0.3. For\nsin2?13 = 0.3, ?+? reaches to the maximal value, 0.5, for L ? 10500 km. For sin2?13 = 0.1\n14\n0 5000 100000\n0.2\n0.4\n0.6\n0.8\n1\nmin1\nmax1\nmin2\nmax2\nbaseline length L [km]\n-? and ?+?, sin2?13=0.2, cos2?23=0\n-? and ?+?, sin2?13=0.2, cos2?23=0\n?? ?+?\n0 5000 10000\nbaseline length L [km]\n0\n0.2\n0.4\n0.6\n0.8\n1\nmin1\nmax1\nmin2\nmax2\n?? and ?+?, sin2?13=0.3, cos2?23=0\n?+???\nFIG. 10: The coefficients ?? and ?+? evaluated along energy curves in the right panel of Fig. 3.\nThe coefficients are calculated with sin2?13 = 0.2 and 0.3 on the left and right panels respectively.\nThe thick curves denote values of ?? while thin curves denote those of ?+?. For solid and dotted\ncurves, the thick curves generally dominate over the corresponding thin ones. For dashed and\ndotted-dashed curves, the thin curves generally dominate over the thick ones.\nand 0.2, ?+? rises quickly as the baseline length L surpasses 10674 km. We note that the\nvalue of Pe? is proportional to ?+?. Hence ?+? shown in Fig. 9 is its own maximal value\nfor each baseline length L.\nThe contour structure of P?? can be analyzed through the quadratic polynomial f(y,z)\nin y. If ?? ? ?+?, generally there are two solution curves for f(y,z) = p compatible with\nthe ranges of y and z where p is a given value for P??. Let us suppose that z ? sin2?13\nis measured in the future [27, 28] with a central value z0. The two solution curves for the\nequation f(y,z) = p then intersect with the straight line z ? sin2?13 = z0 at two points\n(y1,z0) and (y2,z0). This is actually what we have seen in Fig. 7 for local minima of P??. If,\non the other hand, ?? ? ? + ? or even ?? ? ? + ?, there exists only one solution curve\nfor the equation f(y,z) = p. This is because that the two points (y1,z0) and (y2,z0) can not\nsimultaneously satisfy the constraint ?0.316 < y < 0.316 since |y1 +y2| = ?(?+?)/? ? 1.\nThis is actually what we have seen in Fig. 7 for local maxima of P??. To justify this\nobservation, it remains to show that the coefficient ?? dominates over ? + ? at energies\ncorresponding to local minima of P?? while the latter dominates over the former at energies\ncorresponding to local maxima of P??. This is clearly demonstrated in Fig. 10 where the\n15\ncoefficients ?? and ? + ? are evaluated along energy curves in the right panel of Fig. 3.\nWe have calculated the coefficients with cos2?23 = 0 and sin2?13 = 0.2, 0.3 respectively.\nWe remark that other choices for cos2?23 do not produce noticeable changes on the energy\ncurves where ?? and ? + ? are evaluated.\nIt is easily seen that ?+? always dominates over ?? when these coefficients are evaluated\natenergies alongmax1 ormax2inthe right panelofFig.3. Insuch cases, the ?23 degeneracy\nis absent in the solutions of f(y,z) = p. Namely there exists only one solution curve for\nthe above equation. Reversely, ?? always dominates over ?+? when these coefficients are\nevaluated at energies along min1. The situation is slightly more complicated when these\ncoefficients are evaluated at energies along min2. In this case ?? no longer dominates\nover ? + ? for baseline lengths around 104 km. In fact, with sin2?13 = 0.3, ? + ? is even\nlarger than ?? for 9000 ? L/km ? 10500. This explains the contour structure of P??\nat L = 10000 km (see Fig. 7) where the straight line z = 0.3 only intersects one equal\nprobability curve f(y,z = 0.3) = p. The straight line z = 0.2 also behaves the same except\nfor a very small p. We reiterate that the range for y ? cos2?23 is ?0.316 < y < 0.316 due\nto the constraint sin2 2?23 > 0.9 [2]. Therefore, given z = z0, the equation f(y,z0) = p could\nhave only one solution for y if ?(?(z0) +?(z0))/?(z0) > 0.632. In other words, such values\nof ?(?(z0) + ?(z0))/?(z0) lead to the absence of ?23 degeneracy. In fact, the condition for\nthe absence of ?23 degeneracy is even more relaxed. To see this, let us divide our discussions\naccording to the true octant of ?23.\n1. min2, ?23 < pi/4\nSince ? < 0 and ? + ? > 0, the two solutions for y in f(y,z0) = p are both negative for\n1??(z0)?p > 0 while they have opposite signs for 1??(z0)?p < 0. If the true value of\n?23 is less than pi/4, i.e., the true value of y is positive, then the experimental measurement\nshould give 1??(z0)?p < 0 so that a positive solution for y exists. With 1??(z0)?p <\n0, the two solutions for f(y,z0) = p have opposite signs and the negative solution has\na larger absolute value. The negative solution will violate the constraint ?0.316 < y if\n?(?(z0) + ?(z0))/?(z0) > 0.316. For z0 = 0.2, ?(?(z0) + ?(z0))/?(z0) > 0.316 is valid\nfor 8300 ? L/km ? 10770. For z = 0.3, the above baseline range is extended to 7410 ?\nL/km ? 10790.\n16\n2. min2, ?23 > pi/4\nWith a true value of ?23 greater than pi/4, i.e., the true value of y less than zero, the\nvalue of 1 ? ?(z0) ? p can either be positive or negative. The condition 1 ? ?(z0) ? p >\n(<)0 is equivalent to the condition |y| < (>)(?(z0) +?(z0))/(??(z0)). For ?(?(z0) +\n?(z0))/?(z0) > 0.316, one must have 1 ? ?(z0) ? p > 0. Hence there exist two negative\nsolutions for y. In this case, the corresponding solutions for ?23 are both located in the same\noctant. For 0.316 < ?(?(z0)+?(z0))/?(z0) < 0.632, the spurious solution for y may or may\nnot violate the constraint y > ?0.316. For ?(?(z0) + ?(z0))/?(z0) > 0.632, the spurious\nsolution for y must violate the constraint y > ?0.316, hence the ?23 degeneracy is surely\nabsent. For sin2?13 = 0.2, the condition ?(?(z0)+?(z0))/?(z0) > 0.632 can not be achieved\nalong min2. For sin2?13 = 0.3, the above condition is satisfied for 8270 ? L/km ? 10720.\nFor ?(?(z0) + ?(z0))/?(z0 < 0.316, 1 ? ?(z0) ?p can either be positive or negative. For\n1??(z0)?p > 0, both solutions for y are negative and satisfying the constraint y > ?0.316.\nFor 1 ? ?(z0) ? p < 0, both solutions for y satisfy the constraint ?0.316 < y < 0.316.\nHowever their corresponding ?23 angles are situated in different octants.\nLet us summarize the results obtained in this subsection. The coefficient ?+? dominates\nover ?? for energy values along curves max1 and max2 for all baseline lengths. Hence the\n?23 degeneracy is absent along these energy curves for all baseline lengths. The situation\nalong the curve min1 is just the opposite, the coefficient ?? dominates over ? + ? for all\nbaseline lengths. Hence the ?23 degeneracy is present for all baseline lengths in this case.\nThe issue of ?23 degeneracy becomes more complicated along min2, which we have discussed\naccording to the true octant of ?23. Along the energy curve min2, the non-degeneracy\nbaseline range is larger for the ?23 < pi/4 case.\nIV. DISCUSSIONS AND CONCLUSIONS\nWe have presented the baselines and energies ideal for probing the octant of ?23 through\nneutrino oscillations. The appearance mode ?e ? ?? can be studied in a very long baseline\nwith the facility of neutrino factory [29] or the more recent proposed ? beam [30]. As said,\nthe sensitivity of Pe? to ?23 is dg(y,z)/dy = ?(?(z) + ?(z)) where g(y,z) represents Pe? in\nthe analytic approximation given by Eq. (12). The maximal value of ?+? for each baseline\n17\nlength is shown in Fig. 9. At the magic baseline, L = 7600 km, ?+? = 0.06, 0.21 and 0.38\nfor sin2?13 = 0.1, 0.2 and 0.3 respectively. For a sufficiently large sin2?13 and a baseline\nlength close to the magic value [14, 15, 16], Pe? is ideal for probing the octant of ?23.\nThe probability P?? is also relevant in neutrino oscillation experiments with neutrino\nfactories. The sensitivity of this probability to ?23 is determined by the derivative\nr ? dP??dcos2?\n23\n= ?2?cos2?23 + (? + ?). (15)\nSince ? is negative, the sensitivity r is larger for cos2?23 > 0, i.e., ?23 < pi/4. For a\nmeasurement performed around a local maximum of P??, the sensitivity to ?23 is completely\ndetermined by the coefficient ?+?, since the coefficient ? is generally rather suppressed in\nthis case. Along the energy curve denoted by max1, ?+? peaks at 7480 km for sin2?13 = 0.2\nand it peaks at L = 7350 km for sin2?13 = 0.3. The values of ?+? at those peaks are 0.17\nand 0.32 respectively. Along the curve max2, ? + ? peaks around L = 10750 km for both\nsin2?13 = 0.2 and 0.3 with values 0.43 and 0.48 respectively.\nFor a measurement performed around a local minimum of P??, the sensitivity to ?23 is\ndetermined by both coefficients ?? and ? + ?. Along the energy curve denoted by min1,\nthe coefficient ?? is always close to unity while the coefficient ? + ? is always suppressed\nfor all baseline lengths. It is understood that the magnitude of ? + ? determines the size\nof matter effects. Hence the matter effect is small at energies along the curve min1. The\nsuppression of ? + ? compared to ?? leads to the ?23 degeneracy as discussed before. The\nbehavior of P?? along the energy curve min2 is more interesting. If the true value of ?23\nis less than pi/4, the ?23 degeneracy from the measurement of P?? is absent in the baseline\nrange 8300 ? L/km ? 10770 for sin2?13 = 0.2. The above non-degeneracy baseline range\nextends to 7410 ? L/km ? 10790 for sin2?13 = 0.3. On the other hand, if the true ?23\nis greater than pi/4, the non-degeneracy baseline range does not exist along the energy\ncurve min2 for sin2?13 = 0.2. For sin2?13 = 0.3, the non-degeneracy baseline range is\n8270 ? L/km ? 10720.\nThe existence of non-degeneracy baseline range along the energy curve min2 has impor-\ntant implications. It can be seen from Fig. 3 that the curve min2 lies in between curves\nmax1 and max2. Since the degeneracy of ?23 is absent on both max1 and max2 for all\nbaselines, it is possible that there exists a non-degeneracy region spanned by ranges of the\nbaseline length and the neutrino energy. For example, with sin2?13 = 0.2 and a true value of\n18\nTABLE I: The baseline range in which the ?23 degeneracy is absent in the probability P?? for all\nenergy values between the curves max2 and max1. The entry corresponding to ?23 > pi/4 and\nsin2?13 = 0.2 is left blank since, with such set of parameters, there exists no baseline length where\nthe condition for the absence of ?23 degeneracy can be satisfied.\n?23 octant sin2?13 = 0.2 sin2?13 = 0.3\n?23 < pi/4 8550 ? L/km ? 10680 7950 ? L/km ? 10700\n?23 > pi/4 8450 ? L/km ? 10680\n?23 less than pi/4, the ?23 degeneracy is absent for 8300 ? L/km ? 10770 for energies along\ncurves max2, min2 and max1. It is of great interest to investigate if the ?23 degeneracy is\nalso absent for any neutrino energy larger than the value on max2 and smaller than that on\nmax1. By taking all these energies into account, we find that the ?23 degeneracy is absent\nfor 8550 ? L/km ? 10680. For a true value of ?23 greater than pi/4 and sin2?13 = 0.3,\nthe ?23 degeneracy is absent for 8270 ? L/km ? 10720 for energies along curves max2,\nmin2 and max1. However, with all energies between curves max2 and max1 considered,\nwe find that the ?23 degeneracy is absent for 8450 ? L/km ? 10680. The non-degeneracy\nbaseline range corresponding to different combinations of ?23 and ?13 values are summarized\nin Table I.\nIt is interesting to compare measurements on Pe? and P?? since both oscillations appear\nin experiments with neutrino factories [29]. The main issue for comparison is on the deter-\nmination of the true ?23 value under the assumption that both the sign of ?m231 and the\nvalue of sin2?13 are known. Let us begin the discussion with a true value of ?23 less than pi/4\nand sin2?13 = 0.2. For L < 8550 km, the appearance mode ?e ? ?? is useful for probing the\noctant of ?23, in particular for L close to the magic value, 7600 km. However, the survival\nmode ?? ? ?? is not as useful since the ?23 degeneracy is absent only at energies near max1\nand max2. Concerning the sensitivity to ?23, we note that the differentiation of Pe? with\nrespect to cos2?23 is ?(?+?). The value of ?+? increases with L as shown in Fig. 9. It is\n0.21 at L = 7600 km, and 0.26 at L = 8550 km. For 8550 ? L/km ? 10680, both ?e ? ??\nand ?? ? ?? are useful for probing the octant of ?23. We note that peak positions of Pe?\nare mostly around 6 GeV. Hence they overlap with the non-degeneracy energy range of P??.\nFrom Eq. (15) and our assumption of ?23 < pi/4, we find that P?? is more sensitive to ?23\n19\nas compared to Pe? for the same neutrino energy. For L > 10680 km, ?e ? ??, is again the\nonly useful mode for probing the octant of ?23.\nLet us turn to the case where the true value of ?23 is greater than pi/4 and sin2?13 = 0.2.\nIn such a case, the value for Pe? is enhanced compared to that with y > 0. Furthermore\nPe? is always more sensitive to cos2?23 as compared to P?? for the same neutrino energy.\nIt is clear that the ?e ? ?? appearance mode is more useful for probing ?23 regardless the\nbaseline length. Although there exists a baseline range where the ?23 degeneracy is absent\nin P?? for neutrino energies between curves max2 and max1. However this requires a large\nvalue of sin2?13, such as sin2?13 = 0.3.\nIt is essential to remark that the above non-degeneracy baseline range is not sensitive to\nthe value of ?m231, which we have so far taken to be 2.4 ? 10?3 eV2. Changing the value\nof ?m231 only shifts the probability curves in Fig. 4 and Fig. 6 so that positions for local\nmaxima and local minima of these probabilities shift accordingly. However, the maximal or\nminimal values of these probabilities remain unchanged. In other words, although the energy\ncurves in Fig. 3 are shifted, the coefficients ?? and ?+? plotted in Fig. 10, which combine\nto form Pe? and P?? (see Eq. (12)), remain the same. The values of these coefficients as\nfunctions of the baseline length L then determine the non-degeneracy baseline range.\nInconclusion, we have studied theprobabilities Pe? andP?? forvery longbaseline neutrino\noscillations. We focus on sensitivities of these probabilities to mixing angles ?13, ?23 and the\nCP violation phase ?CP. Taking ?CP = 0 as an example, we presented contour graphs of\nPe? and P?? in the sin2?13 ? cos2?23 plane for baseline lengths L = 1000 km, 5000 km,\n10000 km and 12000 km. The energy values chosen for such studies are in the vicinities of\neither local minima or local maxima of neutrino oscillation probabilities. For each baseline\nlength, we have found that P?? is more sensitive to sin2?13 at energies around its local\nmaxima while it is more sensitive to cos2?23 at energies around its local minima. On the\nother hand, the appearance probability Pe? is sensitive to sin2?13 and cos2?23 only near its\nlocal maximum. Such findings have been applied to probe the octant of mixing angle ?23\nassuming that the angle ?13 and the sign of ?m231 are known. The appearance probability\nPe? is non-degenerate in ?23. The sensitivity of Pe? to cos2?23 is studied for baseline lengths\nfrom 1000 km to 12000 km. We also studied the sensitivity of P?? to cos2?23 for the same\nrange of baseline length. We have identified the ranges of neutrino energy and baseline\nlengths where the ?23 degeneracy is absent. We have pointed out that, for a true value of ?23\n20\nless than pi/4 and a baseline length between 8000 and 10000 km, the survival mode ?? ? ??\nis equally good as the appearance mode ?e ? ?? for probing the octant of ?23.\nAcknowledgements\nG.L.L likes to thank D. Indumathi for informative discussions. This work is supported\nby National Science Council of Taiwan under the grant number NSC 94-2112-M-009-026.\n[1] Y. Ashie et al. [Super-Kamiokande Collaboration], Phys. Rev. D 71, 112005 (2005)\n[arXiv:hep-ex/0501064].\n[2] Y. Ashie et al. [Super-Kamiokande Collaboration], Phys. Rev. Lett. 93 (2004) 101801\n[arXiv:hep-ex/0404034].\n[3] E. Aliu et al. [K2K Collaboration], Phys. Rev. Lett. 94 (2005) 081802 [arXiv:hep-ex/0411038].\n[4] M. H. Ahn et al. [K2K Collaboration], Phys. Rev. D74, 072003 (2006) [arXiv:hep-ex/0606032].\n[5] K. Eguchi et al. [KamLAND Collaboration], Phys. Rev. Lett. 90 (2003) 021802\n[arXiv:hep-ex/0212021].\n[6] T. Araki et al. [KamLAND Collaboration], Phys. Rev. Lett. 94 (2005) 081801\n[arXiv:hep-ex/0406035].\n[7] See G. L. Fogli, E. Lisi, A. Marrone and A. Palazzo, Prog. Part. Nucl. Phys. 57, 742 (2006)\n[arXiv:hep-ph/0506083], which contains a list of original references on solar neutrino oscilla-\ntions.\n[8] G. L. Fogli and E. Lisi, Phys. Rev. D 54, 3667 (1996) [arXiv:hep-ph/9604415].\n[9] M. Apollonio et al. [CHOOZ Collaboration], Phys. Lett. B 466, 415 (1999)\n[arXiv:hep-ex/9907037].\n[10] F. Boehm et al., Phys. Rev. D 64, 112001 (2001) [arXiv:hep-ex/0107009].\n[11] I. Mocioiu and R. Shrock, Phys. Rev. D 62, 053017 (2000) [arXiv:hep-ph/0002149];\nV. D. Barger, S. Geer, R. Raja and K. Whisnant, Phys. Lett. B 485, 379 (2000)\n[arXiv:hep-ph/0004208]; V. D. Barger, S. Geer, R. Raja and K. Whisnant, Phys. Rev. D\n62, 013004 (2000) [arXiv:hep-ph/9911524]; M. Freund, M. Lindner, S. T. Petcov and A. Ro-\nmanino, Nucl. Phys. B 578, 27 (2000) [arXiv:hep-ph/9912457]; M. Freund, P. Huber and\n21\nM. Lindner, Nucl. Phys. B 585, 105 (2000) [arXiv:hep-ph/0004085]; A. Cervera, A. Donini,\nM. B. Gavela, J. J. Gomez Cadenas, P. Hernandez, O. Mena and S. Rigolin, Nucl. Phys. B\n579, 17 (2000) [Erratum-ibid. B 593, 731 (2001)] [arXiv:hep-ph/0002108].\n[12] D. Choudhury and A. Datta, JHEP 0507, 058 (2005) [arXiv:hep-ph/0410266]; D. Indu-\nmathi and M. V. N. Murthy, Phys. Rev. D 71, 013001 (2005) [arXiv:hep-ph/0407336];\nS. Choubey and P. Roy, Phys. Rev. D 73, 013006 (2006) [arXiv:hep-ph/0509197]. D. In-\ndumathi, M. V. N. Murthy, G. Rajasekaran and N. Sinha, Phys. Rev. D 74, 053004 (2006)\n[arXiv:hep-ph/0603264].\n[13] We adopt the approach of M. Freund and T. Ohlsson, Mod. Phys. Lett. A 15, 867 (2000)\n[arXiv:hep-ph/9909501], by dividing the Earth density regions into the Earth mantle and the\nEarth core. However we have further introduced the concept of average density to be discussed\nin details later.\n[14] V. Barger, D. Marfatia and K. Whisnant, Phys. Rev. D 65, 073023 (2002)\n[arXiv:hep-ph/0112119].\n[15] P. Huber and W. Winter, Phys. Rev. D 68, 037301 (2003) [arXiv:hep-ph/0301257].\n[16] A. Y. Smirnov, arXiv:hep-ph/0610198.\n[17] Z. Maki, M. Nakagawa and S. Sakata, Prog. Theor. Phys. 28, 870 (1962); see also , B. Pon-\ntecorvo, Zh. Eksp. Teor. Fiz. 53, 1717 (1967) [Sov. Phys. JETP 26, 984 (1968)].\n[18] A. Dziewonski, Earth Structure, Global, in: The Encyclopedia of Solid Earth Geophysics,\nDavid E. James, ed. (Van Nostrand Reinhold, New York 1989) p. 331.\n[19] M. V. Chizhov and S. T. Petcov, Phys. Rev. D 63, 073003 (2001) [arXiv:hep-ph/9903424];\nM. V. Chizhov and S. T. Petcov, Phys. Rev. Lett. 83, 1096 (1999) [arXiv:hep-ph/9903399].\n[20] E. K. Akhmedov, Nucl. Phys. B 538, 25 (1999) [arXiv:hep-ph/9805272].\n[21] S. T. Petcov, Phys. Lett. B 214, 259 (1988).\n[22] J. Bernabeu, S. Palomares-Ruiz, A. Perez and S. T. Petcov, Phys. Lett. B 531, 90 (2002)\n[arXiv:hep-ph/0110071].\n[23] Y. C. Hsu, Master Thesis, NCTU (2005).\n[24] See E. K. Akhmedov, R. Johansson, M. Lindner, T. Ohlsson and T. Schwetz, JHEP 0404,\n078 (2004) [arXiv:hep-ph/0402175] and earlier works cited in this paper.\n[25] J. N. Bahcall, M. C. Gonzalez-Garcia and C. Pena-Garay, JHEP 0408 (2004) 016\n[arXiv:hep-ph/0406294].\n22\n[26] I. Mocioiu and R. Shrock, JHEP 0111, 050 (2001) [arXiv:hep-ph/0106139].\n[27] F. Ardellier et al. [Double Chooz Collaboration], arXiv:hep-ex/0606025.\n[28] Y. Wang, arXiv:hep-ex/0610024.\n[29] S. Geer, Phys. Rev. D 57, 6989 (1998) [Erratum-ibid. D 59, 039903 (1999)]\n[arXiv:hep-ph/9712290]; A. De Rujula, M. B. Gavela and P. Hernandez, Nucl. Phys. B 547,\n21 (1999) [arXiv:hep-ph/9811390]; V. D. Barger, S. Geer and K. Whisnant, Phys. Rev. D 61,\n053004 (2000) [arXiv:hep-ph/9906487].\n[30] P. Zucchelli, Phys. Lett. B 532, 166 (2002).\n23\n"}
{"id":"oai:arXiv.org:quant-ph/0610192","text":"arXiv:q-bio/0601020v1  [q-bio.BM]  14 Jan 2006\nComputation of protein geometry and its applications: Packing and\nfunction prediction\nJie Liang\nFebruary 9, 2008\nContents\n6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n6.2 Theory and Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n6.2.1 The idealized ball model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n6.2.2 Surface models: Lee-Richards and Connolly?s surfaces . . . . . . . . . . . . . . . . . . 2\n6.2.3 Geometric constructs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n6.2.4 Topological structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n6.2.5 Metric measurement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n6.3 Computation and software . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n6.4 Applications: Packing analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n6.5 Applications: Protein function prediction from structures. . . . . . . . . . . . . . . . . . . . . 13\n6.6 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n6.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n6.8 Further reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n6.9 Acknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n6.1 Introduction\nThree-dimensional atomic structures of protein molecules provide rich information for understanding how\nthese working molecules of a cell carry out their biological functions. With the amount of solved protein\nstructures rapidly accumulating, computation of geometric properties of protein structure becomes an indis-\npensable component in studies of modern biochemistry and molecular biology. Before we discuss methods for\ncomputing the geometry of protein molecules, we first briefly describe how protein structures are obtained\nexperimentally.\nThereareprimarilythree experimentaltechniques for obtainingprotein structures: X-raycrystallography,\nsolution nuclear magnetic resonance (NMR), and recently freeze-sample electron microscopy (cryo-EM). In\nX-ray crystallography, the diffraction patterns of X-ray irradiation of a high quality crystal of the protein\nmolecule are measured. Since the diffraction is due to the scattering of X-rayby the electrons of the molecules\nin the crystal, the position, the intensity, and the phase of each recorded diffraction spot provide information\nfor the reconstruction of an electron density map of atoms in the protein molecule. Based on independent\ninformation of the amino acid sequence, a model of the protein conformation is then derived by fitting model\nconformations of residues to the electron density map. An iterative process called refinement is then applied\nto improve the quality of the fit of the electron density map. The final model of the protein conformation\nconsists of the coordinates of each of the non-hydrogen atoms [1].\nThe solution NMR technique for solving protein structure is based on measuring the tumbling and\nvibrating motion of the molecule in solution. By assessing the chemical shifts of atomic nuclei with spins due\nto interactions with other atoms in the vicinity, a set of estimated distances between specific pairs of atoms\ncan be derived from NOSEY spectra. When a large number of such distances are obtained, one can derive\na set of conformations of the protein molecule, each is consistent with all of the distance constraints [2].\nAlthough determining conformations from either X-ray diffraction patterns or NMR spectra is equivalent to\nsolving an ill-posed inverse problem, technique such as Bayesian Markov chain Monte Carlo with parallel\n1\ntempering has been shown to be effective in obtaining protein structures from NMR spectra [3]. The cryo-EM\ntechnique for obtaining protein structure is described in more details in Chapter 11.\n6.2 Theory and Model\n6.2.1 The idealized ball model\nThe shape of a protein molecule is complex. The chemical properties of atoms in a molecule are determined\nby their electron charge distribution. It is this distribution that generates the scattering patterns of the\nX-ray diffraction. Chemical bonds between atoms lead to transfer of electronic charges from one atom to\nanother, and the resulting isosurfaces of the electron density distribution depend not only on the location of\nindividual nuclei but also on interactions between atoms. This results in an overall complicated isosurface\nof electron density [4].\nThe geometric model of macromolecule amenable to convenient computation is an idealized model, where\nthe shapes of atoms are approximated by three-dimensional balls. The shape of a protein or a DNA molecule\nconsisting of many atoms is then the space-filling shape taken by a set of atom balls. This model is often\ncalled the interlocking hard-sphere model, the fused ball model, the space filling model [5?8], or the union\nof ball model [9]. In this model, details in the distribution of electron density, e.g., the differences between\nregions of covalent bonds and non-covalent bonds, are ignored. This idealization is quite reasonable, as it\nreflects the fact that the electron density reaches maximum at a nucleus, and its magnitude decays almost\nspherically away from the point of the nucleus. Despite possible inaccuracy, this idealized model has found\nwide acceptance, because it enables quantitative measurement of important geometric properties (such as\narea and volume) of molecules. Insights gained from these measurements correlate well with experimental\nobservations [5,8,10?13].\nIn this idealization, the shape of each atom is that of a ball, and its size parameter is the ball radius.\nThere are many possible choices for the parameter set of atomic radii [14,15]. Frequently, atomic radii are\nassigned the values of their van der Waals radii [16]. Among all these atoms, hydrogen atom has the smallest\nmass, and has a much smaller radius than those of other atoms. For simplification, the model of united\natom is often employed to approximate the union of a heavy atom and the hydrogen atoms connected by a\ncovalent bond. In this case, the radius of the heavy atom is increased to approximate the size of the union of\nthe two atoms. This practice significantly reduces the total number of atom balls in the molecule. However,\nthis approach has been questioned for possible inadequacy [17].\nThe mathematical model of this idealized model is that of the union of balls [9]. For a molecule M of n\natoms, the i-th atom is modeled as a ball bi, whose center is located at zi ? R3, and the radius of this ball\nis ri ? R, namely, we have bi ? {x|x ? R3,||x?zi|| ? ri} parameterized by (zi,ri). The molecule M is\nformed by the union of a finite number n of such balls defining the set B:\nM =\nuniondisplay\nB =\nnuniondisplay\ni=1\n{bi}.\nIt creates a space-filling body corresponding to the union of the excluded volumes vol(uniontextni=1 bi) [9]. When\nthe atoms are assigned the van der Waals radii, the boundary surface ?uniontextB of the union of balls is called\nthe van der Waals surface.\n6.2.2 Surface models: Lee-Richards and Connolly?s surfaces\nProtein folds into native three-dimensional shape to carry out its biological functional roles. The interac-\ntions of a protein molecule with other molecules (such as ligand, substrate, or other protein) determine its\nfunctional roles. Such interactions occur physically on the surfaces of the protein molecule.\nThe importance of protein surface was recognized very early on. Lee and Richards developed the widely\nused solvent accessible surface (SA) model, which is also often called the Lee-Richards surface model [5].\n2\nba c\nFigure 6.1: Geometric models of protein surfaces. (a) The solvent accessible surface (SA surface) is shown\nin the front. The van der Waals surface (beneath the SA surface) can be regarded as a shrunken version\nof the SA surface by reducing all atomic radii uniformly by the amount of the radius of the solvent probe\nrs = 1.4?A. The elementary pieces of the solvent accessible surface are the three convex spherical surface\npieces, the three arcs, and the vertex where the three arcs meet. (b) The molecular surface (MS, beneath\nthe SA surface) also has three types of elementary pieces: the convex spheric pieces, which are shrunken\nversion of the corresponding pieces in the solvent accessible surface, the concave toroidal pieces, and concave\nspheric surface. The latter two are also called the re-entrant surface. (c) The toroidal surface pieces in the\nmolecular surface, correspond to the arcs in the solvent accessible surface, and the concave spheric surface\nto the vertex. The set of elements in one surface can be continuously deformed to the set of elements in the\nother surface.\nIntuitively, this surface is obtained by rolling a ball of radius rs everywhere along the van der Waals surface of\nthe molecule. The center of the solvent ball will then sweep out the solvent accessible surface. Equivalently,\nthe solvent accessible surface can be viewed as the boundary surface ?uniontextBrs of the union of a set of inflated\nballs Brs, where each ball takes the position of an atom, but with an inflated radius ri + rs (Fig. 6.1a).\nThe solvent accessible surface in general has many sharp crevices and sharp corners. In hope of obtaining\na smoother surface, one can take the surface swept out by the front instead of the center of the solvent ball.\nThis surface is the molecular surface (MS model), which is often called the Connolly?s surface after Michael\nConnolly who developed the first algorithm for computing molecular surface [11]. Both solvent accessible\nsurface and molecular surface are formed by elementary pieces of simpler shape.\nElementary pieces. For the solvent accessible surface model, the boundary surface of a molecule consists\nof three types of elements: the convex spherical surface pieces, arcs or curved line segments (possibly a\nfull circle) formed by two intersecting spheres, and a vertex that is the intersection point of three atom\nspheres. The whole boundary surface of the molecules can be thought of as a surface formed by stitching\nthese elements together.\nSimilarly, the molecular surface swept out by the front of the solvent ball can also be thought of as being\nformed by elementary surface pieces. In this case, they are the convex spherical surface pieces, the toroidal\nsurface pieces, and the concave or inverse spherical surface pieces (Fig. 6.1b) . The latter two types of surface\npieces are often called the ?re-entrant surfaces? [8,11].\nThe surface elements of the solvent accessible surface and the molecular surface are closely related.\nImagine a process where atom balls are shrunk or expanded. The vertices in solvent accessible surface\nbecomes the concave spherical surface pieces, the arcs becomes the toroidal surfaces, and the convex surface\npieces become smaller convex surface pieces (Fig. 6.1c). Because of this mapping, these two type of surfaces\nare combinatorically equivalent and have similar topological properties, i.e., they are homotopy equivalent.\nHowever, the SA surface and the MS surface differ in their metric measurement. In concave regions of a\nmolecule, often the front of the solvent ball can sweep out a larger volume than the center of the solvent ball.\nA void of size close to zero in solvent accessible surface model will correspond to a void of the size of a solvent\nball (4pir3s/3). It is therefore important to distinguish these two types of measurement when interpreting the\nresults of volume calculations of protein molecules. The intrinsic structures of these fundamental elementary\n3\nvoid\na cb\nFigure 6.2: Geometry of a simplified two dimensional model molecule, to illustrate the geometric constructs\nand the procedure mapping the Voronoi diagram to the Delaunay triangulation. (a) The molecule formed by\nthe union of atom disks of uniform size. Voronoi diagram is in dashed lines. (b) The shape enclosed by the\nboundary polygon is the convex hull. It is tessellated by the Delaunay triangulation. (c) The alpha shape of\nthe molecule is formed by removing those Delaunay edges and triangles whose corresponding Voronoi edges\nand Voronoi vertices do not intersect with the body of the molecule. A molecular void is represented in the\nalpha shape by two empty triangles.\npieces are closely related to several geometric constructs we describe below.\n6.2.3 Geometric constructs\nVoronoi diagram. Voronoi diagram (Fig 6.2a), also known as Voronoi tessellation, is a geometric construct\nthat has been used for analyzing protein packing in the early days of protein crystallography [6,18,19]. For\ntwo dimensional Voronoi diagram, we consider the following analogy. Imagine a vast forset containing a\nnumber of fire observation towers. Each fire ranger is responsible for putting out any fire closer to his/her\ntower than to any other tower. The set of all trees for which a ranger is responsible constitutes the Voronoi\ncell associated with his/hertower, and the map of rangerresponsibilities, with towersand boundariesmarked,\nconstitutes the Voronoi diagram.\nWe formalize this for three dimensional space. Consider the point set S of atom centers in three dimen-\nsional space R3. The Voronoi region or Voronoi cell Vi of an atom bi with atom center zi ? R3 is the set of\nall points that are at least as close to zi than to any other atom centers in S:\nVi = {x ?R3|||x?zi|| ? ||x?zj||,zj ? S}. (6.1)\nWe can have an alternative view of the Voronoi cell of an atom bi. Considering the distance relationship of\natom center zi with the atom center zk of another atom bk. The plane bisecting the line segment connecting\npoints zi and zk divides the full R3 space into two half spaces, where points in one half space is closer to\nzi than to zk, and points in the other allspice is closer to zk than to zi. If we repeat this process and take\nzk in turn from the set of all atom centers other than zi, we will have a number of halfspaces where points\nare closer to zi than to each of the atom center zk. The Voronoi region Vi is then the common intersections\nof these half spaces, which is convex. When we consider atoms of different radii, we replace the Euclidean\ndistance ||x?zi|| with the power distance defined as: pii(x) ? ||x?zi||2 ?r2i .\nDelaunay tetrahedrization. Delaunay triangulation in R2 or Delaunay tetrahedrization in R3 is a geo-\nmetric construct that is closely related to the Voronoi diagram (Fig 6.2b). In general, it uniquely tessellates\nor tile up the space of the convex hull of the atom centers in R3 with tetrahedra. Convex hull for a point\n4\nset is the smallest convex body that contains the point set 1. The Delaunay tetrahedrization of a molecule\ncan be obtained from the Voronoi diagram. Consider that the Delaunay tetrahedrization is formed by gluing\nfour types of primitive elements together: vertices, edges, triangles, and tetrahedra. Here vertices are just\nthe atom centers. We obtain a Delaunay edge by connecting atom centers zi and zj if and only if the\nVoronoi regions Vi and Vj have a common intersection, which is a planar piece that may be either bounded\nor extend to infinity. We obtain a Delaunay triangle connecting atom centers zi, zj, and zk if the common\nintersection of Voronoi regions Vi,Vj and Vk exists, which is either a line segment, or a half-line, or a line\nin the Voronoi diagram. We obtain a Delaunay tetrahedra connecting atom centers zi,zj,zk and zl if and\nonly if the Voronoi regions Vi,Vj,Vk and Vl intersect at a point.\n6.2.4 Topological structures\nDelaunay complex. The structures in both Voronoi diagram and Delaunay tetrahedrization are better\ndescribed with concepts from algebraic topology. We focus on the intersection relationship in the Voronoi\ndiagram and introduce concepts formalizing the primitive elements. In R3, between two to four Voronoi re-\ngions may have common intersections. We use simplices of various dimensions to record these intersection or\noverlap relationships. We have vertices ?0 as 0-simplices, edges ?1 as 1-simplices, triangles ?2 as 2-simplices,\nand tetrahedra ?3 as 3-simplices. Each of the Voronoi plane, Voronoi edge, and Voronoi vertices corresponds\nto a 1-simplex (Delaunay edge), 2-simplex (Delaunay triangle), and 3-simplex (Delaunay tetrahedron), re-\nspectively. If we use 0-simplices to represent the Voronoi cells, and add them to the simplices induced by\nthe intersection relationship, we can think of the Delaunay tetrahedrization as the structure obtained by\n?glueing? these simplices properly together. Formally, these simplices form a simplicial complex K:\nK = {?|I|?1|\nintersectiondisplay\ni?I\nVi negationslash= ?}, (6.2)\nwhere I is an index set for the vertices representing atoms whose Voronoi cells overlap, and |I|? 1 is the\ndimension of the simplex.\nAlpha shape and protein surfaces. Imagine we can turn a knob to increase or decrease the size of all\natoms simultaneously. We can then have a model of growing balls and obtain further information from the\nDelaunay complex about the shape of a protein structure. Formally, we use a parameter ? ? R to control\nthe size of the atom balls. For an atom ball bi of radius ri, we modified its radius ri at a particular ? value\nto ri(?) = (r2i +?)1/2. When ?ri < ? < 0, the size of an atom is shrunk. The atom could even disappear if\n? < 0 and |?| > ri. We start to collect the simplices at different ? value as we increase ? from ?? to +?\n(see Fig 6.3 for a two-dimensional example). At the beginning, we only have vertices. When ? is increased\nsuch that two atoms are close enough to intersect, we collect the corresponding Delaunay edge that connects\nthese two atom centers. When three atoms intersect, we collect the correspondingDelaunay triangle spanning\nthese three atom centers. When four atoms intersect, we collect the corresponding Delaunay tetrahedron.\nAt any specific ? value, we have a dual simplicial complex or alpha complex K? formed by the collected\nsimplices. If all atoms take the incremented radius of ri +rs and ? = 0, we have the dual simplicial complex\nK0 of the protein molecule. When ? is sufficiently large, we have collected all simplices and we get the full\nDelaunay complex. This series of simplicial complexes at different ? value form a family of shapes (Fig 6.3),\ncalled alpha shapes, each faithfully represents the geometric and topological property of the protein molecule\nat a particular resolution parametrized by the ? value.\nAn equivalent way to obtain the alpha shape at ? = 0 is to take a subset of the simplices, with the\nrequirement that the corresponding intersections of Voronoi cells must overlap with the body of the union\n1For a two dimensional toy molecule, we can imagine that we put nails at the locations of the atom centers, and tightly wrap\na rubber band around these nails. The rubber band will trace out a polygon. This polygon and the region enclosed within\nis the convex hull of the set of points corresponding to the atom centers. Similarly, imagine if we can tightly wrap a tin-foil\naround a set of points in three dimensional space, the resulting convex body formed by the tin-foil and space enclosed within\nis the convex hull of this set of points in R3.\n5\na b c\nd e f\nFigure 6.3: The family of alpha shapes or dual simplicial complexes for a two-dimensional toy molecule.\n(a) We collect simplices from the Delaunay triangulation as atoms grow by increasing the ? value. At the\nbeginning as ? grows from ??, atoms are in isolation and we only have vertices in the alpha shape. (b) and\n(c) When ? is increased such that some atom pairs start to intersect, we collect the corresponding Delaunay\nedges. (d) When three atoms intersect as ? increases, we collect the corresponding Delaunay triangles.\nWhen ? = 0, the collection of vertices, edges, and triangles form the dual simplicial complex K0, which\nreflecting the topological structure of the protein molecule. (e) More edges and triangles from the Delaunay\ntriangulation are now collected as atoms continue to grow. (d) Finally, all vertices, edges, and triangles are\nnow collected as atoms are grown to large enough size. We get back the full original Delaunay complex.\nof the balls. We obtain the dual complex or alpha shape K0 of the molecule at ? = 0 (Fig 6.2c):\nK0 = {?|I|?1|\nintersectiondisplay\ni?I\nVi ?\nuniondisplay\nB negationslash= ?}. (6.3)\nAlpha shape provides a guide map for computing geometric properties of the structures of biomolecules.\nTake the molecular surface as an example, the re-entrant surfaces are formed by the concave spherical patch\nand the toroidal surface. These can be mapped from the boundary triangles and boundary edges of the\nalpha shape, respectively [20]. Recall that a triangle in the Delaunay tetrahedrization corresponds to the\nintersection of three Voronoi regions, i.e., a Voronoi edge. For a triangle on the boundary of the alpha shape,\nthe corresponding Voronoi edge intersects with the body of the union of balls by definition. In this case,\nit intersects with the solvent accessible surface at the common intersecting vertex when the three atoms\noverlap. This vertex corresponds to a concave spherical surface patch in the molecular surface. For an\nedge on the boundary of the alpha shape, the corresponding Voronoi plane coincides with the intersecting\nplane when two atoms meet, which intersect with the surface of the union of balls on an arc. This line\nsegment corresponds to a toroidal surface patch. The remaining part of the surface are convex pieces, which\ncorrespond to the vertices, namely, the atoms on the boundary of the alpha shape.\nThe numbers of toroidal pieces and concave spherical pieces are exactly the numbers of boundary edges\nand boundary triangles in the alpha shape, respectively. Because of the restriction of bond length and the\nexcluded volume effects, the number of edges and triangles in molecules are roughly in the order of O(n)\n[21].\n6.2.5 Metric measurement\nWe have described the relationship between the simplices and the surface elements of the molecule. Based\non this type of relationship, we can compute efficiently size properties of the molecule. We take the problem\n6\nof volume computation as an example.\nConsider a grossly incorrect way to compute the volume of a protein molecule using the solvent accessible\nsurface model. We could define that the volume of the molecule is the summation of the volumes of individual\natoms, whose radii are inflated to account for solvent probe. By doing so we would have significantly inflated\nthe value of the true volume, because we neglected to consider volume overlaps. We can explicitly correct\nthis by following the inclusion-exclusion formula: when two atoms overlap, we subtract the overlap; when\nthree atoms overlap, we first subtract the pair overlaps, we then add back the triple overlap, etc. This\ncontinues when there are four, five, or more atoms intersecting. At the combinatorial level, the principle\nof inclusion-exclusion is related to the Gauss-Bonnet theorem used by Connolly [11]. The corrected volume\nV (B) for a set of atom balls B can then be written as:\nV (B) =\nsummationdisplay\nvol(intersectiontext T)>0\nT?B\n(?1)dim(T)?1 vol(\nintersectiondisplay\nT), (6.4)\nwhere vol(intersectiontextT) represents volume overlap of various degree, T ? B is a subset of the balls with non-zero\nvolume overlap: vol(intersectiontextT) > 0.\nHowever, the straightforward application of this inclusion-exclusion formula does not work. The degree\nof overlap can be very high: theoretical and simulation studies showed that the volume overlap can be up\nto 7-8 degrees [22,23]. It is difficult to keep track of these high degree of volume overlaps correctly during\ncomputation, and it is also difficult to compute the volume of these overlaps because there are many different\ncombinatorial situations, i.e., to quantify how large is the k-volume overlap of which one of the parenleftbig7kparenrightbig or parenleftbig8kparenrightbig\noverlapping atoms for all of k = 2,??? ,7 [23]. It turns out that for three-dimensional molecules, overlaps\nof five or more atoms at a time can always be reduced to a ?+? or a ??? signed combination of overlaps\nof four or fewer atom balls [9]. This requires that the 2-body, 3-body, and 4-body terms in Eqn 6.4 enter\nthe formula if and only if the corresponding edge ?ij connecting the two balls (1-simplex), triangles ?ijk\nspanning the three balls (2-simplex), and tetrahedron ?ijkl cornered on the four balls (3-simplex) all exist in\nthe dual simplicial complex K0 of the molecule [9,21]. Atoms corresponding to these simplices will all have\nvolume overlaps. In this case, we have the simplified exact expansion:\nV (B) =\nsummationdisplay\n?i?K\nvol(bi)?\nsummationdisplay\n?ij?K\nvol(bi ?bj)\n+\nsummationdisplay\n?ijk?K\nvol(bi ?bj ?bk)?\nsummationdisplay\n?ijkl?K\nvol(bi ?bj ?bk ?bl).\nThe same idea is applicable for the calculation of surface area of molecules.\nAn example. An example of area computation by alpha shape is shown in Fig 6.4. Let b1,b2,b3,b4 be the\nfour disks. To simplify the notation we write Ai for the area of bi, Aij for the area of bi ?bj, and Aijk for\nthe area of bi ?bj ?bk. The total area of the union, b1 ?b2 ?b3 ?b4, is\nAtotal = (A1 + A2 + A3 + A4)\n? (A12 + A23 + A24 + A34)\n+ A234.\nWe add the area of bi if the corresponding vertex belongs to the alpha complex (Fig 6.4), we subtract the\narea of bi ?bj if the corresponding edge belongs to the alpha complex, and we add the area of bi ?bj ?bk if\nthe corresponding triangle belongs to the alpha complex. Note without the guidance of the alpha complex,\nthe inclusion-exclusion formula may be written as:\nAtotal = (A1 + A2 + A3 + A4)\n? (A12 + A13 + A14 + A23 + A24 + A34)\n+ (A123 + A124 + A134 + A234)\n? A1234.\n7\nb1\nb2\nb3\nb4\nA\nb1\nb2\nb3\nb4\nB\nFigure 6.4: An example of analytical area calculation. (a) Area can be computed using the direct inclusion-\nexclusion. (b) The formula is simplified without any redundant terms when using alpha shape.\nThis contains 6 canceling redundant terms: A13 = A123, A14 = A124, and A134 = A1234. Computing these\nterms would be wasteful. Such redundancy does not occur when we use the alpha complex: the part of the\nVoronoi regions contained in the respective atom balls for the redundant terms do not intersect. Therefore,\nthe corresponding edges and triangles do not enter the alpha complex. In two dimensions, we have terms of at\nmost three disk intersections, corresponding to triangles in the alpha complex. Similarly, in three dimensions\nthe most complicated terms are intersections of four spherical balls, and they correspond to tetrahedra in\nthe alpha complex.\nVoids and pockets. Voids and pockets represent the concave regions of a protein surface. Because shape-\ncomplementarity is the basis of many molecular recognition processes, binding and other activities frequently\noccur in pocket or void regions of protein structures. For example, the majority of enzyme reactions take\nplace in surface pockets or interior voids.\nThe topological structure of the alpha shape also offers an effective method for computing voids and\npockets in proteins. Consider the Delaunay tetrahedra that are not included in the alpha shape. If we\nrepeatedly merge any two such tetrahedra on the condition that they share a 2-simplex triangle, we will\nend up with discrete sets of tetrahedra. Some of them will be completely isolated from the outside, and\nsome of them are connected to the outside by triangle(s) on the boundary of the alpha shape. The former\ncorresponds to voids (or cavities) in proteins, the latter corresponds to pockets and depressions in proteins.\nA pocket differs from a depression in that it must have an opening that is at least narrower than one\ninterior cross-section. Formally, the discrete flow [24] explains the distinction between a depression and a\npocket. In a two dimensional Delaunay triangulation, the empty triangles that are not part of the alpha\nshape can be classified into obtuse triangles and acute triangles. The largest angle of an obtuse triangle is\nmore than 90 degrees, and the largest angle of an acute triangle is less than 90 degrees. An empty obtuse\ntriangle can be regarded as a ?source? of empty space that ?flows? to its neighbor, and an empty acute\ntriangle a ?sink? that collects flow from its obtuse empty neighboring triangle(s). In Figure 6.5a, obtuse\ntriangles 1, 3, 4 and 5 flow to the acute triangle 2, which is a sink. Each of the discrete empty spaces on\nthe surface of protein can be organized by the flow systems of the corresponding empty triangles: Those\nthat flow together belong to the same discrete empty space. For a pocket, there is at least one sink among\nthe empty triangles. For a depression, all triangles are obtuse, and the discrete flow goes from one obtuse\ntriangle to another, from the innermost region to outside the convex hull. The discrete flow of a depression\ntherefore goes to infinity. Figure 6.5b gives an example of a depression formed by a set of obtuse triangles.\nOnce voids and pockets are identified, we can apply the inclusion-exclusion principle based on the sim-\nplices to compute the exact size measurement (e.g., volume and area) of each void and pocket [24,25].\nThe distinction between voids and pockets depends on the specific set of atomic radii and the solvent\n8\n1\n2 34\n5\n1\n345\nInfinity\n2\na b\nFigure 6.5: Discrete flow of empty space illustrated for two dimensional disks. (a) Discrete flow of a pocket.\nTriangles 1, 3, 4 and 5 are obtuse. The free volume flows to the ?sink? triangle 2, which is acute. (b) In a\ndepression, the flow is from obtuse triangles to the outside.\nradius. When a larger solvent ball is used, the radii of all atoms will be inflated by a larger amount. This\ncould lead to two different outcomes. A void or pocket may become completely filled and disappear. On the\nother hand, the inflated atoms may not fill the space of a pocket, but may close off the opening of the pocket.\nIn this case, a pocket becomes a void. A widely used practice in the past was to adjust the solvent ball\nand repeatedly compute voids, in the hope that some pockets will become voids and hence be identified by\nmethods designed for cavity/void computation. The pocket algorithm [24] and tools such as CastP [26,27]\noften makes this unnecessary.\n6.3 Computation and software\nComputing Delaunay tetrahedrization and Voronoi diagram. It is easier to discuss the computation\nof tetrahedrization first. The incremental algorithm developed in [28] can be used to compute the weighted\ntetrahedrization for a set of atoms of different radii. For simplicity, we sketch the outline of the algorithm\nbelow for two dimensional unweighted Delaunay triangulation.\nThe intuitive idea of the algorithm can be traced back to the original observation of Delaunay. For the\nDelaunay triangulation of a point set, the circumcircle of an edge and a third point forming a Delaunay\ntriangle must not contain a fourth point. Delaunay showed that if all edges in a particular triangulation\nsatisfy this condition, the triangulation is a Delaunay triangulation. It is easy to come up with an arbitrary\ntriangulation for a point set. A simple algorithm to covert this triangulation to the Delaunay triangulation is\ntherefore to go through each of the triangles, and make corrections using ?flips? discussed below if a specific\ntriangle contains an edge violating the above condition. The basic ingredients for computing Delaunay\ntetrahedrization are generalizations of these observations. We discuss the concept of locally Delaunay edge\nand the edge-flip primitive operation below.\nLocally Delaunay edge. We say an edge ab is locally Delaunay if either it is on the boundary of the convex\nhull of the point set, or if it belongs to two triangles abc and abd, and the circumcircle of abc does not contain\nd (e.g., edge cd in Fig 6.6a).\nEdge-flip. If ab is not locally Delaunay (edge ab in Fig 6.6a), then the union of the two triangles abc?abd\nis a convex quadrangle acbd, and edge cd is locally Delaunay. We can replace edge ab by edge cd. We call\nthis an edge-flip or 2-to-2 flip, as two old triangles are replaced by two new triangles.\nWe recursively check each boundary edge of the quadrangle abcd to see if it is also locally Delaunay after\nreplacing ab by cd. If not, we recursively edge-flip it.\nIncremental algorithm for Delaunay triangulation. Assume we have a finite set of points (namely, atom\ncenters) S = {z1,z2,??? ,zi,??? ,zn}. We start with a large auxiliary triangle that contains all these points.\nWe insert the points one by one. At all times, we maintain a Delaunay triangulation Di upto insertion of\n9\n1?to?3 flip\nb\n2?to?2 flip\na\nb\nc\nd\na\nb\nc\nd\na\nFigure 6.6: An illustration of locally Delaunay edge and flips. (a) For the quadrilateral abcd, edge ab is not\nlocally Delaunay, as the circumcircle passing through edge ab and a third point c contains a fourth point d.\nEdge cd is locally Delaunay, as b is outside the circumcircle adc. An edge-flip or 2-to-2 flip replaces edge ab\nby edge cd, and replace the original two triangles abc and adb with two new triangles acd and bcd. (b) When\na new vertex is inserted, we replace the old triangle containing this new vertex with three new triangles.\nThis is called 1-to3 flips.\npoint zi.\nAfter inserting point zi, we search for the triangle ?i?1 that contains this new point. We then add zi to\nthe triangulation and split the original triangle ?i?1 into three smaller triangles. This split is called 1-to-3\nflip, as it replaces one old triangle with three new triangles. We then check if each of the three edges in ?i?1\nstill satisfies the locally Delaunay requirement. If not, we perform a recursive edge-flip. This algorithm is\nsummarized in Algorithm 1.\nAlgorithm 1 Delaunay triangulation\nObtain random ordering of points {z1,??? ,zn};\nfor i = 1 to n do\nfind ?i?1 such zi ? ?i?1;\nadd zi, and split ?i?1 into three triangles (1-to-3 flip);\nwhile any edge ab not locally Delaunay do\nflip ab to other diagonal cd (2-to-2 edge flip);\nend while\nend for\nIn R3, the algorithm of tetrahedrization becomes more complex, but the same basic ideas apply. In this\ncase, we need to locate a tetrahedron instead of a triangle that contains the newly inserted point. The\nconcept of locally Delaunay is replaced by the concept of locally convex, and there are flips different than the\n2-to-2 flip in R3 [28]. Although an incremental approach, i.e., sequentially adding points, is not necessary\nfor Delaunay triangulation in R2, it is necessary in R3 to avoid non-flippable cases and to guarantee that\nthe algorithm will terminate. This incremental algorithm has excellent expected performance [28].\nThe computation of Voronoi diagram is conceptually easy once the Delaunay triangulation is available.\nWe can take advantage of the mathematical duality and compute all of the Voronoi vertices, edges, and\nplanar faces from the Delaunay tetrahedra, triangles, and edges. Because one point zi may be an vertex of\nmany Delaunay tetrahedra, the Voronoi region of zi therefore may contain many Voronoi vertices, edges,\nand planar faces. The efficient quad-edge data structure can be used for software implementation [29].\nVolume and area computation. Let V and A denote the volume and area of the molecule, respectively,\nK? for the alpha complex, ? for a simplex in K, i for a vertex, ij for an edge, ijk for a triangle, and ijkl for\na tetrahedron. The algorithm for volume and area computation can be written as Algorithm 2. Additional\ndetails of volume and area computation can be found in [20,21].\nSoftware. The software package Delcx for computing weighted Delaunay tetrahedrization, Mkalf for\ncomputing the alpha shape, Volbl for computing volume and area of both molecules and interior voids\n10\nAlgorithm 2 Volume and area measurement\nV := A := 0.0;\nfor all ? ? K do\nif ? is a vertex i then\nV := V +vol(bi); A := A+area(bi);\nend if\nif ? is an edge ij then\nV := V ?vol(bi ?bj); A := A?area(bi ?bj);\nend if\nif ? is a triangle ijk then\nV := V +vol(bi ?bj ?bk); A := A +area(bi ?bj ?bk);\nend if\nif ? is a tetrahedron ijkl then\nV := V ?vol(bi ?bj ?bk ?bl); A := A?area(bi ?bj ?bk ?bl);\nend if\nend for\nand be found at www.alphashape.org. The CastP webserver for pocket computation can be found at\ncast.engr.uic.edu. There are other studies that compute or use Voronoi diagrams of protein structures\n[30?32], although not all computes the weighted version which allows atoms to have different radii.\nIn this short description of algorithm, we have neglected many details important for geometric compu-\ntation. For example, the problem of how to handle geometric degeneracy, namely, when three points are\nco-linear, or when four points are co-planar. Interested readers should consult the excellent monograph by\nEdelsbrunner for a detailed treatise of these and other important topics in computational geometry [33].\n6.4 Applications: Packing analysis.\nAn important application of the Voronoi diagram and volume calculation is the measurement of protein\npacking. Tight packing is an important feature of protein structure [6,10], and is thought to play important\nroles in protein stability and folding dynamics [34]. The packing density of a protein is measured by the\nratio of its van der Waals volume and the volume of the space it occupies. One approach is to calculate the\npacking density of buried residues and atoms using Voronoi diagram [6,10]. This approach was also used to\nderive radii parameters of atoms [15].\nBased on the computation of voids and pockets in proteins, a detailed study surveying major represen-\ntatives of all known protein structural folds showed that there is a substantial amount of voids and pockets\nin proteins [35]. On average, every 15 residues introduces a void or a pocket (Fig 6.7a). For a perfectly\nsolid three-dimensional sphere of radius r, the relationship between volume V = 4pir3/3 and surface area\nA = 4pir2 is: V ? A3/2. In contrast, Figure 6.7b shows that the van der Waals volume scales linearly with\nthe van der Waals surface areas of proteins. The same linear relationship holds irrespective of whether we\nrelate molecular surface volume and molecular surface area, or solvent accessible volume and solvent acces-\nsible surface area. This and other scaling behavior point out that protein interior is not packed as tight as\nsolid [35]. Rather, packing defects in the form of voids and pockets are common in proteins.\nIf voids and pockets are prevalent in proteins, an interesting question is what is then the origin of the\nexistence of these voids and pockets. This question was studied by examining the scaling behavior of packing\ndensity and coordination number of residues through the computation of voids, pockets, and edge simplices\nin the alpha shapes of random compact chain polymers [36]. For this purpose, a 32-state discrete state\nmodel was used to generate a large ensemble of compact self-avoiding walks. This is a difficult task, as it is\nvery challenging to generate a large number of independent conformations of very compact chains that are\nself-avoiding. The results in [36] showed that it is easy for compact random chain polymers to have similar\nscaling behavior of packing density and coordination number with chain length. This suggests that proteins\n11\nNumber of Residues\nNum of Voids and Pockets\n0 200 600 1000\n0\n50\n100\n150\nA x 1000\nV x 1000\n0 200 400 600 800\n0\n100\n300\n500\nFigure 6.7: Voids and pockets for a set of 636 proteins representing most of the known protein folds, and\nthe scaling behavior of the geometric properties of proteins. (a) The number of voids and pockets detected\nwith a 1.4 ?A probe is linearly correlated with the number of residues in a protein. Only proteins with\nless than 1,000 residues are shown. Solid triangles and empty circles represent the pockets and the voids,\nrespectively. (b) The van der Waals (vdw) volume and van der Waals area of proteins scale linearly with\neach other. Similarly, molecular surface (ms) volume also scales linearly with molecular surface area using\na probe radius of 1.4?A. (Data not shown. Figure adapted after [35])\n12\nare not optimized by evolution to eliminate voids and pockets, and the existence of many pockets and voids is\nrandom in nature, and is due to the generic requirement of compact chain polymers. The frequent occurrence\nand the origin of voids and pockets in protein structures raise a challenging question: How can we distinguish\nvoids and pockets that perform biological functions such as binding from those formed by random chance?\nThis question is related to the general problem of protein function prediction.\n6.5 Applications: Protein function prediction from structures.\nConservation of protein structures often reveals very distant evolutionary relationship, which are otherwise\ndifficult to detect by sequence analysis [37]. Comparing protein structures can provide insightful ideas about\nthe biochemical functions of proteins (e.g., active sites, catalytic residues, and substrate interactions) [38?40].\nA fundamental challenge in inferring protein function from structure is that the functional surface of\na protein often involves only a small number of key residues. These interacting residues are dispersed in\ndiverse regions of the primary sequences and are difficult to detect if the only information available is the\nprimary sequence. Discovery of local spatial motifs from structures that are functionally relevant has been\nthe focus of many studies.\nGraph based methods for spatial patterns in proteins. To analyze local spatial patterns in proteins.\nArtymiuk et al developed an algorithm based on subgraph isomorphism detection [41]. By representing\nresidue side-chains as simplified pseudo-atoms, a molecular graph is constructed to represent the patterns of\nside-chain pseudo-atoms and their inter-atomic distances. A user defined query pattern can then be searched\nrapidly against the Protein Data Bank for similarity relationship. Another widely used approach is the\nmethod of geometric hashing. By examining spatial patterns of atoms, Fischer et al developed an algorithm\nthat can detect surface similarity of proteins [42,43]. This method has also been applied by Wallace et al for\nthe derivation and matching of spatial templates [44]. Russell developed a different algorithm that detects\nside-chain geometric patterns common to two protein structures [45]. With the evaluation of statistical\nsignificance of measured root mean square distance, several new examples of convergent evolution were\ndiscovered, where common patterns of side-chains were found to reside on different tertiary folds.\nThese methods have a number of limitations. Most require a user-defined template motif, restricting their\nutility for automated database-wide search. In addition, the size of the spatial pattern related to protein\nfunction is also often restricted.\nPredicting protein functions by matching pocket surfaces. Protein functional surfaces are frequently\nassociated with surface regions of prominent concavity [26,46]. These include pockets and voids, which can\nbe accurately computed as we have discussed. Computationally, one wishes to automatically identify voids\nand pockets on protein structures where interactions exist with other molecules such as substrate, ions,\nligands, or other proteins.\nBinkowski et al. developed a method for predicting protein function by matching a surface pocket or void\non a protein of unknown or undetermined function to the pocket or void of a protein of known function\n[47,48]. Initially, the Delaunay tetrahedrization and alpha shapes for almost all of the structures in the\nPDB databank are computed [27]. All surface pockets and interior voids for each of the protein structure\nare then exhaustively computed [24,25]. For each pocket and void, the residues forming the wall are then\nconcatenated to form a short sequence fragment of amino acid residues, while ignoring all intervening residues\nthat do not participate in the formation of the wall of the pocket or void. Two sequence fragments, one\nfrom the query protein and another from one of the proteins in the database, both derived from pocket or\nvoid surface residues, are then compared using dynamic programming. The similarity score for any observed\nmatch is assessed for statistical significance using an empirical randomization model constructed for short\nsequence patterns.\nFor promising matches of pocket/void surfaces showing significant sequence similarity, we can further\nevaluate their similarity in shape and in relative orientation. The former can be obtained by measuring\nthe coordinate root mean square distance (rmsd) between the two surfaces. The latter is measured by\n13\nfirst placing a unit sphere at the geometric center z0 ? R3 of a pocket/void. The location of each residue\nz = (x,y,z)T is then projected onto the unit sphere along the direction of the vector from the geometric\ncenter: u = (z ?z0)/||z ?z0||. The projected pocket is represented by a collection of unit vectors located\non the unit sphere, and the original orientation of residues in the pocket is preserved. The rmsd distance of\nthe two sets of unit vectors derived from the two pockets are then measured, which is called the ormsd for\norientation rmsd [47]. This allows similar pockets with only minor conformational changes to be detected\n[47].\nThe advantage of the method of Binkowski et al is that it does not assume prior knowledge of functional\nsite residues, and does not require a priori any similarity in either the full primary sequence or the backbone\nfold structures. It has no limitation in the size of the spatially derived motif and can successfully detect\npatterns small and large. This method has been successfully applied to detect similar functional surfaces\namong proteins of the same fold but low sequence identities, and among proteins of different fold [47,49].\nFunction prediction through models of protein surface evolution. To match local surfaces such as\npockets and voids and to assess their sequence similarity, an effective scoring matrix is critically important.\nIn the original study of Binkowski et al, Blosum matrix was used. However, this is problematic, as Blosum\nmatrices were derivedfrom analysisof precomputed large quantities of sequences, while the information of the\nparticular protein of interest has limited or no influence. In addition, these precomputed sequences include\nburied residues in protein core, whose conservation reflects the need to maintain protein stability rather\nthan to maintain protein function. In reference [50,51], a continuous time Markov process was developed\nto explicitly model the substitution rates of residues in binding pockets. Using a Bayesian Markov chain\nMonte Carlo method, the residue substitution rates at functional pocket are estimated. The substitution\nrates are found to be very different for residues in the binding site and residues on the remaining surface of\nproteins. In addition, substitution rates are also very different for residues in the buried core and residues\non the solvent exposed surfaces.\nThese rates are then used to generate a set of scoring matrices of different time intervals for residues\nlocated in the functional pocket. Application of protein-specific and region-specific scoring matrices in\nmatching protein surfaces result in significantly improved sensitivity and specificity in protein function\nprediction [50,51].\nIn a large scale study of predicting protein functions from structures, a subset of 100 enzyme families are\ncollected from the total of 286 enzyme families containing between 10?50 member protein structures with\nknown Enzyme Classification (E.C.) labels. By estimating the substitution rate matrix for residues on the\nactive site pocket of a query protein, a series of scoring matrices of different evolutionary time is derived. By\nsearching for similar pocket surfaces from a database of 770,466 pockets derived from the CastP database\n(with the criterion that each must contain at least 8 residues), this method can recover active site surfaces\non enzymes similar to that on the query structure at an accuracy of > 92%. Fig 6.8 shows the Receiver\nOperating Characteristic Curve of this study. An example of identifying human amylase using template\nsurfaces from B. subtilis and from barley is shown in Fig 6.9.\nThe method of surface matching based on evolutionary model is also especially effective in solving the\nchallenging problems of protein function prediction of orphan structures of unknown function (such as those\nobtained in structural genomics projects), which have only sequence homologs that are themselves hypothet-\nical proteins with unknown functions.\n6.6 Discussion\nA major challenge in studying protein geometry is to understand our intuitive notions of various geometric\naspects of molecular shapes, and to quantify these notions with mathematical models that are amenable to\nfast computation. The advent of the union of ball model of protein structures enabled rigorous definition\nof important geometric concepts such as solvent accessible surface and molecular surface. It also led to\nthe development of algorithms for area and volume calculations of proteins. Deep understanding of the\ntopological structure of molecular shapes is also based on the idealized union of ball model [9]. A success\n14\n0.0 0.2 0.4 0.6 0.8 1.0\n0.75\n0.80\n0.85\n0.90\nnewy\nTrue Positive Rate(sensitivity)\nFalse Positve Rate(1?specificity)\nFigure 6.8: A large scale study of protein function prediction from structures by matching similar func-\ntional surfaces for 100 protein families. A correct prediction is made if the matched surface comes from a\nprotein structure with the same Enzyme Classification (E.C.) number (upto the 4-th digit) as that of the\nquery protein. The x-axis of the Receiver Operating Characteristics curve reflects the false positive rate\n(1?specificity) at different statistical significance p-value by cRMSD measurement, and the y-axis reflects\nthe true positive rate (sensitivity).\nin approaching these problems is exemplified in the development of the pocket algorithm [24]. Another\nexample is the recent development of a rigorous definition of protein-protein binding or interaction interface\nand algorithm for its computation [52].\nPerhaps a more fundamental problem we face is to identify important structural and chemical features\nthat are the determinants of biological problems of interest. For example, we would like to know what are the\nshape features that has significant influences on protein solvation, protein stability, ligand specific binding,\nand protein conformational changes. It is not clear whether our current geometric intuitions are sufficient,\nor are the correct or the most relevant ones. There may still be important unknown shape properties of\nmolecules that elude us at the moment.\nAn important application of geometric computation of protein structures is to detect patterns important\nfor protein function. The shape of local surface regions on a protein structure and their chemical texture are\nthe basis of its binding interactions with other molecules. Proteins fold into specific native structure to form\nthese local regions for carrying out various biochemical functions. The geometric shape and chemical pattern\nof the local surface regions, and how they change dynamically are therefore of fundamental importance in\ncomputational studies of proteins.\nAnother important application is the development of geometric potential functions. Potential functions\nare important for generating conformations, for distinguishing native and near native conformations from\nother decoy conformations in protein structure predictions [53?56] and in protein-protein docking [57]. They\nare also important for peptide and protein design [57,58]. Chapter 4 describes in details the development of\ngeometric potential and applications in decoy discrimination and in protein-protein docking prediction.\nWe havenot described in detail the approachof studying protein geometryusing graphtheory. In addition\nto side-chain pattern analysis briefly discussed earlier, graph based protein geometric model also has lead to\na number of important insights, including the optimal design of model proteins formed by hydrophobic and\npolar residues [59], and methods for optimal design of side-chain packing [60,61]. Another important topic\nwe did not touch upon is the analysis of the topology of protein backbones. Based on concepts from knot\ntheory, R?gen and Bohr developed a family of global geometric measures for protein structure classification\n[62]. These measures originate from integral formulas of Vassiliev knot invariants. With these measures,\nR?gen and Fain further constructed a system that can automatically classify protein chains into folds [63].\n15\nFigure 6.9: Protein function prediction as illustrated by the example of alpha amylases. Two template\nbinding surfaces are used to search database of protein surfaces to identify protein structures that are of\nsimilar functions. (a) The phylogenetic tree for the template Pdb structure 1bag from B. subtilis. (b)\nThe template binding pocket of alpha amylase on 1bag. (c) A matched binding surface on a different\nprotein structure (1b2y from human, full sequence identity 22%) obtained by querying with 1bag. (d) The\nphylogenetic tree for the template structure 1bg9 from H. vulgare. (e) The template binding pocket on 1bg9.\n(f) A matched binding surface on a different protein structure (1u2y from human, full sequence identity\n23%) obtained by querying with 1bg9 (Adapted from [51]).\nThis system can reproduce the Cath classification system that requires explicit structural alignment as well\nas human curation.\nFurther development of descriptions of geometric shape and topological structure, as well as algorithms\nfor their computation will provide a solid foundation for studying many important biological problems. The\nother important tasks are then to show how these descriptors may be effectively used to deepen our biological\ninsights and to develop accurate predictive models of biological phenomena. For example, in computing\nprotein-protein interfaces, a challenging task is to discriminate surfaces that are involved in protein binding\nfrom other non-binding surface regions, and to understand in what fashion this depends on the properties\nof the binding partner protein.\nUndoubtedly, evolution plays central roles in shaping up the function and stability of protein molecules.\nThe method of analyzing residue substitution rates using a continuous time Markov models [50,51], and\nthe method of surface mapping of conservation entropy and phylogeny [64,65] only scratches the surface of\n16\nthis important issue. Much remains to be done in incorporating evolutionary information in protein shape\nanalysis for understanding biological functions.\n6.7 Summary\nThe accumulation of experimentally solved molecular structures of proteins provides a wealth of information\nfor studying many important biological problems. With the development of a rigorous model of the structure\nof protein molecules, various shape properties, including surfaces, voids, and pockets, and measurements of\ntheir metric properties can be computed. Geometric algorithms have found important applications in protein\npacking analysis, in developing potential functions, in docking, and in protein function prediction. It is\nlikely further development of geometric models and algorithms will find important applications in answering\nadditional biological questions.\n6.8 Further reading\nThe original work of Lee and Richards surface can be found in [5], where they also formulated the molecular\nsurface model [8]. Michael Connolly developed the first method for the computation of the molecular surface\n[11]. Tsai et al. described a method for obtaining atomic radii parameter [15]. The mathematical theory of\nthe union of balls and alpha shape was developed by Herbert Edelsbrunner and colleague [9,66]. Algorithm\nfor computing weighted Delaunay tetrahedrization can be found in [28], or in a concise monograph with\nin-depth discussion of geometric computing [33]. Details of area and volume calculations can be found in\n[20,21,25]. The theory of pocket computation and applications can be found in [24,26]. Richards and Lim\noffered a comprehensive review on protein packing and protein folding [12]. A detailed packing analysis of\nproteins can be found in [35]. The study on inferring protein function by matching surfaces is described in\n[47]. The study of the evolutionary model of protein binding pocket and its application in protein function\nprediction can be found in [51].\n6.9 Acknowledgments\nThis work is supported by grants from the National Science Foundation (CAREER DBI0133856), the Na-\ntional Institute of Health (GM68958), the Office of Naval Research (N000140310329), and the Whitaker\nFoundation (TF-04-0023). The author thanks Jeffrey Tseng for help in preparing this chapter.\n17\nBibliography\n[1] G. Rhodes. Crystallography Made Crystal Clear: A Guide for Users of Macromolecular Models. Aca-\ndemic Press, 1999.\n[2] G. M. Crippen and T. F. Havel. Distance Geometry and Molecular Conformation. J. Wiley & Sons,\n1988.\n[3] W. Rieping, M. Habeck, and M. Nilges. Inferential structure determination. Science, 309(5732):303?6,\n2005.\n[4] R.F.W. Bader. Atoms in Molecules: A Quantum Theory. The international series of mongraphs on\nchemistry, No. 22. Oxford University Press, 1994.\n[5] B. Lee and F. M. Richards. The interpretation of protein structures: estimation of static accessibility.\nJ. Mol. Biol., 55:379?400, 1971.\n[6] F. M. Richards. The interpretation of protein structures: total volume, group volume distributions and\npacking density. J. Mol. Biol., 82:1?14, 1974.\n[7] T. J. Richmond. Solvent accessible surface area and excluded volume in proteins: analytical equations\nfor overlapping spheres and implications for the hydrophobic effect. J. Mol. Biol., 178:63?89, 1984.\n[8] F. M. Richards. Calculation of molecular volumes and areas for structures of known geometries. Methods\nin Enzymology, 115:440?464, 1985.\n[9] H. Edelsbrunner. The union of balls and its dual shape. Discrete Comput. Geom., 13:415?440, 1995.\n[10] F. M. Richards. Areas, volumes, packing, and proteinstructures. Ann. Rev. Biophys. Bioeng., 6:151?176,\n1977.\n[11] M. L. Connolly. Analytical molecular surface calculation. J. Appl. Cryst., 16:548?558, 1983.\n[12] F. M. Richards and W. A. Lim. An analysis of packing in the protein folding problem. Q. Rev. Biophys.,\n26:423?498, 1994.\n[13] M. Gerstein and F. M Richards. Protein Geometry: Distances, Areas, and Volumes, volume F, chap-\nter 22. International Union of Crystallography, 1999.\n[14] F. M. Richards. The interpretation of protein structures: total volume, group volume distributions and\npacking density. J. Mol. Biol., 82:1?14, 1974.\n[15] J. Tsai, R. Taylor, C. Chothia, and M. Gerstein. The packing density in proteins: standard radii and\nvolumes. J Mol Biol, 290(1):253?66, 1999.\n[16] A. Bondi. VDW volumes and radii. J. Phys. Chem., 68:441?451, 1964.\n[17] J.M. Word, S.C. Lovell, J.S. Richardson, and D.C. Richardson. Asparagine and glutamine: using\nhydrogen atom contacts in the choice of side-chain amide orientation. J Mol Biol, 285(4):1735?47, 1999.\n18\n[18] J. L. Finney. Volume occupation, environment and accessibility in proteins. The problem of the protein\nsurface. J. Mol. Biol., 96:721?732, 1975.\n[19] B. J. Gellatly and J.L. Finney. Calculation of protein volumes: an alternative to the Voronoi procedure.\nJ. Mol. Biol., 161:305?322, 1982.\n[20] H. Edelsbrunner, M. Facello, P. Fu, and J. Liang. Measuring proteins and voids in proteins. In Proc.\n28th Ann. Hawaii Int?l Conf. System Sciences, volume 5, pages 256?264, Los Alamitos, California, 1995.\nIEEE Computer Scociety Press.\n[21] J. Liang, H. Edelsbrunner, P. Fu, P. V. Sudhakar, and S. Subramaniam. Analytical shape computing\nof macromolecules I: Molecular area and volume through alpha-shape. Proteins, 33:1?17, 1998.\n[22] K. W. Kratky. Intersecting disks (and spheres) and statistical mechanics. I. mathematical basis. J. Stat.\nPhys., 25:619?634, 1981.\n[23] M. Petitjean. On the analytical calculation of van der waals surfaces and volumes: some numerical\naspects. J. Comput. Chem., 15:507?523, 1994.\n[24] H. Edeslbrunner, M. Facello, and J. Liang. On the definition and the construction of pockets in macro-\nmolecules. Disc. Appl. Math., 88:18?29, 1998.\n[25] J. Liang, H. Edelsbrunner, P. Fu, P. V. Sudhakar, and S. Subramaniam. Analytical shape computing\nof macromolecules II: Identification and computation of inaccessible cavities inside proteins. Proteins,\n33:18?29, 1998.\n[26] J. Liang, H. Edelsbrunner, and C. Woodward. Anatomy of protein pockets and cavities: Measurement\nof binding site geometry and implications for ligand design. Protein Sci, 7:1884?1897, 1998.\n[27] T. A. Binkowski, S. Naghibzadeh, and J. Liang. CASTp: Computed atlas of surface topography of\nproteins. Nucleic Acids Res., 31:3352?3355, 2003.\n[28] H. Edelsbrunner and N.R. Shah. Incremental topological flipping works for regular triangulations.\nAlgorithmica, 15:223?241, 1996.\n[29] L. Guibas and J. Stolfi. Primitives for the manipulation of general subdivisions and the computation of\nVoronoi diagrams. ACM Transactions on Graphiques, 4:74?123, 1985.\n[30] S. Chakravarty, A. Bhinge, and R. Varadarajan. A procedure for detection and quantitation of cavity\nvolumes proteins. application to measure the strength of the hydrophobic driving force in protein folding.\nJ Biol Chem, 277(35):31345?53, 2002.\n[31] A. Goede, R. Preissner, and C. Frommel. Voronoi cell: New method for allocation of space among\natoms: Elimination of avoidable errors in calculation of atomic volume and density. J. Comput. Chem.,\n18:1113?1123, 1997.\n[32] Y. Harpaz, M. Gerstein, and C. Chothia. Volume changes on protein folding. Structure, 2(7):641?9,\n1994.\n[33] H. Edelsbrunner. Geometry and Topology for Mesh Generation. Cambridge University Press, 2001.\n[34] M. Levitt, M. Gerstein, E. Huang, S. Subbiah, and J. Tsai. Protein folding: the endgame. Annu Rev\nBiochem, 66:549?579, 1997.\n[35] J. Liang and K. A. Dill. Are proteins well-packed? Biophys. J., 81:751?766, 2001.\n[36] J. Zhang, R. Chen, C. Tang, and J. Liang. Origin of scaling behavior of protein packing density: A\nsequential monte carlo study of compact long chain polymers. J. Chem. Phys., 118:6102?6109, 2003.\n19\n[37] A. E. Todd, C. A. Orengo, and J. M. Thornton. Evolution of function in protein superfamilies, from a\nstructural perspective. J. Mol. Biol., 307:1113?1143, 2001.\n[38] L. Holm and C. Sander. New structure: Novel fold? Structure, 5:165?171, 1997.\n[39] A. C. R. Martin, C. A. Orengo, E. G. Hutchinson, A. D. Michie, A. C. Wallace, M. L. Jones, and J. M.\nThornton. Protein folds and functions. Structure, 6:875?884, 1998.\n[40] C. A. Orengo, A. E. Todd, and J. M. Thornton. From protein structure to function. Curr. Opinion\nStructural Biology, 9(4):374?382, 1999.\n[41] P. J. Artymiuk, A. R. Poirrette, H. M. Grindley, D.W. Rice, and P. Willett. A graph-theoretic approach\nto the identification of three-dimensional patterns of amino acid side-chains in protein structure. J. Mol.\nBiol., 243:327?344, 1994.\n[42] D. Fischer, R. Norel, H. Wolfson, and R. Nussinov. Surface motifs by a computer vision technique:\nsearches, detection, and implications for protein- ligand recognition. Proteins: Structure, Function and\nGenetics, 16:278?292, 1993.\n[43] R. Norel, D. Fischer, H. J. Wolfson, and R. Nussinov. Molecualr surface recognition by computer\nvision-based technique. Protein Eng., 1994.\n[44] A. C. Wallace, N. Borkakoti, and J. M. Thornton. TESS: a geometric hashing algorithm for deriving\n3d coordinate templates for searching structural databases. Application to enzyme active sites. Protein\nSci., 6:2308?2323, 1997.\n[45] R. Russell. Detection of protein three-dimensional side-chain patterns: New examples of convergent\nevolution. J. Mol. Biol., 279:1211?1227, 1998.\n[46] R. A. Laskowski, N. M. Luscombe, M. B. Swindells, and J. M. Thornton. Protein clefts in molecular\nrecognition and function. Protein Sci., 5:2438?2452, 1996.\n[47] T. A. Binkowski, L. Adamian, and J. Liang. Inferring functional relationship of proteins from local\nsequence and spatial surface patterns. J. Mol. Biol., 332:505?526, 2003.\n[48] T.A. Binkowski, A. Joachimiak, and J. Liang. Protein surface analysis for function annotation in\nhigh-throughput structural genomics pipeline. Protein Sci, 14(12):2972?81, 2005.\n[49] T.A. Binkowski, P. Freeman, and J. Liang. pvSOAR: Detecting similar surface patterns of pocket and\nvoid surfaces of amino acid residues on proteins. Nucleic Acid Research, 32:W555?W558, 2004.\n[50] Y.Y. Tseng and J. Liang. Estimating evolutionary rate of local protein binding surfaces: a bayesian\nmonte carlo approach. Proceedings of 2005 IEEE-EMBC Conference, 2005.\n[51] Y.Y. Tseng and J. Liang. Estimation of amino acid residue substitution rates at local spatial regions\nand application in protein function inference: A Bayesian Monte Carlo approach. Mol. Biol. Evol.,\n23:421?436, 2006.\n[52] Y. Ban, H. Edelsbrunner, and J. Rudolph. Interface surfaces for protein-protein complexes. In RE-\nCOMB, pages 205?212, 2004.\n[53] R. K.Singh, A. Tropsha, and I. I. Vaisman. Delaunaytessellationof proteins: fourbody nearest-neighbor\npropensities of amino-acid residues. J. Comp. Bio., 3:213?221, 1996.\n[54] W. Zheng, S. J. Cho, I. I. Vaisman, and A. Tropsha. A new approach to protein fold recognition based\non Delaunay tessellation of protein structure. In R.B. Altman, A.K. Dunker, L. Hunter, and T.E. Klein,\neditors, Pacific Symposium on Biocomputing?97, pages 486?497, Singapore, 1997. World Scientific.\n20\n[55] X. Li, C. Hu, and J. Liang. Simplicial edge representation of protein structures and alpha contact\npotential with confidence measure. Proteins, 53:792?805, 2003.\n[56] X. Li and J. Liang. Geometric cooperativity and anticooperativity of three-body interactions in native\nproteins. Proteins, 60(1):46?65, 2005.\n[57] X. Li and J. Liang. Computational design of combinatorial peptide library for modulating protein-\nprotein interactions. Pac Symp Biocomput, pages 28?39, 2005.\n[58] C. Hu, X. Li, and J. Liang. Developing optimal nonlinear scoring function for protein design. Bioinfor-\nmatics, 20:3080?3098, 2004.\n[59] J. Kleinberg. Efficient algorithms for protein sequence design and the analysis of certain evolutionary\nfitness landscapes. In RECOMB, pages 205?212, 2004.\n[60] J. Xu. Rapid protein side-chain packing via tree decomposition. In RECOMB, pages 423?439, 2005.\n[61] A. Leaver-Fay, B. Kuhlman, and J. Snoeyink. An adaptive dynamic programming algorithm for the\nside chain placement problem. In Pacific Symposium on Biocomputing, pages 17?28, 2005.\n[62] P. R?gen and H. Bohr. A new family of global protein shape descriptors. Math Biosci, 182(2):167?81,\n2003.\n[63] P. R?gen and B. Fain. Automatic classification of protein structure by using gauss in tegrals. Proc Natl\nAcad Sci U S A, 100(1):119?24, 2003.\n[64] O. Lichtarge, H.R. Bourne, and F.E. Cohen. An evolutionary trace method defines binding surfaces\ncommon to protein families. J Mol Biol, 257(2):342?58, 1996.\n[65] F. Glaser, T. Pupko, I. Paz, R.E. Bell, D. Shental, E. Martz, and N. Ben-Tal. Consurf: identifica-\ntion of functional regions in proteins by surface-mapping of phylogenetic information. Bioinformatics,\n19(1):163?4, 2003.\n[66] H. Edelsbrunner and E.P. M?ucke. Three-dimensional alpha shapes. ACM Trans. Graphics, 13:43?72,\n1994.\n21\n"}
{"id":"oai:arXiv.org:quant-ph/0610192","text":"arXiv:quant-ph/0610192v1  23 Oct 2006\nICMPA-MPA/2006/20\nCP3-06-13\n(p,q)-Deformations and (p,q)-Vector Coherent States\nof the Jaynes-Cummings Model\nin the Rotating Wave Approximation\nJoseph Ben Geloun?, Jan Govaerts?,?,1 and M. Norbert Hounkonnou?\n?International Chair in Mathematical Physics and Applications (ICMPA-UNESCO)\n072 B.P. 50 Cotonou, Republic of Benin\nE-mail: jobengeloun@yahoo.fr, norbert?hounkonnou@cipma.net\n?Department of Theoretical Physics, School of Physics\nThe University of New South Wales, Sydney NSW 2052, Australia\nE-mail: Jan.Govaerts@fynu.ucl.ac.be\nFebruary 1, 2008\nAbstract\nClasses of (p,q)-deformations of the Jaynes-Cummings model in the rotating wave ap-\nproximation are considered. Diagonalization of the Hamiltonian is performed exactly, leading\nto useful spectral decompositions of a series of relevant operators. The latter include ladder\noperators acting between adjacent energy eigenstates within two separate infinite discrete\ntowers, except for a singleton state. These ladder operators allow for the construction of\n(p,q)-deformed vector coherent states. Using (p,q)-arithmetics, explicit and exact solutions\nto the associated moment problem are displayed, providing new classes of coherent states\nfor such models. Finally, in the limit of decoupled spin sectors, our analysis translates into\n(p,q)-deformations of the supersymmetric harmonic oscillator, such that the two supersym-\nmetric sectors get intertwined through the action of the ladder operators as well as in the\nassociated coherent states.\n1On sabbatical leave from the Center for Particle Physics and Phenomenology (CP3), Institute of Nuclear\nPhysics, Catholic University of Louvain, 2, Chemin du Cyclotron, B-1348 Louvain-la-Neuve, Belgium.\n1 Introduction\nIn recent years, quantum algebras and groups [1] which appear as a generalization of the sym-\nmetry concept [2] and the basics of so-called noncommutative theories, have been the subject of\nintensive research interest in both mathematics and physics. The q- and more generally (p,q)-\ndeformation of a pre-defined algebraic structure [3, 4, 5] proves to be a powerful tool widely used\nin the representation theory of quantum groups. The field of ?q-mathematics? has a long history\n[6, 7] dating back to over 150 years, and includes several famous names such as Cauchy, Jacobi\nand Heine to mention just a few. Its possible relation to physics has been considerably reinforced\nduring the last thirty years [3, 8]. In particular, great attention has been devoted to deformations\nof the bosonic Fock-Heisenberg algebra. The most commonly studied deformed bosons, with\nannihilation and creation operators a and a?, respectively, satisfy the q-commutation relation\n[3] (also called quommutation)\naa??qa?a = I, (1)\nor some variant forms of such a relation [4, 9]. Still more general deformations, which include in\nspecific limits the above standard q-deformed case and which also provides consistent extensions\nof the harmonic oscillator algebra, proceed from the two parameter deformation of the Fock\nalgebra introduced by Chakrabarty and Jagannathan [5], namely the so-called (p,q)-oscillator\nquantum algebras generated by three operators a, a? and N which obey [5, 10]\n[N,a] =?a, [N,a?] = a?, aa??qa?a = p?N, aa??p?1a?a = qN. (2)\nHere, p and q are free parameters, which henceforth are chosen to be both real and such that\np > 1, 0 < q < 1 and pq < 1. Clearly, one recovers the ordinary Fock algebra of the harmonic\noscillator algebra in the double limit p,q?1, with then [a,a?] = I and N = a?a. Furthermore,\nthese q- and (p,q)-deformed algebras have found a number of relevant applications and provide\nalgebraic interpretations of various q- and (p,q)-special functions [9, 10, 11].\nThe harmonic oscillator algebra is central in the construction of a number of models in\nphysics, among which the Jaynes?Cummings model (JCm) plays a significant role. Indeed ever\nsince Jaynes and Cummings? historical work [12], the JCm has been at the basis of many in-\nvestigations. This system belongs to a class of physically relevant models widely used in atomic\nphysics and quantum optics. As far as we know, a great deal of analytically solvable models of\nthis type have been studied in the rotating wave approximation (r.w.a.) within the framework\nof non-deformed commutative theories (see [12]?[17] and references therein). TheJCm has also\nbeen considered in the context of generalized intensity dependent oscillator algebras including\nnonlinear dynamical supersymmetry[18] or using shapeinvariance techniques [19, 20]. Compara-\ntively, much fewer papers have dealt with generalizations of these models including deformations.\nAmong the latter and mainly based on the generalized intensity-dependent coupling of Buck and\nSukumar [21], one may mention, on the one hand, the work by Chaichan et al. [22], and on the\nother hand, that by Chang [23], both dealing with a generalized q-deformed intensity-dependent\ninteraction Hamiltonian of theJCm given by the Holstein-Primakoff suq(1,1) or suq(2) quantum\nalgebra realizations of the Hamiltonian field operators and the related Peremolov, Glauber or\nBarut-Girardello group theoretical construction of coherent states. In the same vein, the paper\nby Naderi et al. considers the dynamical properties of a two-level atom in three variants of the\ntwo-photon q-deformedJCm [24]. In this latter work, the authors focused their attention onto\nthe time evolution of atomic properties including population inversion and quantum fluctuations\nof the atomic dipole variables. However, it is not clear to us how the main issues related to the\nmoment problem as well as the mathematical foundation of the coherent and squeezed states\nwhich they use and on which a great part of their analysis rests in a crucial way, are solved.\n1\nIn a recent publication [14], Hussin and Nieto have performed an interesting systematic\nsearch of different types of ladder operators for theJCm model in the r.w.a. and constructed\nassociated coherent states. In the present work, and in line with that investigation, we provide\na generalization of that analysis to (p,q)-deformations of the same model.\nThe outline of the paper is the following. In Section 2, we briefly recall the main results\nrelevant to theJCm in the r.w.a. in the non-deformed situation [14]. Section 3 then introduces\n(p,q)-deformations of the same model. By providing an explicit diagonalization of the (p,q)-\ndeformed Hamiltonian, the spectrum and its eigenstates are exactly identified. As in the non-\ndeformed case [14], except for a singleton state, all other energy eigenstates are organized into\ntwo separate discrete towers, for which ladder operators transforming states into one another\nwithin each tower separately may be introduced. Using properties of these ladder operators, in\nSection 4 we introduce general classes of (p,q)-deformed vector coherent states. The freedom\nafforded in their construction is fixed from two alternative points of view, discussed in Section 5,\nwhich in the ordinary case of the non-deformed Fock algebra coincide. However at all stages of\nour discussion, the double limit p,q?1 reproduces the corresponding results of [14]. Section 5\nalso briefly considers the situation in the uncoupled limit of theJCm, while Section 6 presents\nsome concluding remarks. An Appendix collects useful facts in connection with properties of\n(p,q)-deformed algebras and related functions.\n2 The Ordinary JCm in the Rotating Wave Approximation\nThe JCm describes the interaction between one mode of the quantized electromagnetic field\nand a two-level model of an atomic system [12, 14]?[16]. It has proved to be a theoretical\nlaboratory of great relevance to many topics in atomic physics and quantum optics, as well\nas in the study of ion traps, cavity QED theory and quantum information processing [13, 14].\nFurthermore, the spin-orbit interaction term which appears in the JCm is essentially the so-\ncalled Dresselhaus spin-orbit term [25]. The model is thus also widely used in condensed matter\nphysics for its relevance in spintronics [26] which exploits the electron spin rather than its charge\nto develop a new generation of electronic devices [27, 28]. The solution of the completeJCm is\nnot yet known in a closed form [14]. However, in the r.w.a., although the Hamiltonian remains\nnonlinear, the model becomes exactly solvable in closed form with explicit expressions for its\neigenenergy states. In this Section, we briefly recall, in a streamlined presentation, the main\nresults in the non-deformed case (see [14, 15] and references therein) of relevance to our analysis\nof (p,q)-deformations hereafter.\nIn the r.w.a., the reduced dimensionlessJCm Hamiltonian reads [15]\nHred = 1planckover2pi1?\n0\nH= (1+?)\nparenleftbigg\na?a+ 12\nparenrightbigg\n+ 12?3 +?\nparenleftBig\na??? +a?+\nparenrightBig\n, (3)\nwhere a and a? are the usual photon annihilation and creation operators, respectively, obeying\nthe ordinary Fock algebra, and (?1,?2,?3) are the Pauli matrices with ?? = ?1?i?2. The r.w.a.\nis related to the detuning parameter ? which is such that|?|?1, with ?0 being the fixed atomic\nfrequency and ? = ?0(1 + ?) the actual field mode frequency. The r.w.a. is reliable provided\n|???0|??,?0. Finally, ? is the reduced spin-orbit coupling modelling the interaction strength\nbetween the radiation field and the atom.\n2\nThe Hilbert spaceV of the system is the tensor product of the Fock space representation\nof the Fock algebra (a,a?) and the 2-dimensional representation of the SU(2) algebra associated\nto the Pauli matrices. A basis of the former is provided by the number operator, N = a?a,\northonormalized eigenstates |n? = (1/?n!)(a?)n|0? (n = 0,1,2,???), with a|n? = ?n|n?1?,\na?|n?=?n+ 1|n + 1?and N|n?= n|n?, while a basis of the latter spin sector is the orthonor-\nmalized set {|+?,|??} such that ?3|??=?|??. The tensor product space is thus spanned by\nthe states|n,??=|n??|??.\nThe diagonalization of the Hamiltonian (3) is readily achieved. The orthonormalized\nenergy eigenspectrum consists of a ?singleton? state|E??,\nHred|E??= E?|E??, (4)\nwith\nE? = 12?, |E??=|0,??, (5)\nand two infinite discrete towers of states |E?n? such that Hred|E?n? = E?n|E?n? for all n =\n0,1,2,???, expressed as [14]\n|E+n? = sin?(n)|n,+?+ cos?(n)|n+ 1,??, (6)\n|E?n? = cos?(n)|n,+??sin?(n)|n+ 1,??, (7)\nwhere, given Q(n+ 1) =radicalbig?2/4 +?2(n+ 1), the mixing angle ?(n) is such that\nsin?(n) = sign(?)\nradicalBigg\nQ(n+ 1)??/2\n2Q(n + 1) , cos?(n) =\nradicalBigg\nQ(n+ 1) +?/2\n2Q(n+ 1) , (8)\nwhile the energy eigenvalues are\nE?n = (1 +?)(n+ 1)?Q(n+ 1). (9)\nConsequently, one has the spectral decomposition of the reduced Hamiltonian (3),\nHred =|E??E??E?| +\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|. (10)\nIt proves useful to introduce the following notations. Let V0 be the (complex) one-\ndimensional subspace of the Hilbert space V spanned by the state |0,?? = |E??, and V be\nits complement in the Hilbert spaceV, spanned by{|E?n?,n?N}. We thus haveV=V0?V.\nFurthermore let us introduce [14] operatorsU andU? defined through their action on the\nabove two sets of basis vectors, for all n?N,\nU|n,??=|E?n?; U?|E??= 0, U?|E?n?=|n,??, (11)\nnamely\nU =\n?summationdisplay\nn=0,?\n|E?n??n,?|, U? =\n?summationdisplay\nn=0,?\n|n,???E?n|. (12)\nClearly we have\nUV =V; U?V =V, U?V=V. (13)\n3\nNote that even though neither U nor U? is unitary on the full Hilbert space V, they are the\nadjoint of one another, hence the notation.\nIt is of interest to apply these operators onto the quantum Hamiltonian (3). One obtains\nHred =U?HredU =\n?summationdisplay\nn=0,?\n|n,??E?n ?n,?|, (14)\nand conversely,\nUHredU? =\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|=Hred ?|E??E??E?|. (15)\nThe energy eigenstates spanning V may be organized into two subspaces referred to as\n?towers?, namely {|E+n?,n?N} and {|E?n?,n?N}. The states in the tower {|E+n?,n?N}\nare associated to strictly increasing eigenvalues so that they constitute a nondegenerate set\nof eigenstates. The second group does not necessarily possess the same feature depending\non the values for the parameters ? and ?. It is possible [16] to identify a range of values\nfor these parameters such that {|E?n?,n?N} only contains nondegenerate states of strictly\nincreasing eigenvalues with n. Some of the considerations discussed hereafter may require a\nnondegenerate spectrum, which may always be achieved by properly ?detuning? the parameters\n? and ? away from a degenerate case, but not necessarily a strictly increasing spectrum in the\nlabel n?N. Whatever the case may be though, bounded from below spectra such that E?n > E?0\nfor n = 1,2,???are always assumed implicitly.\nIt is possible to consider ladder operators acting between successive energy eigenstates\nwithin each of the above two towers, irrespective of whether the spectral values are strictly\nincreasing or not1. Namely, let us first consider operators M? and M+ given as\nM? =\n?summationdisplay\nn=0,?\n|n?1,??K?(n)?n,?|; M+ =\n?summationdisplay\nn=0,?\n|n+ 1,??K??(n+ 1)?n,?|, (16)\nwhere K?(n) are, at this stage, arbitrary complex coefficients such that K?(0) = 0. Then,\nintroduce the ladder operators\nM? =UM?U? =\n?summationdisplay\nn=0,?\n|E?n?1?K?(n)?E?n|; M+ =UM+U? =\n?summationdisplay\nn=0,?\n|E?n+1?K??(n+ 1)?E?n|,\n(17)\nwhich are thus such that, for all n = 0,1,2,???,\nM?|E??= 0, M?|E?n?= K?(n)|E?n?1?; M+|E??= 0, M+|E?n?= K??(n+ 1)|E?n+1?.\n(18)\nNote thatM? andM+ are adjoint of one another but in effect only act on the subspaceV.\nGeneral vector coherent states (VCS) may then be introduced [29]?[32] on the space V\nas eigenstates of the lowering operator M? with as eigenvalue an arbitrary complex number\nz?C. Furthermore, these VCS are also parametrized by two real quantities ?? which account\nfor their stability under time evolution generated by the operator expbraceleftbig?i?0tHredbracerightbig, as well as\nthe two spherical coordinates (?,?)?[0,?]?[0,2?[ parametrizing a unit vector in the 2-sphere\n1We differ on this point with [14], where strictly increasing energy spectra in each tower are required.\n4\nS2 (hence the name of ?vector? coherent states). Explicitly, one has [14]\n|z;??;?,?? = N+(|z|)cos?\n?summationdisplay\nn=0\nzn\nK+(n)!e\n?i?0?+E+n |E+\nn?\n+ N?(|z|)ei? sin?\n?summationdisplay\nn=0\nzn\nK?(n)!e\n?i?0??E?n |E?\nn?, (19)\nwhere K?(n)! =producttextnk=1 K?(k) (with, by convention, K?(0)! = 1), while the normalization factors\nare defined as\nN?(|z|) =\nbracketleftBigg ?summationdisplay\nn=0\n|z|2n\n|K?(n)!|2\nbracketrightBigg?1/2\n(20)\nin order that the VCS be of unit norm. The smallest value, R, of the two convergence radii of\nthese two series in |z| also defines the disk DR in z ?C for which these VCS are well defined.\nThese states are clearly such that\nM?|z;??;?,??= z|z;??;?,??, e?i?0tHred|z;??;?,??=|z;t +??;?,??. (21)\nFurther restrictions are necessary to finally specify in a unique fashion the factors K?(n),\nand then solve the moment problem implied by the requirement of overcompleteness overV for\nthe VCS (19) given a choice of a SU(2) matrix-valued integration measure over C?S2 [30]-[32].\nDifferent choices are available [14], each leading to a different set of VCS. Furthermore, taking\nthe limit case ??0 or the zero-detuning limit (resonance case) ??0, different models arise\nwith their associated VCS.\nFor the sake of illustration, let us consider one such choice explicitly [14]. The factors\nK?(n) may be restricted for example by requiring that the ladder operatorsM? andM+ obey\nthe usual Fock algebra of annihilation and creation operators on the spaceV,\nbracketleftbigM?,M+bracketrightbig=M?M+ ?M+M? = I\nV =\n?summationdisplay\nn=0,?\n|E?n??E?n|. (22)\nFrom the expressions in (18) and the initial conditions K?(0) = 0, it follows that the quantities\nK?(n) are now determined up to arbitrary phase factors ??(n) as\nK?(n) = ei??(n)?n, n = 0,1,2,???. (23)\nConsequently, one has N?(|z|) = e?|z|2/2, which is well-defined for all z?C. Hence so are then\nall the VCS|z;??;?,??.\n3 The (p,q)-Deformed JCm in the Rotating Wave Approxima-\ntion\nLet us now introduce a (p,q)-deformation of the JCm Hamiltonian (3), namely (p,q)-JCm\nmodels. The eigenstates and spectrum are first identified, before considering the construction\nof ladder operators following the same rationale as in Section 2. A study of the associated VCS\nand examples of exactly solvable reduced models is differed to Section 4.\n5\n3.1 Energy spectrum and eigenstates\nGiven the (p,q)-deformation (2) of the ordinary Fock algebra (see the Appendix for further\ndetails and identities pertaining to such deformations), we now consider (p,q)-deformations of\nthe Hamiltonian (3) of the form2\nHred = (1 +?)\nbraceleftbigg\nh(p,q)[N] + 12\nbracerightbigg\n+ 12?3 +?\nparenleftBig\na??? +a?+\nparenrightBig\n, (24)\nwhere [N] = (p?N ?qN)/(p?1?q), and h(p,q) is some arbitrary positive function of the real\nparameters p > 1 and 0 < q < 1 (with pq < 1) such that limp,q?1 h(p,q) = 1 in order to recover\n(3) in the non-deformed case.\nThe Hilbert space V of quantum states of the model is again the tensor product of the\n(p,q)-deformed Fock space spanned by the states3 |n?(n?N) such as a|n?= radicalbig[n]|n?1?and\na?|n?=radicalbig[n+ 1]|n+1?(see the Appendix), with the 2-dimensional representation of the SU(2)\nalgebra associated to the Pauli matrices ?i (i = 1,2,3). Hence the diagonalization of (24) is\nreadily achieved in the same way as in the non-deformed case, on the basis|n,??=|n??|??of\nV.\nFor any n?N, let us introduce the following quantities,\nE([n+1]) = (1+?)h(p,q)\nparenleftBig\n[n+1]?[n]\nparenrightBig\n?1, Q([n+1]) =\nradicalbigg\n1\n4E\n2([n +1]) + ?2 [n+1], (25)\nas well as the mixing angles ?([n]) defined by\nsin?([n]) = sign(?)\nradicalBigg\nQ([n+ 1])?E([n + 1])/2\n2Q([n + 1]) , cos?([n]) =\nradicalBigg\nQ([n + 1]) +E([n+ 1])/2\n2Q([n +1]) .\n(26)\nThe energy eigenspectrum of (24) is then obtained as follows. First, there exists a singleton\nstate|E??=|0,??such that\nHred|E??= E?|E??, E? = 12?, (27)\nwith an eigenvalue which is thus independent of the deformation parameters p and q. Next, one\nalso finds two infinite discrete towers of states for all n?N such that\n|E+n? = sin?([n])|n,+? + cos?([n])|n + 1,??, (28)\n|E?n? = cos?([n])|n,+?? sin?([n])|n + 1,??, (29)\nwith\nHred|E?n?= E?n |E?n?, E?n = 12 (1 +?)\nbraceleftBig\nh(p,q)\nparenleftBig\n[n+ 1] + [n]\nparenrightBig\n+1\nbracerightBig\n? Q([n+ 1]). (30)\nNote that the energy spectrum of these states is deformed by the parameters p and q as compared\nto the ordinary case. In particular, the Zeeman spin splitting ?En = E+n ?E?n = 2Q([n + 1]),\n2Make no mistake that henceforth, all quantities correspond to the (p,q)-deformed analysis even though the\nnotations used coincide with those of Section 2 and do not make explicit the fact that all expressions correspond\nnow to the deformed case. When wanting to make the difference explicit, notations such as for instance [N] ?\n[N](p,q) = (p?N ?qN)/(p?1 ?q) and [n] ? [n](p,q) = (p?n ?qn)/(p?1 ?q) are used.\n3Once again, the states |n? = |n?(p,q) are not to be confused with the number operator eigenstates of the\nordinary Fock algebra as in Section 2, in spite of an identical notation.\n6\nproportional to the Rabi frequency, is function of the values for p and q. In terms of these\nresults, the reduced Hamiltonian (24) possesses the spectral resolution\nHred =|E??E??E?| +\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|. (31)\nLet us again introduce the following notations and operators. LetV0 denote the subspace\nof the Hilbert space V spanned by the singleton state |E??= |0,??, and V its complement in\nV, namely the subspace spanned by{|E?n?,n?N}, with of courseV=V0?V. Acting on these\nspaces, let us consider the operators\nU =\n?summationdisplay\nn=0,?\n|E?n??n,?|; U? =\n?summationdisplay\nn=0,?\n|n,???E?n|, (32)\nsuch that, for all n = 0,1,2,???,\nU|n,??=|E?n?; U?|E??= 0, U?|E?n?=|n,??, (33)\nand thus\nUV=V; U?V=V, U?V =V. (34)\nHence once again the operators U and U?, even though non unitary on V, are adjoint of one\nanother. More specifically, one has\nU?U =\n?summationdisplay\nn=0,?\n|n,???n,?|= IV, UU? =\n?summationdisplay\nn=0,?\n|E?n??E?n|= IV. (35)\nApplying these operators to the reduced Hamiltonian, one finds\nHred =U?HredU =\n?summationdisplay\nn=0,?\n|n,??E?n ?n,?|, (36)\nand conversely,\nUHredU? =\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|=Hred ?|E??E??E?|. (37)\nSome remarks on the spectrum are in order. First, as in the ordinary JCm, except\nfor the singleton state |E?? = |0,??, the spectrum is the direct sum of two towers of states\n{|E?n?,n?N}. However, in contradistinction to the non-deformed case or even the q-deformation\nwith p = 1, the (p,q)-basic numbers [n] = [n](p,q) are not strictly increasing as a function of\nn?N when p > 1, 0 < q < 1 and pq < 1. There always exists a finite positive value n0 ?N\nsuch that [n] decreases once n > n0. Hence, depending on the values for the parameters ? and ?\nas well as the positive function h(p,q), parts of the spectrum E?n may turn negative or present\nsome degeneracies (as in [16]). Without exploring this issue any further in the present work,\nhenceforth we shall assume that parameter values are such that no degeneracies occur and that\nthe spectrum E?n remains bounded from below (E+n is obviously positive). The definition of the\nladder operators to be considered next does not require a strictly increasing spectrum, while it\nis only for one of possible choices leading to vector coherent states to be discussed hereafter that\nthe condition of non degeneracy in E?n > E?0 , for n?1, becomes relevant. Since it has been\n7\nshown [16] that such conditions may be met in the non-deformed case for appropriate ranges\nof values for the available parameters, through an argument of continuity in the deformation\nparameters p and q, similar ranges ought to exist also for the (p,q)-deformed realizations of the\nJCm model.\nAnother feature of potential interest related to these facts, and which will also not be\npursued here, is the possibility that through the (p,q)-deformation of theJCm, the levels E+n\nand E?n+1 cross one another. Such a property may lead to effects similar to the phenomenon\nof resonant spin-Hall conductance at the Fermi level recently observed in spintronics [27, 28].\nNote that this (p,q)-dependent crossing phenomenon is expected since the Zeeman splitting\n?En is also modified as a function of p and q. This remark is also in line with the recent\nsuggestion [33, 34, 35] that (p,q)-deformed or space noncommutative realizations of exactly\nsolvable systems may provide useful model approximations to more realistic complex interacting\ndynamics of collective phenomena.\n3.2 Ladder operators\nIn order to construct ladder operators mapping each of the successive states |E?n? into one\nanother separately within each of the towers, let us first introduce the following operators acting\nonV,\nA? =\n?summationdisplay\nn=0,?\n|n?1,??K?([n])?n,?|; A+ =\n?summationdisplay\nn=0,?\n|n+ 1,??K??([n +1])?n,?|, (38)\nwhere K?([n]) are arbitrary complex quantities such that K?([0]) = K?(0) = 0. Note that A?\nand A+ are adjoint of one another onV.\nThen the relevant ladder operators are obtained as\nA? =UA?U? =\n?summationdisplay\nn=0,?\n|E?n?1?K?([n])?E?n|; A+ =UA+U? =\n?summationdisplay\nn=0,?\n|E?n+1?K??([n+ 1])?E?n|.\n(39)\nConsequently, we have indeed, for all n?N,\nA?|E??= 0, A?|E?n?= K?([n])|E?n?1?; A+|E??= 0, A+|E?n?= K??([n+ 1])|E?n+1?.\n(40)\nNote thatA? andA+ are adjoint of one another, but that in effect they act only on the subspace\nV.\nIt is of course possible to express these ladder operators in the|n,??basis. In the case of\nthe lowering operator, one finds\nA? = summationtext?n=0 |n,+?A?++(n)?n+ 1,+| + summationtext?n=0 |n,+?A?+?(n)?n+ 2,?|\n+ summationtext?n=0 |n,??A??+(n)?n,+| + summationtext?n=0 |n,??A???(n)?n+ 1,?|\n(41)\nwhere\nA?++(n) = sin?([n]) sin?([n+ 1])K+([n + 1]) + cos?([n]) cos?([n+ 1])K?([n + 1]),\nA?+?(n) = sin?([n]) cos?([n+ 1])K+([n + 1]) ? cos?([n]) sin?([n+ 1])K?([n + 1]),\n8\nA??+(n) = cos?([n?1]) sin?([n])K+([n]) ? sin?([n?1]) cos?([n])K?([n]),\nA???(n) = cos?([n?1]) cos?([n])K+([n]) + sin?([n?1]) sin?([n])K?([n]). (42)\nLikewise for the raising operator,\nA+ = summationtext?n=0 |n+ 1,+?parenleftbigA?++(n)parenrightbig? ?n,+| + summationtext?n=0 |n,+?parenleftbigA??+(n)parenrightbig? ?n,?|\n+ summationtext?n=0 |n+ 2,??parenleftbigA?+?(n)parenrightbig? ?n,+| + summationtext?n=0 |n+ 1,??parenleftbigA???(n)parenrightbig? ?n,?|.\n(43)\nNote that we haveA??+(0) = 0 =A???(0), since K?([0]) = 0.\nThe quantities K?([n]) parametrize the freedom available in the choice of such ladder\noperators. Further restrictions arise when considering first the possible existence of vector\ncoherent states meeting a series of general conditions charateristic of such states [30]-[32], starting\nwith one involving the lowering operatorA? itself.\n4 (p,q)-Vector Coherent States for the (p,q)-JCm\nBy considering the action of the lowering operatorA?, we are able to construct an overcomplete\nset of vectors in V, so-called vector coherent states [30]-[32] for the (p,q)-JCm. Since these\nstates are associated to unit vectors in the 2-sphere S2 [29], they are referred to as (p,q)-vector\ncoherent states ((p,q)-VCS). As in Section 2, these (p,q)-VCS are parametrized by a complex\nvariable z ?C, two real parameters ?? to track a stable time evolution of the (p,q)-VCS, and\nfinally the spherical angle coordinates (?,?) on S2,|z;??;?,??. In the double limit that p,q?1,\nthese (p,q)-VCS reduce to those of [14] discussed in Section 2. The dependence of the (p,q)-VCS\non all these quantities is introduced as follows, according to the discussion in [30].\n4.1 Identifying (p,q)-VCS\nAs a slight extension of the analysis so far, given two real parameters ? and ?, let us consider\nthe operator\nQV =|E???E?| +\n?summationdisplay\nn=0,?\n|E?n?\nparenleftbiggq?\np?\nparenrightbiggn\n?E?n|. (44)\nHence, the energy eigenstates of the (p,q)-JCm are also eigenstates of this operator QV, with\neigenvalues given through the above spectral decomposition.\nWe are now in a position to successively identify the dependence of the (p,q)-VCS to be\nconstructed on each of the parameters of which they are functions, first z, then ??, and finally,\n? and ?. Having defined both the operatorsA? and QV, let us consider the following eigenvalue\nproblem in z for the (p,q)-VCS,\nA?|z;??;?,??= zQV|z;??;?,?? (45)\nwhich generalizes to a two-level system the definition of coherent states as advocated in [30]-\n[32]. The particular case ? = 0 = ? yields also a consistent definition of (p,q)-VCS viewed as\nthe limit ?,? ?0 of the present definition (note that their domain of definition in z, required\n9\nfor the convergence of the infinite series to be considered hereafter, may have to be adapted\naccordingly).\nBy expanding the (p,q)-VCS in the Hamiltonian eigenstate basis as\n|z;??;?,??= C?(z)|E??+\n?summationdisplay\nn=0,?\nC?n (z)|E?n?, (46)\nwhere C?(z) and C?n (z) are complex continuous functions of z to be specified presently, the\ncondition (45) then requires, for all n?N,\nC?(z) = 0, C?n+1(z)K?([n+ 1]) = z q\n?n\np?n C\n?\nn (z), (47)\nof which the solution is\nC?n (z) =\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK?([n])! C\n?\n0 (z), (48)\nwhere C?0 (z) are arbitrary complex functions of z, while we defined K?([n])! = producttextnk=1 K?([k])\nwith, by convention, K?([0])! = 1. Hence, the general solution to (45) defines states lying only\nwithin the subspaceV, of the form\n|z;??;?,??=\n?summationdisplay\nn=0,?\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK?([n])! C\n?\n0 (z)|E\n?\nn?. (49)\nNote that the eigenvalue problem (45) is singular at the particular value z = 0, since its solution\nis an arbitrary superposition of the three states|E??and|E?0 ?. Nevertheless, we shall consider\nthe (p,q)-VCS associated to z = 0, |z = 0;??;?,??, as being defined through the continuous\nlimit in z?0 of the construction in (49), namely|z = 0;??;?,??= C+0 (0)|E+0 ?+C?0 (0)|E?0 ?.\nLet us now turn to the issue of the stability of the (p,q)-VCS under time evolution gener-\nated by the Hamiltonian (24). Namely, we now require furthermore that (p,q)-VCS are trans-\nformed into one another under time evolution according to the following dependence on the real\nparameters ??, for all t?R,\ne?i?0tHred|z;??;?,??=|z;t +??;?,??. (50)\nSince one has, for all n?N,\ne?i?0tHred|E?n?= e?i?0tE?n |E?n?, (51)\none needs to factor out their complex phases from the quantities K?([n]),\nK?([n]) = ei??([n])K0?([n]), (52)\nwhere K0?([n]) > 0 are now real positive scalars. The stability condition (50) is then solved by\nchoosing, for all n = 1,2,???,\n??([n]) = ?0??bracketleftbigE?n ?E?n?1bracketrightbig, (53)\nand redefining\nC?0 (z) =C?0 (z)e?i?0??E?0 , (54)\n10\nwhereC?0 (z) are new complex functions of z. Hence,\n|z;??;?,??=\n?summationdisplay\nn=0,?\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK0?([n])!C\n?\n0 (z)e\n?i?0??E?n |E?\nn?. (55)\nHaving identified both the z and ?? dependences of the coherent states, finally let us\naccount for their (?,?) dependence and S2 vector character implicit so far through the two\nfunctionsC?0 (z). The latter are now chosen to be given as\nC+0 (z) = N+(|z|) cos?, C?0 (z) = N?(|z|)ei? sin?, (56)\nN?(|z|) being factors such that the constructed (p,q)-VCS be of unit norm,\nN?(|z|) =\nbraceleftBigg ?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2\nbracerightBigg?1/2\n. (57)\nThe convergence radii R? of these two series in z,\nR? = limn??\nbraceleftBig\n(q?p??)?(n?1) K0?([n])\nbracerightBig\n, (58)\ndepend on the choice of functions K0?([n]) as well as on (?,?) possibly. Specific cases are\nconsidered hereafter.\nConsequently, the (p,q)-VCS constructed here are properlydefined provided z?DR where\nDR denotes the disk in the complex plane centered at z = 0 and of radius R = min(R+,R?).\nTheir general structure is thus of the form\n|z;??;?,?? = N+(|z|) cos?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK0+([n])! e\n?i?0?+ E+n |E+\nn?\n+ N?(|z|)ei? sin?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK0?([n])! e\n?i?0??E?n |E?\nn?. (59)\nOnly the real positive functions K0?([n]) still need to be specified. They parametrize the remain-\ning freedom in the construction. Particular examples will be considered hereafter by imposing\nfurther requirements on these (p,q)-VCS. Note that the double limit p,q?1 yields the VCS of\nthe non-deformedJCm as obtained by Hussin and Nieto [14], briefly described in Section 2.\n4.2 Some expectation values\nBefore dealing with further requirements on the family of (p,q)-VCS, among which their over-\ncompleteness in the space V, let us consider some relevant expectation values for these states.\nGiven (59), the mean value ofHred for any of the (p,q)-VCS is simply\n?Hred? = |N+(|z|)|2 cos2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n+([n])!\nparenrightbig2 E+n\n+|N?(|z|)|2 sin2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2 E?n . (60)\n11\nLikewise for the ?number? operator associated to the ladder operators A? and A+, one finds\nthe expectation value\n?A+A?? = |z|2\nbraceleftBigg\n|N+(|z|)|2 cos2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n+1) |z|2n\nparenleftbigK0\n+([n])!\nparenrightbig2\n+|N?(|z|)|2 sin2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n+1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2\nbracerightBigg\n. (61)\nFinally, the average atomic spin time evolution ??3(t)? = ?U?1(t)?3U(t)?, with U(t) =\nexp{?i?0tHred}being the time evolution operator, has the form\n??3(t)?= 12\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1)\n|z|2nE([n+ 1])Q([n+ 1])\nbraceleftBigg\n?|N\n+(|z|)|2\nparenleftbigK0\n+([n])!\nparenrightbig2 cos2 ? + |N\n?(|z|)|2\nparenleftbigK0\n?([n])!\nparenrightbig2 sin2 ?\nbracerightBigg\n+?N+(|z|)N?(|z|)sin2?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nK0+([n])!K0?([n])!\n[n+ 1]\nQ([n+ 1]) cos?n(t), (62)\nwith\n?n(t) = ?0bracketleftbig(t+?+)E+n ? (t +??)E?nbracketrightbig + ? = ?0?En t + ?0bracketleftbig?+E+n ???E?nbracketrightbig+?. (63)\nAs is the case in the non-deformed model, the explicit time dependence which arises for the\natomic inversion ??3(t)? is due to the mixed state sector, namely the fact that the mixed-spin\nmatrix elements of the Heisenberg picture operator ?3(t) do not vanish when ? negationslash= 0. Hence,\nthe proposition which states that the time dependence of atomic inversion consists of Rabi\noscillations when a system is prepared in a coherent state of the radiation field [17] extends to\n(p,q)-VCS. However, in the limit where ??0, no such oscillations occur. Let us also point out\nthat the time dependence of??3(t)?diplays chaotic behaviour for appropriate values of the model\nparameters, as was previously mentioned for the q-deformation of the model, with 0 < q < 1, in\nthe work by Naderi et al. [24].\n4.3 Overcompleteness and the moment problem\nAn important property that coherent states ought to meet is that of overcompleteness in the\nspace over which they are defined [30]. In the present case, this means that the (p,q)-VCS in\n(59) must also provide a resolution of the identity operator over the subspaceV, namely\nIV = IV0 + IV =|E???E?| + IV, (64)\nwhile\nIV =\n?summationdisplay\nn=0,?\n|E?n??E?n|=\nintegraldisplay\nDR?S2\nd?(z;?,?)|z;??;?,???z;??;?,?|, (65)\nwhere d?(z;?,?) is some SU(2) matrix-valued integration measure over DR?S2 to be determined\nfrom the above requirement.\nLet us thus consider the following parametrization of that measure,\nd?(z;?,?) = d2zd? sin?d?\nbraceleftBigg\nW+(|z|)\n?summationdisplay\nn=0\n|E+n??E+n| + W?(|z|)\n?summationdisplay\nn=0\n|E?n??E?n|\nbracerightBigg\n, (66)\n12\nin terms of real weight functions W?(|z|) to be identified. Using the radial parametrization\nz = rei? and d2z = drrd? where r ? [0,?[ and ? ? [0,2?[, a direct substitution in (65)\nleads to the moment problem associated to the overcompleteness relation (65). In terms of the\nfunctions h?(r2) defined through\nh+(r2) = 4?\n2\n3 |N\n+(r)|2W+(r), h?(r2) = 8?2\n3 |N\n?(r)|2W?(r), (67)\nthe following two infinite sets of moment identities must be met, for all n?N,\nintegraldisplay R2\n0\nduun h?(u) =\nparenleftbiggq?\np?\nparenrightbigg?n(n?1) parenleftbig\nK0?([n])!parenrightbig2 . (68)\nIn conclusion, the resolution of the identity operator over V in terms of the (p,q)-VCS\nis achieved provided the Stieljes moment problem (68) can be solved [36, 37]. This requires a\nchoice of functions K0?([n]) > 0 such that not only the conditions (68) may all be met, but also\nsuch that the normalization factors N?(|z|) converge in a non-empty disc of the complex plane.\nAs a result of this analysis, a priori there may exist a large number of sets of (p,q)-VCS\nwhich fulfill all the above properties, namely continuity in the complex parameter z, temporal\nstability through a simple additive time dependence in the real parameters ??, a unit vector\nvalued characterization on the sphere S2 in terms of the spherical coordinates ? and ?, and the\ncompleteness propertyof a resolution of the unit operator with a SU(2) matrix-valued integration\nmeasure over these spaces. These sets of (p,q)-VCS are distinguished from one another by\ndifferent choices of real positive weight factors K0?([n]), in agreement with the considerations\ndeveloped in [30, 38]. The above construction of (p,q)-VCS is general, but can admit explicit\nexact solutions to the moment problem(68) for particular cases. Concrete examples are discussed\nin Section 5..\n4.4 Action-angle variables\nOne of the useful properties that general coherent states constructed according to the arguments\nof [38] possess, is that action-angle variables are readily identified in relation to the continuous\nparameters ensuring stability of the coherent states under time evolution. In the present case,\ncanonical reduced action-angle variables (J?(t),??(t)) are such that for the previously evaluated\nexpectation values of the reduced Hamiltonian (24) in the (p,q)-VCS, one has\n?Hred?= J+ ?+ + J? ?? =\nsummationdisplay\n?\nJ? ??, (69)\nin relation to the action-angle variational principle of the form\nintegraldisplay\ndt\nsummationdisplay\n?\nbracketleftbiggd?\n?\ndt J? ? ??J?\nbracketrightbigg\n??\nintegraldisplay\ndt\nbracketleftbigg\n? i?\n0\nd\ndt???H\nred?\nbracketrightbigg\n, (70)\nwhere ?? are two constant factors to be chosen appropriately. Consequently\nd??\ndt =\n??Hred?\n?J? = ??,\ndJ?\ndt =?\n??Hred?\n??? = 0. (71)\n13\nGiven the time evolution, ??(t) = t + ??(0), one simply finds ?? = 1. From the expression in\n(60), one then has the identifications\nJ+ = |N+(|z|)|2 cos2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n+([n])!\nparenrightbig2 E+n ,\nJ? = |N?(|z|)|2 sin2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2 E?n . (72)\nAs a final remark, let us mention that the saturated Heisenberg uncertainty relations\nwhich are obeyed by q- and (p,q)-coherent states are also well-known in q-mechanics (see for\ninstance [39]). Such minimal uncertainties may be characterized through small corrections to\ncanonical commutation relations defined in [39, 40]. Such properties in the case of the (p,q)-VCS\nconstructed here are deferred to a later study.\n5 Explicit Solutions\nIn order to completely specify the quantities K0?([n]), one last set of conditions needs to be\nimplemented. In the present Section, two such choices are discussed, one of which allows for an\nexact and explicit solution to the moment problem, hence the construction of a set of (p,q)-VCS.\nFirst, in line with the illustrative example of Section 2, we consider restricting the algebra of the\nladder operatorsA?. Then as a second and independent possibility, we apply a final additional\ncriterion developed in [30] in order to uniquely characterize a set of coherent states which meet\nalready all the requirements considered heretofore and having led to the representation (59),\neven though the moment problem remains unsolved for that choice.\n5.1 Constraining the ladder operator algebra\nIn order to uniquely identify the set of functions K0?([n]) > 0, let us consider the possibility\nthat this may be achieved by restricting the algebraic properties of the ladder operators. In line\nwith the general (p,q)-deformations of the Fock algebra in (2), let us constrain the algebra of\nthe operators A? acting onV to be such that\nA?A+ ? q0A+A? = p?N0 =\n?summationdisplay\nn=0,?\n|n,??p?n0 ?n,?|,\nA?A+ ? p?10 A+A? = qN0 =\n?summationdisplay\nn=0,?\n|n,??qn0 ?n,?|, (73)\nwhere p0 and q0 are again two real parameters such that p0 > 1, 0 < q0 < 1 and p0q0 < 1, which\nmay or may not be identical to p and q. For instance, we could have p0 = 1 and q0 = 1 thus\ncorresponding to an ordinary Fock algebra, or else p0 = p and q0 = q, but also more generally\np0 = p? and q0 = q?, ? being some real constant. As a matter of fact, exact solutions to the\nmoment problem are presented hereafter in all these situations.\nIn terms of the ladder operatorsA? =UA?U? acting on the subspaceV, the associated\nalgebraic constraint reads\nA?A+ ? q0A+A? =\n?summationdisplay\nn=0,?\n|E?n?p?n0 ?E?n|,\n14\nA?A+ ? p?10 A+A? =\n?summationdisplay\nn=0,?\n|E?n?qn0 ?E?n|. (74)\nWhether in terms of (73) or (74), these algebraic constraints translate into the following identi-\nties, for all n?N,\nparenleftbigK0\n?([n+ 1])\nparenrightbig2 ? q\n0\nparenleftbigK0\n?([n])\nparenrightbig2 = p?n\n0 ,\nparenleftbigK0\n?([n+ 1])\nparenrightbig2 ? p?1\n0\nparenleftbigK0\n?([n])\nparenrightbig2 = qn\n0. (75)\nGiven the initial values K0?([0]) = 0, the solution to these recursion relations is simply\nK0?([n]) =\nradicalBig\n[n](p0,q0) =\nradicalBig\n[n](q?1\n0 ,p\n?1\n0 )\n, (76)\nwhere4\n[n](p0,q0) = p\n?n\n0 ?qn0\np?10 ?q0 =\nparenleftbigq?1\n0\nparenrightbig?n?parenleftbigp?1\n0\nparenrightbign\nparenleftbigq?1\n0\nparenrightbig?1?parenleftbigp?1\n0\nparenrightbig = [n](q?10 ,p?10 ). (77)\nGiven this solution, the normalization factors are defined by the series\n|N?(|z|)|?2 =\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\n[n](p0,q0)!, (78)\nof which the convergence radius is\nR = limn??\nbracketleftBiggparenleftbigg\nq?\np?\nparenrightbigg?2(n?1) p?n\n0 ?qn0\np?10 ?q0\nbracketrightBigg1/2\n= limn??\nbracketleftbiggparenleftbig\np0p?2?q2?parenrightbig?(n?1) 1?(p0q0)\nn\n1?(p0q0)\nbracketrightbigg1/2\n. (79)\nProvided p0p?2?q2? < 1, a condition which we shall henceforth assume to be satisfied5, this\nradius of convergence is infinite, R =?, and the moment problem (68) then becomes, for all\nn?N, integraldisplay\n?\n0\nduun h?(u) =\nparenleftbiggq?\np?\nparenrightbigg?n(n?1) parenleftbig\n[n](p0,q0)!parenrightbig. (80)\nIn order to solve these equations, the Ramanujan integral (121) discussed in the Appendix\nsuggests itself quite naturally, through a simple but appropriate rescaling of its arguments in\nthe form of (123).\nAfter a little moment?s thought one comes to the conclusion that a solution to (80) based\non (123) is possible for the following choice of parameters,\n? = 12, ? = 0, p0 = p, q0 = q, (81)\nin which case p0p?2?q2? = pq < 1, hence corresponding indeed to an infinite radius of conver-\ngence. For this choice, one has (for definitions of the (p,q)-exponential functions appearing in\nthese expressions, see the Appendix),\nh?parenleftbig|z|2parenrightbig=\nparenleftbigp?1?qparenrightbig\nqlog(1/pq) e(p,q)\nparenleftBig\n?|z|2 p?1/2q?1parenleftbigp?1?qparenrightbig\nparenrightBig\n, (82)\n4Incidentally, it is because of this identity, corresponding to the exchange p0 ? q?1\n0 , that the two solutions to\nthe above two recursion relations are consistent, as are the two algebraic restrictions in (73) and (74).\n5If p0p?2?q2? = 1, the radius of convergence is finite with R = (1?p0q0)?1/2, while when p0p?2?q2? > 1 the\nradius of convergence vanishes, implying that (p,q)-VCS cannot be constructed in such a case.\n15\nas well as6\nparenleftbigK0\n?([n])\nparenrightbig2 = [n], |N?(|z|)|?2 =E(1/2,0)\n(p,q)\nparenleftBig\n|z|2q?1/2parenleftbigp?1?qparenrightbig\nparenrightBig\n, (83)\nwith for the weight functions W?(|z|) in the integration measure (66) of the overcompleteness\nrelation (65),\nW+ (|z|) = 34?2 |N+ (|z|)|?2 h+parenleftbig|z|2parenrightbig, W?(|z|) = 38?2 |N?(|z|)|?2 h?parenleftbig|z|2parenrightbig. (84)\nExplicit expressions for all previously computed quantities readily follow, beginning with the\ndefinition of the associated (p,q)-VCS which then meet all thenecessary requirements expected of\ncoherent states. Note that up to the coefficients 3/(2?) and 3/(4?), the reduced weights obtained\nare compatible with that of the q-shape invariant harmonic oscillator [20]. Furthermore, (82)\nis a (p,q)-generalization of the q-harmonic oscillator coherent state moment problem solution\nconstructed in [41]. Finally, in the double limit p,q?1, the results of [14] are recovered.\nThe functions (82) thus provide a complete and explicit solution to the moment problem of\nthe (p,q)-VCS for the (p,q)-JCm such that the ladder operatorsA? obey the same (p,q)-Fock\nalgebra as the original modes a and a? of the initial Hamiltonian (24), namely with the choice\np0 = p and q0 = q. It is also possible to construct an explicit solution when the ladder operators\nA? are constrained to rather obey the ordinary non-deformed Fock algebra onV, corresponding\nto the choice p0 = 1 and q0 = 1. One then has to consider7, for all n?N,\nK0?([n]) =?n,\nintegraldisplay ?\n0\nduun h?(u) =\nparenleftbiggq?\np?\nparenrightbigg?n(n?1)\n(n!), p??q??1. (85)\nAn obvious solution to this moment problem is obtained when ? = 0 = ?, in which case the\ncondition for an infinite radius of convergence is saturated. One then has\nh?parenleftbig|z|2parenrightbig= e?|z|2, |N? (|z|)|?2 = e|z|2, W+ (|z|) = 34?2, W?(|z|) = 38?2. (86)\nIn fact, the above two explicit solutions belong to a general class of solutions obtained\nby taking (p0,q0) = (p?,q?) with ? a positive real parameter, ? > 0, such that p??2?q2? < 1\nin order to ensure an infinite radius of convergence8 in z ?C. Once again based on (123), an\nexplicit solution to the moment problem (80) is achieved for the following choice of parameters,\n? = 12?, ? = 0, p0 = p?, q0 = q?, (87)\nfor which the radius of convergence is indeed infinite, p??2?q2? = (pq)? < 1. One then has\nh?parenleftbig|z|2parenrightbig= (p\n???q?)\nq? log(1/p?q?) e(p?,q?)\nparenleftBig\n?|z|2 p??/2q??parenleftbigp???q?parenrightbig\nparenrightBig\n, (88)\nwith\n|N?(|z|)|?2 =E(1/2,0)(p?,q?)\nparenleftBig\n|z|2q??/2parenleftbigp???q?parenrightbig\nparenrightBig\n, (89)\nleading finally to the weight functionsW?(|z|) given in terms of the latter two quantities through\nthe same relations as in (84). In the limits that ? ? 1 or ? ? 0, the previous two explicit\nsolutions are then recovered as particular cases.\n6Restricting to p0 = p and q0 = q but keeping ? and ? arbitrary such that p1?2?q2? < 1 in order to retain an\ninfinite radius of convergence, one has parenleftbigK0?([n])parenrightbig2 = [n] and |N? (|z|)|?2 = E(?,?)(p,q) parenleftbig|z|2 p? q??parenleftbigp?1 ?qparenrightbigparenrightbig, hence\nalso all other previous expressions given accordingly.\n7Leading to |N? (|z|)|?2 = e(?,?)\n(p,q)\nparenleftbig|z|2 p? q??parenrightbig, which converges for all |z| < ? provided p??q? ? 1.\n8Leading to |N? (|z|)|?2 = E(?/?,?/?)\n(p?,q?)\nparenleftbig|z|2p?q??(p?? ?q?)parenrightbig.\n16\n5.2 The action identity constraint\nAn alternative to fixingthe factors K0?([n]) through conditions on the algebra ofladder operators,\nis to consider the action identity constraint discussed in [30] as the one last requirement which\nsingles out coherent states uniquely. In the case of the ordinary Fock algebra, this action\nidentity constraint is equivalent to requiring that the ladder operators obey themselves the Fock\nalgebra as well. We shall establish that this is not the case for the (p,q)-VCS of the (p,q)-JCm\nconstructed above.\nGiven the relations (72), in the present model the action identity constraint is of the form\nJ+ = cos2 ?parenleftbig|z|2 +E+0 parenrightbig, J? = sin2 ?parenleftbig|z|2 +E?0 parenrightbig. (90)\nBy direct substitution into these constraints of the relations (72), the identification of the suc-\ncessive powers in|z|2 leads to the following solution for the factors K0?([n]),\nK0?([n]) =\nparenleftbiggq?\np?\nparenrightbigg(n?1) radicalBig\nE?n ? E?0 . (91)\nThese positive real quantities are thus well-defined provided one has E?n > E?0 for all n ? 1,\nas is implicitly assumed. It is noteworthy that, as (p,q) ? (1+,1?), these factors reduce to\nexactly those obtained in [16] by the factorization method. On the other hand, since the present\nsolution for K0?([n]) cannot be brought into the form of (76) for some choice of constants p0 and\nq0 meeting our assumptions for these quantities, it follows indeed that for the (p,q)-JCm the\naction identity constraint is not equivalent to requiring an algebraic constraint on the ladder\noperators of the (p0,q0)-deformed Fock algebra type.\nThis choice also allows for the factorization of the Hamiltonian in (36) in the form\nHred = A+\nparenleftbiggq?\np?\nparenrightbigg?2N\nA +\n?summationdisplay\nn=0,?\n|n,??E?0 ?n,?|, (92)\nextending a similar expression in [14].\nGiven this solution for the factors K0?([n]), the general moment problem (68) reduces to\nthe following conditions,\nintegraldisplay R2\n0\ndu h?(u) = 1;\nintegraldisplay R2\n0\nduun h?(u) =\nnproductdisplay\nk=1\nparenleftbigE?\nk ?E\n?\n0\nparenrightbig, n = 1,2,3,???, (93)\nwhere the radius of convergence R is given as\nR = min (R+,R?), R? = limn?+?\nradicalBig\nE?n ?E?0 . (94)\nIn the absence of a detailed analysis of the energy spectra E?n as functions of the parameters p,\nq, ? and ? and the function h(p,q), nothing more explicit may be said concerning this moment\nproblem. Since when p > 1 the quantities [n] always possess a turn-around behaviour as func-\ntions of n for n sufficiently large, it is to be expected generally that the radius of convergence\nR, hence the moment problem as well, are associated to a finite disk DR in the complex plane.\nNevertheless, one conclusion of the present discussion is that indeed for the (p,q)-VCS consid-\nered in this work, the action identity constraint leads to coherent states different from those\nconstructed in Section 5.1 and for which explicit solutions to the moment problem have been\ngiven.\n17\n5.3 The spin decoupled limit ? = 0\nIn the limit that ? = 0, the two spin sectors of the model are decoupled, and the (p,q)-JCm\nreduces to the supersymmetric harmonic oscillator [43, 44, 18] with a (p,q)-deformation. Diago-\nnalization of the reduced Hamiltonian (24) is then of course straightforward in the ?3-eigenbasis,\nwith, for n = 0,1,2,???,\nHred?=0|n,??= ??n |n,??, ??n = (1 +?)h(p,q)[n] + 12(1 +?)?12. (95)\nFrom that point of view, one thus has two decoupled (p,q)-deformed Fock bases, for which\none could consider the usual (p,q)-coherent states in each spin sector separately. However, such\ncoherent states do not coincide with any of those constructed in this paper and obtained in the\nlimit ? = 0, because of the distinguished role played by the singleton state |E?? = |0,?? and\nthe S2 unit vector character of the (p,q)-VCS. In particular the ladder operators A? acting\nwithin each of the towers |E?n? do not coincide with the annihilation and creation operators a\nand a? defining the Hamiltonian (24), even in the decoupled limit ? = 0. As a matter of fact,\nthe action of the ladder operatorsA? may switch between the two spin sectors as a function of\nn depending on the sign of the quantityE([n+ 1]).\nMore specifically, let us introduce the notation\nsn = signE([n+ 1]), n?N. (96)\nIn the limit that ? = 0, one has Q([n + 1]) =|E([n + 1])|/2, so that the mixing angle ?([n]) is\nnow such that, for all n?N,\n? = 0 : sin?([n]) = 12(1?sn)(sign?), cos?([n]) = 12(1 +sn). (97)\nConsequently, the towers of energy eigenstates|E?n?are then given as follows, for all n?N,\nIf sn = +1 : |E+n??=0 =|n+1,??, |E?n??=0 =|n,+?;\nIf sn =?1 : |E+n??=0 = (sign?)|n,+?, |E?n??=0 =?(sign?)|n + 1,??,\n(98)\nwhile the energy eigenvalues are given as\nIf sn = +1 : E+n (? = 0) = (1 +?)h(p,q)[n +1] + 12(1 +?) ? 12,\nE?n (? = 0) = (1 +?)h(p,q)[n] + 12(1 +?) + 12;\nIf sn =?1 : E+n (? = 0) = (1 +?)h(p,q)[n] + 12(1 +?) + 12,\nE?n (? = 0) = (1 +?)h(p,q)[n +1] + 12(1 +?) ? 12.\n(99)\nThese spectra do indeed coincide with those in (95), once the singleton state|E??=|0,??with\nE? = ?/2 is included as well.\nThese expressions show how, even in the decoupled spin limit ? = 0, the (p,q)-VCS\nconstructed here are not simply the juxtaposition of two separate (p,q)-coherent states of the\n(p,q)-deformed Fock algebra in each of the two spin sectors. Since the spectrum of the system\nis discrete infinite, by leaving aside the singleton state|0,??, all the remaining states still allow\nfor similar types of constructions of coherent states, but in such a way that different spin sectors\nare getting superposed, leading to the SU(2) vector coherent states of the type studied here. All\nthe expressions detailed in the previous sections for the (p,q)-VCS may readily be particularized\nto the limit ??0.\n18\n6 Conclusion\nIn this work, we considered (p,q)-deformations of the Jaynes-Cummings model in the rotating\nwave approximation, extending recent developments on this topic in the non-deformed case [14].\nHaving introduced (p,q)-deformed versions of the model, first its energy eigenspectrum has been\nidentified, enabling the definition of different relevant operators acting on Hilbert space and the\ncharacterization of the spectrum in terms of two separate infinite discrete towers and a singleton\nstate. Among these operators, ladder operators acting within each of the two towers separately\nmay be considered, defined up to some arbitrary normalization factors.\nSuch a structure sets the stage for the introduction of vector coherent states for the (p,q)-\ndeformed Jaynes-Cummings model, following the approach of [14] and the rationale outlined\nin [30]. These (p,q)-VCS are parametrized by elements of C?S2, and enjoy temporal sta-\nbility through a further action-angle identification. The moment problem associated to the\novercompleteness property of these (p,q)-VCS involves SU(2)-valued matrix weight functions.\nUsing (p,q)-arithmetic techniques, some explicit and exact solutions to the moment problem\nhave been displayed, hence characterizing specific classes of such (p,q)-VCS. All these solutions\nprovide (p,q)-extensions to the non-deformed vector coherent states of theJCm considered in\n[14]. These explicit solutions are obtained by requiring that specific algebraic constraints of the\n(p,q)-deformed Fock algebra type be obeyed by the ladder operators. However, in contradis-\ntinction to [14], we have not been able to display an explicit and exact solution to the moment\nproblem in the generic case by imposing an action identity constraint.\nFinally, the spin decoupled limit of these models was considered, corresponding to a (p,q)-\nsupersymmetric oscillator of which the two sectors are intertwined in a manner depending on\nthe sign of the energy level spacing between the two decoupled spin sectors as function of the\nexcitation level. In the non-deformed limit (p,q) = (1,1), this feature disappears, reproducing\nthe ordinary supersymmetric oscillator. Our results thus provide new classes of generalized\nversions of theJCm in the rotating wave approximation [20, 18]. Finally, the (p,q)-VCS built\nhere extend the q-coherent states obtained by other techniques involving supersymmetric shape\ninvariance and self-similar potential formalisms applied to the harmonic oscillator [20, 45].\nAcknowledgements\nJ. B. G. is grateful to the Abdus Salam International Centre for Theoretical Physics (ICTP,\nTrieste, Italy) for a Ph.D. fellowship under the grant Prj-15. M. N. H. is particularly indebted\nto V. Hussin for discussions relating to the JCm as well as for provided references during his\nstay at the Centre de Recherches Math?ematiques, Universit?e de Montr?eal, Canada. The ICMPA\nis in partnership with the Daniel Iagoniltzer Foundation (DIF), France.\nJ. G. acknowledges a visiting appointment as Visiting Professor in the School of Physics\n(Faculty of Science) at the University of New South Wales. He is grateful to Prof. Chris Hamer\nand the School of Physics for their hospitality during his sabbatical leave, and for financial sup-\nport through a Fellowship of the Gordon Godfrey Fund. His stay in Australia is also supported\nin part by the Belgian National Fund for Scientific Research (F.N.R.S.) through a travel grant.\nJ. G. acknowledges the Abdus Salam International Centre for Theoretical Physics (ICTP,\nTrieste, Italy) Visiting Scholar Programme in support of a Visiting Professorship at the ICMPA.\nHis work is also supported by the Belgian Federal Office for Scientific, Technical and Cultural\nAffairs through the Interuniversity Attraction Pole (IAP) P5/27.\n19\nAppendix\nThis appendix lists some useful facts related to the (p,q)-boson algebra and associated functions.\nThe (p,q)-deformed oscillator algebra introduced in [5] is generated by operators a, a? and N\nobeying the relations\n[N,a] =?a, [N,a?] = a?,\naa??qa?a = p?N, aa??p?1a?a = qN. (100)\nThroughout the text, we assume the real parameters p and q are such that p > 1, 0 < q < 1\nand pq < 1. The limit p ? 1+ yields the q-oscillator of Arik and Coon [3] while p = q gives\nthe q-deformed oscillator algebra of Biedenharn and MacFarlane [4]. Finally, the algebra (100)\nreduces to the ordinary harmonic oscillator Fock algebra as q ? 1 for p = 1+ or p = q. At\nany stage of the discussion, the (p,q)-deformed model readily reduces to its usual counterpart\nas (p,q)?(1,1).\nThe associated (p,q)-deformed Fock-Hilbert space representation is spanned by the vac-\nuum|0?annihilated by a and the orthonormalized states|n?, such that\na|0?= 0, ?0|0?= 1, |n?= 1radicalBig\n[n](p,q)!\nparenleftBig\na?\nparenrightBign\n|0?,\na|n?=\nradicalBig\n[n](p,q)|n?1?, a?|n?=\nradicalBig\n[n+ 1](p,q)|n+ 1?, N|n?= n|n?, (101)\nwhere the symbol [n](p,q) = (p?n?qn)/parenleftbigp?1?qparenrightbigis called (p,q)-basic number with, by conven-\ntion, [0](p,q) = 0, and its (p,q)-factorial is defined through [n](p,q)! = [n](p,q)parenleftbig[n?1](p,q)!parenrightbig and\nthe convention [0](p,q)! = 1. There exists a formal (p,q)-number operator denoted by [N](p,q), or\nsimply by [N] when no confusion arises. As a matter of fact, from the second pair of relations\nin (100), it follows that [N] = a?a as well as [N + 1] = aa?. One has of course [N]|n?= [n]|n?.\nHence, (101) provides a well defined Fock-Hilbert representation space of the algebra (100).\nThe following relations hold for any function f ?f(N) and consequently for any function\nof [N],\naf(N?1) = f(N)a, a?f(N) = f(N?1)a?. (102)\nLet us define q-shifted products and factorials and their (p,q)-analogues. Using the nota-\ntions of [46], for any quantity x, (x;q)? is constructed as follows,\n(x;q)0 = 1, (x;q)? = (x;q)?(xq?;q)\n?\n, (x;q)? =\n?productdisplay\nn=0\n(1?xqn). (103)\nFurthermore, in the notations of [10], (p,q)-shifted products and factorials are defined as follows,\nfor any real quantities a and b such that anegationslash= 0,\n[a,b;p,q]0 = 1, [a,b;p,q]? = [a,b;p,q]?[ap?,bq?;p,q]\n?\n, [a,b;p,q]? =\n?productdisplay\nn=0\nparenleftbigg 1\napn ?bq\nn\nparenrightbigg\n. (104)\nFor ? = n?N, we have\n[p?,q?;p,q]n =\nparenleftbigg 1\np? ?q\n?\nparenrightbiggparenleftbigg 1\np?+1 ?q\n?+1\nparenrightbigg\n...\nparenleftbigg 1\np?+n?1 ?q\n?+n?1\nparenrightbigg\n20\n= p??n?n(n?1)/2(p?q?;pq)n. (105)\nThis identity is a central formula since it defines a bridge between q- and (p,q)-analogue quan-\ntities and functions.\nLet us now introduce q-analogues of the ordinary exponential funtion. There exist many\ntypes of q-deformations of the exponential function ez, z ?C (see, for instance, [9]). For any\n(z,?)?C?R, the (?,q)-exponential is the complex function [9]\nE(?)q (z) =\n?summationdisplay\nn=0\nq?n2\n(q;q)nz\nn. (106)\nThis series has an infinite radius of convergence for ? > 0. For ? = 0 its domain of definition\nreduces to the unit disk, |z| < 1, while it is nowhere convergent in C for ? < 0. Rescaling\nz?z(1?q) and taking the limit limq?1 E?q (z(1?q)), one recovers ez. For some specific values\nof ?, (106) reproduces some standard q-exponentials [9, 11],\nE(0)q (z) = eq(z) = 1(z;q)\n?\n=\n?summationdisplay\nn=0\nzn\n(q;q)n, |z|< 1, (107)\nE(1/2)q (z) = Eq(q1/2z) = (?q1/2z;q)?, z?C, (108)\nwhere\nEq(z) =\n?summationdisplay\nn=0\nqn(n?1)/2zn\n(q;q)n , z?C, (109)\nis known as the Jackson q-exponential [6]. Note that whereas E(?)q (z) is defined in the entire\ncomplex plane, |z| < ?, for any ? > 0, its reduction eq(z) is only defined on the unit disc.\nFinally, it is also well established that [11]\nEq(?z)eq(z) = 1. (110)\n(p,q)-analogues of the usual exponential function ez, z?C may also be introduced (see,\nfor instance, [10]). Given any (z,?,?)?C?R?R, consider the (?,?,p,q)-exponential function\nE(?,?)(p,q) (z) =\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn2 zn\n[p,q;p,q]n. (111)\nKeeping in mind the condition pq < 1, the radius of convergence R of this series is such that\nR1 =\n?\n?\n?\n?, if q2?p1?2? < 1;\np??1q??, if q2?p1?2? = 1;\n0, if q2?p1?2? > 1.\n(112)\nThus the functionE(?,?)(p,q) (z) exists only provided q2?p1?2? ?1.\nIn order to recover the usual exponential function, one has to rescale z?z(p?1?q), for\nexample, and then take the limit lim(p,q)?(1,1)E?,?(p,q)(z(p?1?q)) = ez. For particular values of\nthe parameters ? and ?, (111) reproduces known (p,q)-exponentials,\nE(1/2,1/2)(p,q) (z) = E(p,q)\nparenleftBiggparenleftbigg\nq\np\nparenrightbigg1/2\nz\nparenrightBigg\n=\n?summationdisplay\nn=0\nparenleftbiggq\np\nparenrightbiggn2/2 zn\n[p,q;p,q]n, (113)\n21\nwhere\nE(p,q)(z) =\n?summationdisplay\nn=0\nparenleftbiggq\np\nparenrightbiggn(n?1)/2 zn\n[p,q;p,q]n. (114)\nThe function E(p,q) may be found in [10]. Note that (114) coincides with (109) as p?1. In the\nsame limit, (111) reproduces the (?,q)-deformed exponential map E(?)q (z) [9]. If ? = 0 = ? the\nseries (111) is not defined since then R = 0, unless one has taken p = 1 in which case the radius\nof convergence is unity. A (p,q)-analogue of (107) is given by\ne(p,q)(z) =\n?summationdisplay\nn=0\n1\npn2/2\nzn\n[p,q;p,q]n, |z|< p\n?1/2, (115)\nwhich reproduces exactly eq(z) converging in the unit disc as p ? 1+. Furthermore, we have\nfrom (105)\ne(p,q)(z) =\n?summationdisplay\nn=0\n(p1/2z)n\n(pq;pq)n = epq(p\n1/2z). (116)\nUsing (105) and (109), we may also write\nE(p,q)(z) =\n?summationdisplay\nn=0\nparenleftbiggq\np\nparenrightbiggn(n?1)/2 zn\np?n(n+1)/2(pq;pq)n\n=\n?summationdisplay\nn=0\nqn(n?1)/2 (zp)\nn\n(pq;pq)n = Epq(pz). (117)\nThen taking into account (110), (116) and (117), a (p,q)-analogue of (110) is given by\nEpq(?pz)epq(pz) = E(p,q)(?z)e(p,q)(p1/2z) = 1. (118)\nFinally, consider\ne(?,?)(p,q)(z) =\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn2 zn\nn!. (119)\nTherefore, e(?,?)(p,q)(z), which converges to ez as (p,q) ? (1,1), provides a (p,q)-deformed ex-\nponential analogue to the q-function used by Penson and Solomon [42] which coincides with\ne(1,?)(1,q)(q?1/2z). The radius of convergence of (119) is given as\nR2 =\nbraceleftbigg ?, if q?p?? ?1;\n0, if q?p?? > 1. (120)\nFinally, consider the Ramanujan integral [7, 19], valid for any integer n?N,\nintegraldisplay ?\n0\ndttn eq(?t) =? (q;q)nqn(n+1)/2 logq. (121)\nThrough the change of variables\nq?pq, t??0 p?1/2 t, ?0 > 0, (122)\nand using once again (105), the following identity is obtained, for any n?N,\nintegraldisplay ?\n0\ndttn e(p,q)\nparenleftBig\n??0p?1/2t\nparenrightBig\n= [p,q;p,q]n?n+1\n0 qn(n+1)/2\nlog\nparenleftbigg 1\npq\nparenrightbigg\n. (123)\nThis result is indeed a (p,q)-analogue of the Ramanujan integral (121).\n22\nReferences\n[1] S. Majid, Quantum Groups (Cambridge Univ. Press, Cambridge, 1995);\nV. G. Drinfeld, Quantum Groups, Lecture Notes in Mathematics, Ed. P. P. Kulish (Springer,\nBerlin, 1992).\n[2] See for example,\nJ. Wess and B. Zumino, Nucl. Phys. B (Proceedings Supplements) 18, 302-312 (1991);\nA. Lorek and J. Wess, Z. Phys. C 67, 671-680 (1995).\n[3] M. Arik and D. D. Coon, J. Math. Phys. 17, 524-527 (1976).\n[4] A. J. Macfarlane, J. Phys. A: Math. Gen. 22, 4581-4588 (1989);\nL. C. Biedenharn, J. Phys A: Math. Gen. 22, L873-L878 (1989).\n[5] R. Chakrabarti and R. Jagannathan, J. Phys. A: Math. Gen. 26, L711-L719 (1991).\n[6] F. Jackson, Mess. Math. 38, 57 (1909).\n[7] S. Ramanujan, Mess. Math. 44, 10-18 (1915).\n[8] H. Exton, q-Hypergeometric Functions and Application (John Wiley and Sons, New York,\n1983).\n[9] F. Floreanini and L. Vinet, Lett. Math. Phys. 22, 45-54 (1991);\nF. Floreanini, J. LeTourneux and L. Vinet, J. Phys. A: Math. Gen. 28, L287-L239 (1995).\n[10] R. Floreanini, L. Lapointe and L. Vinet, J. Phys. A: Math. Gen. 26, L611-L614 (1993).\n[11] R. Koekoek and R. F. Swarttouw, The Askey-scheme of hypergeometric orthogonal polyno-\nmials and its q-analogue, Delft University Technology, Report 94-05 (1994).\n[12] E. T. Jaynes and F. Cummings, FW Proc. IEEE 51, 89-109 (1963).\n[13] P. Meystre and E. M. Wright, Phys. Rev. A 37, 2524 (1988).\n[14] V. Hussin and L. M. Nieto, J. Math. Phys. 46, 122102 (2005).\n[15] Y. B?erub?e-Lauziere, V. Hussin and L. M. Nieto, Phys. Rev. A 50, 1725 (1994).\n[16] L. Dello Sbarba and V. Hussin, in Group of Theoretical Methods in Physics: Proceeding\nof the XXV International Colloqium on Group Theoretical Methods in Physics, Institute\nof Physics Conferences Series, Vol. 185, Eds. G. S. Pogosyan, L. E. Vincent and K. B. Wolf\n(IOP, Bristol, 2005).\n[17] M. Daoud and V. Hussin, J. Phys. A: Math. Gen. 35, 7381-7402 (2002).\n[18] M. Daoud and J. Douari, Int. J. Mod. Phys. B 17, 2473-2486 (2003).\n[19] A. B. Balantekin, To be published in the Proceedings of ?Computational And Group The-\noretical Methods In Nuclear Physics: Symposium In Honor Of Jerry P. Draayer?s 60th\nBirthday, 18-21 Feb 2003, Playa del Carmen, Mexico?; e-print arXiv:nucl-th/0309038.\n23\n[20] A. N. F. Aleixo, A. B. Balantekin and M. A. Candido Ribeiro, J. Phys. A: Math. Gen. 35,\n9063-9070 (2002);\nA. N. F. Aleixo, A. B. Balantekin and M. A. Candido Ribeiro, J. Phys. A: Math. Gen. 36,\n11631-11642 (2003);\nA. N. F. Aleixo and A. B. Balantekin, J. Phys. G 30, 1225-1230 (2004).\n[21] B. Buck and C. V. Sukumar, Phys. Lett. A 81, 132 (1981).\n[22] M. Chaichan, D. Ellinas and P. Kulish, Phys. Rev. Lett. 65, 980-983 (1990).\n[23] Z. Chan, Phys. Rev. A 47, 5017-5023 (1993).\n[24] M. H. Naderi, M. Soltanolkotabi and R. Roknizadeh, Journal of the Physical Society of\nJapan 73, 2413-2423 (2004).\n[25] G. Dresselhaus, Phys. Rev. 100, 580 (1955).\n[26] For a recent review on spintronics, see\nJ. Schliemann, e-print arXiv:cond-mat/0602330.\n[27] S-Q. Shen, Y-J Bao, M. Ma, X. C. Xie and F. C. Zhang, Phys. Rev. B 71, 155316 (2005).\n[28] S-Q. Shen, M. Ma, X. C. Xie and F. C. Zhang, Phys. Rev. Lett. 92, 256603 (2004).\n[29] S. T. Ali and F. Bagarello, J. Math. Phys. 46, 053518 (2004).\n[30] J-P. Gazeau and J. R. Klauder, J. Phys. A: Math. Gen. 32, 123 (1999).\n[31] J-P. Antoine, J-P. Gazeau, P. Monceau, J. R. Klauder and K. A. Penson, J. Math. Phys.\n42, 2349 (2001).\n[32] S. T. Ali, J-P. Antoine and J-P. Gazeau, Coherent States, Wavelets and their Generaliza-\ntions (Springer-Verlag, Berlin, 2000).\n[33] F. G. Scholtz, B. Chakraborty, S. Gangopadhyay and J. Govaerts, J. Phys. A: Math. Gen.\n38, 9849-9858 (2005).\n[34] F. G. Scholtz, B. Chakraborty, S. Gangopadhyay and A. Ghosh Hazra, Phys. Rev. D 71,\n085005 (2005).\n[35] J. Ben Geloun, J. Govaerts and M. N. Hounkonnou, A (p,q)-deformed Landau problem\nin a spherical harmonic well: spectrum and noncommuting coordinates, preprint ICMPA-\nMPA/2006/22, CP3-06-12, e-print arXiv:hep-th/0609120, submitted to J. Phys. A: Math.\nGen.\n[36] M. N. Hounkonnou and K. Sodoga, J. Phys. A: Math. Gen. 38, 7851-7862 (2005).\n[37] For an exhaustive dicussion on the moment problem, see for instance\nB. Simon, Adv. Math. 137, 82-203 (1998).\n[38] J. R. Klauder, Contribution to the 7th ICSSUR Conference, June 2001, e-print\narXiv:quant-ph/0110108.\n[39] A. Kempf, J. Math. Phys. 35, 4483 (1994);\nH. Hinrichsen and A. Kempf, J. Math. Phys. 37, 2121 (1996).\n24\n[40] C. Quesne, K. A. Penson and V. M. Tkachuk, Phys. Lett. A 313, 29-36 (2003).\n[41] C. Quesne, J. Phys. A: Math. Gen. 35, 9213-9226 (2002).\n[42] K. A. Penson and A. I. Solomon, J. Math. Phys. 40, 2354 (1999).\n[43] C. Aragone and F. Zypman, J. Phys. A: Math. Gen. 19, 2267-2279 (1986).\n[44] M. Orszag and S. Salamo, J. Phys. A: Math. Gen. 21, L1059-L1064 (1988).\n[45] F. Cooper, A. Khare and U. Sukhatme, Supersymmetry in Quantum Mechanics 2nd Ed.\n(World Scientific, Singapore, 2004).\n[46] G. Gasper and M. Rahman, Basic Hypergeometric Series (Cambridge Univ. Press, Cam-\nbridge, 1990).\n25\n"}
{"id":"oai:arXiv.org:quant-ph/0610192","text":"arXiv:quant-ph/0602178v2  17 May 2006\nDuality, Phase Structures and Dilemmas in Symmetric Quantum Games\nTsubasa Ichikawa and Izumi Tsutsui\nHigh Energy Accelerator Research Organization (KEK), Tsukuba, Ibaraki 305-0801, Japan\n(Dated: February 22, 2006)\nSymmetric quantum games for 2-player, 2-qubit strategies are analyzed in detail by using a scheme\nin which all pure states in the 2-qubit Hilbert space are utilized for strategies. We consider two\ndifferent types of symmetric games exemplified by the familiar games, the Battle of the Sexes (BoS)\nand the Prisoners? Dilemma (PD). These two types of symmetric games are shown to be related by a\nduality map, which ensures that they share common phase structures with respect to the equilibria\nof the strategies. We find eight distinct phase structures possible for the symmetric games, which\nare determined by the classical payoff matrices from which the quantum games are defined. We\nalso discuss the possibility of resolving the dilemmas in the classical BoS, PD and the Stag Hunt\n(SH) game based on the phase structures obtained in the quantum games. It is observed that\nquantization cannot resolve the dilemma fully for the BoS, while it generically can for the PD and\nSH if appropriate correlations for the strategies of the players are provided.\nPACS numbers: 02.50.Le, 03.67.-a, 87.23.Ge\nKeywords: quantum mechanics, game theory, entanglement\nI. INTRODUCTION\nQuantum game theory has attracted much attention\nin recent years as an interesting attempt to expand the\nscope of the conventional (classical) game theory, which\nis now a standard tool in various fields, most notably in\neconomics, for analyzing decision making processes. The\nmain thrust in the investigation of quantum game has\ncome from the remarkable observation by Eisert et al. [1]\nthat the famous dilemma in the Prisoners?Dilemma (PD)\ngame can be resolved if the players resort to strategies\navailable in quantum theory. Subsequently, Marinatto\nand Weber [2] examined the dilemma in the Battle of\nthe Sexes (BoS) game, another typical dilemma in game\ntheory, and observed that this, too, could be resolved\nby adopting a quantum strategy involving a maximally\nentangled state. Application of quantum strategies to\nvarious other games, such as the Stag Hunt (SH) or the\nSamaritan?s Dilemma game, has also been discussed in\n[3].\nThese studies of the quantum games presented in [1, 3]\nand [2] employ different schemes of quantum strategies,\nand it has turned out that the outcome of the analysis is\nhighly dependent on the scheme used. In fact, it has been\npointed out in [4, 5, 6] that in the scheme used in [1, 3]\nthe dilemma in PD can be resolved only if the strategic\nspace is restricted artificially, while a more recent study\n[7] shows that there exists a new scheme in which the\ndilemma can be resolved even with a full strategic space.\nSimilarly, the resolution of the dilemma in the BoS has\nbeen argued using different reasonings depending on the\nschemes [3, 8, 9] (for a generalized scheme, with no analy-\nsis on dilemmas, see [10]), casting a doubt on the genuine\nnature of the resolution and, more importantly, the uni-\nversality of the outcomes of quantum game in general.\nThe distinction among these schemes can be found in\nthe definitions of quantum strategy, the strategic space\nwhich the players can exploit, and the way the quan-\ntum correlation (entanglement) is furnished. These dif-\nferences are crucial, because (as observed in [4, 5, 6])\ndifferent strategic spaces admit different stable solutions,\nand moreover the amount of entanglement required to\nresolve the dilemma will depend on the stage in the pro-\ncess it is measured. Despite of this scheme-dependence,\nwe have found in [7] an intriguing phase structure for the\nquantum PD game, which is reminiscent of the ?phase\ntransition? of equilibrium solutions discovered earlier in\n[11] in a different scheme. This suggests that the phase\nstructures may exhibit a scheme-independent, intrinsic\nfeatures of quantum games under consideration.\nThe aim of the present paper is to support this idea by\nproviding a convenient tool to analyze quantum games\nin general terms. We consider 2-player, 2-qubit strategy\ngames, which are the simplest nontrivial and yet have not\nbeen fully analyzed. Using the scheme introduced in [7],\nwe study in detail two types of ?symmetric games?, exem-\nplified by the BoS and PD games, respectively. We show\nthat these two types of games are actually related by a\nduality map, which brings a game in one symmetric type\ninto a game in the other symmetric type without chang-\ning the payoff in effect. This is convenient because then\nwe can use the outcome of the analysis of the BoS for the\nstudy of the PD, for instance. A quantum game may be\nregarded as a family of games provided by quantum cor-\nrelations which are absent in classical settings, and our\ngeometric picture used to portray the correlation-family\nin this paper turns out to be quite convenient, espe-\ncially for analyzing the phase structures of the game. We\nshall then see that symmetric games admit eight differ-\nent types of phase structures with regard to the possible\nstable strategies (related to classical strategies) preferred\nby the players, and that these types are determined by\nthe original classical games. With these phase structures,\nwe find that the dilemma in the BoS cannot be resolved\nfully in our scheme, albeit alleviated to some extent [2],\nirrespective of the amount of entanglement provided. In\n2\ncontrast, the dilemma of the PD game can be resolved if\na certain amount of correlationsare introduced. An anal-\nogous conclusion will also be drawn for the SH game, for\nwhich we find rather intricate phase structures for the full\nstable strategies compared to the BoS and PD games.\nThe plan of the paper is as follows. We first introduce\nour scheme of quantum gamein section II and present the\nduality map between the two types of symmetric games.\nThe phase structures of the symmetric games are studied\nin section III. Section IV is devoted to the analysis of the\nBoS, PD and SH games, where we examine the resolution\nof the dilemmas based on the results obtained in section\nIII. Finally, we give our conclusion and discussions in\nsection V.\nII. QUANTUM GAME AND DUALITY FOR\nSYMMETRIC GAMES\nTo begin with, we first recapitulate the classical 2-\nplayer, 2-strategy game and then introduce its quantum\nversion following [7]. Let i = 0,1, j = 0,1 be the la-\nbels of the strategies available for the players, Alice and\nBob, respectively, and let also Aij and Bij be their pay-\noffs when their joint strategy is (i,j). In classical game\ntheory, the game is said to be ?symmetric? if Bji = Aij,\nthat is, if their payoffs coincide when their strategies are\nswapped (i,j) ? (j,i). To make a distinction from the\nother symmetry discussed shortly, we call such a game\nS-symmetric in this paper. The PD and other famil-\niar games such as the SH and the Chicken game (see,\ne.g., [3, 12]) are S-symmetric games. Similarly, we call\nthe game T-symmetric if B1?j,1?i = Aij, that is, if the\npayoff matrices coincide when the strategies of the two\nplayers are ?twisted? as (i,j) ? (1 ? j,1 ? i). The BoS\nis an example of T-symmetric games with the additional\nproperty A01 = A10. The payoffs in these S-symmetric\nand T-symmetric games are displayed in the form of the\nbi-matrix (Aij,Bij) in Table I.\nGiven a payoff matrix, each player tries to maximize\nhis/her payoff by choosing the best possible strategy, and\nif there exists a pair of strategies in which no player can\nbring him/her in a better position by deviating from it\nunilaterally, we call it a Nash equilibrium (NE) of the\ngame. The players will be happy if the NE is unique\nand fulfills certain conditions attached to the game (e.g.,\nPareto-optimality or risk-dominance as mentioned later).\nEven when there are more than one NE, the players will\nstill be satisfied if a particular NE can be selected over\nthe other upon using some reasonings. Otherwise, the\nplayers may face a dilemma, as they do in the case of the\nBoS and the PD.\nTo introduce a quantum version of the classical game,\nwe first regard Alice?s strategies i as vectors in a Hilbert\nspace HA of a qubit. Namely, corresponding to the clas-\nsical strategies i we consider vectors |i?A for i = 0 and 1\nwhich are orthonormal in HA. A general quantum strat-\negyavailablefor Alice is then representedbya normalized\nS-symmetric:\nstrategy Bob 0 Bob 1\nAlice 0 (A00,A00) (A01,A10)\nAlice 1 (A10,A01) (A11,A11)\nT-symmetric:\nstrategy Bob 0 Bob 1\nAlice 0 (A00,A11) (A01,A01)\nAlice 1 (A10,A10) (A11,A00)\nTABLE I: Payoff bi-matrices (Aij,Bij) of the S-symmetric\ngame (above) and the T-symmetric game (below).\nvector |??A (with the overall phase ignored, i.e., a unit\nray) in HA. Bob?s strategy is similarly represented by\na normalized vector |??B in another qubit Hilbert space\nHB spanned by orthonormal vectors |j?B for j = 0 and\n1 in HB. The strategies of the players can thus be ex-\npressed in the linear combinations,\n|??A =\nsummationdisplay\ni\n?i(?)|i?A ,\n|??B =\nsummationdisplay\nj\n?j(?)|j?B ,\n(2.1)\nusing the bases |i?A, |j?B which correspond to the clas-\nsical strategies, with complex coefficients ?i(?), ?j(?)\nwhich are functions of the parameters ? and ? normal-\nized as summationtexti|?i|2 = summationtextj |?j|2 = 1. The strategies of the\nindividual players are, therefore, realized by local actions\nimplemented by the players independently.\nThe joint strategy of the players, on the other hand,\nis given by a vector in the direct product Hilbert space\nH = HA ?HB. Here lies one of the crucial differences\nbetween the classical and quantum games: in quantum\ngame theory, the joint strategy is specified not just by the\nchoice of the strategies of the players but also by furnish-\ning the quantum correlation (essentially the entangle-\nment) between the individual strategies. Consequently,\nthe outcome of a quantum game rests also on a third\nparty (or referee) that determines the correlation. To be\nmore explicit, using the product vector|?,?? = |??A|??B\nwhich is uniquely specified by the individual strategies,\na vector in the total strategy space H is written as\n|?,?;?? = J(?)|?,?? = J(?)|??A|??B , (2.2)\nwhere J(?) is a unitary operator providing the quantum\ncorrelation between the individual strategies. The corre-\nlation factor J(?) with the parameter set ? is designed to\nexhaust all possible joint strategies available in H. The\npayoffs for Alice and Bob are then given by the expecta-\ntion values of some appropriate self-adjoint operators A\nand B, respectively:\n?A(?,?;?) = ??,?;?|A|?,?;??,\n?B(?,?;?) = ??,?;?|B|?,?;??. (2.3)\nTo sum up, a quantum game is defined formally by the\ntriplet {H,A,B}.\n3\nTo choose the payoff operators A and B, we require\nthat, in the absence of quantum correlations J(?) = I\n(I is the identity operator in H), the payoff values re-\nduce to the classical ones when the players choose the\n?semiclassical (pure) strategies? |i,j? = |i?A|j?B,\n?i?,j?|A|i,j? = Aij?i?i?j?j,\n?i?,j?|B|i,j? = Bij?i?i?j?j. (2.4)\nAdopting, for simplicity, the value ? = 0 for the refer-\nence point at which J(?) = I holds, we find that, for\nthe uncorrelated product strategies |?,?;0? = |?,??, the\npayoffs (2.3) become\n?A(?,?;0) = ??,?;0|A|?,?;0? =\nsummationdisplay\ni,j\nxiAijyj,\n?B(?,?;0) = ??,?;0|B|?,?;0? =\nsummationdisplay\ni,j\nxiBijyj,\n(2.5)\nwhere xi = |?i|2, yj = |?j|2 represent the probability\nof realizing the strategies |i?A, |j?B under the general\nchoice |??A, |??B (see (2.1)). This ensures the exis-\ntence of a classical limit at which the quantum game\nreduces to the classical game defined by the payoff ma-\ntrix Aij, where now Alice and Bob are allowed to adopt\nmixed strategies (see, e.g., [13]) with probability distri-\nbutions xi, yj (summationtextxi = summationtextyj = 1) for strategies i, j.\nWe thus see that the quantum game is an extension of\nthe classical game, in which the correlation parameter ?\nplays a role similar to the Planck constant planckover2pi1 in quantum\nphysics in the technical sense that the classical limit is\nobtained by their vanishing limit. Note that, since the set\n{|i,j?, i,j = 0,1} forms a basis set in the entire Hilbert\nspace H, the payoff operators A and B are uniquely de-\ntermined from the classical payoff matrices by (2.4); in\nother words, our quantization is unique.\nThe aforementioned symmetries in classical game can\nalso be incorporated into quantum game by using cor-\nresponding appropriate symmetry operators. Indeed, by\nintroducing the swap operator\nS|i,j? = |j,i?, (2.6)\nwe see immediately that in the classical limit the game\nis S-symmetric, ?B(?,?;0) = ?A(?,?;0), provided that\nthe payoff operators A and B fulfill\nB = SAS. (2.7)\nAnalogously, if we introduce the notation ?i = 1 ? i for\ni = 0,1 (i.e., ?0 = 1 and ?1 = 0) and thereby the twist\noperator,\nT|i,j? = |?j,?i?, (2.8)\nand the twisted states,\nvextendsinglevextendsingle??, ??angbracketrightbig := T |?,?? = summationdisplay\ni,j\n?i(?)?j(?)|?j,?i?, (2.9)\nwe find that in the classial limit the game is T-symmetric,\n?B(??, ??;0) = ?A(?,?;0), provided that the operators\nfulfill\nB = T AT. (2.10)\nThe symmetries can be elevated to the full quantum\nlevel if we adopt the correlation factor in the form [7],\nJ(?) = ei?1S/2ei?2T/2, (2.11)\nwith real parameters ?i ? [0,2pi) for i = 1,2 [17]. In fact,\none can readily confirm, using [S,T] = ST ? TS = 0,\nthat under (2.10) the game is S-symmetric\n?B(?,?;?) = ?A(?,?;?), (2.12)\neven in the presence of the correlation (2.11). Similarly,\nthe game is T-symmetric\n?B(??, ??;?) = ?A(?,?;?), (2.13)\nif (2.10) is fulfilled. Since the correlation parameters in\n? are arbitrary, the properties (2.12), (2.13) imply that\na symmetric quantum game consists of a (?-parameter)\nfamily of games with the (S or T) symmetry exhibited\nfor each ?.\nIt is interesting to observe that these two types of sym-\nmetric games are actually related by unitary transforma-\ntions. To see this, let us introduce the operator CA which\nimplements the conversion for Alice?s strategies,\nCA|i,j? = |?i,j?. (2.14)\nNote that CA satisfies\nCA SCA = T, CA T CA = S. (2.15)\nConsider then the transformation of strategy by unilat-\neral conversion by Alice,\n|?,?;??? CA|?,?;??. (2.16)\nOn account of the relation (2.14) and the form of the\ncorrelation (2.11), we find\nCA|?,?;?? = |??,?;???, (2.17)\nwith ?? given by\n(??1,??2) = (?2,?1). (2.18)\nIn addition, one may also consider the transformation\non the payoff operators,\nA ? ?A = CA ACA, B ? ?B = CA BCA. (2.19)\nOne then observesthat, if the game is S-symmetricfulfill-\ning (2.7), the game defined by the transformed operators\nbecomes T-symmetric,\n?B = T ?AT. (2.20)\n4\nAnalogously, if the game is T-symmetric fulfilling (2.10),\nthen the transformed operators define an S-symmetric\ngame,\n?B = S ?AS. (2.21)\nThis shows that the conversion CA in (2.14) provides\na one-to-one correspondence, or duality, between an S-\nsymmetric game and a T-symmetric game. Some quan-\ntities in quantum game are invariant under the duality\nmap while other are not. For instance, the trace of the\npayoff,\nTrA =\nsummationdisplay\ni,j\nAij = A00 +A01 +A10 +A11, (2.22)\nremains invariant TrA ? Tr ?A = TrA, whereas the al-\nternate trace defined by\n?(A) =\nsummationdisplay\ni,j\n(?)i+jAij = A00 ?A01 ?A10 +A11, (2.23)\nchanges the sign ?(A) ? ?( ?A) = ??(A).\nIn formal terms, the two games given by {H,A,B}and\n{H, ?A, ?B} are dual to each other in the sense that the\npayoff under the strategy |?,?;?? in one game is equiva-\nlent to the payoff under the dual strategy CA|?,?;?? =\n|??,?;??? in the other. In particular, if the former\ngame happens to be S-symmetric, then the latter is T-\nsymmetric, and vice versa. This allows us to regard any\ntwo games as ?identical? if their payoff operators are re-\nlated by the duality map (2.19).\nEvidently, the other conversionofthe strategiesby Bob\nCB|i,j? = |i,1?j? can also be used to provide a similar\nbut different duality. Besides, their combination,\nC = CA ?CB, (2.24)\nimplements the renaming of the strategies 0 ? 1 for both\nof the players, and yields a duality map which does not\nalter the type of symmetries of the game. These dual-\nity maps CA, CB and C are used later to identify games\ndefined from different classical payoff matrices. We men-\ntion that these dualities are actually a special case of the\nmore general ?gauge symmetry? in quantum game the-\nory, which is that the two games defined by {H,A,B}\nand {H,UAU?,UBU?} with some unitary operator U\nare dual to each other under the corresponding strategies\n|?,?;?? and U|?,?;??. Thus the identification of games\ncan be extended to those which are unitarily equivalent.\nIII. CLASSIFICATION OF T-SYMMETRIC\nGAMES\nThe foregoing argument suggeststhat in order to study\nthe two types of symmetric games it is sufficient to con-\nsider either one of the two. Moreover, even if the two\ngames are of the same symmetric type, a further identi-\nfication may be possible using the full conversion C. In\nview of this, in the following we choose the T-symmetric\ngames and analyze the pattern of the allowed equilibria\nthere. To start with, we furnish the definition of an equi-\nlibrium which corresponds to the NE in classical game\n[18]. A joint strategy |??,??? is called quantum Nash\nequilibrium (QNE), if it satisfies\n?A(??,??;?) ? ?A(?,??;?), (3.1)\nfor all ?, and also\n?B(??,??;?) ? ?B(??,?;?), (3.2)\nfor all ?. Note that the QNE is defined for a given ?\ntreated as a set of external parameters. Below, we study\nthe conditions for ? under which a QNE appears.\nTo evaluate the payoffs explicitly, we write the strate-\ngies as\n|??A = cos(?1/2)|0?A + sin(?1/2)ei?2|1?A,\n|??B = cos(?1/2)|0?B + sin(?1/2)ei?2|1?B, (3.3)\nwith angle parameters ?1,?1 ? [0,pi] and ?2,?2 ? [0,2pi).\nFor convenience, we henceforth adopt both of the ket\nnotations |?? and |i? with the convention that |0? and |1?\nrefer always to the latter notations. Using (3.3) we find\nthat, for a T-symmetric game fulfilling (2.10), the payoff\nfor Alice reads\n?A(?,?;?) = 14{TrA+?(A)cos?1 cos?1\n+I?+(?)cos?1 +I??(?)cos?1\n?I+(?)sin?1 sin?1 sin?2 cos?2\n?I?(?)sin?1 sin?1 cos?2 sin?2},\n(3.4)\nwhere we have defined\nI?(?) = G+(?)?G?(?),\nI??(?) = G?+(?)?G??(?), (3.5)\nwith\nG+(?) = (A00 ?A11)sin?2,\nG?+(?) = (A00 ?A11)cos?2,\nG?(?) = (A01 ?A10)sin?1,\nG??(?) = (A01 ?A10)cos?1.\n(3.6)\nThe payoff ?B(?,?;?) for Bob is readily obtained from\n(3.4) using the relation (2.13). The conditions for QNE\n(3.1) and (3.2) imply\n??i?A(?,??;?)|?? = 0,\n??i?B(??,?;?)|?? = 0, (3.7)\nfor i = 1,2. Besides, the Hessian matrices PA and PB\ngiven by\nPA(?,?;?)ij = ??i??j?A(?,?;?),\nPB(?,?;?)ij = ??i??j?B(?,?;?), (3.8)\n5\n|??,??? Hessian conditions ?A(??,??;?)\n|0,0? H+ > 0, H? > 0 [TrA+?(A)+ 2G?+]/4\n|0,1? H? < 0 [TrA??(A)+ 2G??]/4\n|1,0? H+ < 0 [TrA??(A)? 2G??]/4\n|1,1? H+ > 0, H? > 0 [TrA+?(A)? 2G?+]/4\nTABLE II: Hessian conditions and Alice?s payoffs for edge\nstrategies in T-symmetric games. Bob?s payoffs can be ob-\ntained from ?B(??,??;?) = ?A(???, ???;?).\nmust be both negative semi-deifinite,\nPA(??,??;?) ? 0, PB(??,??;?) ? 0. (3.9)\nUsing (3.4) we obtain, for example,\n??2?A(?,??;?)|?? = ???2?B(??,?;?)|??\n= 14 sin??1 sin??1 [I?(?)sin??2 sin??2\n?I+(?)cos??2 cos??2]. (3.10)\nThese conditions (3.7) and (3.9) will now be analyzed in\ndetail.\nA. Edge strategies\nFrom (3.10) we see that an obvious set of solutions for\n(3.7) are obtained if\nsin??1 = sin??1 = 0. (3.11)\nThese have solutions given by the semiclassical pure\nstrategies |i,j? for i,j = 0,1, i.e., the four ?edge? strate-\ngies,\n|0,0?, |1,1?, |0,1?, |1,0?, (3.12)\nwhich correspond to classical pure strategies (i,j). Note,\nhowever, that these quantum edge strategies differ from\nthe classical counterparts because the joint strategy is\ndetermined with the additional correlation factor J(?).\nNote also that on the edge strategies the unitary opera-\ntion J(?) yields only a one-parameter family of correla-\ntions for joint states |i,j;?? in (2.2), since one of the two\nfactors in (2.11) gives merely an overall phase.\nFor the edge states to become QNE, they also need to\nobey the Hessian conditions (3.9), which pose different\nrequirements for the states as\n|0,0? : H+(?) > 0, H?(?) > 0,\n|0,1? : H?(?) < 0,\n|1,0? : H+(?) < 0,\n|1,1? : H+(?) > 0, H?(?) > 0,\n(3.13)\nwhere we have used\nH?(?) = ?(A)?I?+(?), (3.14)\nlabel QNE characteristics\nBoS |0,0? and |1,1? none\nPD |1,0? or |0,1? not Pareto optimal\nSH |1,0? and |0,1? either payoff or risk dominant\nTABLE III: QNE and their characteristics in the domains\non the G?+-G?? plane classified by the labels of the classi-\ncal games. Both PD and SH games are mapped to their T-\nsymmetric dual versions.\nand ignored the cases of equalities for brevity. These con-\nditions and the payoffs for the edge solutions are sum-\nmarized in Table II. To see when these conditions are\nfulfilled for different ?, it is convenient to consider the\nplane coordinated by (G?+,G??) with G?? given in (3.6).\nOne then sees that, as shown in Figure 1, the entire pa-\nrameter region of ? is mapped to a rectangular area in\nthe centre of the G?+-G?? plane with the horizontal length\nLh and the vertical length Lv given by\nLh = 2|A00 ?A11|, Lv = 2|A01 ?A10|. (3.15)\nIt is worth noting that, at each of the midpoints of\nthe four edges, the operation J(?) can yield a maximally\nentangled joint strategy state. For instance, for A01 >\nA10 the midpoint (G?+,G??) = (0,Lv/2) corresponds\nto J(pi/2,0) under which the edge state |01? becomes\n(|01? + i|10?)/?2. Similarly, for A00 > A11 the mid-\npoint (G?+,G??) = (Lh/2,0) corresponds to J(0,pi/2) un-\nder which the edge state |00? becomes (|00?+i|11?)/?2.\nThe four corners of the rectangle, on the other hand, cor-\nrespond to J(mpi,npi) for m,n = 0,1, which are S, T, C,\nand I operations, and hence the resultant joint strategies\nare all unentangled. On the G?+-G?? plane, the Hessian\nconditions determine the domains of allowed edge QNE\nwhich are separated by the parallel lines H?(?) = 0 (see\nFigure 1). Observe that the allowed edge QNE are differ-\nent depending onthe domains, and that the combinations\nof the QNE change when the sign of ?(A) is reversed.\nNote that for ?(A) > 0 all edge strategies in (3.12) could\narise as a QNE for some ?, whereas for ?(A) < 0 only\n|0,1? and/or |1,0? become QNE.\nAs will be seen shortly, as long as the edge strategies\nareconcerned our quantum gameis simulated by classical\ngames possessing the corresponding NE. In view of this,\nwe may characterize the domains on the G?+-G?? plane\nby the typical classical games sharing the same NE. We\ndo this by using the BoS, PD and SH as the representa-\ntives (see Table III). Here, the label ?BoS? is chosen to\ndesignate the domain of games possessing two edge QNE\nat |0,0? and |1,1?, which is an obvious choice because\nthe classical BoS game is T-symmetric and has the cor-\nresponding NE at (i,j) = (0,0) and (1,1). None of these\nNE admits better payoffs to both of the players, simulta-\nneously, leading to the dilemma that they cannot decide\non which strategy the should choose. The domain ?BoS?\narises only for ?(A) > 0 and the required conditions are\nBoS : H+ < 0, H? < 0. (3.16)\n6\nG?+\nG??\n? > 0\nH? = 0H+ = 0\n|0,1?\n|1,0?\nBoS\nPD\nPD\nG?+\nG??\n? < 0\nH+ = 0H? = 0\n|0,1?\n|1,0?\nSH\nSH\nPD\nPD\nFIG. 1: Phase structures of QNE in terms of edge strategies: ?(A) > 0 (above), ?(A) < 0 (below). The names of the domains\nare borrowed from the classical games sharing the same characteristic dilemmas (see Table III). Games in the domains without\nnames are free from dilemmas within edge strategies and possess a single stable strategy |1,0? or |0,1? among at most two QNE.\nThe correlation family of a quantum game forms a rectangle on the plane, as shown by the dotted line for the case ?(A) > 0.\nThe domain fulfilling these forms a diagonal strip be-\ntween the parallel lines H? = 0 on the G?+-G?? plane\n(see Figure 1).\nTo justify the assignment of the other labels, recall\nthat the classical PD game is an S-symmetric game and\nhas a NE at (1,1) which is unique. The problem of the\ngame is that the NE is not Pareto optimal, i.e., there\nexists another strategy which improves the payoffs for\nthe two players, simultaneously, and this constitutes the\ndilemma. Upon quantization, the quantum PD, in the\nclassical limit, will have one edge QNE at |1,1?, which\nturns into |0,1? by the duality map (2.14) when it is\nemployed to convert the PD into the T-symmetric dual\nversion. For this reason, we use ?PD? to label the do-\nmain of those T-symmetric games possessing the edge\nQNE at |0,1? which is not Pareto optimal. The Pareto\noptimality can be examined by comparing the payoff val-\nues with other strategies, and in the present case this\nis done essentially by comparing the payoffs between the\ntwo strategies|1,0? and |0,1?. From Table II, we see that\nthis situation occurs when\nPD : H+ > 0, H? < 0, G?? < 0. (3.17)\nWe also use the same label ?PD? for the domain of games\npossessing a QNE at |1,0? which is not Pareto optimal,\nsince thoseareidentified bythe full conversionC in (2.24)\nwith the standard quantum PD. This is the case when\nwe have\nPD : H+ < 0, H? > 0, G?? > 0. (3.18)\nAs shown in Figure 1, the domains of PD appear both\nfor ?(A) > 0 and ?(A) < 0.\nThe classical SH game, on the other hand, is an S-\nsymmetric game which has two NE at (0,0) and (1,1),\nin which (0,0) is payoff dominant (i.e., better than (1,1)\nin the payoff) and (1,1)is risk dominant (i.e., better than\n(0,0) in the ?average? over the choice of the other player).\nThe dilemma is that, while (0,0) is Pareto optimal, (1,1)\nis preferable for the minimal risk, which makes the play-\ners uncertain to decide which to choose. Now, after the\nquantization and the application of the duality map to\nget the T-symmetric quantum version of the game, we\nwill have two edge QNE at |1,0? and |0,1? in the classi-\ncal limit, with payoff dominant |1,0? and risk dominant\n|0,1?. We therefore use the label ?SH? to name the do-\nmain in which the games possess the same QNE with the\nabove property. In the presence of correlations, we find\nfrom Table II that the payoff dominance of |1,0? requires\nG?? < 0. The risk dominance of |0,1? demands that the\naverage payoff Alice receives under the choice |0?A be\nlarger than that obtained under the choice |1?A, which\nis ensured if G?+ + G?? > 0. As in the case of the PD,\nthe label ?SH? is also used for the domain of games pos-\nsessing the two QNE with payoff dominant |0,1? and risk\ndominant |1,0? for Alice, which are possible if G?? > 0\nand G?+ + G?? < 0. These domains ?SH? are allowed\nonly for ?(A) < 0 where |1,0? and |0,1? arise as QNE\nbetween the two parallel lines H? = 0 on the G?+-G??\nplane. Combined with the above additional conditions,\nthe SH domains are characterized by\nSH : H+ > 0, H? > 0, G??(G?+ +G??) < 0. (3.19)\nAs shown in Figure 1, the classification of the games\nleavesunlabeled domains on the G?+-G?? plane for each of\nthe cases ?(A) > 0 and ?(A) < 0. For ?(A) > 0, we find\ntwo separate domains which contain games possessing a\nunique QNE, either at |0,1? or |1,0?. These QNE are\nPareto optimal, and hence the games are free from the\ndilemma of the PD type. For ?(A) < 0, we have two ad-\nditional domains of games possessing QNE at |0,1? and\n|1,0?, which are free from the dilemma of the SH. This\nresult suggests that, if the game under consideration can\nbe driven to lie in these unlabeled domains by adjusting\nthe correlations appropriately, then the original dilemma\nmay be resolved under these correlations, at least within\nthe realm of edge strategies. In this respect, the phase\ndiagram given by Figure 1 provides a convenient basis to\nexamine the problem of optimality of strategies in quan-\ntum games.\nSince the correlation-family of a symmetric quantum\ngame is mapped to a rectangle on the G?+-G?? plane, we\ncan classify quantum games in terms of the patterns of\nthe rectangle formed on the plane. As shown in Figure\n7\nFIG. 2: Four patterns of rectangles which are possible in re-\nlation to the parallel lines H? = 0 provide distinct phase\nstructures for symmetric quantum games. The rectangle may\nreduce to a line as we see in the case of the BoS later.\n2, there are four types of rectangles, determined from\nthe values of Lh and Lv in (3.15), which are different\nin position with respect to the parallel lines H?(?) = 0\nappearing in Figure 1. Combining the two cases ?(A) > 0\nand?(A) < 0 whichoffer different structuresfor domains,\nwe find that there are altogether eight classes of quantum\ngames which have distinct phase structures of QNE in\nterms of edge strategies.\nOne of the advantages of the present quantization\nscheme is that it allows us to establish the connection\nbetween the classical and quantum games in a simple\nmanner and thereby examine how ?quantum? the game\nactually is. To see this, let us introduce the correlated\npayoff matrices\nA(?) = J?(?)AJ(?), B(?) = J?(?)BJ(?). (3.20)\nWith these, the payoffs (2.3) are expressed in terms of\nseparable (uncorrelated) states\n?A(?,?;?) = ??,?|A(?)|?,??,\n?B(?,?;?) = ??,?|B(?)|?,??. (3.21)\nOne may decompose each of the correlated payoffs into\n?pseudo-classical? and ?interference? terms as\nA(?) = Apc(?)+Ain(?), (3.22)\nwith\nApc(?) = cos2 ?12 A+ (cos2 ?22 ?cos2 ?12 )SAS\n+ sin2 ?22 C AC,\n(3.23)\nwhere C is given in (2.24) and\nAin(?) = i2 sin?1 [A,S] + i2 sin?2[A,T]. (3.24)\nThe pointis thatthe pseudo-classicalpartApc isdiagonal\nand hence for separable strategies it can be interpreted\nas a classical payoff matrix. In contrast, the interference\npart Apc is non-diagonal and represents a non-classical\ncontribution. Accordingly, the payoff for Alice in a T-\nsymmetric game is decomposed into the sum ?A = ?pcA +\n?inA, where we have\n?inA(?,?;?) = 0, (3.25)\nfor edge strategies. This observation confirms that our\nquantum game with edge strategies are, in effect, equiv-\nalent to the classical game with the payoff matrices Apc\nand Bpc (the latter can be defined analogously for the\ncorrelated payoff B(?)). Possible game theoretical inter-\npretations of the pseudo-classical payoff based on altru-\nism and value-conversion have been noted in Ref.[7].\nB. Non-edge strategies\nTo discuss QNE beyond the edge strategies (3.12), we\nrecall (2.13) and seek solutions which are T-symmetric,\n|??,??? = |???, ????. In the representation (3.3) of the\nstate (which is defined up to an overall phase), this trans-\nlates into\n??1 ???1 = pi, ??2 +??2 = pi. (3.26)\nUnder the T-symmetric ansatz and the non-edge require-\nment sin??1 negationslash= 0, the conditions in (3.7) imply\ncos??1 [?(A)?G?(?)sin2??2]?I?+(?) = 0,\nG?(?)cos2??2 +G+(?) = 0. (3.27)\nBesides, the Hessian condition (3.9) implies\nG? sin2??2 ? 0. (3.28)\nBefore analyzing the solutions in detail, we observe\nthat at the classical limit ? = 0 the above conditions are\nsimplified to the single condition,\ncos??1 = ?+(A)?(A) , (3.29)\nwith ?+(A) defined as\n??(A) = (A00 ?A11)?(A01 ?A10). (3.30)\nThe condition (3.29) has a solution when |?(A)| ?\n|?+(A)|, which is equivalent to\nA00 ? A10 and A11 ? A01, or\nA00 ? A10 and A11 ? A01. (3.31)\nThe solution for (3.29) corresponds to the NE for mixed\nstrategies in classical games with x?1 = y?1 = cos2(??1/2),\nand (3.31) agrees precisely with the conditions for such\nnontrivial NE to arise. It is important to note, how-\never, that the non-edge QNE in quantum game and the\nmixed NE in classical game are completely different in\nthe meaning of strategies. Namely, the NE in classical\ngame is relevant only for the situation where the games\n8\nFIG. 3: Possible patterns of allowed regions by (3.33) in the\nrectangle of the game under Lh < Lv (left), Lh = Lv (middle)\nand Lh > Lv (right). These regions are shaded, and the dot\nin the centre represents the origin of the G?+-G?? plane.\nare repeated many times in which the players can con-\nsider probability distributions in choosing their strategies\n? the mixed NE and pure NE belong to different cate-\ngories conceptually. In contrast, the non-edge QNE in\nquantum game is a pure strategy and meaningful with-\nout repeating the game ? it belongs to the same category\nas the edge QNE.\nTo discuss solutions for generic ?, we notice first that\nthe second condition in (3.27) determines ??2, which can\nbe used to determine ??1 in the first condition. In terms\nof ?(?) :=\nradicalBig\nG2? ?G2+ for which we have\n?2 = (G?+)2 ?(G??)2 ??+ ??, (3.32)\nthe condition for the existence of ??2 reads\n? ? 0. (3.33)\nNotice that ?+ ?? = (L2h ?L2v)/4 measures the squared\ndifference in length between the two edges of the rectan-\ngle of the game. It follows that the regions allowed by\n(3.33) are those enclosed by the two hyperbolae ?2 = 0\nand the edges of the rectangle, which vary depending on\nthe types of the rectangle (see Figure 3).\nOn the other hand, by combining the two conditions\nin (3.27) and (3.28) we see that the solution for ??1 exists\nif\n(H+ + ?)(H? + ?) ? 0. (3.34)\nUsing (3.32), one can readily depict the regions where\n(3.34) is fulfilled on the G?+-G?? plane. The games be-\nlonging to the overlapped areas of the above two regions\nadmit non-edge QNE, and this is indeed possible if the\npayoff A meets certain conditions, as illustrated by the\nSH game later. When this happens, the non-edge QNE,\nwhich we denote by |??,??;?? = |?ne,?ne;??, offers the\nsame payoff (as ensured by the T-symmetry) for Alice\nand Bob,\n?A(?ne,?ne;?) = ?B(?ne,?ne;?)\n= 14\nbracketleftbigg\nTrA+ ?(A)?(?)??+(A)??(A)?(A) + ?(?)\nbracketrightbigg\n. (3.35)\nIn particular, at the classical limit the payoff becomes\n?A(?ne,?ne;0) = A00A11 ?A01A10A\n00 +A11 ?A01 ?A10\n, (3.36)\nwhich is the familiar payoff expression for the mixed NE\nin classicalT-symmetricgames. This showsthat the non-\nedge QNE are actually an extension of the classicalmixed\nNE. In fact, at the classical limit, we find from ?(0) = 0\nthat the condition (3.33) is trivially fulfilled, and that\n(3.34) reduces to\nH+(0)H?(0) = 4(A00 ?A10)(A11 ?A01) ? 0, (3.37)\nwhich is exactly the condition for mixed NE (3.31). In\nother words, if the classical game admits a mixed NE,\nthen the quantum game defined from the classical game\nadmits a QNE for a certain range of correlations includ-\ning the classical limit.\nTo summarize, non-edge QNE may exist as an exten-\nsion of mixed NE under various correlations in quantum\ngame theory, and their existence can be examined from\nthe rectangle of the game specified from the classical pay-\noff matrix Aij. Game theoretical analysis, including the\nresolution of dilemma in classical game, should be made\nbased on the combination of edge and non-edge QNE.\nIV. DILEMMAS IN BOS, PD AND SH\nHaving obtained the phase structures of symmetric\nquantum games for edge QNE as well as the conditions\nfor non-edgeQNE,we nowexamineif andhowthe typical\ndilemmas familiar in classical game theory ? the dilem-\nmas in the BoS, the PD and the SH game ? can be re-\nsolved in quantum game theory. All of the dilemmas\nin these cases are intrinsically different, and there is no\nunique criterion for the resolution. We thus consider the\nresolution based on the conventional requirements which\nare attached to the respective classical games, and find\nthat the quantization of the games lead to considerably\ndifferent outcomes for the three cases.\nA. Battle of the Sexes\nThe BoS game is a special case of the T-symmetric\ngame specified by the payoff matrix,\nA00 > A11 > A01 = A10. (4.1)\nThe degeneracy A01 = A10 provides the T-symmetric\ngame with an extra symmetry between the payoff matri-\nces, that is,\nB = T AT = C AC. (4.2)\nOnaccountofthe degeneracy,we haveG?(?) = G??(?) =\n0, which implies that the parameter ?1 drops out from\nour consideration of QNE. Notice that the BoS defined\nby (4.1) has ?(A) > 0 and that, as shown in Figure 4, the\nrectangle of the game in the G?+-G?? plane is smashed to\na line on the G?+-axis with length Lh. Notice also from\nA00 > A11 that the classical limit is found at the right\n9\nend of the line. Now, an important point to observe is\nthat since\n?(A)?(A00 ?A11) = 2(A11 ?A01) > 0, (4.3)\nthe line segment of the game lies entirely within the BoS\ndomain (see Figure 4). This shows that, so far as the edge\nstrategies are concerned, even in the presence of the cor-\nrelation J(?), the dilemma in the BoS does not disappear\nin quantum game. Using (3.21) and (3.23), Alice finds\nher payoff ?A(i,i;?) at the edge QNE |??,??? = |i,i? for\ni = 0,1 as\n?A(i,i;?) = cos2 ?22 Aii + sin2 ?22 A?i?i. (4.4)\nNote that the correlationinterpolates between the largest\ntwo payoff values A00 and A11, and hence ?A(i,i;?) ?\nA11 for both of the edge QNE, i = 0,1.\nTo see if the dilemma can be resolved by taking non-\nedge QNE into account, we first observe that for BoS the\nconditions (3.27) are fulfilled for ?2 = 0, pi with arbitrary\n?1. For that non-edge QNE, the payoff ?A(?ne,?ne;?) in\n(3.35) reduces to (3.36) with A01 = A10. At ?1 = 0 this\nnon-edge QNE corresponds to the known mixed strategy\nNE in classical BoS, which cannot resolve the dilemma\nsince the payoffs are strictly less than those obtained un-\nder the two edge QNE for both of the players. The situa-\ntion doesnot improveevenfor?1 negationslash= 0, because the payoffs\nare independent of ?1 for all strategies. Moreover, on the\ngeneral basis of the assignments (4.1) (i.e., without mak-\ning use of the ansatz (3.26)), one can confirm by looking\nat the Hessian condition (3.9) that there is no non-edge\nQNE for BoS except for the one mentioned above. Thus\nwe find that under any correlations ? for the non-edge\nQNE we have ?A(?ne,?ne;?) < A11 and hence\n?A(i,i;?) > ?A(?ne,?ne;?), for i = 0,1. (4.5)\nAlthough the dilemma does not disappear even in\nquantum BoS, one may argue that the problem is some-\nwhat mitigated at?2 = pi/2 wherethe joint strategystate\nis maximally entangled. Indeed, under this correlation\nthe payoffs for the two edge QNE (4.18) for i = 0,1 coin-\ncide and hence the choice of strategies becomes irrelevant\nfor the players. The dilemma still remains in essence [16],\nhowever, because the players, who cannot communicate,\nmay inadvertently end up with a wrong strategy, |0,1? or\n|1,0?, yielding the worst payoff ?A = ?B = A01 (for all\n?). A similar conclusion has been drawn for BoS in [2, 8]\nusing a different quantization scheme with mixed quan-\ntum states, while a way out is suggested in an extended\nscheme [9]. The analysis [3] made in the scheme of [1]\nyields a considerably different outcome, with infinitely\nmany QNE with the payoffs lower than those of our edge\nQNE, indicating that the dilemma is unresolved unless\nsome subtle reasoning (focal point effect) is invoked.\nG?+\nG??\nCL\nME\nFIG. 4: Phase structure of edge QNE in the BoS game. The\nrectangle of the game is smashed to a line segment lying at the\ncentre as shown by the dotted line, which is entirely contained\nin the BoS domain. The right end point CL is the classical\nlimit and the middle point ME represents the point where the\nmaximally entangled correlation is realized.\nB. Prisoners? Dilemma\nThe PD game can also be analyzed in our scheme by\nconverting it to a dual T-symmetric game using the map\n(2.19). The general S-symmetric PD in classical game\ntheory may be defined by the payoff matrix for Alice Aij\nsatisfying\nA10 > A00 > A11 > A01, (4.6)\ntogether with Bob?s payoff given by Bij = Aji. Supple-\nmental conditions (which is inessential for the following\nargument),\n2A00 > A01 +A10 > 2A11, (4.7)\nmay also be imposed in order to render the strategies\n(i,j) = (0,0) and (1,1) the best and the worst of all\npossible strategies with respect to the sum of the payoffs\n[13]. The quantum PD is obtained by considering the\nself-adjointoperatorsA, B fulfilling (2.4), and the duality\nmap (2.19) yieldsthe T-symmetricversionof the PD with\nthe payoff operator ?A possessing the diagonal (classical)\nvalues\n( ?A00, ?A01, ?A10, ?A11) = (A10,A11,A00,A01). (4.8)\nIn terms of the converted payoff values, the conditions\n(4.6) and (4.7) turn out to be\n?A00 > ?A10 > ?A01 > ?A11, (4.9)\nand\n2 ?A10 > ?A00 + ?A11 > 2 ?A01. (4.10)\nNote that under the duality map for strategies (2.16) the\nparameters of the states (3.3) acquire the change\n(??1, ??2) = (?1 +pi, pi ??2). (4.11)\nIn addition, the duality relation in the correlation (2.18)\namounts to ?1 ? ?2 in G? and G??. To accommodate\nthese changes caused by the duality map, we use nota-\ntions such as\n?G? = G?|A? ?A,????, ?H? = H?|A? ?A,????, (4.12)\n10\nG?+\nG??\nCL\nG?+\nG??\nCL\nFIG. 5: Phase structure of edge QNE in the (T-symmetrized)\nPD game for the cases ?( ?A) > 0 (left) and ?( ?A) < 0 (right).\nFor both of the cases, the rectangle of the game, whose edges\nare shown by dotted lines, extends to domains of no dilemmas.\nfor our discussion of T-symmetric games.\nTo examine the possible phase structures of the game,\nwe observe that neither of the conditions (4.9) and (4.10)\ndetermines the sign of ?( ?A). However, since (4.9) implies\nthat the classical limit ? = 0 locates at the lower right\ncorner of the rectangle of the game, the inequalities\n?H+(0) = 2( ?A00 ? ?A10) > 0,\n?H?(0) = 2( ?A11 ? ?A10) < 0, (4.13)\nobtained at the classical limit ? = 0 from (4.9) are suf-\nficient to specify where the corner lies on the G?+-G??\nplane. The phase structures of the quantum PD game\nare then determined from the patterns of the rectangle\nin both of the cases ?( ?A) > 0 and ?( ?A) < 0, as illustrated\nin Figure 5. The outcome indicates that the correlation-\nfamily given by the rectangle does extend to domains of\nno dilemmas. It follows that, as long as edge QNE are\nconcerned, the quantum PD can be made dilemma-free\nwhen the correlations are furnished appropriately.\nFor a full resolution of the dilemma, we need to see\nwhether a non-edge QNE, if any, alters our conclusion\ndrawn from the edge QNE. This can be examined from\nthe analysis given in the previous section. We then learn\nthat, since the condition (3.31) is violated for (4.9), there\nis no non-edge QNE at the classical limit. We also re-\nalize that, for generic ?, the existence of non-edge QNE\nis dependent on the actual classical values of Aij, and\nthat for a wide range of payoff values centered at the\nstandard ones (A10,A00,A11,A01) = (5,3,1,0) used in\nthe literature (e.g., [1]), there exists no region fulfilling\n(3.33) and (3.34) simultaneously, and hence no non-edge\nQNE. Thus, our conclusion concerning the resolution of\nthe dilemma does not change in these standard settings\nof the PD game.\nC. Stag Hunt\nThe classical SH game is an S-symmetric game in\nwhich the payoff matrix for Alice fulfills the conditions,\nA00 > A10 ? A11 > A01, (4.14)\nwhich ensure that the strategies (0,0) and (1,1) are clas-\nsical NE. Among them, (0,0) is payoff dominant while\nG?+\nG??\nCL\nH+ + ? = 0\nH? + ? = 0\nFIG. 6: Phase structures of edge QNE (left) and non-edge\nQNE (right) in the (T-symmetrized) SH game. For edge\nQNE, the rectangle of the game extends to domains of no\ndilemmas. For non-edge QNE, the allowed regions by (3.33)\nare of the third type in Figure 3, and the two narrow regions\noverlapped with (3.34) shown in thick gray indicate the do-\nmains where a non-edge QNE appears.\nthe other (1,1) becomes risk dominant if\nA10 +A11 > A00 +A01. (4.15)\nAnalogously to the PD, we quantize the SH according to\n(2.4) and then T-symmetrizeit by the duality map (2.19).\nThis yields the payoffoperator ?A with the diagonalvalues\n(4.8) obeying\n?A10 > ?A00 ? ?A01 > ?A11, (4.16)\nand\n?A00 + ?A01 > ?A10 + ?A11. (4.17)\nNote that (4.16) implies ?( ?A) < 0. It also shows that\nthe classical limit is at the lower right corner of the rect-\nangle of the game, and that we have ?H?(0) < 0. From\nthis we can determine the position of the rectangle on the\nG?+-G?? plane as shown in Figure 6. The phase structure\nof the quantum SH game then suggests that, as in PD,\nthe correlation-family given by the rectangle extends to\ndomains without dilemmas. Within the edge strategies,\nthe dilemma of the SH can therefore be resolved in quan-\ntum game, if one adjusts the correlations appropriately.\nThe payoffs ?A(i,?i;?) at the edge QNE |??,??? = |i,?i?\nfor i = 0,1 read\n?A(i,?i;?) = cos2 ?12 ?Ai?i + sin2 ?12 ?A?ii, (4.18)\nwhich fall within the range of the payoffs of the two clas-\nsical NE, ?A10 ? ?A(i,?i;?) ? ?A01.\nThe classical SH game admits a mixed NE, and ac-\ncordingly the quantum SH admits a non-edge QNE for\na range of correlations including the classical limit, as\ncan be confirmed explicitly by examining the condition\n(3.37). To see where such correlations occur on the G?+-\nG?? plane, we consider the lines of equality H? + ? = 0\ndetermined by the condition (3.34), which are rewritten\nas\nG?+ = ?G?? ? ?\n2 +?+??\n2(G?? ??). (4.19)\n11\nCL:\nstrategy Bob |0? Bob |1? Bob |?ne?\nAlice |0? (3,0) (3,3) (3,3/4)\nAlice |1? (4,4) (0,3) (3,15/4)\nAlice |?ne? (15/4,3) (3/4,3) (3,3)\nME:\nstrategy Bob |0? Bob |1? Bob |?ne?\nAlice |0? (3,0) (7/2,7/2) (3,0)\nAlice |1? (7/2,7/2) (0,3) (7/2,7/2)\nAlice |?ne? (7/2,7/2) (0,3) (7/2,7/2)\nTABLE IV: Quantum payoff bi-matrices (?A,?B) of the SH\ngame for edge QNE and non-edge QNE. We used the values\n?A10 = 4, ?A00 = ?A01 = 3 and ?A11 = 0 (obtained from those\nmentioned in the text) to evaluate the payoffs at the classi-\ncal limit CL and the maximally entangled point ME, which\nare given by (G?+,G??) = (3,?1) and (3,0), respectively. The\npresence of the non-edge QNE worsens the risk balance be-\ntween the two edge QNE as we increase the amount of en-\ntanglement, but the dilemma disappears at ME where their\npayoffs become identical, for which the non-edge QNE does\nnot contribute.\nFor the SH we find ?2+?+?? > 0 from (4.16) and (4.17).\nThe domains where the non-edge QNE arise are then\nfound to be surrounded by the hyperbolae ? = 0 and\nthe curves (4.19), both of which come in contact at\n(G?+,G??) = ? 12? parenleftbig?2 +?+??,?2 ??+??parenrightbig. (4.20)\nAs illustrated in Figure 6, these domains are given by\ntwo narrow regions along the left and right edges of the\nrectangle of the game, indicating that under generic cor-\nrelations the non-edge QNE does not spoil the resolution\nof the dilemma in terms of edge QNE. It is, however,\nconceivable that the non-edge QNE, in the region where\nit is allowed, could alter the nature of the dilemmas, that\nis, the non-edge QNE could be both payoff and risk dom-\ninant under some particular correlations in the domains\nof SH, or it could pose a new dilemma in the domains\nwhere there was no dilemma originally. These possibili-\nties should be examined for the actual values of the payoff\nmatrix (4.16), but the analysis with the standard values\n(A00,A10,A11,A01) = (4,3,3,0) given in Table IV sug-\ngests that these are not likely to occur unless the payoff\nvalues are fine-tuned.\nV. CONCLUSION AND DISCUSSIONS\nIn this paper, we studied the phase structures of sym-\nmetric quantum games with respect to the stable strate-\ngies (QNE) available by pure states in quantum mechan-\nics. For quantization of classical games we adopted the\nscheme [7] which defines a unique correlation-family of\nquantum games from a classical game, allowing for all\npossible strategies realized by pure states, entangled or\nnot. The correlation-family is projected onto a rectangu-\nlar area in the G?+-G?? plane, where the phase structures\nof both the edge and non-edge QNE in the game can\nreadily be recognized. We have found that for symmet-\nric games there arise altogether eight different classes of\nphase structures for edge QNE depending on the payoff\nmatrices of the classical game we started with. This re-\nsult gives a more detailed account of the phase structures\nmentioned in [1] and discussed later in [5, 11].\nThe symmetric games considered in this paper consist\nof two types, T-symmetric and S-symmetric. We have\npresented a unified framework to treat them by means\nof a duality map, which enables us to use the results\nof the analysis of T-symmetric games for studying S-\nsymmetric games and vice versa. As an example of the\nT-symmetric game, we studied the BoS which is known\nto be a?icted with a dilemma classically. We have found\nthat the dilemma in the BoS cannot be resolved fully\n(albeit it can be alleviated) with strategies given by pure\nstates, even if we go over to quantum game where arbi-\ntrarily entangled states are utilized. Thus, the previous\nobservation made in [2, 8] remains essentially unchanged\neven in our enlarged scheme of quantum game, while the\noutcome is considerably different from those obtained in\nother schemes [3, 9]. As for the S-symmetric game, we\nexamined the PD and the SH to observe that for both of\nthe games the correlation-family contains a phase which\nis free from dilemmas under edge QNE. Since the stan-\ndard PD does not admit non-edge QNE, we concluded\nthat for the PD the classical dilemma disappears after\nquantization. For the SH, on the other hand, there ex-\nists a non-edge QNE which does not affect the resolution\nrealized by the edge QNE, generically. In short, quantum\nentanglement can resolve classical dilemmas for certain\ngames, and the games for which this is possible can be\njudged from the classical payoff matrices. We remark\nthat entanglement is necessary for the resolution of the\ndilemmas in our scheme, and that this is so in any other\nschemes of quantum games in which the resolution is pos-\nsible and the classical games are recovered in the limit\nwhere the joint strategies become separable as in (2.5).\nHowever, the actual amount of entanglement required de-\npends on the scheme used (because the class of families\nconsidered may be scheme-dependent) as well as on the\nvalues of the classical payoffs.\nCompared to most other schemes proposed so far, our\nscheme of quantum game is distinguished in the specifica-\ntion of strategies and correlations which are expressed in\nthe ordering of operations implementing them. Namely,\nin our scheme the players first make their choice of strate-\ngies independently, by performing the corresponding lo-\ncal unitary transformations on a fixed separable state,\nbefore a third party furnishes a correlation for the local\nstates. The player?s strategy is represented by a quantum\nstate, not by the local unitary transformation as consid-\nered in [1]. The advantage for this is that different pure\nstates used to specify the strategies yield different out-\ncomes of the payoff in general, while this is not ensured\nif unitary transformations are regarded as strategies. In\n12\nfact, it has been pointed out [6] that unitary transfor-\nmations become redundant (i.e., different unitary oper-\nations give the same quantum states) when the strate-\ngies are maximally entangled. Obviously, the choice of\nquantization scheme is directly related to the question of\nthe role of the third party which provides the quantum\ncorrelation in the game, and this has not been fully ex-\nplored yet. In this regard, we have found here a number\nof interesting features of quantum games which are com-\nmonly observed in various different schemes, in the phase\nstructures of the QNE and the resolution of dilemmas in\nsome of the familiar games. We hope that these findings\nwill help uncover the core elements ? independent of the\nscheme employed ? in quantum games, which are crucial\nfor laying a solid foundation of quantum game theory.\nAcknowledgments\nWe thank T. Cheon for helpful discussions. This work\nis supported by the Grant-in-Aid for Scientific Research,\nNo.13135206and No.16540354,ofthe JapaneseMinistry\nof Education, Science, Sports and Culture.\n[1] J. Eisert, M. Wilkens and M. Lewenstein, Quantum\ngames and quantum strategies, Phys. Rev. Lett. 83\n(1999) 3077-3080.\n[2] L. Marinatto and T. Weber, A quantum approach to\nstatic games of complete information, Phys. Lett. A272\n(2000) 291-303.\n[3] J. Shimamura, S. K. ?Ozdemir, F. Morikoshi and N.\nImoto, Quantum and classical correlations between play-\ners in game theory, Int.Journ. Quant.Inf.2(2004) 79-89.\n[4] J. Eisert and M. Wilkens, Quantum Games, J. Mod. Opt.\n47 (2000) 2543-2556.\n[5] J. Du, X. Xu, H. Li, X. Zhou and R. Han, Playing Pris-\noner?s Dilemma with Quantum Rules, Fluct. and Noise\nLett. 2 (2002) 189-203.\n[6] S. C. Benjamin and P. M. Hayden, Comment on ?Quan-\ntum Games and Quantum Strategies?, Phys. Rev. Lett.\n87 (2001) 069801.\n[7] T. Cheon and I. Tsutsui, Classical and Quantum Con-\ntents of Solvable Game Theory on Hilbert Space, Phys.\nLett. A348 (2006) 147-152\n[8] L. Marinatto and T. Weber, Reply to ?Comment on: A\nQuantum Approach to Static Games of Complete Infor-\nmation?, Phys. Lett. A277 (2000) 183-184.\n[9] A. Nawaz and A. H. Toor, Dilemma and Quantum Battle\nof Sexes, J. Phys. A: Math. Gen. 37 (2004) 4437-4443.\n[10] A. Nawaz and A. H. Toor, Generalized Quantization\nScheme for Two-Person Non-Zero-Sum Games, J. Phys.\nA: Math. Gen. 37 (2004) 11457-11463.\n[11] J. Du, X. Xu, H. Li, X. Zhou and R. Han, Experimental\nrealization of quantum games on a quantum computer,\nPhys. Rev. Lett. 88 (2002) 137902.\n[12] A. P. Flitney and D. Abbott, Advantage of a quantum\nplayer over a classical one in 2x2 quantum games, Poc\n.R. Soc. (London) A459 (2003) 2463-2474.\n[13] E. Rasmusen, An Introduction to Game Theory, Cam-\nbridge Univ. Press, Cambridge, 1989.\n[14] J. F. Nash, Equilibrium points in N-person games, Proc.\nNat. Acad. Sci. U.S.A. 36 (1950) 48-49.\n[15] C. F. Lee and N. Johnson, Quantum Game Theory, Phys.\nRev. A67 (2003) 022311.\n[16] S. C. Benjamin, Comment on ?A quantum approach to\nstatic games of complete information?, Phys. Lett. A277\n(2000) 180-182.\n[17] Apart from the irrelevant freedoms concerning the over-\nall phase and the normalization, the dimensionality of the\njoint strategy space is dimH ? 2 = 6 in real variables.\nSince the individual strategies |??A and |??B are specified\nby 2 + 2 = 4 parameters (e.g., see (3.3)), the correlation\nfactor must have another 2 parameters to cover the full\njoint strategy space. The actual construction of the cor-\nrelation factor is far from unique, and our form (2.11) is\nadopted based on the convenience for the duality map.\n[18] In the present paper, we consider quantum joint strate-\ngies given by pure states only. The space of pure states is\nnot convex, and hence the Nash theorem [14], which en-\nsures the existence of NE for a classical game with mixed\nstrategies, is no longer available. The existence of QNE\nin quantum game is, therefore, non-trivial [15].\n"}
{"id":"oai:arXiv.org:quant-ph/0610192","text":"arXiv:hep-ph/0610379v2  12 Jul 2007\nDirect detection of neutralino dark matter in non-standard\ncosmologies\nGraciela B. Gelmini,1, ? Paolo Gondolo,2, ? Adrian Soldatenko,1, ? and Carlos E. Yaguna1, ?\n1Department of Physics and Astronomy, UCLA,\n475 Portola Plaza, Los Angeles, CA 90095, USA\n2Department of Physics, University of Utah,\n115 S 1400 E # 201, Salt Lake City, UT 84112, USA\nAbstract\nWe compute the neutralino direct detection rate in non-standard cosmological scenarios where\nneutralinos account for the dark matter of the Universe. Significant differences are found when\nsuch rates are compared with those predicted by the standard cosmological model. For bino-\nlike neutralinos, the main feature is the presence of additional light (m? lessorsimilar 40 GeV) and heavy\n(m? greaterorsimilar 600 GeV) neutralinos with detection rates within the sensitivity of future dark matter\nexperiments. For higgsino- and wino-like neutralinos lighter than m? ? 1 TeV, enhancements of\nmore than two orders of magnitude in the largest detection rates are observed. Thus, if dark matter\nis made up of neutralinos, the prospects for their direct detection are in general more promising\nthan in the standard cosmology.\n?Electronic address: gelmini@physics.ucla.edu\n?Electronic address: paolo@physics.utah.edu\n?Electronic address: asold@physics.ucla.edu\n?Electronic address: yaguna@physics.ucla.edu\n1\nI. INTRODUCTION\nThe Large Hadron Collider is now in its final preparation stages and may soon be search-\ning for supersymmetric particles. Among them, the lightest neutralino in the minimal su-\npersymmetric standard model plays a distinctive role as a dark matter candidate [1]. It is\nneutral, weakly interacting, and stable (provided it is the lightest supersymmetric particle).\nIf evidence for low energy supersymmetry is found, it will strongly support the idea that\nneutralinos constitute the dark matter of the Universe. A logical next step would then be\nthe use of neutralinos as cosmological probes of the early Universe. Neutralinos could, in\nparticular, test the standard cosmological model well before big bang nucleosynthesis. Being\nan observable sensitive to the conditions in the early Universe, the neutralino direct detec-\ntion rate provides a plausible way of discriminating between different cosmological models,\nand therefore an indirect way of testing the standard scenario. Most studies on the direct\ndetection of neutralinos already assume the standard cosmology so it is not known what to\nexpect in a more general cosmological framework.\nThe vastness of the supersymmetric parameter space is the most compelling reason to\nassume the standard cosmological model. In a general setup, neither the neutralino mass\nor gauge composition nor its interaction rate, for example, can be determined a priori. To\nreduce such uncertainties, the dark matter constraint is usually imposed on supersymmetric\nmodels. That is, the neutralino relic density is computed within the standard cosmological\nmodel and only models with ?std < ?DM are considered (here ?std is the neutralino density\nin the standard cosmological model, and ?DM is the cold dark matter density, both in units\nof the critical density). This bound, it turns out, is very effective in restricting the parameter\nspace of supersymmetric models. In minimal supergravity models (mSUGRA), for instance,\nthe neutralino typically has a small annihilation rate in the early Universe, thus its relic\ndensity tends to be larger than observed. At the end, the requirement ?std < ?DM is found\nto be satisfied only along four narrow regions: the ?bulk? (with a light neutralino and tight\naccelerator constraints), the ?coannihilation region? (where the stau is almost degenerate\nwith the neutralino and coannihilation effects suppress the relic density), the ?funnel region?\n(where m? ?mA/2 and resonance effects enhance the ?-? annihilation rate) and the ?focus\npoint region? (where the neutralino acquires a non-negligible higgsino fraction). Accounting\nfor the dark matter provides, in fact, the most stringent constraint on supersymmetric\n2\nmodels, well over precision data or accelerator searches (see e.g. [2]).\nThough useful in reducing the supersymmetric parameter space, the dark matter con-\nstraint should not be taken for granted, as it relies on untested assumptions about the early\nUniverse. In particular, it postulates that the entropy of matter and radiation is conserved\nand that the Universe is radiation dominated at high temperatures (T ? m?). Several sce-\nnarios where such assumptions do not hold and, more generally, where the evolution of the\nUniverse before big bang nucleosynthesis deviates from the standard cosmological model,\nhave been studied in the literature. They are generically known as non-standard cosmolo-\ngies and include models with gravitino [3], moduli [4] or Q-ball decay [5], thermal inflation\n[6], the Brans-Dicke-Jordan [7] cosmological model, models with anisotropic expansion [8]\nor quintessence domination [9]. Non-standard cosmological models are viable alternatives\nagainst which the predictions of the standard scenario may be compared.\nIn non-standard cosmological scenarios, the neutralino relic density ?? may be larger or\nsmaller than ?std [11]-[20]. Smaller densities are usually the result of an episode of entropy\nproduction that dilutes the neutralino abundance. Larger densities are due either to ad-\nditional contributions to the expansion rate of the Universe, or to non-thermal neutralino\nproduction mechanisms. Usually these scenarios contain additional parameters that can be\nadjusted to modify the neutralino relic density. A distinctive feature of non-standard\ncosmologies is that the new physics they incorporate does not manifest in ac-\ncelerator or detection experiments. That is certainly the case, for instance, for\nthe several models mentioned above. Neutralino scattering rates, therefore, are\nnot affected by the cosmological model.\nA prototype non-standard cosmological model is that of a scalar field ? with\ncouplings of gravitational strength whose late decay reheats the Universe to\na low reheating temperature. The reheating temperature in this scenario can\nbe lower than the standard neutralino freeze-out temperature without spoiling\nprimordial nucleosynthesis [10]. Such scalar fields are common in superstring\nmodels where they appear as moduli fields. In these models, the decay of ?\ninto radiation increases the entropy, diluting the neutralino number density.\nInstead, the decay of ? into supersymmetric particles, which eventually decay\ninto neutralinos, increases the neutralino number density. In this non-standard\ncosmological model it has been shown that practically all neutralinos can have\n3\nthe density of the dark matter, provided the right combination of two parameters\ncan be achieved in the high energy theory: the reheating temperature, and\nthe ratio of the number of neutralinos produced per ? decay over the ? field\nmass [19, 20].\nIn this paper, we compute the neutralino direct detection rate in generic cosmological\nscenarios where neutralinos constitute the dark matter of the Universe. That is, we assume\nthat, independently of the supersymmetric spectrum, the parameters of the non-standard\ncosmological model can always be chosen so that ?? = ?DM. By randomly scanning the\nsupersymmetric parameter space, we obtain a large sample of models and compute their\ndetection rates in non-standard cosmologies. These predictions are then compared with\nthose obtained within the standard cosmological model. Our goal is twofold. First, we\nexplore the possibility of using the neutralino direct detection rate as a test of the standard\ncosmological model. Second, we establish the potential of future dark matter detectors in\nprobing the parameter space of supersymmetric models in a cosmology-independent setup.\nII. THE SUPERSYMMETRIC MODELS\nIn the MSSM, neutralinos are linear combinations of the fermionic partners of the neutral\nelectroweak bosons, called bino ( ?B0) and wino ( ?W03), and of the fermionic partners of the\nneutral Higgs bosons, called higgsinos ( ?H0u, ?H0d). We assume that the lightest neutralino, ?,\nis the dark matter candidate. Its composition can be parameterized as\n? = N11 ?B0 +N12 ?W03 +N13 ?H0d +N14 ?H0u . (1)\nBecause the neutralino interactions are determined by its gauge content, it is useful to\ndistinguish between bino-like (N211 > N212, N213 + N214), wino-like (N212 > N211, N213 + N214),\nand higgsino-like (N213 + N214 > N211, N212) neutralinos according to the hierarchy of terms\nin (1). This classification implies that even so-called mixed neutralinos, those with two or\nmore comparable components, are considered as either binos, winos or higgsinos.\nBino-like neutralinos annihilate mainly into fermion-antifermion pairs through sfermion\nexchange. Such annihilation cross-section is helicity suppressed and gives rise to a standard\nrelic density that is usually larger than observed. Agreement with the observed dark matter\nabundance can still be achieved in standard cosmological scenarios but only in restricted\n4\nregions of the parameter space where special mechanisms such as coannihilations or resonant\nannihilations help reduce the relic density. Owing to the gaugino unification condition, bino-\nlike neutralinos are a generic prediction of minimal supergravity models.\nWino-like andhiggsino-like neutralinos annihilate mostly into gaugebosons (W+W?, ZZ,\nif kinematically allowed) through neutralino or chargino exchange; otherwise they annihilate\ninto fermions. Due to coannihilations with the lightest chargino (and, for higgsinos, with the\nnext-to-lightest neutralino), their standard relic density is rather small. Neutralino masses\nas large as 1 TeV for higgsinos or 2 TeV for winos are required to bring their thermal density\nwithin the observed range. Wino-like and higgsino-like neutralinos can be obtained in models\nwith non-universal gaugino masses; models with anomaly mediated supersymmetry breaking\n(AMSB) [21], for instance, feature a wino-like neutralino.\nWe consider a general class of MSSM models defined in terms of the parameter set M3,\nM2, M1, mA, ?, tan?, m?q, m?? At, and Ab. Here Mi are the three gaugino masses, mA\nis the mass of the pseudoscalar higgs boson, and tan? denotes the ratio v2/v1. The soft\nbreaking scalar masses are defined through the simplifying ansatz MQ = MU = MD = m?q\nand ME = ML = m??, whereas the trilinear couplings are given by AU = diag(0,0,At),\nAD = diag(0,0,Ab), and AE = 0. All these parameters are defined at the weak scale.\nSpecific realizations of supersymmetry breaking such as mSUGRA, mAMSB [21] or split-\nSUSY [22] are similar to - though not necessarily coincide with - particular examples of these\nmodels.\nWe performed a random scan of such parameter space within the following ranges\n10 GeV < M1,M2,M3 < 50 TeV (2)\n40 GeV < mA,?,m?q,m?? < 50 TeV (3)\n?3m0 < At,Ab < 3m0 (4)\n1 < tan? < 60 (5)\nA logarithmic distribution was used for Mi, mA, ?, m?q and m??, and a linear one for At, Ab,\nand tan?; the sign of ? was randomly chosen. After imposing accelerator constraints, as\ncontained in DarkSUSY version 4.1 [23], a sample of about 105 viable models was obtained.\nThe following analysis is based on such a sample of supersymmetric models.\n5\n10 100 1000 10000\nNeutralino mass (GeV)\n0.0001\n0.01\n1\n100\n10000\n1e+06\n?h\n2\nBinos\nWinos\nHiggsinos\nFIG. 1: The standard neutralino relic density as a function of the neutralino mass for our sample\nof models. The models are differentiated according to the bino, wino, or higgsino character of the\nlightest neutralino. The horizontal band indicates the dark matter range.\nIII. RESULTS\nFigure 1 shows the standard relic density as a function of the neutralino mass for our\nsample of models. Each cell -triangle, circle or dot- represents a small region around which at\nleast one model was found. The models are classified as binos, winos, or higgsinos, according\nto the gauge composition of the lightest neutralino. The horizontal band corresponds to\nthe observed dark matter density ?stdh2 = ?dmh2 = 0.109+0.003?0.006, obtained for a ?CDM\nmodel with scale-invariant primordial perturbation spectrum through a global fit of cosmic\nmicrowave background, supernovae, and large scale structure data [24]. Several observations\ncan be made from this figure. Models with bino-like neutralinos are spread over a wide area\nand usually give a rather large relic density. Models with wino- and higgsino-like neutralinos,\non the contrary, are concentrated over narrow bands and their relic density exceeds the dark\nmatter density only for large masses, m? greaterorsimilar 1 TeV. Finally, notice that in our sample the\n6\nneutralino relic density varies between 106 and 10?4.\nWe now want to compute, for our set of models, the neutralino interaction rates in generic\ncosmologies where the neutralino accounts for the dark matter and compare them with those\nobtained in the standard cosmology. Since spin-dependent searches are harder than spin-\nindependent ones, we will focus on the latter. The neutralino interaction rate in direct\ndark matter detection experiments is proportional to the product of the spin-independent\nneutralino-nucleus cross section ?SI and the number density of neutralinos passing through\nthe detector, f. We assume that, as expected for collisionless cold dark matter, f = ??/?dm.\n?SI is determined only by the supersymmetric spectrum but ?? is sensitive to the cosmo-\nlogical setup. Thus, the neutralino detection rate depends on the cosmology only through\nf.\nIf the standard cosmological model is assumed, then all models above the horizontal band\nin figure 1 are rejected. They have a standard relic density larger than the observed dark\nmatter density (?std > ?DM) and therefore are considered incompatible with cosmological\nobservations. Models with a relic density below the dark matter density are still viable,\nthough neutralinos make up only a fraction of the dark matter. They have f < 1, so their\ndetection rate is typically suppressed. Finally, those models with a neutralino relic density\nwithin the observed dark matter range are viable and have f = 1. They have been the focus\nof the large majority of studies on neutralino direct detection.\nIn non-standard cosmologies, ?? = ?DM may be ensured and the previous picture is\nmodified in two important ways. On the one hand, the viable parameter space is different. In\nfact, overdense models, those with ?std > ?DM, canno longer be rejected. On theother hand,\nunderdense models, those with ?std < ?DM, no longer will have the f < 1 suppression factor\nin the detection rate. Hence, in non-standard cosmologies, we expect more viable models\nand larger detection rates. A priori, however, it is not possible to predict the detection rate\nfor the new viable models or to know whether the enhanced detection rates are within the\nsensitivity of future dark matter detection experiments. Thus, a careful analysis is required\nto establish the implications of non-standard cosmologies for dark matter searches. In the\nfollowing, such an analysis will be carried out.\nFigure 2 displays the detection rate in standard and non-standard cosmologies for bino-\nlike neutralinos as a function of the neutralino mass. As before, the figure has been divided\ninto a rectangular grid and each occupied cell denotes the existence of at least one model\n7\n10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 2: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM for bino-like neutralinos in the standard and non-standard cosmological\nmodels. The solid line indicates the CDMS II present limit [25]. The dashed lines show sensitivity\nlimits for -from top to bottom on the right- CDMS II,ZEPLINIV , XENON-1Ton, and SuperCDMS\nphase C [26].\naround it. For comparison, we also show the current limit from the CDMS II experiment [25]\naswell asthe expected sensitivity of CDMS II, ZEPLIN IV , XENON-1Ton, andSuperCDMS\nphase C [26]. In the standard scenario, both the lower and the upper limit on the bino\nmass are set by the relic density constraint. That is why the range of neutralino masses\nextends to lower and higher values in non-standard cosmologies. They yield many more\nviable models, though most of them have rather small detection rates. This fact is not\nentirely surprising. Small annihilation rates, as those associated with bino-like neutralinos,\nare generically correlated with small scattering rates. Regarding dark matter searches, the\nmost remarkable difference observed in the figure is the existence of new viable models with\nneutralino masses not allowed in the standard cosmology and detection rates within the\nreach of future experiments. Such models feature either m? lessorsimilar 40 GeV or m? greaterorsimilar 600 GeV\n8\n10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 3: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM for higgsino-like neutralinos in the standard and non-standard cosmological\nmodels. The solid line indicates the CDMS II present limit [25]. The dashed lines show sensitivity\nlimits for -from top to bottom on the right- CDMS II,ZEPLINIV , XENON-1Ton, and SuperCDMS\nphase C [26].\nand may be detected in ZEPLIN IV, XENON-1Ton, or SuperCDMS phase C.\nThe detection rate for higgsino-like neutralinos is shown in figure 3 as a function of\nthe neutralino mass in standard and non-standard cosmologies. The lower limit on the\nhiggsino mass is now set by the experimental constraint on the chargino mass and is therefore\nindependent of the cosmological scenario. Two features clearly distinguish the standard and\nthe non-standard cosmologies. One of them is the existence of viable models with heavy\nneutralinos, m? greaterorsimilar 1 TeV. A sizable fraction of them has detection rates large enough\nto be observed in ZEPLINIV, XENON-1Ton, or SuperCDMS phase C. The other feature\nis the significant enhancement in the detection rate of neutralinos lighter than lessorsimilar 1 TeV.\nIn the standard scenario, such neutralinos are usually underdense (see figure 1) and have\nsuppressed detection rates. From the figure we see that non-standard cosmologies yield an\n9\n10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 4: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM for wino-like neutralinos in the standard and non-standard cosmological\nmodels. The solid line indicates the CDMS II present limit [25]. The dashed lines show sensitivity\nlimits for -from top to bottom on the right- CDMS II,ZEPLINIV , XENON-1Ton, and SuperCDMS\nphase C [26].\nenhancement of up to two orders of magnitude for the neutralinos with the largest detection\nrates. Some of them are already ruled out by the present limit and many more will be within\nthe expected sensitivity of the CDMSII experiment.\nA compelling signature of non-standard cosmologies would be the detection of a wino-\nlike neutralino by the CDMSII experiment, as revealed in figure 4. Indeed, in the standard\nscenario, winos with m? lessorsimilar 1-2 TeV are usually underdense and therefore their detection rate\nis suppressed by the factor f = ?std/?DM. In non-standard cosmologies, such suppression\nis nonexistent and light winos have larger detection rates. The enhancement in the largest\ndetection rates are typically larger than for higgsinos, amounting in some cases to three\norders of magnitude. As for higgsinos, the lower bound on m? is not set by the dark matter\nbound but rather by the experimental constraint on the chargino mass, so no additional\n10\n1 10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 5: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM in the standard cosmological model and in the late decaying scalar field\nmodel. Here the lower limit of M1 in Eq. (2) has been lowered to 0.1 MeV The solid upper line\nindicates the CDMS II present limit [25] and the lower solid line the XENON limit [27]. The\ndashed lines show sensitivity limits for -from top to bottom on the right- CDMS II, ZEPLIN IV ,\nXENON-1Ton, and SuperCDMS phase C [26].\nmodels are found at low neutralino masses. For m? greaterorsimilar 2 TeV we do find new viable models\ncorresponding to overdense neutralinos in the standard cosmology. Most of them, however,\nhave small scattering rates, lying below the sensitivity of future detection experiments.\nFigure 5 summarizes the potential increase in neutralino candidates in the\nmodels studied in references [19] and [20]. For this figure the lower limit on M1 in\nEq. (2) has been lowered to 0.1 GeV (which is compatible with all experimental\nlimits (while no assumption is made on the relation between M1 and M2). In the\nlate decaying scalar field scenario most neutrinos can be brought to have the\ndark matter density (provided the value of the two relevant parameters of the\nphysics at the high scale can be suitably arranged). One exception is that of\n11\nvery light neutralinos which would be very overdense in the standard cosmology.\nRequiring the reheating temperature to be above 4 MeV [10], in order not to\nmodify nucleosynthesis, from the equations of reference [19] it is immediate to\nsee that neutralinos of mass m? should have a standard density smaller than\nthe dark matter density times (m?/120MeV)4 for it to be possible to bring their\ndensity to be that of the dark matter in the late decaying scalar field scenario.\nThis constraint is included in figure 5 where it is clearly shown the increase\nin potential neutralino candidates in the particular non-standard cosmological\nmodel considered with respect to the standard cosmological model.\nIV. CONCLUSION\nTo summarize, in this paper we computed the direct detection rate of MSSM neutralinos\nin generic cosmological scenarios where they constitute the dark matter of the Universe.\nWhen compared with the predictions of the standard cosmology, considerable differences\nwere encountered. If the neutralino is bino-like, as in msugra models, additional light m? lessorsimilar\n40 GeV and heavy m? greaterorsimilar 600 GeV neutralinos with non-negligible detection rates were found.\nThey could be detected in a variety of dark matter experiments such as ZEPLINIV, XENON-\n1Ton, or SuperCDMS phase C. For higgsino-like neutralinos, we found enhancements of up\nto two orders of magnitude in the largest detection rates as well as new viable models with\nheavy m? greaterorsimilar 1 TeV neutralinos. Both effects yielding detection rates within the sensitivity\nof future experiments. Wino-like neutralinos provide the clearest signature of non-standard\ncosmologies. Their detection rates may be enhanced by up to three orders of magnitude and\nthey could be detected in CDMSII. Thus, the prospects for the direct detection of neutralinos\nin non-standard cosmologies are significantly more promising than in the standard scenario.\nAcknowledgments\nWe thank Oleg Kalashev for allowing us to use the graphreader program. G.G., A.S. and\nC.Y. were supported in part by the US Department of Energy Grant DE-FG03-91ER40662,\nTask C and G.G. also by NASA grants NAG5-13399 and ATP03-0000-0057 at UCLA. P.G.\n12\nwas supported in part by the NFS grant PHY-0456825 at the University of Utah.\n[1] K. Griest and M. Kamionkowski, Phys. Rept. 333 (2000) 167.\n[2] J. R. Ellis, K. A. Olive, Y. Santoso and V. C. Spanos, Phys. Lett. B 565, 176 (2003).\n[3] T. Moroi, M. Yamaguchi and T. Yanagida, Phys. Lett.B 342,105 (1995); M Kawasaki, T.\nMoroi and T. Yanagida, Phys. Lett.B 370,52 (1996).\n[4] T. Moroi and L. Randall, Nucl. Phys. B570, 455 (2000).\n[5] M. Fujii, K. Hamaguchi, Phys. Rev. D 66, 083501 (2002); M. Fujii, M. Ibe, Phys. Rev. D 69,\n035006 (2004).\n[6] D. H. Lyth, E.D. Stewart, Phys. Rev. D 53, 1784 (1996).\n[7] M. Kamionkowski and M. S. Turner, Phys. Rev. D 42, 3310 (1990).\n[8] J. D. Barrow, Nucl. Phys. B 208, 501 (1982).\n[9] P. Salati, Phys. Lett. B 571, 121 (2003) [arXiv:astro-ph/0207396]; S. Profumo and P. Ullio,\nJCAP 0311, 006 (2003) [arXiv:hep-ph/0309220]. S. Profumo and C. E. Yaguna,\nPhys. Rev. D 70, 095004 (2004)\n[arXiv:hep-ph/0407036].\n[10] M. Kawasaki, K. Kohri, and N. Sugiyama, Phys. Rev. Lett. 82, 4168 (1999); Phys. Rev. D\n62, 023506 (2000); S. Hannestad, Phys. Rev. D 70, 043506 (2004).\n[11] M. Kamionkowski, M. Turner, Phys. Rev. D 42 3310 (1990); R. Jeannerot, X. Zhang, R.\nBrandenberger, JHEP 12, 003 (1999); W. B. Lin, D. H. Huang, X. Zhang, R. Brandenberger,\nPhys. Rev. Lett. 86 954 (2001).\n[12] T. Moroi, M. Yamaguchi and T. Yanagida, Phys. Lett.B 342,105 (1995); M Kawasaki, T.\nMoroi and T. Yanagida, Phys. Lett.B 370,52 (1996).\n[13] D. J.H. Chung, E. W. Kolb and A. Riotto, Phys. Rev. D60, 063504 (1999).\n[14] G. F. Giudice, E. W. Kolb and A. Riotto, Phys. Rev. D64, 023508 (2001).\n[15] R. Allahverdi and M. Drees, Phys. Rev. Lett. 89, 091302 (2002) and Phys. Rev. D66, 063513\n(2002).\n[16] S. Khalil, C. Mu?noz and E. Torrente-Lujan, New Journal of Physics 4, 27 (2002); E. Torrente-\nLujan, hep-ph/0210036 (2002).\n[17] N. Fornengo, A. Riotto, and S. Scopel, Phys. Rev. D67, 023514 (2003).\n13\n[18] C. Pallis, Astrop. Phys. 21, 689 (2004).\n[19] G. B. Gelmini and P. Gondolo, Phys. Rev. D 74, 023510 (2006)\n[20] G. Gelmini, P. Gondolo, A. Soldatenko and C. E. Yaguna, Phys. Rev. D 74, 083514 (2006).\n[21] L. Randall and R. Sundrum, Nucl. Phys. B 557, 79 (1999) [arXiv:hep-th/9810155].\nG. F. Giudice, M. A. Luty, H. Murayama and R. Rattazzi, JHEP 9812, 027 (1998)\n[arXiv:hep-ph/9810442].\n[22] N. Arkani-Hamed, S. Dimopoulos, G. F. Giudice and A. Romanino, Nucl. Phys. B 709,\n3 (2005) [arXiv:hep-ph/0409232]. G. F. Giudice and A. Romanino, Nucl. Phys. B 699, 65\n(2004) [Erratum-ibid. B 706, 65 (2005)] [arXiv:hep-ph/0406088].\n[23] P. Gondolo, J. Edsjo, P. Ullio, L. Bergstrom, M. Schelke and E. A. Baltz, JCAP 0407, 008\n(2004).\n[24] D.N. Spergel et al. Astrophys. J., Suppl. Ser. 148, 175 (2003); D.N.\nSpergel it et al., astro-ph/0603449 (2006); http:// lambda.gsfc.nasa.gov/ prod-\nuct/map/current/parameters.cfm.\n[25] D. S. Akerib et al. [CDMS Collaboration], Phys. Rev. Lett. 96, 011302 (2006)\n[arXiv:astro-ph/0509259].\n[26] R. J. Gaitskell, Ann. Rev. Nucl. Part. Sci. 54, 315 (2004).\n[27] D. N. McKinsey [XENON Collaboration], AIP Conf. Proc. 870 (2006) 202; J. Angle et al.\n[XENON Collaboration], arXiv:0706.0039 [astro-ph].\n14\n"}
{"id":"oai:arXiv.org:quant-ph/0610192","text":"arXiv:hep-ph/0612309v1  22 Dec 2006\nProbing the octant of ?23 with very long baseline neutrino\noscillation experiments: a global look\nGuey-Lin Lina,b? and Yoshiaki Umedaa?\naInstitute of Physics, National Chiao-Tung University, Hsinchu 300, Taiwan\nbPhysics Division, National Center for Theoretical Sciences, Hsinchu 300, Taiwan\n(Dated: February 7, 2008)\nAbstract\nWe investigate the baseline range in which the ?23 degeneracy in neutrino oscillation probabilities\nis absent for fixed values of ?13 and CP violation phase ?CP. We begin by studying sensitivities\nof neutrino oscillation probabilities to ?13, ?23 and ?CP for very-long-baseline neutrino oscillations.\nWe show contour graphs of the muon-neutrino survival probability P(?? ? ??) and the appearance\nprobability P(?e ? ??) on the cos2?23?sin2?13 plane for baseline lengths L = 1000, 5000, 10000,\nand 12000 km. For each baseline length, it is found that P(?? ? ??) is more sensitive to sin2?13 at\nenergies around its local maximum while it is more sensitive to cos2?23 at energies around its local\nminimum. On the other hand, the appearance probability P(?e ? ??) is sensitive to sin2?13 and\ncos2?23 only near its local maximum. We observe that the ?23 degeneracy in P(?? ? ??) is absent\nat energies around the local maximum of this probability, provided ?13 is sufficiently large. The\n?23 degeneracy is also absent in general near the local maximum of P(?e ? ??). Using analytic\napproximations for neutrino oscillation probabilities, we demonstrate that the above observations\nfor L = 1000, 5000, 10000, and 12000 km are in fact valid for all distances. The implications of\nthese results on probing the octant of ?23 are discussed in details.\nPACS numbers: 14.60.Pq, 13.15.+g, 14.60.Lm\n? E-mail: glin@cc.nctu.edu.tw\n? E-mail: umeda@faculty.nctu.edu.tw\n1\nI. INTRODUCTION\nThe understanding of neutrino masses and mixing matrix is crucial to unveil the mystery\nof lepton flavor structures. The updated SK analysis of the atmospheric neutrino data gives\n[1]\n1.5?10?3 eV2 < |?m231| < 3.4?10?3 eV2, sin2 2?23 > 0.92. (1)\nThis is a 90%C.L. range with the best fit values given by sin2 2?23 = 1 and ?m231 =\n2.1?10?3 eV2 respectively. An earlier result based upon L/E analysis gives [2]\n1.9?10?3 eV2 < |?m231| < 3.0?10?3 eV2, sin2 2?23 > 0.9. (2)\nat 90%C.L. where the best fit values are given by sin2 2?23 = 1 and ?m231 = 2.4?10?3 eV2\nrespectively. The scenario of ?? ? ?? oscillation for atmospheric neutrinos has been con-\nfirmed by the K2K experiment [3, 4]. Furthermore the results in the solar neutrino oscillation\nmeasurements are also confirmed by KamLAND reactor measurements [5, 6]. Combining\nthese measurements, the LMA solution of the solar neutrino problem is established and the\nupdated 2? parameter ranges are given by [7]\n7.21?10?5 eV2 < ?m221 < 8.63?10?5 eV2, 0.267 < sin2 ?12 < 0.371, (3)\nwith the best fit values ?m221 = 7.92?10?5 eV2 and sin2 ?12 = 0.314.\nDespite the achievements so far in measuring the neutrino mixing parameters, the sign\nof ?m231, the mixing angle ?13 and the CP violating parameter ?CP in the mixing matrix\nremain to be determined. Furthermore, one is keen to resolve the octant degeneracy of ?23\n[8].\nThe mixing angle ?13 is constrained by the reactor experiments [9, 10]. The CHOOZ\nexperiment [9] gives a more stringent constraint on ?13 with sin2 2?13 < 0.1 for a large\n?m231 (90% C.L.). A recent global fit based upon three-flavor neutrino oscillation gives the\n2? upper bound, sin2 2?13 < 0.124 [7]. It is well known that the mixing angle ?13 can be\nenhanced by the matter effect in Earth. The appearance oscillations ?? ? ?e, ?e ? ??,\nand the survival mode ?? ? ?? performed in a very-long baseline have been proposed\n[11] to probe the angle ?13 and the sign of ?m231. Furthermore, the aforementioned very\nlong baseline neutrino experiments as well as future atmospheric neutrino experiments are\nproposed to determine the deviation of ?23 to maximality [12]. In this work, we focus on\n2\nthe mixing angle ?23. We shall provide a global survey on ideal neutrino energies in the\nGeV range and baseline lengths from 103 km to 104 km for probing the octant of the mixing\nangle ?23. The muon neutrino survival probability P(?? ? ??) ? P?? and electron neutrino\nappearance probability P(?e ? ??) ? Pe? are both studied for this purpose. We observe\nthat the muon neutrino survival probability P?? has complementary dependencies on mixing\nangles ?13 and ?23 as the neutrino energy varies. This property is established by studying\nthe dependencies of P?? on cos2?23 and sin2?13 while keeping other parameters fixed. The\nchoice of the parameter cos2?23 is appropriate as\n1\n2 cos2?23 =\n1\n2 ?sin\n2 ?23, (4)\nwhich is a probe to the deviation of ?23 to the best-fit value pi/4. We find that the de-\npendencies of P?? on cos2?23 and sin2?13 at energies near local maxima of this probability\ndiffer drastically from those at energies near local maxima of the same probability. In the\nformer case, the probability P?? is always more sensitive to sin2?13. Furthermore, the ?23\ndegeneracy is absent in this case. In the latter case, the probability P?? is more sensitive to\ncos2?23 while the ?23 degeneracy is generally present. Such information is useful for probing\nthe octant of ?23. We also study sensitivities of the probability Pe? to cos2?23 and sin2?13\nwith other parameters fixed. We only focus on energies near the local maximum of Pe? as\nthis probability is not sensitive to mixing parameters for energies near its local minimum.\nThis paper is organized as follows. In Section II, we compare results on the oscillation\nprobability Pe? obtained by the full calculation with those obtained by various analytic\napproximations. This comparison is essential since analytic approximations will be employed\nfor discussions in later sessions. To set up the analytic approximation, we introduce the\nconcept of average density which varies with the total neutrino path-length inside the Earth.\nApplying full calculations and the two-layer analytic approximations [13], we identify the\nenergy values for local maxima and local minima of neutrino oscillation probabilities P?? and\nPe? for baseline lengths 1000 ? L/km ? 12000. It is found that the two-layer approximation\nis quite satisfactory compared to the full calculation for computing these energy values. In\nSection III, we first present the dependencies of P?? and Pe? on the CP violation phase\n?CP. It will be shown that, unlike Pe?, P?? is not sensitive to the CP violation phase ?CP.\nWe study numerically the effect of CP violation phase to the appearance probability Pe?.\nThe result confirms the so-called magic baseline [14, 15, 16] at L ? 7600 km where Pe? is\n3\nrather insensitive to the CP violation phase. After discussions on the CP violation phase,\nwe present the contour graphs of probabilities P?? and Pe? on cos2?23 ?sin2?13 plane for\nbaseline lengths L = 1000, 5000, 10000, and 12000 km. At all these baseline lengths, we\nshall see that P?? is more sensitive to sin2?13 at energies around its local maximum while\nit is more sensitive to cos2?23 at energies around its local minimum. Such observations\nare then justified by using the two-layer analytic approximations for neutrino oscillation\nprobabilities. With this approximation, the baseline lengths and neutrino energies allowing\nan unambiguous determination of ?23 through measuring P?? are identified. In Section IV,\nwe discuss the prospects of probing the ?23 octant via measuring Pe? and P??. We then\nconclude in the same section.\nII. THE COMPARISON OF FULL CALCULATIONSAND ANALYTICAPPROX-\nIMATIONS\nWe begin the discussions with the relation connecting flavor and mass eigenstates of\nneutrinos, ?? =summationtexti U?i?i, with U the Maki-Nakagawa-Sakata mixing matrix [17] given by\nU =\n?\n??\n??\nc12c13 s12c13 s13e?i?CP\n?s12c23 ?c12s13s23ei?CP c12c23 ?s12s13s23ei?CP c13s23\ns12s23 ?c12s13c23ei?CP ?c12s23 ?s12s13c23ei?CP c13c23\n?\n??\n?? , (5)\nwhere sij and cij denote sin?ij and cos?ij, respectively. The value for the Dirac type CP-\nphase ?CP ranges from 0 to 2pi. The evolutions of neutrino flavor eigenstates are governed\nby the equation\ni ddt|?(t)? =\n?\n????\n????\n1\n2E?U\n?\n??\n??\n0 0 0\n0 ?m221 0\n0 0 ?m231\n?\n??\n??U? +\n?\n??\n??\nV 0 0\n0 0 0\n0 0 0\n?\n??\n??\n?\n????\n????|?(t)?, (6)\nwhere |?(t)? = (?e(t),??(t),??(t))T, ?m2ij ? m2i ?m2j is the mass-squared difference between\nthe i-th and j-th mass eigenstates, and V ? ?2GFNe is the effegtive potential arising\nfrom the charged current interaction between ?e and electrons in the medium with Ne the\nelectron number density. Numerically V = 7.56?10?14 (?/[g/cm3])Ye [eV] with Ye denoting\nthe number of electrons per nucleon. We take Ye ? 0.5 in our calculations. One solves\nEq. (6) by diagonalizing the Hamiltonian on its right hand side. This amounts to writing\n4\n0 5000 10000\nbaseline length L[km]\n0\n5\n10\n? [g/cm\n3 ]\naverage density\ndensity in the mantle\ndensity in the core\naverage density\nFIG. 1: The average Earth density along the path traversed by the neutrino as a function of the\npath length L.\nthe right hand side of Eq. (6) as U?H?U??|?(t)? with U? the neutrino mixing matrix in the\nmatter and H? ? diag(E1,E2,E3) the Hamiltonian after diagonalization. To obtain various\noscillation probabilities described later, we have used the parametrization in [18] for the\nEarth density profile.\nFor analytic calculations, we employ the two-layer approximation for the Earth density\nprofile [13]. Given a path-length L for a neutrino traversing the Earth medium, one can\ndivide L into the sum L = L1 + L2 + ???Ln with each Li corresponding to a region with\na specific matter density. The average density for this path-length is then given by ? =\n(?1L1 + ?2L2 + ????nLn)/L. The Earth medium can be categorized as the Earth mantle\nand the Earth core. If a neutrino only traverses the Earth mantle, we shall use the one-\ndensity approximation for the analytic calculation with the density defined by the above\nprescription. However, if a neutrino traverses both the Earth mantle and the Earth core,\none should write the total neutrino path-length as L = 2Lm + Lc with\nLm = R\nparenleftBigg\ncos?n ?\nradicalbigg\nr2c\nR2 ?sin\n2 ?n\nparenrightBigg\n,\nLc = 2R\nradicalbigg\nr2c\nR2 ?sin\n2 ?n, (7)\n5\nwhere R = 6371 km and rc = 3480 km are the radii of the entire Earth and the Earth core\nrespectively while ?n is the incident Nadir angle of the neutrino. We note that the critical\nNadir angle for a neutrino to pass the Earth core is 33.17? corresponding to L = 10674 km.\nFor L > 10674 km, one separately defines average densities within the path-length Lm and\nthe path-length Lc respectively. The average densities as functions of the neutrino path-\nlength is shown in Fig. 1. For L ? 10674 km, there is only one curve for the average density,\nwhich is represented by the solid line in the figure. Beyond this distance, one can define the\naverage density in the core and the average density in the mantle, which are represented\nby dashed and dotted lines respectively. Alternatively, one can also define single average\ndensity for L > 10674 km by ignoring the distinction between the mantle and the core. This\nis seen from the solid line for L > 10674 km. However, in our analytic calculations, we shall\nadopt the two-density approach for L > 10674 km.\nFor analytic calculations, we only compute oscillation probabilities up to the lowest order\nin ? ? ?m221/?m231. In other words, we set ?m221=0 in analytic calculations and conse-\nquently the mixing angle ?12 and the CP phase ?CP dropout fromthe oscillation probabilities.\nThe probabilities P?? and Pe? in the two-layer approximations are given by[19, 20, 21, 22, 23]:\nP?? = cos4 ?23 +parenleftbigu2 + v2parenrightbigsin4 ?23 + 2cos2 ?23 sin2 ?23 (ucost+ vsint),\nPe? = sin2 ?23parenleftbig1?u2 ?v2parenrightbig. (8)\nThe quantities u, v and t are defined as\nu = cos(2?m)cos(?c)?cos(2?c13 ?2?m13)sin(2?m)sin(?c),\nv = ?cos(2?m13)[sin(?c)cos(2?m)cos(2?c13 ?2?m13) + cos(?c)sin(2?m)]\n+sin(2?m13)sin(?c)sin(2?c13 ?2?m13),\nt = (M\n2\n13)\nm + (m2\n13)\nm\n4E ?2L\nm + (M\n2\n13)\nc + (m2\n13)\nc\n4E ?L\nc, (9)\nwhere\n?m(c) = ?\nm(c)\n31\n4E L\nm(c),\n(M213)m(c) = (?m231 + Am(c)e + ?m(c)31 )/2,\n(m213)m(c) = (?m231 + Am(c)e ??m(c)31 )/2, (10)\nwith\n?m(c)31 =\nradicalBig\n(?m231 sin2?13)2 + (Am(c)e ??m231 cos2?13)2. (11)\n6\n0 5 10\nE [GeV]\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nP e?\nFull\nTwo-Layer\nOne-Layer\n(First order)\nOne-Layer\n(Second order)\nFull (?m212 =0)\nPe? for L=11400 km, sin2?13=0.3, cos2?23=0\nFIG. 2: A comparison of Pe? obtained by the full numerical calculation and various approximations.\nThe thick solid curve denotes the result by the full numerical calculation. The dotted-dashed\ncurve denotes the result by setting ?m221 = 0 in the full numerical calculation. The dashed\ncurve represents the result obtained by the two-layer approximation in the leading order of ? ?\n?m221/?m231. The dotted curve denotes the result obtained by one-density approximation in the\nleading order of ? while the thin solid curve is that obtained by the one-density approximation in\nthe next-to-leading order of ?.\nThe superscripts m and c denote quantities defined in the Earth mantle and the Earth\ncore respectively. For neutrinos traversing only the Earth mantle, one simply sets Lc =\n0, 2Lm = L in the above equations and recovers well known expressions for P?? and Pe? in\nthe one-density approximation [24].\nThe accuracy of two-layer approximation is shown in Fig. 2 with a comparison of this\napproximation to the full numerical calculation and other approximations. In the calcula-\ntions, we have assumed the normal mass hierarchy and taken sin2?13 = 0.3, cos2?23 = 0,\n?CP = 0, ?m231 = 2.4?10?3 eV2, ?m221 = 8.2?10?5 eV2, and tan2 ?12 = 0.39 [25]. This\nset of parameters will be adopted for later calculations unless specific mentioning of other\nchoices. This set of parameters differ from the most updated best-fit values quoted right\nafter Eq. (3). However, both set of parameters give undistinguishable results on Pe? and P??\n7\n0 5000 10000\nbaseline length L[km]\n0\n5\n10\n15\nenergy [GeV]\nFull calculation\nTwo-Layer\nThe energy at local maximum of Pe?\nmax1\nmax2\n0 5000 10000\nbaseline length L[km]\n0\n5\n10\n15\n20\nenergy [GeV]\nFull calculation\nTwo-Layer calculation\nThe energies at local maximum and local minimum of P??\nmin2\nmax1\nmin1\nmax2\nFIG. 3: Left panel: the energy at the local maximum of Pe?, as a function of L. Right panel:\nenergies at local maxima and local minima of P??, as functions of L.\nin the energy range concerned here. A comparison made at L = 11400 km has two purposes.\nFirst of all, it is known that the series expansion in the parameter ? is valid for L/E? ? 104\n(km/GeV) [24, 26]. Hence analytic calculations performed at this baseline length test the\nmarginal region of the condition L/E? ? 104 (km/GeV). Secondly this path-length implies\nthat the neutrino traverses both the Earth mantle and the Earth core. Therefore it is also\na good test to the two-layer approximation. It is seen that the two-layer approximation,\nunlike the one-layer approximation, reproduces well the peak energies of Pe?, while it gives\npeak probabilities deviating from those obtained from the full calculation by 15% ?20%.\nWe also see that the two-layer approximation agrees well with the full calculation in the\nlimit ?m221 = 0.\nFor later analysis, we compute energies at local maxima of Pe? and those at local maxima\nand local minima of P?? for the baseline range 1000 ? L/km ? 12000. The results are\ndepicted in Fig. 3. We do not study local minima of Pe? since their values are not sensitive\nto mixing angles ?13 and ?23. It is seen that the analytic approximation is satisfactory for\ncomputing energies at local maxima and local minima of neutrino oscillation probabilities.\nWe point out that the energy curves in Fig. 3 are calculated with sin2?13 = 0.3 and cos2?23 =\n0. It is found that these curves are not sensitive to the values of sin2?13 and cos2?23.\n8\n0 1 2 3 4 5\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n(P ??\n)\n?CP=0\n?CP=0.5pi\n?CP=pi\n?CP=1.5pi\nP?? and Pe? for L=1000 km, sin2?13=0.3, cos2?23=0\nPe?P??\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=5000 km, sin2?13=0.3, cos2?23=0\n0 5 10 15 20\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=10000 km, sin2?13=0.3, cos2?23=0\n0 5 10 15 20\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=12000 km, sin2?13=0.3, cos2?23=0\nFIG. 4: The CP phase dependencies of P?? and Pe? for L = 1000 km, 5000 km, 10000 km and\n12000 km respectively. The probability P?? is described by the thick curve while Pe? is described\nby the thin curve.\nIII. CONDITIONS FOR THE ABSENCE OF ?23 DEGENERACY IN P?? AND Pe?\nAT DIFFERENT ENERGIES\nA. The dependencies of P?? and Pe? on ?CP\nBefore concentrating on ?13 and ?23 dependencies of neutrino oscillation probabilities,\nwe first study the CP phase dependencies with the full numerical calculations. It is easily\nseen from Fig. 4 that P?? is not sensitive to the CP phase for all distances displayed. On\nthe other hand, Pe? is rather sensitive to the CP phase for L = 1000 km and 5000 km.\nIn order to quantify the CP phase dependence of Pe?, we study peak values of Pe?, which\noccur at energies described by the curve max1 in Fig. 3 for different baseline lengths. This\npeak value for a specific baseline length depends on the CP violation phase ?CP and we\n9\n0 2000 4000 6000 8000 10000\nbaseline length L [km]\n0\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\nP e?max\n?  P\ne?min\nPe?max ?  Pe?min,  sin2?13=0.3, cos2?23=0\n0 2000 4000 6000 8000 10000\nbaseline length L [km]\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nP e?min\n/  P\ne?max\nPe?min /  Pe?max,  sin2?13=0.3, cos2?23=0\nFIG. 5: The difference and the ratio of Pmaxe? and Pmine? as functions of the baseline length.\ndenote the maximum and the minimum of this value as Pmaxe? and Pmine? respectively. The\ndifference and the ratio of these two values as functions of the baseline length L are shown\nin Fig. 5. It is interesting to note that the ratio Pmine? /Pmaxe? increases monotonically with the\nbaseline length until L = 7600 km. The ratio begins to decrease for a larger baseline but\nremains larger than 90%. In fact, one can see that Pmaxe? and Pmine? differ by less than 10%\nfor L ? 6500 km. We point out that 1?Pmine? /Pmaxe? reaching to minimum at L = 7600 km\nconfirms the so-called magic baseline for the probability Pe? [14, 15, 16].\nB. The dependencies of P?? and Pe? on mixing angles ?13 and ?23\nHaving studied CP phase dependencies of oscillation probabilities, we now focus on ?13\nand ?23 dependencies. In this study we set the CP phase ?CP equal to zero. The results\nare presented in Fig. 6. It is easily seen that the values of P?? at its local maximum and\nlocal minimum depend on mixing angles ?13 and ?23 while only the local maximum of Pe?\ndepends on these parameters. This confirms our earlier comments concerning the left panel\nof Fig. 3. We point out that the differences between solid and dotted curves in Fig. 6 reflect\nthe effect of sin2?13; while the differences between solid and dashed curves there reflect the\neffect of cos2?23.\nWe now present contour graphs of P?? and Pe? on the cos2?23 ? sin2?13 plane. The\nrange for cos2?23 is chosen such that sin2?23 > 0.9 [2], i.e., ?0.316 < cos2?23 < 0.316; while\nsin2 2?13 is chosen to be less than 0.1, i.e., sin2?13 < 0.316. The contour graphs of P?? at\n10\n0 1 2 3 4 5\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nsin2?13=0.3,   cos2?23=0\nsin2?13=0.15, cos2?23=0\nsin2?13=0.3,   cos2?23=0.3\nsin2?13=0.3,   cos2?23=?0.3\nP?? and Pe? for L=1000 km\nPe?P??\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=5000 km\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=10000 km\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=12000 km\nFIG. 6: The ?13 and ?23 dependencies of P?? and Pe? for L = 1000 km, 5000 km, 10000 km and\n12000 km respectively. The probability P?? is described by the thick curve while Pe? is described\nby the thin curve.\ndifferent baseline lengths are presented in Fig. 7. Except for L = 1000 km, we have shown\ncontours of P?? for energies in the vicinity of both local maximum and local minimum of\nthis probability. The contour for the local maximum of P?? at L = 1000 km is not shown\nsince P?? at this energy and baseline length is not sensitive to mixing angles ?13 and ?23. For\nL = 5000 km, 10000 km and 12000 km, it is seen that the contours at local maxima of P??\nand those at local minima of P?? behave rather differently. The former are in general more\nparallel to the cos2?23-axis while the latter are generally more parallel to the sin2?13-axis.\nWe note that the local maximum (max2) of P?? at L = 12000 km can vary from 0.9 to a\nmuch smaller value, 0.45, which is a result of significant matter effects. Similarly, due to\nlarge matter effects, the local minimum (min2) of P?? at L = 10000 km can vary from 0\nto a much larger value, 0.4. We also notice that, at this baseline length, the ?23 degeneracy\n11\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=1.39-2.39 GeV (min1), L=1000 km\n0.065\n0.08\n0.08\n0.1\n0.1\n0.13\n0.13\n0.16\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=4.25-5.25 GeV (max1, solid)\nand E=8.74-9.74 GeV (min1, dashed), L= 5000 km\n0.005\n0.02\n0.02\n0.05\n0.05\n0.08\n0.08\n0.12\n0.96 0.93 0.9 0.85\n0.8\n0.75\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=8.71-9.71 GeV (max1, solid)\nand E=5.74-6.74 GeV (min2, dashed), L=10000 km\n0.06\n0.05\n0.3\n0.04\n0.1\n0.1\n0.15 0.40.2\n0.93\n0.982 0.97\n0.95\n0.9\n0.87\n0.84\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=5.00-6.00 GeV (max2, solid)\nand E=6.65-7.65 GeV (min2, dashed), L=12000 km\n0.12\n0.09\n0.450.15\n0.15\n0.6\n0.18\n0.7\n0.86\n0.86\n0.8\n0.06\n0.03\n0.18\nFIG. 7: The contour graphs of the muon neutrino survival probability P?? on the cos2?23?sin2?13\nplane. At L = 1000 km, the local minimum of P?? on the curve min1 occurs at E = 1.89 GeV. We\nplot the contour graph of P?? by averaging this probability over an 1 GeV energy range centered\nat the above local minimum. At L = 5000 km, the local maximum of P?? on the curve max1\noccurs at E = 4.75 GeV while the local minimum of this probability on the curve min1 occurs at\nE = 9.24 GeV. We plot the contour graphs of P?? in the energy range 4.25 ? E/GeV ? 5.25 for\nthe former case and 8.74 ? E/GeV ? 9.74. The same type of convention applies to L = 10000 km\nand 12000 km.\nis absent for P?? > 0.1. In general, such a degeneracy is also absent for energies near local\nmaxima of P??. However, the probabilities are not sensitive to cos2?23 in those cases. For\ncomparisons, we also present contour graphs for the appearance probability Pe? at different\nbaseline lengths. It is clearly seen that Pe? is only sensitive to sin2?13 for most cases. The\nsensitivity to cos2?23 only occurs at very long baseline lengths and large values of sin2?13.\n12\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=1.39-2.39 GeV (max1), L=1000 km\n0.002\n0.01 0.02\n0.03 0.04\n0.06\n0.08\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=5.31-6.31 GeV (max1), L=5000 km\n0.01 0.05\n0.1\n0.15\n0.2\n0.25\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=5.49-6.49 GeV (max1), L=10000 km\n0.03 0.1 0.2\n0.4\n0.5\n0.3\n0.6\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=2.64-3.64 GeV (max1), L=12000 km\n0.01 0.1 0.2\n0.4\n0.5\n0.3\nFIG. 8: The contour graphs for the oscillation probability Pe? on the cos2?23 ?sin2?13 plane. We\nplot contours of Pe? at energies near the local maximum (max1) of this probability.\nFor example, at L = 10000 km, Pe? becomes sensitive to cos2?23 as sin2?13 approaches 0.3.\nAt L = 12000 km, Pe? becomes sensitive to cos2?23 when sin2?13 is greater than 0.2.\nC. A global look at the absence of ?23 degeneracy\nIn this subsection, we focus on ?23 dependencies of P?? and Pe? for general baseline\nlengths. The two-layer analytic approximations for P?? and Pe? will be employed for our\ndiscussions, and observations in the previous subsection shall be justified. It is instructive\nto rewrite Eq. (8) in polynomials of cos2?23:\nf(y,z) = ??y2 + (? + ?)y + (1??),\ng(y,z) = ??(y ?1), (12)\n13\n2000 4000 6000 8000 10000 12000\nbaseline length L [km]\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n?+?\nsin2?13=0.1\nsin2?13=0.2\nsin2?13=0.3\nFIG. 9: The coefficient ?(z) + ?(z) calculated along the energy curve max1 in the left panel of\nFig. 3. The values of sin2?13 are taken to be 0.1, 0.2 and 0.3 respectively.\nwith f(y,z) ? P??, g(y,z) ? Pe?, y ? cos2?23 and z ? sin2?13. Furthermore,\n? = ?14bracketleftbig(u?cost)2 + (v?sint)2bracketrightbig,\n? = 12parenleftbig1?u2 ?v2parenrightbig+ 14bracketleftbig(u?cost)2 + (v ?sint)2bracketrightbig,\n? = 12parenleftbig1?u2 ?v2parenrightbig. (13)\nWe note that the sin2?13 dependencies of P?? and Pe? reside in quantities u, v, cost and\nsint. These quantities also depend on the baseline length L and the neutrino energy E.\nHence the coefficients ?, ? and ? also depend on the baseline length L and the neutrino\nenergy E. It is interesting to note that ? + ? = ?. Therefore we have\nP?? = ?parenleftbigy2 ?1parenrightbig, (14)\nusing P?e +P?? +P?? = 1 and P?e = Pe? with our choice of ?CP = 0. The contour structure\nof Pe? is straightforward as g(y,z) is only a linear function of y. Hence no ?23 degeneracy\npresents in the contour graphs depicted in Fig. 8. Additionally, the sensitivity of Pe? to\ncos2?23 is dg(y,z)/dy = ?(?(z) + ?(z)). The coefficient ? + ? evaluated along the energy\ncurve max1 in the left panel of Fig. 3 are plotted in Fig. 9 for sin2?13 = 0.1, 0.2 and 0.3. For\nsin2?13 = 0.3, ?+? reaches to the maximal value, 0.5, for L ? 10500 km. For sin2?13 = 0.1\n14\n0 5000 100000\n0.2\n0.4\n0.6\n0.8\n1\nmin1\nmax1\nmin2\nmax2\nbaseline length L [km]\n-? and ?+?, sin2?13=0.2, cos2?23=0\n-? and ?+?, sin2?13=0.2, cos2?23=0\n?? ?+?\n0 5000 10000\nbaseline length L [km]\n0\n0.2\n0.4\n0.6\n0.8\n1\nmin1\nmax1\nmin2\nmax2\n?? and ?+?, sin2?13=0.3, cos2?23=0\n?+???\nFIG. 10: The coefficients ?? and ?+? evaluated along energy curves in the right panel of Fig. 3.\nThe coefficients are calculated with sin2?13 = 0.2 and 0.3 on the left and right panels respectively.\nThe thick curves denote values of ?? while thin curves denote those of ?+?. For solid and dotted\ncurves, the thick curves generally dominate over the corresponding thin ones. For dashed and\ndotted-dashed curves, the thin curves generally dominate over the thick ones.\nand 0.2, ?+? rises quickly as the baseline length L surpasses 10674 km. We note that the\nvalue of Pe? is proportional to ?+?. Hence ?+? shown in Fig. 9 is its own maximal value\nfor each baseline length L.\nThe contour structure of P?? can be analyzed through the quadratic polynomial f(y,z)\nin y. If ?? ? ?+?, generally there are two solution curves for f(y,z) = p compatible with\nthe ranges of y and z where p is a given value for P??. Let us suppose that z ? sin2?13\nis measured in the future [27, 28] with a central value z0. The two solution curves for the\nequation f(y,z) = p then intersect with the straight line z ? sin2?13 = z0 at two points\n(y1,z0) and (y2,z0). This is actually what we have seen in Fig. 7 for local minima of P??. If,\non the other hand, ?? ? ? + ? or even ?? ? ? + ?, there exists only one solution curve\nfor the equation f(y,z) = p. This is because that the two points (y1,z0) and (y2,z0) can not\nsimultaneously satisfy the constraint ?0.316 < y < 0.316 since |y1 +y2| = ?(?+?)/? ? 1.\nThis is actually what we have seen in Fig. 7 for local maxima of P??. To justify this\nobservation, it remains to show that the coefficient ?? dominates over ? + ? at energies\ncorresponding to local minima of P?? while the latter dominates over the former at energies\ncorresponding to local maxima of P??. This is clearly demonstrated in Fig. 10 where the\n15\ncoefficients ?? and ? + ? are evaluated along energy curves in the right panel of Fig. 3.\nWe have calculated the coefficients with cos2?23 = 0 and sin2?13 = 0.2, 0.3 respectively.\nWe remark that other choices for cos2?23 do not produce noticeable changes on the energy\ncurves where ?? and ? + ? are evaluated.\nIt is easily seen that ?+? always dominates over ?? when these coefficients are evaluated\natenergies alongmax1 ormax2inthe right panelofFig.3. Insuch cases, the ?23 degeneracy\nis absent in the solutions of f(y,z) = p. Namely there exists only one solution curve for\nthe above equation. Reversely, ?? always dominates over ?+? when these coefficients are\nevaluated at energies along min1. The situation is slightly more complicated when these\ncoefficients are evaluated at energies along min2. In this case ?? no longer dominates\nover ? + ? for baseline lengths around 104 km. In fact, with sin2?13 = 0.3, ? + ? is even\nlarger than ?? for 9000 ? L/km ? 10500. This explains the contour structure of P??\nat L = 10000 km (see Fig. 7) where the straight line z = 0.3 only intersects one equal\nprobability curve f(y,z = 0.3) = p. The straight line z = 0.2 also behaves the same except\nfor a very small p. We reiterate that the range for y ? cos2?23 is ?0.316 < y < 0.316 due\nto the constraint sin2 2?23 > 0.9 [2]. Therefore, given z = z0, the equation f(y,z0) = p could\nhave only one solution for y if ?(?(z0) +?(z0))/?(z0) > 0.632. In other words, such values\nof ?(?(z0) + ?(z0))/?(z0) lead to the absence of ?23 degeneracy. In fact, the condition for\nthe absence of ?23 degeneracy is even more relaxed. To see this, let us divide our discussions\naccording to the true octant of ?23.\n1. min2, ?23 < pi/4\nSince ? < 0 and ? + ? > 0, the two solutions for y in f(y,z0) = p are both negative for\n1??(z0)?p > 0 while they have opposite signs for 1??(z0)?p < 0. If the true value of\n?23 is less than pi/4, i.e., the true value of y is positive, then the experimental measurement\nshould give 1??(z0)?p < 0 so that a positive solution for y exists. With 1??(z0)?p <\n0, the two solutions for f(y,z0) = p have opposite signs and the negative solution has\na larger absolute value. The negative solution will violate the constraint ?0.316 < y if\n?(?(z0) + ?(z0))/?(z0) > 0.316. For z0 = 0.2, ?(?(z0) + ?(z0))/?(z0) > 0.316 is valid\nfor 8300 ? L/km ? 10770. For z = 0.3, the above baseline range is extended to 7410 ?\nL/km ? 10790.\n16\n2. min2, ?23 > pi/4\nWith a true value of ?23 greater than pi/4, i.e., the true value of y less than zero, the\nvalue of 1 ? ?(z0) ? p can either be positive or negative. The condition 1 ? ?(z0) ? p >\n(<)0 is equivalent to the condition |y| < (>)(?(z0) +?(z0))/(??(z0)). For ?(?(z0) +\n?(z0))/?(z0) > 0.316, one must have 1 ? ?(z0) ? p > 0. Hence there exist two negative\nsolutions for y. In this case, the corresponding solutions for ?23 are both located in the same\noctant. For 0.316 < ?(?(z0)+?(z0))/?(z0) < 0.632, the spurious solution for y may or may\nnot violate the constraint y > ?0.316. For ?(?(z0) + ?(z0))/?(z0) > 0.632, the spurious\nsolution for y must violate the constraint y > ?0.316, hence the ?23 degeneracy is surely\nabsent. For sin2?13 = 0.2, the condition ?(?(z0)+?(z0))/?(z0) > 0.632 can not be achieved\nalong min2. For sin2?13 = 0.3, the above condition is satisfied for 8270 ? L/km ? 10720.\nFor ?(?(z0) + ?(z0))/?(z0 < 0.316, 1 ? ?(z0) ?p can either be positive or negative. For\n1??(z0)?p > 0, both solutions for y are negative and satisfying the constraint y > ?0.316.\nFor 1 ? ?(z0) ? p < 0, both solutions for y satisfy the constraint ?0.316 < y < 0.316.\nHowever their corresponding ?23 angles are situated in different octants.\nLet us summarize the results obtained in this subsection. The coefficient ?+? dominates\nover ?? for energy values along curves max1 and max2 for all baseline lengths. Hence the\n?23 degeneracy is absent along these energy curves for all baseline lengths. The situation\nalong the curve min1 is just the opposite, the coefficient ?? dominates over ? + ? for all\nbaseline lengths. Hence the ?23 degeneracy is present for all baseline lengths in this case.\nThe issue of ?23 degeneracy becomes more complicated along min2, which we have discussed\naccording to the true octant of ?23. Along the energy curve min2, the non-degeneracy\nbaseline range is larger for the ?23 < pi/4 case.\nIV. DISCUSSIONS AND CONCLUSIONS\nWe have presented the baselines and energies ideal for probing the octant of ?23 through\nneutrino oscillations. The appearance mode ?e ? ?? can be studied in a very long baseline\nwith the facility of neutrino factory [29] or the more recent proposed ? beam [30]. As said,\nthe sensitivity of Pe? to ?23 is dg(y,z)/dy = ?(?(z) + ?(z)) where g(y,z) represents Pe? in\nthe analytic approximation given by Eq. (12). The maximal value of ?+? for each baseline\n17\nlength is shown in Fig. 9. At the magic baseline, L = 7600 km, ?+? = 0.06, 0.21 and 0.38\nfor sin2?13 = 0.1, 0.2 and 0.3 respectively. For a sufficiently large sin2?13 and a baseline\nlength close to the magic value [14, 15, 16], Pe? is ideal for probing the octant of ?23.\nThe probability P?? is also relevant in neutrino oscillation experiments with neutrino\nfactories. The sensitivity of this probability to ?23 is determined by the derivative\nr ? dP??dcos2?\n23\n= ?2?cos2?23 + (? + ?). (15)\nSince ? is negative, the sensitivity r is larger for cos2?23 > 0, i.e., ?23 < pi/4. For a\nmeasurement performed around a local maximum of P??, the sensitivity to ?23 is completely\ndetermined by the coefficient ?+?, since the coefficient ? is generally rather suppressed in\nthis case. Along the energy curve denoted by max1, ?+? peaks at 7480 km for sin2?13 = 0.2\nand it peaks at L = 7350 km for sin2?13 = 0.3. The values of ?+? at those peaks are 0.17\nand 0.32 respectively. Along the curve max2, ? + ? peaks around L = 10750 km for both\nsin2?13 = 0.2 and 0.3 with values 0.43 and 0.48 respectively.\nFor a measurement performed around a local minimum of P??, the sensitivity to ?23 is\ndetermined by both coefficients ?? and ? + ?. Along the energy curve denoted by min1,\nthe coefficient ?? is always close to unity while the coefficient ? + ? is always suppressed\nfor all baseline lengths. It is understood that the magnitude of ? + ? determines the size\nof matter effects. Hence the matter effect is small at energies along the curve min1. The\nsuppression of ? + ? compared to ?? leads to the ?23 degeneracy as discussed before. The\nbehavior of P?? along the energy curve min2 is more interesting. If the true value of ?23\nis less than pi/4, the ?23 degeneracy from the measurement of P?? is absent in the baseline\nrange 8300 ? L/km ? 10770 for sin2?13 = 0.2. The above non-degeneracy baseline range\nextends to 7410 ? L/km ? 10790 for sin2?13 = 0.3. On the other hand, if the true ?23\nis greater than pi/4, the non-degeneracy baseline range does not exist along the energy\ncurve min2 for sin2?13 = 0.2. For sin2?13 = 0.3, the non-degeneracy baseline range is\n8270 ? L/km ? 10720.\nThe existence of non-degeneracy baseline range along the energy curve min2 has impor-\ntant implications. It can be seen from Fig. 3 that the curve min2 lies in between curves\nmax1 and max2. Since the degeneracy of ?23 is absent on both max1 and max2 for all\nbaselines, it is possible that there exists a non-degeneracy region spanned by ranges of the\nbaseline length and the neutrino energy. For example, with sin2?13 = 0.2 and a true value of\n18\nTABLE I: The baseline range in which the ?23 degeneracy is absent in the probability P?? for all\nenergy values between the curves max2 and max1. The entry corresponding to ?23 > pi/4 and\nsin2?13 = 0.2 is left blank since, with such set of parameters, there exists no baseline length where\nthe condition for the absence of ?23 degeneracy can be satisfied.\n?23 octant sin2?13 = 0.2 sin2?13 = 0.3\n?23 < pi/4 8550 ? L/km ? 10680 7950 ? L/km ? 10700\n?23 > pi/4 8450 ? L/km ? 10680\n?23 less than pi/4, the ?23 degeneracy is absent for 8300 ? L/km ? 10770 for energies along\ncurves max2, min2 and max1. It is of great interest to investigate if the ?23 degeneracy is\nalso absent for any neutrino energy larger than the value on max2 and smaller than that on\nmax1. By taking all these energies into account, we find that the ?23 degeneracy is absent\nfor 8550 ? L/km ? 10680. For a true value of ?23 greater than pi/4 and sin2?13 = 0.3,\nthe ?23 degeneracy is absent for 8270 ? L/km ? 10720 for energies along curves max2,\nmin2 and max1. However, with all energies between curves max2 and max1 considered,\nwe find that the ?23 degeneracy is absent for 8450 ? L/km ? 10680. The non-degeneracy\nbaseline range corresponding to different combinations of ?23 and ?13 values are summarized\nin Table I.\nIt is interesting to compare measurements on Pe? and P?? since both oscillations appear\nin experiments with neutrino factories [29]. The main issue for comparison is on the deter-\nmination of the true ?23 value under the assumption that both the sign of ?m231 and the\nvalue of sin2?13 are known. Let us begin the discussion with a true value of ?23 less than pi/4\nand sin2?13 = 0.2. For L < 8550 km, the appearance mode ?e ? ?? is useful for probing the\noctant of ?23, in particular for L close to the magic value, 7600 km. However, the survival\nmode ?? ? ?? is not as useful since the ?23 degeneracy is absent only at energies near max1\nand max2. Concerning the sensitivity to ?23, we note that the differentiation of Pe? with\nrespect to cos2?23 is ?(?+?). The value of ?+? increases with L as shown in Fig. 9. It is\n0.21 at L = 7600 km, and 0.26 at L = 8550 km. For 8550 ? L/km ? 10680, both ?e ? ??\nand ?? ? ?? are useful for probing the octant of ?23. We note that peak positions of Pe?\nare mostly around 6 GeV. Hence they overlap with the non-degeneracy energy range of P??.\nFrom Eq. (15) and our assumption of ?23 < pi/4, we find that P?? is more sensitive to ?23\n19\nas compared to Pe? for the same neutrino energy. For L > 10680 km, ?e ? ??, is again the\nonly useful mode for probing the octant of ?23.\nLet us turn to the case where the true value of ?23 is greater than pi/4 and sin2?13 = 0.2.\nIn such a case, the value for Pe? is enhanced compared to that with y > 0. Furthermore\nPe? is always more sensitive to cos2?23 as compared to P?? for the same neutrino energy.\nIt is clear that the ?e ? ?? appearance mode is more useful for probing ?23 regardless the\nbaseline length. Although there exists a baseline range where the ?23 degeneracy is absent\nin P?? for neutrino energies between curves max2 and max1. However this requires a large\nvalue of sin2?13, such as sin2?13 = 0.3.\nIt is essential to remark that the above non-degeneracy baseline range is not sensitive to\nthe value of ?m231, which we have so far taken to be 2.4 ? 10?3 eV2. Changing the value\nof ?m231 only shifts the probability curves in Fig. 4 and Fig. 6 so that positions for local\nmaxima and local minima of these probabilities shift accordingly. However, the maximal or\nminimal values of these probabilities remain unchanged. In other words, although the energy\ncurves in Fig. 3 are shifted, the coefficients ?? and ?+? plotted in Fig. 10, which combine\nto form Pe? and P?? (see Eq. (12)), remain the same. The values of these coefficients as\nfunctions of the baseline length L then determine the non-degeneracy baseline range.\nInconclusion, we have studied theprobabilities Pe? andP?? forvery longbaseline neutrino\noscillations. We focus on sensitivities of these probabilities to mixing angles ?13, ?23 and the\nCP violation phase ?CP. Taking ?CP = 0 as an example, we presented contour graphs of\nPe? and P?? in the sin2?13 ? cos2?23 plane for baseline lengths L = 1000 km, 5000 km,\n10000 km and 12000 km. The energy values chosen for such studies are in the vicinities of\neither local minima or local maxima of neutrino oscillation probabilities. For each baseline\nlength, we have found that P?? is more sensitive to sin2?13 at energies around its local\nmaxima while it is more sensitive to cos2?23 at energies around its local minima. On the\nother hand, the appearance probability Pe? is sensitive to sin2?13 and cos2?23 only near its\nlocal maximum. Such findings have been applied to probe the octant of mixing angle ?23\nassuming that the angle ?13 and the sign of ?m231 are known. The appearance probability\nPe? is non-degenerate in ?23. The sensitivity of Pe? to cos2?23 is studied for baseline lengths\nfrom 1000 km to 12000 km. We also studied the sensitivity of P?? to cos2?23 for the same\nrange of baseline length. We have identified the ranges of neutrino energy and baseline\nlengths where the ?23 degeneracy is absent. We have pointed out that, for a true value of ?23\n20\nless than pi/4 and a baseline length between 8000 and 10000 km, the survival mode ?? ? ??\nis equally good as the appearance mode ?e ? ?? for probing the octant of ?23.\nAcknowledgements\nG.L.L likes to thank D. Indumathi for informative discussions. This work is supported\nby National Science Council of Taiwan under the grant number NSC 94-2112-M-009-026.\n[1] Y. Ashie et al. [Super-Kamiokande Collaboration], Phys. Rev. D 71, 112005 (2005)\n[arXiv:hep-ex/0501064].\n[2] Y. Ashie et al. [Super-Kamiokande Collaboration], Phys. Rev. Lett. 93 (2004) 101801\n[arXiv:hep-ex/0404034].\n[3] E. Aliu et al. [K2K Collaboration], Phys. Rev. Lett. 94 (2005) 081802 [arXiv:hep-ex/0411038].\n[4] M. H. Ahn et al. [K2K Collaboration], Phys. Rev. D74, 072003 (2006) [arXiv:hep-ex/0606032].\n[5] K. Eguchi et al. [KamLAND Collaboration], Phys. Rev. Lett. 90 (2003) 021802\n[arXiv:hep-ex/0212021].\n[6] T. Araki et al. [KamLAND Collaboration], Phys. Rev. Lett. 94 (2005) 081801\n[arXiv:hep-ex/0406035].\n[7] See G. L. Fogli, E. Lisi, A. Marrone and A. Palazzo, Prog. Part. Nucl. Phys. 57, 742 (2006)\n[arXiv:hep-ph/0506083], which contains a list of original references on solar neutrino oscilla-\ntions.\n[8] G. L. Fogli and E. Lisi, Phys. Rev. D 54, 3667 (1996) [arXiv:hep-ph/9604415].\n[9] M. Apollonio et al. [CHOOZ Collaboration], Phys. Lett. B 466, 415 (1999)\n[arXiv:hep-ex/9907037].\n[10] F. Boehm et al., Phys. Rev. D 64, 112001 (2001) [arXiv:hep-ex/0107009].\n[11] I. Mocioiu and R. Shrock, Phys. Rev. D 62, 053017 (2000) [arXiv:hep-ph/0002149];\nV. D. Barger, S. Geer, R. Raja and K. Whisnant, Phys. Lett. B 485, 379 (2000)\n[arXiv:hep-ph/0004208]; V. D. Barger, S. Geer, R. Raja and K. Whisnant, Phys. Rev. D\n62, 013004 (2000) [arXiv:hep-ph/9911524]; M. Freund, M. Lindner, S. T. Petcov and A. Ro-\nmanino, Nucl. Phys. B 578, 27 (2000) [arXiv:hep-ph/9912457]; M. Freund, P. Huber and\n21\nM. Lindner, Nucl. Phys. B 585, 105 (2000) [arXiv:hep-ph/0004085]; A. Cervera, A. Donini,\nM. B. Gavela, J. J. Gomez Cadenas, P. Hernandez, O. Mena and S. Rigolin, Nucl. Phys. B\n579, 17 (2000) [Erratum-ibid. B 593, 731 (2001)] [arXiv:hep-ph/0002108].\n[12] D. Choudhury and A. Datta, JHEP 0507, 058 (2005) [arXiv:hep-ph/0410266]; D. Indu-\nmathi and M. V. N. Murthy, Phys. Rev. D 71, 013001 (2005) [arXiv:hep-ph/0407336];\nS. Choubey and P. Roy, Phys. Rev. D 73, 013006 (2006) [arXiv:hep-ph/0509197]. D. In-\ndumathi, M. V. N. Murthy, G. Rajasekaran and N. Sinha, Phys. Rev. D 74, 053004 (2006)\n[arXiv:hep-ph/0603264].\n[13] We adopt the approach of M. Freund and T. Ohlsson, Mod. Phys. Lett. A 15, 867 (2000)\n[arXiv:hep-ph/9909501], by dividing the Earth density regions into the Earth mantle and the\nEarth core. However we have further introduced the concept of average density to be discussed\nin details later.\n[14] V. Barger, D. Marfatia and K. Whisnant, Phys. Rev. D 65, 073023 (2002)\n[arXiv:hep-ph/0112119].\n[15] P. Huber and W. Winter, Phys. Rev. D 68, 037301 (2003) [arXiv:hep-ph/0301257].\n[16] A. Y. Smirnov, arXiv:hep-ph/0610198.\n[17] Z. Maki, M. Nakagawa and S. Sakata, Prog. Theor. Phys. 28, 870 (1962); see also , B. Pon-\ntecorvo, Zh. Eksp. Teor. Fiz. 53, 1717 (1967) [Sov. Phys. JETP 26, 984 (1968)].\n[18] A. Dziewonski, Earth Structure, Global, in: The Encyclopedia of Solid Earth Geophysics,\nDavid E. James, ed. (Van Nostrand Reinhold, New York 1989) p. 331.\n[19] M. V. Chizhov and S. T. Petcov, Phys. Rev. D 63, 073003 (2001) [arXiv:hep-ph/9903424];\nM. V. Chizhov and S. T. Petcov, Phys. Rev. Lett. 83, 1096 (1999) [arXiv:hep-ph/9903399].\n[20] E. K. Akhmedov, Nucl. Phys. B 538, 25 (1999) [arXiv:hep-ph/9805272].\n[21] S. T. Petcov, Phys. Lett. B 214, 259 (1988).\n[22] J. Bernabeu, S. Palomares-Ruiz, A. Perez and S. T. Petcov, Phys. Lett. B 531, 90 (2002)\n[arXiv:hep-ph/0110071].\n[23] Y. C. Hsu, Master Thesis, NCTU (2005).\n[24] See E. K. Akhmedov, R. Johansson, M. Lindner, T. Ohlsson and T. Schwetz, JHEP 0404,\n078 (2004) [arXiv:hep-ph/0402175] and earlier works cited in this paper.\n[25] J. N. Bahcall, M. C. Gonzalez-Garcia and C. Pena-Garay, JHEP 0408 (2004) 016\n[arXiv:hep-ph/0406294].\n22\n[26] I. Mocioiu and R. Shrock, JHEP 0111, 050 (2001) [arXiv:hep-ph/0106139].\n[27] F. Ardellier et al. [Double Chooz Collaboration], arXiv:hep-ex/0606025.\n[28] Y. Wang, arXiv:hep-ex/0610024.\n[29] S. Geer, Phys. Rev. D 57, 6989 (1998) [Erratum-ibid. D 59, 039903 (1999)]\n[arXiv:hep-ph/9712290]; A. De Rujula, M. B. Gavela and P. Hernandez, Nucl. Phys. B 547,\n21 (1999) [arXiv:hep-ph/9811390]; V. D. Barger, S. Geer and K. Whisnant, Phys. Rev. D 61,\n053004 (2000) [arXiv:hep-ph/9906487].\n[30] P. Zucchelli, Phys. Lett. B 532, 166 (2002).\n23\n"}
{"id":"oai:arXiv.org:quant-ph/0602178","text":"arXiv:q-bio/0601020v1  [q-bio.BM]  14 Jan 2006\nComputation of protein geometry and its applications: Packing and\nfunction prediction\nJie Liang\nFebruary 9, 2008\nContents\n6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n6.2 Theory and Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n6.2.1 The idealized ball model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n6.2.2 Surface models: Lee-Richards and Connolly?s surfaces . . . . . . . . . . . . . . . . . . 2\n6.2.3 Geometric constructs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n6.2.4 Topological structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n6.2.5 Metric measurement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n6.3 Computation and software . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n6.4 Applications: Packing analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n6.5 Applications: Protein function prediction from structures. . . . . . . . . . . . . . . . . . . . . 13\n6.6 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n6.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n6.8 Further reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n6.9 Acknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n6.1 Introduction\nThree-dimensional atomic structures of protein molecules provide rich information for understanding how\nthese working molecules of a cell carry out their biological functions. With the amount of solved protein\nstructures rapidly accumulating, computation of geometric properties of protein structure becomes an indis-\npensable component in studies of modern biochemistry and molecular biology. Before we discuss methods for\ncomputing the geometry of protein molecules, we first briefly describe how protein structures are obtained\nexperimentally.\nThereareprimarilythree experimentaltechniques for obtainingprotein structures: X-raycrystallography,\nsolution nuclear magnetic resonance (NMR), and recently freeze-sample electron microscopy (cryo-EM). In\nX-ray crystallography, the diffraction patterns of X-ray irradiation of a high quality crystal of the protein\nmolecule are measured. Since the diffraction is due to the scattering of X-rayby the electrons of the molecules\nin the crystal, the position, the intensity, and the phase of each recorded diffraction spot provide information\nfor the reconstruction of an electron density map of atoms in the protein molecule. Based on independent\ninformation of the amino acid sequence, a model of the protein conformation is then derived by fitting model\nconformations of residues to the electron density map. An iterative process called refinement is then applied\nto improve the quality of the fit of the electron density map. The final model of the protein conformation\nconsists of the coordinates of each of the non-hydrogen atoms [1].\nThe solution NMR technique for solving protein structure is based on measuring the tumbling and\nvibrating motion of the molecule in solution. By assessing the chemical shifts of atomic nuclei with spins due\nto interactions with other atoms in the vicinity, a set of estimated distances between specific pairs of atoms\ncan be derived from NOSEY spectra. When a large number of such distances are obtained, one can derive\na set of conformations of the protein molecule, each is consistent with all of the distance constraints [2].\nAlthough determining conformations from either X-ray diffraction patterns or NMR spectra is equivalent to\nsolving an ill-posed inverse problem, technique such as Bayesian Markov chain Monte Carlo with parallel\n1\ntempering has been shown to be effective in obtaining protein structures from NMR spectra [3]. The cryo-EM\ntechnique for obtaining protein structure is described in more details in Chapter 11.\n6.2 Theory and Model\n6.2.1 The idealized ball model\nThe shape of a protein molecule is complex. The chemical properties of atoms in a molecule are determined\nby their electron charge distribution. It is this distribution that generates the scattering patterns of the\nX-ray diffraction. Chemical bonds between atoms lead to transfer of electronic charges from one atom to\nanother, and the resulting isosurfaces of the electron density distribution depend not only on the location of\nindividual nuclei but also on interactions between atoms. This results in an overall complicated isosurface\nof electron density [4].\nThe geometric model of macromolecule amenable to convenient computation is an idealized model, where\nthe shapes of atoms are approximated by three-dimensional balls. The shape of a protein or a DNA molecule\nconsisting of many atoms is then the space-filling shape taken by a set of atom balls. This model is often\ncalled the interlocking hard-sphere model, the fused ball model, the space filling model [5?8], or the union\nof ball model [9]. In this model, details in the distribution of electron density, e.g., the differences between\nregions of covalent bonds and non-covalent bonds, are ignored. This idealization is quite reasonable, as it\nreflects the fact that the electron density reaches maximum at a nucleus, and its magnitude decays almost\nspherically away from the point of the nucleus. Despite possible inaccuracy, this idealized model has found\nwide acceptance, because it enables quantitative measurement of important geometric properties (such as\narea and volume) of molecules. Insights gained from these measurements correlate well with experimental\nobservations [5,8,10?13].\nIn this idealization, the shape of each atom is that of a ball, and its size parameter is the ball radius.\nThere are many possible choices for the parameter set of atomic radii [14,15]. Frequently, atomic radii are\nassigned the values of their van der Waals radii [16]. Among all these atoms, hydrogen atom has the smallest\nmass, and has a much smaller radius than those of other atoms. For simplification, the model of united\natom is often employed to approximate the union of a heavy atom and the hydrogen atoms connected by a\ncovalent bond. In this case, the radius of the heavy atom is increased to approximate the size of the union of\nthe two atoms. This practice significantly reduces the total number of atom balls in the molecule. However,\nthis approach has been questioned for possible inadequacy [17].\nThe mathematical model of this idealized model is that of the union of balls [9]. For a molecule M of n\natoms, the i-th atom is modeled as a ball bi, whose center is located at zi ? R3, and the radius of this ball\nis ri ? R, namely, we have bi ? {x|x ? R3,||x?zi|| ? ri} parameterized by (zi,ri). The molecule M is\nformed by the union of a finite number n of such balls defining the set B:\nM =\nuniondisplay\nB =\nnuniondisplay\ni=1\n{bi}.\nIt creates a space-filling body corresponding to the union of the excluded volumes vol(uniontextni=1 bi) [9]. When\nthe atoms are assigned the van der Waals radii, the boundary surface ?uniontextB of the union of balls is called\nthe van der Waals surface.\n6.2.2 Surface models: Lee-Richards and Connolly?s surfaces\nProtein folds into native three-dimensional shape to carry out its biological functional roles. The interac-\ntions of a protein molecule with other molecules (such as ligand, substrate, or other protein) determine its\nfunctional roles. Such interactions occur physically on the surfaces of the protein molecule.\nThe importance of protein surface was recognized very early on. Lee and Richards developed the widely\nused solvent accessible surface (SA) model, which is also often called the Lee-Richards surface model [5].\n2\nba c\nFigure 6.1: Geometric models of protein surfaces. (a) The solvent accessible surface (SA surface) is shown\nin the front. The van der Waals surface (beneath the SA surface) can be regarded as a shrunken version\nof the SA surface by reducing all atomic radii uniformly by the amount of the radius of the solvent probe\nrs = 1.4?A. The elementary pieces of the solvent accessible surface are the three convex spherical surface\npieces, the three arcs, and the vertex where the three arcs meet. (b) The molecular surface (MS, beneath\nthe SA surface) also has three types of elementary pieces: the convex spheric pieces, which are shrunken\nversion of the corresponding pieces in the solvent accessible surface, the concave toroidal pieces, and concave\nspheric surface. The latter two are also called the re-entrant surface. (c) The toroidal surface pieces in the\nmolecular surface, correspond to the arcs in the solvent accessible surface, and the concave spheric surface\nto the vertex. The set of elements in one surface can be continuously deformed to the set of elements in the\nother surface.\nIntuitively, this surface is obtained by rolling a ball of radius rs everywhere along the van der Waals surface of\nthe molecule. The center of the solvent ball will then sweep out the solvent accessible surface. Equivalently,\nthe solvent accessible surface can be viewed as the boundary surface ?uniontextBrs of the union of a set of inflated\nballs Brs, where each ball takes the position of an atom, but with an inflated radius ri + rs (Fig. 6.1a).\nThe solvent accessible surface in general has many sharp crevices and sharp corners. In hope of obtaining\na smoother surface, one can take the surface swept out by the front instead of the center of the solvent ball.\nThis surface is the molecular surface (MS model), which is often called the Connolly?s surface after Michael\nConnolly who developed the first algorithm for computing molecular surface [11]. Both solvent accessible\nsurface and molecular surface are formed by elementary pieces of simpler shape.\nElementary pieces. For the solvent accessible surface model, the boundary surface of a molecule consists\nof three types of elements: the convex spherical surface pieces, arcs or curved line segments (possibly a\nfull circle) formed by two intersecting spheres, and a vertex that is the intersection point of three atom\nspheres. The whole boundary surface of the molecules can be thought of as a surface formed by stitching\nthese elements together.\nSimilarly, the molecular surface swept out by the front of the solvent ball can also be thought of as being\nformed by elementary surface pieces. In this case, they are the convex spherical surface pieces, the toroidal\nsurface pieces, and the concave or inverse spherical surface pieces (Fig. 6.1b) . The latter two types of surface\npieces are often called the ?re-entrant surfaces? [8,11].\nThe surface elements of the solvent accessible surface and the molecular surface are closely related.\nImagine a process where atom balls are shrunk or expanded. The vertices in solvent accessible surface\nbecomes the concave spherical surface pieces, the arcs becomes the toroidal surfaces, and the convex surface\npieces become smaller convex surface pieces (Fig. 6.1c). Because of this mapping, these two type of surfaces\nare combinatorically equivalent and have similar topological properties, i.e., they are homotopy equivalent.\nHowever, the SA surface and the MS surface differ in their metric measurement. In concave regions of a\nmolecule, often the front of the solvent ball can sweep out a larger volume than the center of the solvent ball.\nA void of size close to zero in solvent accessible surface model will correspond to a void of the size of a solvent\nball (4pir3s/3). It is therefore important to distinguish these two types of measurement when interpreting the\nresults of volume calculations of protein molecules. The intrinsic structures of these fundamental elementary\n3\nvoid\na cb\nFigure 6.2: Geometry of a simplified two dimensional model molecule, to illustrate the geometric constructs\nand the procedure mapping the Voronoi diagram to the Delaunay triangulation. (a) The molecule formed by\nthe union of atom disks of uniform size. Voronoi diagram is in dashed lines. (b) The shape enclosed by the\nboundary polygon is the convex hull. It is tessellated by the Delaunay triangulation. (c) The alpha shape of\nthe molecule is formed by removing those Delaunay edges and triangles whose corresponding Voronoi edges\nand Voronoi vertices do not intersect with the body of the molecule. A molecular void is represented in the\nalpha shape by two empty triangles.\npieces are closely related to several geometric constructs we describe below.\n6.2.3 Geometric constructs\nVoronoi diagram. Voronoi diagram (Fig 6.2a), also known as Voronoi tessellation, is a geometric construct\nthat has been used for analyzing protein packing in the early days of protein crystallography [6,18,19]. For\ntwo dimensional Voronoi diagram, we consider the following analogy. Imagine a vast forset containing a\nnumber of fire observation towers. Each fire ranger is responsible for putting out any fire closer to his/her\ntower than to any other tower. The set of all trees for which a ranger is responsible constitutes the Voronoi\ncell associated with his/hertower, and the map of rangerresponsibilities, with towersand boundariesmarked,\nconstitutes the Voronoi diagram.\nWe formalize this for three dimensional space. Consider the point set S of atom centers in three dimen-\nsional space R3. The Voronoi region or Voronoi cell Vi of an atom bi with atom center zi ? R3 is the set of\nall points that are at least as close to zi than to any other atom centers in S:\nVi = {x ?R3|||x?zi|| ? ||x?zj||,zj ? S}. (6.1)\nWe can have an alternative view of the Voronoi cell of an atom bi. Considering the distance relationship of\natom center zi with the atom center zk of another atom bk. The plane bisecting the line segment connecting\npoints zi and zk divides the full R3 space into two half spaces, where points in one half space is closer to\nzi than to zk, and points in the other allspice is closer to zk than to zi. If we repeat this process and take\nzk in turn from the set of all atom centers other than zi, we will have a number of halfspaces where points\nare closer to zi than to each of the atom center zk. The Voronoi region Vi is then the common intersections\nof these half spaces, which is convex. When we consider atoms of different radii, we replace the Euclidean\ndistance ||x?zi|| with the power distance defined as: pii(x) ? ||x?zi||2 ?r2i .\nDelaunay tetrahedrization. Delaunay triangulation in R2 or Delaunay tetrahedrization in R3 is a geo-\nmetric construct that is closely related to the Voronoi diagram (Fig 6.2b). In general, it uniquely tessellates\nor tile up the space of the convex hull of the atom centers in R3 with tetrahedra. Convex hull for a point\n4\nset is the smallest convex body that contains the point set 1. The Delaunay tetrahedrization of a molecule\ncan be obtained from the Voronoi diagram. Consider that the Delaunay tetrahedrization is formed by gluing\nfour types of primitive elements together: vertices, edges, triangles, and tetrahedra. Here vertices are just\nthe atom centers. We obtain a Delaunay edge by connecting atom centers zi and zj if and only if the\nVoronoi regions Vi and Vj have a common intersection, which is a planar piece that may be either bounded\nor extend to infinity. We obtain a Delaunay triangle connecting atom centers zi, zj, and zk if the common\nintersection of Voronoi regions Vi,Vj and Vk exists, which is either a line segment, or a half-line, or a line\nin the Voronoi diagram. We obtain a Delaunay tetrahedra connecting atom centers zi,zj,zk and zl if and\nonly if the Voronoi regions Vi,Vj,Vk and Vl intersect at a point.\n6.2.4 Topological structures\nDelaunay complex. The structures in both Voronoi diagram and Delaunay tetrahedrization are better\ndescribed with concepts from algebraic topology. We focus on the intersection relationship in the Voronoi\ndiagram and introduce concepts formalizing the primitive elements. In R3, between two to four Voronoi re-\ngions may have common intersections. We use simplices of various dimensions to record these intersection or\noverlap relationships. We have vertices ?0 as 0-simplices, edges ?1 as 1-simplices, triangles ?2 as 2-simplices,\nand tetrahedra ?3 as 3-simplices. Each of the Voronoi plane, Voronoi edge, and Voronoi vertices corresponds\nto a 1-simplex (Delaunay edge), 2-simplex (Delaunay triangle), and 3-simplex (Delaunay tetrahedron), re-\nspectively. If we use 0-simplices to represent the Voronoi cells, and add them to the simplices induced by\nthe intersection relationship, we can think of the Delaunay tetrahedrization as the structure obtained by\n?glueing? these simplices properly together. Formally, these simplices form a simplicial complex K:\nK = {?|I|?1|\nintersectiondisplay\ni?I\nVi negationslash= ?}, (6.2)\nwhere I is an index set for the vertices representing atoms whose Voronoi cells overlap, and |I|? 1 is the\ndimension of the simplex.\nAlpha shape and protein surfaces. Imagine we can turn a knob to increase or decrease the size of all\natoms simultaneously. We can then have a model of growing balls and obtain further information from the\nDelaunay complex about the shape of a protein structure. Formally, we use a parameter ? ? R to control\nthe size of the atom balls. For an atom ball bi of radius ri, we modified its radius ri at a particular ? value\nto ri(?) = (r2i +?)1/2. When ?ri < ? < 0, the size of an atom is shrunk. The atom could even disappear if\n? < 0 and |?| > ri. We start to collect the simplices at different ? value as we increase ? from ?? to +?\n(see Fig 6.3 for a two-dimensional example). At the beginning, we only have vertices. When ? is increased\nsuch that two atoms are close enough to intersect, we collect the corresponding Delaunay edge that connects\nthese two atom centers. When three atoms intersect, we collect the correspondingDelaunay triangle spanning\nthese three atom centers. When four atoms intersect, we collect the corresponding Delaunay tetrahedron.\nAt any specific ? value, we have a dual simplicial complex or alpha complex K? formed by the collected\nsimplices. If all atoms take the incremented radius of ri +rs and ? = 0, we have the dual simplicial complex\nK0 of the protein molecule. When ? is sufficiently large, we have collected all simplices and we get the full\nDelaunay complex. This series of simplicial complexes at different ? value form a family of shapes (Fig 6.3),\ncalled alpha shapes, each faithfully represents the geometric and topological property of the protein molecule\nat a particular resolution parametrized by the ? value.\nAn equivalent way to obtain the alpha shape at ? = 0 is to take a subset of the simplices, with the\nrequirement that the corresponding intersections of Voronoi cells must overlap with the body of the union\n1For a two dimensional toy molecule, we can imagine that we put nails at the locations of the atom centers, and tightly wrap\na rubber band around these nails. The rubber band will trace out a polygon. This polygon and the region enclosed within\nis the convex hull of the set of points corresponding to the atom centers. Similarly, imagine if we can tightly wrap a tin-foil\naround a set of points in three dimensional space, the resulting convex body formed by the tin-foil and space enclosed within\nis the convex hull of this set of points in R3.\n5\na b c\nd e f\nFigure 6.3: The family of alpha shapes or dual simplicial complexes for a two-dimensional toy molecule.\n(a) We collect simplices from the Delaunay triangulation as atoms grow by increasing the ? value. At the\nbeginning as ? grows from ??, atoms are in isolation and we only have vertices in the alpha shape. (b) and\n(c) When ? is increased such that some atom pairs start to intersect, we collect the corresponding Delaunay\nedges. (d) When three atoms intersect as ? increases, we collect the corresponding Delaunay triangles.\nWhen ? = 0, the collection of vertices, edges, and triangles form the dual simplicial complex K0, which\nreflecting the topological structure of the protein molecule. (e) More edges and triangles from the Delaunay\ntriangulation are now collected as atoms continue to grow. (d) Finally, all vertices, edges, and triangles are\nnow collected as atoms are grown to large enough size. We get back the full original Delaunay complex.\nof the balls. We obtain the dual complex or alpha shape K0 of the molecule at ? = 0 (Fig 6.2c):\nK0 = {?|I|?1|\nintersectiondisplay\ni?I\nVi ?\nuniondisplay\nB negationslash= ?}. (6.3)\nAlpha shape provides a guide map for computing geometric properties of the structures of biomolecules.\nTake the molecular surface as an example, the re-entrant surfaces are formed by the concave spherical patch\nand the toroidal surface. These can be mapped from the boundary triangles and boundary edges of the\nalpha shape, respectively [20]. Recall that a triangle in the Delaunay tetrahedrization corresponds to the\nintersection of three Voronoi regions, i.e., a Voronoi edge. For a triangle on the boundary of the alpha shape,\nthe corresponding Voronoi edge intersects with the body of the union of balls by definition. In this case,\nit intersects with the solvent accessible surface at the common intersecting vertex when the three atoms\noverlap. This vertex corresponds to a concave spherical surface patch in the molecular surface. For an\nedge on the boundary of the alpha shape, the corresponding Voronoi plane coincides with the intersecting\nplane when two atoms meet, which intersect with the surface of the union of balls on an arc. This line\nsegment corresponds to a toroidal surface patch. The remaining part of the surface are convex pieces, which\ncorrespond to the vertices, namely, the atoms on the boundary of the alpha shape.\nThe numbers of toroidal pieces and concave spherical pieces are exactly the numbers of boundary edges\nand boundary triangles in the alpha shape, respectively. Because of the restriction of bond length and the\nexcluded volume effects, the number of edges and triangles in molecules are roughly in the order of O(n)\n[21].\n6.2.5 Metric measurement\nWe have described the relationship between the simplices and the surface elements of the molecule. Based\non this type of relationship, we can compute efficiently size properties of the molecule. We take the problem\n6\nof volume computation as an example.\nConsider a grossly incorrect way to compute the volume of a protein molecule using the solvent accessible\nsurface model. We could define that the volume of the molecule is the summation of the volumes of individual\natoms, whose radii are inflated to account for solvent probe. By doing so we would have significantly inflated\nthe value of the true volume, because we neglected to consider volume overlaps. We can explicitly correct\nthis by following the inclusion-exclusion formula: when two atoms overlap, we subtract the overlap; when\nthree atoms overlap, we first subtract the pair overlaps, we then add back the triple overlap, etc. This\ncontinues when there are four, five, or more atoms intersecting. At the combinatorial level, the principle\nof inclusion-exclusion is related to the Gauss-Bonnet theorem used by Connolly [11]. The corrected volume\nV (B) for a set of atom balls B can then be written as:\nV (B) =\nsummationdisplay\nvol(intersectiontext T)>0\nT?B\n(?1)dim(T)?1 vol(\nintersectiondisplay\nT), (6.4)\nwhere vol(intersectiontextT) represents volume overlap of various degree, T ? B is a subset of the balls with non-zero\nvolume overlap: vol(intersectiontextT) > 0.\nHowever, the straightforward application of this inclusion-exclusion formula does not work. The degree\nof overlap can be very high: theoretical and simulation studies showed that the volume overlap can be up\nto 7-8 degrees [22,23]. It is difficult to keep track of these high degree of volume overlaps correctly during\ncomputation, and it is also difficult to compute the volume of these overlaps because there are many different\ncombinatorial situations, i.e., to quantify how large is the k-volume overlap of which one of the parenleftbig7kparenrightbig or parenleftbig8kparenrightbig\noverlapping atoms for all of k = 2,??? ,7 [23]. It turns out that for three-dimensional molecules, overlaps\nof five or more atoms at a time can always be reduced to a ?+? or a ??? signed combination of overlaps\nof four or fewer atom balls [9]. This requires that the 2-body, 3-body, and 4-body terms in Eqn 6.4 enter\nthe formula if and only if the corresponding edge ?ij connecting the two balls (1-simplex), triangles ?ijk\nspanning the three balls (2-simplex), and tetrahedron ?ijkl cornered on the four balls (3-simplex) all exist in\nthe dual simplicial complex K0 of the molecule [9,21]. Atoms corresponding to these simplices will all have\nvolume overlaps. In this case, we have the simplified exact expansion:\nV (B) =\nsummationdisplay\n?i?K\nvol(bi)?\nsummationdisplay\n?ij?K\nvol(bi ?bj)\n+\nsummationdisplay\n?ijk?K\nvol(bi ?bj ?bk)?\nsummationdisplay\n?ijkl?K\nvol(bi ?bj ?bk ?bl).\nThe same idea is applicable for the calculation of surface area of molecules.\nAn example. An example of area computation by alpha shape is shown in Fig 6.4. Let b1,b2,b3,b4 be the\nfour disks. To simplify the notation we write Ai for the area of bi, Aij for the area of bi ?bj, and Aijk for\nthe area of bi ?bj ?bk. The total area of the union, b1 ?b2 ?b3 ?b4, is\nAtotal = (A1 + A2 + A3 + A4)\n? (A12 + A23 + A24 + A34)\n+ A234.\nWe add the area of bi if the corresponding vertex belongs to the alpha complex (Fig 6.4), we subtract the\narea of bi ?bj if the corresponding edge belongs to the alpha complex, and we add the area of bi ?bj ?bk if\nthe corresponding triangle belongs to the alpha complex. Note without the guidance of the alpha complex,\nthe inclusion-exclusion formula may be written as:\nAtotal = (A1 + A2 + A3 + A4)\n? (A12 + A13 + A14 + A23 + A24 + A34)\n+ (A123 + A124 + A134 + A234)\n? A1234.\n7\nb1\nb2\nb3\nb4\nA\nb1\nb2\nb3\nb4\nB\nFigure 6.4: An example of analytical area calculation. (a) Area can be computed using the direct inclusion-\nexclusion. (b) The formula is simplified without any redundant terms when using alpha shape.\nThis contains 6 canceling redundant terms: A13 = A123, A14 = A124, and A134 = A1234. Computing these\nterms would be wasteful. Such redundancy does not occur when we use the alpha complex: the part of the\nVoronoi regions contained in the respective atom balls for the redundant terms do not intersect. Therefore,\nthe corresponding edges and triangles do not enter the alpha complex. In two dimensions, we have terms of at\nmost three disk intersections, corresponding to triangles in the alpha complex. Similarly, in three dimensions\nthe most complicated terms are intersections of four spherical balls, and they correspond to tetrahedra in\nthe alpha complex.\nVoids and pockets. Voids and pockets represent the concave regions of a protein surface. Because shape-\ncomplementarity is the basis of many molecular recognition processes, binding and other activities frequently\noccur in pocket or void regions of protein structures. For example, the majority of enzyme reactions take\nplace in surface pockets or interior voids.\nThe topological structure of the alpha shape also offers an effective method for computing voids and\npockets in proteins. Consider the Delaunay tetrahedra that are not included in the alpha shape. If we\nrepeatedly merge any two such tetrahedra on the condition that they share a 2-simplex triangle, we will\nend up with discrete sets of tetrahedra. Some of them will be completely isolated from the outside, and\nsome of them are connected to the outside by triangle(s) on the boundary of the alpha shape. The former\ncorresponds to voids (or cavities) in proteins, the latter corresponds to pockets and depressions in proteins.\nA pocket differs from a depression in that it must have an opening that is at least narrower than one\ninterior cross-section. Formally, the discrete flow [24] explains the distinction between a depression and a\npocket. In a two dimensional Delaunay triangulation, the empty triangles that are not part of the alpha\nshape can be classified into obtuse triangles and acute triangles. The largest angle of an obtuse triangle is\nmore than 90 degrees, and the largest angle of an acute triangle is less than 90 degrees. An empty obtuse\ntriangle can be regarded as a ?source? of empty space that ?flows? to its neighbor, and an empty acute\ntriangle a ?sink? that collects flow from its obtuse empty neighboring triangle(s). In Figure 6.5a, obtuse\ntriangles 1, 3, 4 and 5 flow to the acute triangle 2, which is a sink. Each of the discrete empty spaces on\nthe surface of protein can be organized by the flow systems of the corresponding empty triangles: Those\nthat flow together belong to the same discrete empty space. For a pocket, there is at least one sink among\nthe empty triangles. For a depression, all triangles are obtuse, and the discrete flow goes from one obtuse\ntriangle to another, from the innermost region to outside the convex hull. The discrete flow of a depression\ntherefore goes to infinity. Figure 6.5b gives an example of a depression formed by a set of obtuse triangles.\nOnce voids and pockets are identified, we can apply the inclusion-exclusion principle based on the sim-\nplices to compute the exact size measurement (e.g., volume and area) of each void and pocket [24,25].\nThe distinction between voids and pockets depends on the specific set of atomic radii and the solvent\n8\n1\n2 34\n5\n1\n345\nInfinity\n2\na b\nFigure 6.5: Discrete flow of empty space illustrated for two dimensional disks. (a) Discrete flow of a pocket.\nTriangles 1, 3, 4 and 5 are obtuse. The free volume flows to the ?sink? triangle 2, which is acute. (b) In a\ndepression, the flow is from obtuse triangles to the outside.\nradius. When a larger solvent ball is used, the radii of all atoms will be inflated by a larger amount. This\ncould lead to two different outcomes. A void or pocket may become completely filled and disappear. On the\nother hand, the inflated atoms may not fill the space of a pocket, but may close off the opening of the pocket.\nIn this case, a pocket becomes a void. A widely used practice in the past was to adjust the solvent ball\nand repeatedly compute voids, in the hope that some pockets will become voids and hence be identified by\nmethods designed for cavity/void computation. The pocket algorithm [24] and tools such as CastP [26,27]\noften makes this unnecessary.\n6.3 Computation and software\nComputing Delaunay tetrahedrization and Voronoi diagram. It is easier to discuss the computation\nof tetrahedrization first. The incremental algorithm developed in [28] can be used to compute the weighted\ntetrahedrization for a set of atoms of different radii. For simplicity, we sketch the outline of the algorithm\nbelow for two dimensional unweighted Delaunay triangulation.\nThe intuitive idea of the algorithm can be traced back to the original observation of Delaunay. For the\nDelaunay triangulation of a point set, the circumcircle of an edge and a third point forming a Delaunay\ntriangle must not contain a fourth point. Delaunay showed that if all edges in a particular triangulation\nsatisfy this condition, the triangulation is a Delaunay triangulation. It is easy to come up with an arbitrary\ntriangulation for a point set. A simple algorithm to covert this triangulation to the Delaunay triangulation is\ntherefore to go through each of the triangles, and make corrections using ?flips? discussed below if a specific\ntriangle contains an edge violating the above condition. The basic ingredients for computing Delaunay\ntetrahedrization are generalizations of these observations. We discuss the concept of locally Delaunay edge\nand the edge-flip primitive operation below.\nLocally Delaunay edge. We say an edge ab is locally Delaunay if either it is on the boundary of the convex\nhull of the point set, or if it belongs to two triangles abc and abd, and the circumcircle of abc does not contain\nd (e.g., edge cd in Fig 6.6a).\nEdge-flip. If ab is not locally Delaunay (edge ab in Fig 6.6a), then the union of the two triangles abc?abd\nis a convex quadrangle acbd, and edge cd is locally Delaunay. We can replace edge ab by edge cd. We call\nthis an edge-flip or 2-to-2 flip, as two old triangles are replaced by two new triangles.\nWe recursively check each boundary edge of the quadrangle abcd to see if it is also locally Delaunay after\nreplacing ab by cd. If not, we recursively edge-flip it.\nIncremental algorithm for Delaunay triangulation. Assume we have a finite set of points (namely, atom\ncenters) S = {z1,z2,??? ,zi,??? ,zn}. We start with a large auxiliary triangle that contains all these points.\nWe insert the points one by one. At all times, we maintain a Delaunay triangulation Di upto insertion of\n9\n1?to?3 flip\nb\n2?to?2 flip\na\nb\nc\nd\na\nb\nc\nd\na\nFigure 6.6: An illustration of locally Delaunay edge and flips. (a) For the quadrilateral abcd, edge ab is not\nlocally Delaunay, as the circumcircle passing through edge ab and a third point c contains a fourth point d.\nEdge cd is locally Delaunay, as b is outside the circumcircle adc. An edge-flip or 2-to-2 flip replaces edge ab\nby edge cd, and replace the original two triangles abc and adb with two new triangles acd and bcd. (b) When\na new vertex is inserted, we replace the old triangle containing this new vertex with three new triangles.\nThis is called 1-to3 flips.\npoint zi.\nAfter inserting point zi, we search for the triangle ?i?1 that contains this new point. We then add zi to\nthe triangulation and split the original triangle ?i?1 into three smaller triangles. This split is called 1-to-3\nflip, as it replaces one old triangle with three new triangles. We then check if each of the three edges in ?i?1\nstill satisfies the locally Delaunay requirement. If not, we perform a recursive edge-flip. This algorithm is\nsummarized in Algorithm 1.\nAlgorithm 1 Delaunay triangulation\nObtain random ordering of points {z1,??? ,zn};\nfor i = 1 to n do\nfind ?i?1 such zi ? ?i?1;\nadd zi, and split ?i?1 into three triangles (1-to-3 flip);\nwhile any edge ab not locally Delaunay do\nflip ab to other diagonal cd (2-to-2 edge flip);\nend while\nend for\nIn R3, the algorithm of tetrahedrization becomes more complex, but the same basic ideas apply. In this\ncase, we need to locate a tetrahedron instead of a triangle that contains the newly inserted point. The\nconcept of locally Delaunay is replaced by the concept of locally convex, and there are flips different than the\n2-to-2 flip in R3 [28]. Although an incremental approach, i.e., sequentially adding points, is not necessary\nfor Delaunay triangulation in R2, it is necessary in R3 to avoid non-flippable cases and to guarantee that\nthe algorithm will terminate. This incremental algorithm has excellent expected performance [28].\nThe computation of Voronoi diagram is conceptually easy once the Delaunay triangulation is available.\nWe can take advantage of the mathematical duality and compute all of the Voronoi vertices, edges, and\nplanar faces from the Delaunay tetrahedra, triangles, and edges. Because one point zi may be an vertex of\nmany Delaunay tetrahedra, the Voronoi region of zi therefore may contain many Voronoi vertices, edges,\nand planar faces. The efficient quad-edge data structure can be used for software implementation [29].\nVolume and area computation. Let V and A denote the volume and area of the molecule, respectively,\nK? for the alpha complex, ? for a simplex in K, i for a vertex, ij for an edge, ijk for a triangle, and ijkl for\na tetrahedron. The algorithm for volume and area computation can be written as Algorithm 2. Additional\ndetails of volume and area computation can be found in [20,21].\nSoftware. The software package Delcx for computing weighted Delaunay tetrahedrization, Mkalf for\ncomputing the alpha shape, Volbl for computing volume and area of both molecules and interior voids\n10\nAlgorithm 2 Volume and area measurement\nV := A := 0.0;\nfor all ? ? K do\nif ? is a vertex i then\nV := V +vol(bi); A := A+area(bi);\nend if\nif ? is an edge ij then\nV := V ?vol(bi ?bj); A := A?area(bi ?bj);\nend if\nif ? is a triangle ijk then\nV := V +vol(bi ?bj ?bk); A := A +area(bi ?bj ?bk);\nend if\nif ? is a tetrahedron ijkl then\nV := V ?vol(bi ?bj ?bk ?bl); A := A?area(bi ?bj ?bk ?bl);\nend if\nend for\nand be found at www.alphashape.org. The CastP webserver for pocket computation can be found at\ncast.engr.uic.edu. There are other studies that compute or use Voronoi diagrams of protein structures\n[30?32], although not all computes the weighted version which allows atoms to have different radii.\nIn this short description of algorithm, we have neglected many details important for geometric compu-\ntation. For example, the problem of how to handle geometric degeneracy, namely, when three points are\nco-linear, or when four points are co-planar. Interested readers should consult the excellent monograph by\nEdelsbrunner for a detailed treatise of these and other important topics in computational geometry [33].\n6.4 Applications: Packing analysis.\nAn important application of the Voronoi diagram and volume calculation is the measurement of protein\npacking. Tight packing is an important feature of protein structure [6,10], and is thought to play important\nroles in protein stability and folding dynamics [34]. The packing density of a protein is measured by the\nratio of its van der Waals volume and the volume of the space it occupies. One approach is to calculate the\npacking density of buried residues and atoms using Voronoi diagram [6,10]. This approach was also used to\nderive radii parameters of atoms [15].\nBased on the computation of voids and pockets in proteins, a detailed study surveying major represen-\ntatives of all known protein structural folds showed that there is a substantial amount of voids and pockets\nin proteins [35]. On average, every 15 residues introduces a void or a pocket (Fig 6.7a). For a perfectly\nsolid three-dimensional sphere of radius r, the relationship between volume V = 4pir3/3 and surface area\nA = 4pir2 is: V ? A3/2. In contrast, Figure 6.7b shows that the van der Waals volume scales linearly with\nthe van der Waals surface areas of proteins. The same linear relationship holds irrespective of whether we\nrelate molecular surface volume and molecular surface area, or solvent accessible volume and solvent acces-\nsible surface area. This and other scaling behavior point out that protein interior is not packed as tight as\nsolid [35]. Rather, packing defects in the form of voids and pockets are common in proteins.\nIf voids and pockets are prevalent in proteins, an interesting question is what is then the origin of the\nexistence of these voids and pockets. This question was studied by examining the scaling behavior of packing\ndensity and coordination number of residues through the computation of voids, pockets, and edge simplices\nin the alpha shapes of random compact chain polymers [36]. For this purpose, a 32-state discrete state\nmodel was used to generate a large ensemble of compact self-avoiding walks. This is a difficult task, as it is\nvery challenging to generate a large number of independent conformations of very compact chains that are\nself-avoiding. The results in [36] showed that it is easy for compact random chain polymers to have similar\nscaling behavior of packing density and coordination number with chain length. This suggests that proteins\n11\nNumber of Residues\nNum of Voids and Pockets\n0 200 600 1000\n0\n50\n100\n150\nA x 1000\nV x 1000\n0 200 400 600 800\n0\n100\n300\n500\nFigure 6.7: Voids and pockets for a set of 636 proteins representing most of the known protein folds, and\nthe scaling behavior of the geometric properties of proteins. (a) The number of voids and pockets detected\nwith a 1.4 ?A probe is linearly correlated with the number of residues in a protein. Only proteins with\nless than 1,000 residues are shown. Solid triangles and empty circles represent the pockets and the voids,\nrespectively. (b) The van der Waals (vdw) volume and van der Waals area of proteins scale linearly with\neach other. Similarly, molecular surface (ms) volume also scales linearly with molecular surface area using\na probe radius of 1.4?A. (Data not shown. Figure adapted after [35])\n12\nare not optimized by evolution to eliminate voids and pockets, and the existence of many pockets and voids is\nrandom in nature, and is due to the generic requirement of compact chain polymers. The frequent occurrence\nand the origin of voids and pockets in protein structures raise a challenging question: How can we distinguish\nvoids and pockets that perform biological functions such as binding from those formed by random chance?\nThis question is related to the general problem of protein function prediction.\n6.5 Applications: Protein function prediction from structures.\nConservation of protein structures often reveals very distant evolutionary relationship, which are otherwise\ndifficult to detect by sequence analysis [37]. Comparing protein structures can provide insightful ideas about\nthe biochemical functions of proteins (e.g., active sites, catalytic residues, and substrate interactions) [38?40].\nA fundamental challenge in inferring protein function from structure is that the functional surface of\na protein often involves only a small number of key residues. These interacting residues are dispersed in\ndiverse regions of the primary sequences and are difficult to detect if the only information available is the\nprimary sequence. Discovery of local spatial motifs from structures that are functionally relevant has been\nthe focus of many studies.\nGraph based methods for spatial patterns in proteins. To analyze local spatial patterns in proteins.\nArtymiuk et al developed an algorithm based on subgraph isomorphism detection [41]. By representing\nresidue side-chains as simplified pseudo-atoms, a molecular graph is constructed to represent the patterns of\nside-chain pseudo-atoms and their inter-atomic distances. A user defined query pattern can then be searched\nrapidly against the Protein Data Bank for similarity relationship. Another widely used approach is the\nmethod of geometric hashing. By examining spatial patterns of atoms, Fischer et al developed an algorithm\nthat can detect surface similarity of proteins [42,43]. This method has also been applied by Wallace et al for\nthe derivation and matching of spatial templates [44]. Russell developed a different algorithm that detects\nside-chain geometric patterns common to two protein structures [45]. With the evaluation of statistical\nsignificance of measured root mean square distance, several new examples of convergent evolution were\ndiscovered, where common patterns of side-chains were found to reside on different tertiary folds.\nThese methods have a number of limitations. Most require a user-defined template motif, restricting their\nutility for automated database-wide search. In addition, the size of the spatial pattern related to protein\nfunction is also often restricted.\nPredicting protein functions by matching pocket surfaces. Protein functional surfaces are frequently\nassociated with surface regions of prominent concavity [26,46]. These include pockets and voids, which can\nbe accurately computed as we have discussed. Computationally, one wishes to automatically identify voids\nand pockets on protein structures where interactions exist with other molecules such as substrate, ions,\nligands, or other proteins.\nBinkowski et al. developed a method for predicting protein function by matching a surface pocket or void\non a protein of unknown or undetermined function to the pocket or void of a protein of known function\n[47,48]. Initially, the Delaunay tetrahedrization and alpha shapes for almost all of the structures in the\nPDB databank are computed [27]. All surface pockets and interior voids for each of the protein structure\nare then exhaustively computed [24,25]. For each pocket and void, the residues forming the wall are then\nconcatenated to form a short sequence fragment of amino acid residues, while ignoring all intervening residues\nthat do not participate in the formation of the wall of the pocket or void. Two sequence fragments, one\nfrom the query protein and another from one of the proteins in the database, both derived from pocket or\nvoid surface residues, are then compared using dynamic programming. The similarity score for any observed\nmatch is assessed for statistical significance using an empirical randomization model constructed for short\nsequence patterns.\nFor promising matches of pocket/void surfaces showing significant sequence similarity, we can further\nevaluate their similarity in shape and in relative orientation. The former can be obtained by measuring\nthe coordinate root mean square distance (rmsd) between the two surfaces. The latter is measured by\n13\nfirst placing a unit sphere at the geometric center z0 ? R3 of a pocket/void. The location of each residue\nz = (x,y,z)T is then projected onto the unit sphere along the direction of the vector from the geometric\ncenter: u = (z ?z0)/||z ?z0||. The projected pocket is represented by a collection of unit vectors located\non the unit sphere, and the original orientation of residues in the pocket is preserved. The rmsd distance of\nthe two sets of unit vectors derived from the two pockets are then measured, which is called the ormsd for\norientation rmsd [47]. This allows similar pockets with only minor conformational changes to be detected\n[47].\nThe advantage of the method of Binkowski et al is that it does not assume prior knowledge of functional\nsite residues, and does not require a priori any similarity in either the full primary sequence or the backbone\nfold structures. It has no limitation in the size of the spatially derived motif and can successfully detect\npatterns small and large. This method has been successfully applied to detect similar functional surfaces\namong proteins of the same fold but low sequence identities, and among proteins of different fold [47,49].\nFunction prediction through models of protein surface evolution. To match local surfaces such as\npockets and voids and to assess their sequence similarity, an effective scoring matrix is critically important.\nIn the original study of Binkowski et al, Blosum matrix was used. However, this is problematic, as Blosum\nmatrices were derivedfrom analysisof precomputed large quantities of sequences, while the information of the\nparticular protein of interest has limited or no influence. In addition, these precomputed sequences include\nburied residues in protein core, whose conservation reflects the need to maintain protein stability rather\nthan to maintain protein function. In reference [50,51], a continuous time Markov process was developed\nto explicitly model the substitution rates of residues in binding pockets. Using a Bayesian Markov chain\nMonte Carlo method, the residue substitution rates at functional pocket are estimated. The substitution\nrates are found to be very different for residues in the binding site and residues on the remaining surface of\nproteins. In addition, substitution rates are also very different for residues in the buried core and residues\non the solvent exposed surfaces.\nThese rates are then used to generate a set of scoring matrices of different time intervals for residues\nlocated in the functional pocket. Application of protein-specific and region-specific scoring matrices in\nmatching protein surfaces result in significantly improved sensitivity and specificity in protein function\nprediction [50,51].\nIn a large scale study of predicting protein functions from structures, a subset of 100 enzyme families are\ncollected from the total of 286 enzyme families containing between 10?50 member protein structures with\nknown Enzyme Classification (E.C.) labels. By estimating the substitution rate matrix for residues on the\nactive site pocket of a query protein, a series of scoring matrices of different evolutionary time is derived. By\nsearching for similar pocket surfaces from a database of 770,466 pockets derived from the CastP database\n(with the criterion that each must contain at least 8 residues), this method can recover active site surfaces\non enzymes similar to that on the query structure at an accuracy of > 92%. Fig 6.8 shows the Receiver\nOperating Characteristic Curve of this study. An example of identifying human amylase using template\nsurfaces from B. subtilis and from barley is shown in Fig 6.9.\nThe method of surface matching based on evolutionary model is also especially effective in solving the\nchallenging problems of protein function prediction of orphan structures of unknown function (such as those\nobtained in structural genomics projects), which have only sequence homologs that are themselves hypothet-\nical proteins with unknown functions.\n6.6 Discussion\nA major challenge in studying protein geometry is to understand our intuitive notions of various geometric\naspects of molecular shapes, and to quantify these notions with mathematical models that are amenable to\nfast computation. The advent of the union of ball model of protein structures enabled rigorous definition\nof important geometric concepts such as solvent accessible surface and molecular surface. It also led to\nthe development of algorithms for area and volume calculations of proteins. Deep understanding of the\ntopological structure of molecular shapes is also based on the idealized union of ball model [9]. A success\n14\n0.0 0.2 0.4 0.6 0.8 1.0\n0.75\n0.80\n0.85\n0.90\nnewy\nTrue Positive Rate(sensitivity)\nFalse Positve Rate(1?specificity)\nFigure 6.8: A large scale study of protein function prediction from structures by matching similar func-\ntional surfaces for 100 protein families. A correct prediction is made if the matched surface comes from a\nprotein structure with the same Enzyme Classification (E.C.) number (upto the 4-th digit) as that of the\nquery protein. The x-axis of the Receiver Operating Characteristics curve reflects the false positive rate\n(1?specificity) at different statistical significance p-value by cRMSD measurement, and the y-axis reflects\nthe true positive rate (sensitivity).\nin approaching these problems is exemplified in the development of the pocket algorithm [24]. Another\nexample is the recent development of a rigorous definition of protein-protein binding or interaction interface\nand algorithm for its computation [52].\nPerhaps a more fundamental problem we face is to identify important structural and chemical features\nthat are the determinants of biological problems of interest. For example, we would like to know what are the\nshape features that has significant influences on protein solvation, protein stability, ligand specific binding,\nand protein conformational changes. It is not clear whether our current geometric intuitions are sufficient,\nor are the correct or the most relevant ones. There may still be important unknown shape properties of\nmolecules that elude us at the moment.\nAn important application of geometric computation of protein structures is to detect patterns important\nfor protein function. The shape of local surface regions on a protein structure and their chemical texture are\nthe basis of its binding interactions with other molecules. Proteins fold into specific native structure to form\nthese local regions for carrying out various biochemical functions. The geometric shape and chemical pattern\nof the local surface regions, and how they change dynamically are therefore of fundamental importance in\ncomputational studies of proteins.\nAnother important application is the development of geometric potential functions. Potential functions\nare important for generating conformations, for distinguishing native and near native conformations from\nother decoy conformations in protein structure predictions [53?56] and in protein-protein docking [57]. They\nare also important for peptide and protein design [57,58]. Chapter 4 describes in details the development of\ngeometric potential and applications in decoy discrimination and in protein-protein docking prediction.\nWe havenot described in detail the approachof studying protein geometryusing graphtheory. In addition\nto side-chain pattern analysis briefly discussed earlier, graph based protein geometric model also has lead to\na number of important insights, including the optimal design of model proteins formed by hydrophobic and\npolar residues [59], and methods for optimal design of side-chain packing [60,61]. Another important topic\nwe did not touch upon is the analysis of the topology of protein backbones. Based on concepts from knot\ntheory, R?gen and Bohr developed a family of global geometric measures for protein structure classification\n[62]. These measures originate from integral formulas of Vassiliev knot invariants. With these measures,\nR?gen and Fain further constructed a system that can automatically classify protein chains into folds [63].\n15\nFigure 6.9: Protein function prediction as illustrated by the example of alpha amylases. Two template\nbinding surfaces are used to search database of protein surfaces to identify protein structures that are of\nsimilar functions. (a) The phylogenetic tree for the template Pdb structure 1bag from B. subtilis. (b)\nThe template binding pocket of alpha amylase on 1bag. (c) A matched binding surface on a different\nprotein structure (1b2y from human, full sequence identity 22%) obtained by querying with 1bag. (d) The\nphylogenetic tree for the template structure 1bg9 from H. vulgare. (e) The template binding pocket on 1bg9.\n(f) A matched binding surface on a different protein structure (1u2y from human, full sequence identity\n23%) obtained by querying with 1bg9 (Adapted from [51]).\nThis system can reproduce the Cath classification system that requires explicit structural alignment as well\nas human curation.\nFurther development of descriptions of geometric shape and topological structure, as well as algorithms\nfor their computation will provide a solid foundation for studying many important biological problems. The\nother important tasks are then to show how these descriptors may be effectively used to deepen our biological\ninsights and to develop accurate predictive models of biological phenomena. For example, in computing\nprotein-protein interfaces, a challenging task is to discriminate surfaces that are involved in protein binding\nfrom other non-binding surface regions, and to understand in what fashion this depends on the properties\nof the binding partner protein.\nUndoubtedly, evolution plays central roles in shaping up the function and stability of protein molecules.\nThe method of analyzing residue substitution rates using a continuous time Markov models [50,51], and\nthe method of surface mapping of conservation entropy and phylogeny [64,65] only scratches the surface of\n16\nthis important issue. Much remains to be done in incorporating evolutionary information in protein shape\nanalysis for understanding biological functions.\n6.7 Summary\nThe accumulation of experimentally solved molecular structures of proteins provides a wealth of information\nfor studying many important biological problems. With the development of a rigorous model of the structure\nof protein molecules, various shape properties, including surfaces, voids, and pockets, and measurements of\ntheir metric properties can be computed. Geometric algorithms have found important applications in protein\npacking analysis, in developing potential functions, in docking, and in protein function prediction. It is\nlikely further development of geometric models and algorithms will find important applications in answering\nadditional biological questions.\n6.8 Further reading\nThe original work of Lee and Richards surface can be found in [5], where they also formulated the molecular\nsurface model [8]. Michael Connolly developed the first method for the computation of the molecular surface\n[11]. Tsai et al. described a method for obtaining atomic radii parameter [15]. The mathematical theory of\nthe union of balls and alpha shape was developed by Herbert Edelsbrunner and colleague [9,66]. Algorithm\nfor computing weighted Delaunay tetrahedrization can be found in [28], or in a concise monograph with\nin-depth discussion of geometric computing [33]. Details of area and volume calculations can be found in\n[20,21,25]. The theory of pocket computation and applications can be found in [24,26]. Richards and Lim\noffered a comprehensive review on protein packing and protein folding [12]. A detailed packing analysis of\nproteins can be found in [35]. The study on inferring protein function by matching surfaces is described in\n[47]. The study of the evolutionary model of protein binding pocket and its application in protein function\nprediction can be found in [51].\n6.9 Acknowledgments\nThis work is supported by grants from the National Science Foundation (CAREER DBI0133856), the Na-\ntional Institute of Health (GM68958), the Office of Naval Research (N000140310329), and the Whitaker\nFoundation (TF-04-0023). The author thanks Jeffrey Tseng for help in preparing this chapter.\n17\nBibliography\n[1] G. Rhodes. Crystallography Made Crystal Clear: A Guide for Users of Macromolecular Models. Aca-\ndemic Press, 1999.\n[2] G. M. Crippen and T. F. Havel. Distance Geometry and Molecular Conformation. J. Wiley & Sons,\n1988.\n[3] W. Rieping, M. Habeck, and M. Nilges. Inferential structure determination. Science, 309(5732):303?6,\n2005.\n[4] R.F.W. Bader. Atoms in Molecules: A Quantum Theory. The international series of mongraphs on\nchemistry, No. 22. Oxford University Press, 1994.\n[5] B. Lee and F. M. Richards. The interpretation of protein structures: estimation of static accessibility.\nJ. Mol. Biol., 55:379?400, 1971.\n[6] F. M. Richards. The interpretation of protein structures: total volume, group volume distributions and\npacking density. J. Mol. Biol., 82:1?14, 1974.\n[7] T. J. Richmond. Solvent accessible surface area and excluded volume in proteins: analytical equations\nfor overlapping spheres and implications for the hydrophobic effect. J. Mol. Biol., 178:63?89, 1984.\n[8] F. M. Richards. Calculation of molecular volumes and areas for structures of known geometries. Methods\nin Enzymology, 115:440?464, 1985.\n[9] H. Edelsbrunner. The union of balls and its dual shape. Discrete Comput. Geom., 13:415?440, 1995.\n[10] F. M. Richards. Areas, volumes, packing, and proteinstructures. Ann. Rev. Biophys. Bioeng., 6:151?176,\n1977.\n[11] M. L. Connolly. Analytical molecular surface calculation. J. Appl. Cryst., 16:548?558, 1983.\n[12] F. M. Richards and W. A. Lim. An analysis of packing in the protein folding problem. Q. Rev. Biophys.,\n26:423?498, 1994.\n[13] M. Gerstein and F. M Richards. Protein Geometry: Distances, Areas, and Volumes, volume F, chap-\nter 22. International Union of Crystallography, 1999.\n[14] F. M. Richards. The interpretation of protein structures: total volume, group volume distributions and\npacking density. J. Mol. Biol., 82:1?14, 1974.\n[15] J. Tsai, R. Taylor, C. Chothia, and M. Gerstein. The packing density in proteins: standard radii and\nvolumes. J Mol Biol, 290(1):253?66, 1999.\n[16] A. Bondi. VDW volumes and radii. J. Phys. Chem., 68:441?451, 1964.\n[17] J.M. Word, S.C. Lovell, J.S. Richardson, and D.C. Richardson. Asparagine and glutamine: using\nhydrogen atom contacts in the choice of side-chain amide orientation. J Mol Biol, 285(4):1735?47, 1999.\n18\n[18] J. L. Finney. Volume occupation, environment and accessibility in proteins. The problem of the protein\nsurface. J. Mol. Biol., 96:721?732, 1975.\n[19] B. J. Gellatly and J.L. Finney. Calculation of protein volumes: an alternative to the Voronoi procedure.\nJ. Mol. Biol., 161:305?322, 1982.\n[20] H. Edelsbrunner, M. Facello, P. Fu, and J. Liang. Measuring proteins and voids in proteins. In Proc.\n28th Ann. Hawaii Int?l Conf. System Sciences, volume 5, pages 256?264, Los Alamitos, California, 1995.\nIEEE Computer Scociety Press.\n[21] J. Liang, H. Edelsbrunner, P. Fu, P. V. Sudhakar, and S. Subramaniam. Analytical shape computing\nof macromolecules I: Molecular area and volume through alpha-shape. Proteins, 33:1?17, 1998.\n[22] K. W. Kratky. Intersecting disks (and spheres) and statistical mechanics. I. mathematical basis. J. Stat.\nPhys., 25:619?634, 1981.\n[23] M. Petitjean. On the analytical calculation of van der waals surfaces and volumes: some numerical\naspects. J. Comput. Chem., 15:507?523, 1994.\n[24] H. Edeslbrunner, M. Facello, and J. Liang. On the definition and the construction of pockets in macro-\nmolecules. Disc. Appl. Math., 88:18?29, 1998.\n[25] J. Liang, H. Edelsbrunner, P. Fu, P. V. Sudhakar, and S. Subramaniam. Analytical shape computing\nof macromolecules II: Identification and computation of inaccessible cavities inside proteins. Proteins,\n33:18?29, 1998.\n[26] J. Liang, H. Edelsbrunner, and C. Woodward. Anatomy of protein pockets and cavities: Measurement\nof binding site geometry and implications for ligand design. Protein Sci, 7:1884?1897, 1998.\n[27] T. A. Binkowski, S. Naghibzadeh, and J. Liang. CASTp: Computed atlas of surface topography of\nproteins. Nucleic Acids Res., 31:3352?3355, 2003.\n[28] H. Edelsbrunner and N.R. Shah. Incremental topological flipping works for regular triangulations.\nAlgorithmica, 15:223?241, 1996.\n[29] L. Guibas and J. Stolfi. Primitives for the manipulation of general subdivisions and the computation of\nVoronoi diagrams. ACM Transactions on Graphiques, 4:74?123, 1985.\n[30] S. Chakravarty, A. Bhinge, and R. Varadarajan. A procedure for detection and quantitation of cavity\nvolumes proteins. application to measure the strength of the hydrophobic driving force in protein folding.\nJ Biol Chem, 277(35):31345?53, 2002.\n[31] A. Goede, R. Preissner, and C. Frommel. Voronoi cell: New method for allocation of space among\natoms: Elimination of avoidable errors in calculation of atomic volume and density. J. Comput. Chem.,\n18:1113?1123, 1997.\n[32] Y. Harpaz, M. Gerstein, and C. Chothia. Volume changes on protein folding. Structure, 2(7):641?9,\n1994.\n[33] H. Edelsbrunner. Geometry and Topology for Mesh Generation. Cambridge University Press, 2001.\n[34] M. Levitt, M. Gerstein, E. Huang, S. Subbiah, and J. Tsai. Protein folding: the endgame. Annu Rev\nBiochem, 66:549?579, 1997.\n[35] J. Liang and K. A. Dill. Are proteins well-packed? Biophys. J., 81:751?766, 2001.\n[36] J. Zhang, R. Chen, C. Tang, and J. Liang. Origin of scaling behavior of protein packing density: A\nsequential monte carlo study of compact long chain polymers. J. Chem. Phys., 118:6102?6109, 2003.\n19\n[37] A. E. Todd, C. A. Orengo, and J. M. Thornton. Evolution of function in protein superfamilies, from a\nstructural perspective. J. Mol. Biol., 307:1113?1143, 2001.\n[38] L. Holm and C. Sander. New structure: Novel fold? Structure, 5:165?171, 1997.\n[39] A. C. R. Martin, C. A. Orengo, E. G. Hutchinson, A. D. Michie, A. C. Wallace, M. L. Jones, and J. M.\nThornton. Protein folds and functions. Structure, 6:875?884, 1998.\n[40] C. A. Orengo, A. E. Todd, and J. M. Thornton. From protein structure to function. Curr. Opinion\nStructural Biology, 9(4):374?382, 1999.\n[41] P. J. Artymiuk, A. R. Poirrette, H. M. Grindley, D.W. Rice, and P. Willett. A graph-theoretic approach\nto the identification of three-dimensional patterns of amino acid side-chains in protein structure. J. Mol.\nBiol., 243:327?344, 1994.\n[42] D. Fischer, R. Norel, H. Wolfson, and R. Nussinov. Surface motifs by a computer vision technique:\nsearches, detection, and implications for protein- ligand recognition. Proteins: Structure, Function and\nGenetics, 16:278?292, 1993.\n[43] R. Norel, D. Fischer, H. J. Wolfson, and R. Nussinov. Molecualr surface recognition by computer\nvision-based technique. Protein Eng., 1994.\n[44] A. C. Wallace, N. Borkakoti, and J. M. Thornton. TESS: a geometric hashing algorithm for deriving\n3d coordinate templates for searching structural databases. Application to enzyme active sites. Protein\nSci., 6:2308?2323, 1997.\n[45] R. Russell. Detection of protein three-dimensional side-chain patterns: New examples of convergent\nevolution. J. Mol. Biol., 279:1211?1227, 1998.\n[46] R. A. Laskowski, N. M. Luscombe, M. B. Swindells, and J. M. Thornton. Protein clefts in molecular\nrecognition and function. Protein Sci., 5:2438?2452, 1996.\n[47] T. A. Binkowski, L. Adamian, and J. Liang. Inferring functional relationship of proteins from local\nsequence and spatial surface patterns. J. Mol. Biol., 332:505?526, 2003.\n[48] T.A. Binkowski, A. Joachimiak, and J. Liang. Protein surface analysis for function annotation in\nhigh-throughput structural genomics pipeline. Protein Sci, 14(12):2972?81, 2005.\n[49] T.A. Binkowski, P. Freeman, and J. Liang. pvSOAR: Detecting similar surface patterns of pocket and\nvoid surfaces of amino acid residues on proteins. Nucleic Acid Research, 32:W555?W558, 2004.\n[50] Y.Y. Tseng and J. Liang. Estimating evolutionary rate of local protein binding surfaces: a bayesian\nmonte carlo approach. Proceedings of 2005 IEEE-EMBC Conference, 2005.\n[51] Y.Y. Tseng and J. Liang. Estimation of amino acid residue substitution rates at local spatial regions\nand application in protein function inference: A Bayesian Monte Carlo approach. Mol. Biol. Evol.,\n23:421?436, 2006.\n[52] Y. Ban, H. Edelsbrunner, and J. Rudolph. Interface surfaces for protein-protein complexes. In RE-\nCOMB, pages 205?212, 2004.\n[53] R. K.Singh, A. Tropsha, and I. I. Vaisman. Delaunaytessellationof proteins: fourbody nearest-neighbor\npropensities of amino-acid residues. J. Comp. Bio., 3:213?221, 1996.\n[54] W. Zheng, S. J. Cho, I. I. Vaisman, and A. Tropsha. A new approach to protein fold recognition based\non Delaunay tessellation of protein structure. In R.B. Altman, A.K. Dunker, L. Hunter, and T.E. Klein,\neditors, Pacific Symposium on Biocomputing?97, pages 486?497, Singapore, 1997. World Scientific.\n20\n[55] X. Li, C. Hu, and J. Liang. Simplicial edge representation of protein structures and alpha contact\npotential with confidence measure. Proteins, 53:792?805, 2003.\n[56] X. Li and J. Liang. Geometric cooperativity and anticooperativity of three-body interactions in native\nproteins. Proteins, 60(1):46?65, 2005.\n[57] X. Li and J. Liang. Computational design of combinatorial peptide library for modulating protein-\nprotein interactions. Pac Symp Biocomput, pages 28?39, 2005.\n[58] C. Hu, X. Li, and J. Liang. Developing optimal nonlinear scoring function for protein design. Bioinfor-\nmatics, 20:3080?3098, 2004.\n[59] J. Kleinberg. Efficient algorithms for protein sequence design and the analysis of certain evolutionary\nfitness landscapes. In RECOMB, pages 205?212, 2004.\n[60] J. Xu. Rapid protein side-chain packing via tree decomposition. In RECOMB, pages 423?439, 2005.\n[61] A. Leaver-Fay, B. Kuhlman, and J. Snoeyink. An adaptive dynamic programming algorithm for the\nside chain placement problem. In Pacific Symposium on Biocomputing, pages 17?28, 2005.\n[62] P. R?gen and H. Bohr. A new family of global protein shape descriptors. Math Biosci, 182(2):167?81,\n2003.\n[63] P. R?gen and B. Fain. Automatic classification of protein structure by using gauss in tegrals. Proc Natl\nAcad Sci U S A, 100(1):119?24, 2003.\n[64] O. Lichtarge, H.R. Bourne, and F.E. Cohen. An evolutionary trace method defines binding surfaces\ncommon to protein families. J Mol Biol, 257(2):342?58, 1996.\n[65] F. Glaser, T. Pupko, I. Paz, R.E. Bell, D. Shental, E. Martz, and N. Ben-Tal. Consurf: identifica-\ntion of functional regions in proteins by surface-mapping of phylogenetic information. Bioinformatics,\n19(1):163?4, 2003.\n[66] H. Edelsbrunner and E.P. M?ucke. Three-dimensional alpha shapes. ACM Trans. Graphics, 13:43?72,\n1994.\n21\n"}
{"id":"oai:arXiv.org:quant-ph/0602178","text":"arXiv:quant-ph/0610192v1  23 Oct 2006\nICMPA-MPA/2006/20\nCP3-06-13\n(p,q)-Deformations and (p,q)-Vector Coherent States\nof the Jaynes-Cummings Model\nin the Rotating Wave Approximation\nJoseph Ben Geloun?, Jan Govaerts?,?,1 and M. Norbert Hounkonnou?\n?International Chair in Mathematical Physics and Applications (ICMPA-UNESCO)\n072 B.P. 50 Cotonou, Republic of Benin\nE-mail: jobengeloun@yahoo.fr, norbert?hounkonnou@cipma.net\n?Department of Theoretical Physics, School of Physics\nThe University of New South Wales, Sydney NSW 2052, Australia\nE-mail: Jan.Govaerts@fynu.ucl.ac.be\nFebruary 1, 2008\nAbstract\nClasses of (p,q)-deformations of the Jaynes-Cummings model in the rotating wave ap-\nproximation are considered. Diagonalization of the Hamiltonian is performed exactly, leading\nto useful spectral decompositions of a series of relevant operators. The latter include ladder\noperators acting between adjacent energy eigenstates within two separate infinite discrete\ntowers, except for a singleton state. These ladder operators allow for the construction of\n(p,q)-deformed vector coherent states. Using (p,q)-arithmetics, explicit and exact solutions\nto the associated moment problem are displayed, providing new classes of coherent states\nfor such models. Finally, in the limit of decoupled spin sectors, our analysis translates into\n(p,q)-deformations of the supersymmetric harmonic oscillator, such that the two supersym-\nmetric sectors get intertwined through the action of the ladder operators as well as in the\nassociated coherent states.\n1On sabbatical leave from the Center for Particle Physics and Phenomenology (CP3), Institute of Nuclear\nPhysics, Catholic University of Louvain, 2, Chemin du Cyclotron, B-1348 Louvain-la-Neuve, Belgium.\n1 Introduction\nIn recent years, quantum algebras and groups [1] which appear as a generalization of the sym-\nmetry concept [2] and the basics of so-called noncommutative theories, have been the subject of\nintensive research interest in both mathematics and physics. The q- and more generally (p,q)-\ndeformation of a pre-defined algebraic structure [3, 4, 5] proves to be a powerful tool widely used\nin the representation theory of quantum groups. The field of ?q-mathematics? has a long history\n[6, 7] dating back to over 150 years, and includes several famous names such as Cauchy, Jacobi\nand Heine to mention just a few. Its possible relation to physics has been considerably reinforced\nduring the last thirty years [3, 8]. In particular, great attention has been devoted to deformations\nof the bosonic Fock-Heisenberg algebra. The most commonly studied deformed bosons, with\nannihilation and creation operators a and a?, respectively, satisfy the q-commutation relation\n[3] (also called quommutation)\naa??qa?a = I, (1)\nor some variant forms of such a relation [4, 9]. Still more general deformations, which include in\nspecific limits the above standard q-deformed case and which also provides consistent extensions\nof the harmonic oscillator algebra, proceed from the two parameter deformation of the Fock\nalgebra introduced by Chakrabarty and Jagannathan [5], namely the so-called (p,q)-oscillator\nquantum algebras generated by three operators a, a? and N which obey [5, 10]\n[N,a] =?a, [N,a?] = a?, aa??qa?a = p?N, aa??p?1a?a = qN. (2)\nHere, p and q are free parameters, which henceforth are chosen to be both real and such that\np > 1, 0 < q < 1 and pq < 1. Clearly, one recovers the ordinary Fock algebra of the harmonic\noscillator algebra in the double limit p,q?1, with then [a,a?] = I and N = a?a. Furthermore,\nthese q- and (p,q)-deformed algebras have found a number of relevant applications and provide\nalgebraic interpretations of various q- and (p,q)-special functions [9, 10, 11].\nThe harmonic oscillator algebra is central in the construction of a number of models in\nphysics, among which the Jaynes?Cummings model (JCm) plays a significant role. Indeed ever\nsince Jaynes and Cummings? historical work [12], the JCm has been at the basis of many in-\nvestigations. This system belongs to a class of physically relevant models widely used in atomic\nphysics and quantum optics. As far as we know, a great deal of analytically solvable models of\nthis type have been studied in the rotating wave approximation (r.w.a.) within the framework\nof non-deformed commutative theories (see [12]?[17] and references therein). TheJCm has also\nbeen considered in the context of generalized intensity dependent oscillator algebras including\nnonlinear dynamical supersymmetry[18] or using shapeinvariance techniques [19, 20]. Compara-\ntively, much fewer papers have dealt with generalizations of these models including deformations.\nAmong the latter and mainly based on the generalized intensity-dependent coupling of Buck and\nSukumar [21], one may mention, on the one hand, the work by Chaichan et al. [22], and on the\nother hand, that by Chang [23], both dealing with a generalized q-deformed intensity-dependent\ninteraction Hamiltonian of theJCm given by the Holstein-Primakoff suq(1,1) or suq(2) quantum\nalgebra realizations of the Hamiltonian field operators and the related Peremolov, Glauber or\nBarut-Girardello group theoretical construction of coherent states. In the same vein, the paper\nby Naderi et al. considers the dynamical properties of a two-level atom in three variants of the\ntwo-photon q-deformedJCm [24]. In this latter work, the authors focused their attention onto\nthe time evolution of atomic properties including population inversion and quantum fluctuations\nof the atomic dipole variables. However, it is not clear to us how the main issues related to the\nmoment problem as well as the mathematical foundation of the coherent and squeezed states\nwhich they use and on which a great part of their analysis rests in a crucial way, are solved.\n1\nIn a recent publication [14], Hussin and Nieto have performed an interesting systematic\nsearch of different types of ladder operators for theJCm model in the r.w.a. and constructed\nassociated coherent states. In the present work, and in line with that investigation, we provide\na generalization of that analysis to (p,q)-deformations of the same model.\nThe outline of the paper is the following. In Section 2, we briefly recall the main results\nrelevant to theJCm in the r.w.a. in the non-deformed situation [14]. Section 3 then introduces\n(p,q)-deformations of the same model. By providing an explicit diagonalization of the (p,q)-\ndeformed Hamiltonian, the spectrum and its eigenstates are exactly identified. As in the non-\ndeformed case [14], except for a singleton state, all other energy eigenstates are organized into\ntwo separate discrete towers, for which ladder operators transforming states into one another\nwithin each tower separately may be introduced. Using properties of these ladder operators, in\nSection 4 we introduce general classes of (p,q)-deformed vector coherent states. The freedom\nafforded in their construction is fixed from two alternative points of view, discussed in Section 5,\nwhich in the ordinary case of the non-deformed Fock algebra coincide. However at all stages of\nour discussion, the double limit p,q?1 reproduces the corresponding results of [14]. Section 5\nalso briefly considers the situation in the uncoupled limit of theJCm, while Section 6 presents\nsome concluding remarks. An Appendix collects useful facts in connection with properties of\n(p,q)-deformed algebras and related functions.\n2 The Ordinary JCm in the Rotating Wave Approximation\nThe JCm describes the interaction between one mode of the quantized electromagnetic field\nand a two-level model of an atomic system [12, 14]?[16]. It has proved to be a theoretical\nlaboratory of great relevance to many topics in atomic physics and quantum optics, as well\nas in the study of ion traps, cavity QED theory and quantum information processing [13, 14].\nFurthermore, the spin-orbit interaction term which appears in the JCm is essentially the so-\ncalled Dresselhaus spin-orbit term [25]. The model is thus also widely used in condensed matter\nphysics for its relevance in spintronics [26] which exploits the electron spin rather than its charge\nto develop a new generation of electronic devices [27, 28]. The solution of the completeJCm is\nnot yet known in a closed form [14]. However, in the r.w.a., although the Hamiltonian remains\nnonlinear, the model becomes exactly solvable in closed form with explicit expressions for its\neigenenergy states. In this Section, we briefly recall, in a streamlined presentation, the main\nresults in the non-deformed case (see [14, 15] and references therein) of relevance to our analysis\nof (p,q)-deformations hereafter.\nIn the r.w.a., the reduced dimensionlessJCm Hamiltonian reads [15]\nHred = 1planckover2pi1?\n0\nH= (1+?)\nparenleftbigg\na?a+ 12\nparenrightbigg\n+ 12?3 +?\nparenleftBig\na??? +a?+\nparenrightBig\n, (3)\nwhere a and a? are the usual photon annihilation and creation operators, respectively, obeying\nthe ordinary Fock algebra, and (?1,?2,?3) are the Pauli matrices with ?? = ?1?i?2. The r.w.a.\nis related to the detuning parameter ? which is such that|?|?1, with ?0 being the fixed atomic\nfrequency and ? = ?0(1 + ?) the actual field mode frequency. The r.w.a. is reliable provided\n|???0|??,?0. Finally, ? is the reduced spin-orbit coupling modelling the interaction strength\nbetween the radiation field and the atom.\n2\nThe Hilbert spaceV of the system is the tensor product of the Fock space representation\nof the Fock algebra (a,a?) and the 2-dimensional representation of the SU(2) algebra associated\nto the Pauli matrices. A basis of the former is provided by the number operator, N = a?a,\northonormalized eigenstates |n? = (1/?n!)(a?)n|0? (n = 0,1,2,???), with a|n? = ?n|n?1?,\na?|n?=?n+ 1|n + 1?and N|n?= n|n?, while a basis of the latter spin sector is the orthonor-\nmalized set {|+?,|??} such that ?3|??=?|??. The tensor product space is thus spanned by\nthe states|n,??=|n??|??.\nThe diagonalization of the Hamiltonian (3) is readily achieved. The orthonormalized\nenergy eigenspectrum consists of a ?singleton? state|E??,\nHred|E??= E?|E??, (4)\nwith\nE? = 12?, |E??=|0,??, (5)\nand two infinite discrete towers of states |E?n? such that Hred|E?n? = E?n|E?n? for all n =\n0,1,2,???, expressed as [14]\n|E+n? = sin?(n)|n,+?+ cos?(n)|n+ 1,??, (6)\n|E?n? = cos?(n)|n,+??sin?(n)|n+ 1,??, (7)\nwhere, given Q(n+ 1) =radicalbig?2/4 +?2(n+ 1), the mixing angle ?(n) is such that\nsin?(n) = sign(?)\nradicalBigg\nQ(n+ 1)??/2\n2Q(n + 1) , cos?(n) =\nradicalBigg\nQ(n+ 1) +?/2\n2Q(n+ 1) , (8)\nwhile the energy eigenvalues are\nE?n = (1 +?)(n+ 1)?Q(n+ 1). (9)\nConsequently, one has the spectral decomposition of the reduced Hamiltonian (3),\nHred =|E??E??E?| +\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|. (10)\nIt proves useful to introduce the following notations. Let V0 be the (complex) one-\ndimensional subspace of the Hilbert space V spanned by the state |0,?? = |E??, and V be\nits complement in the Hilbert spaceV, spanned by{|E?n?,n?N}. We thus haveV=V0?V.\nFurthermore let us introduce [14] operatorsU andU? defined through their action on the\nabove two sets of basis vectors, for all n?N,\nU|n,??=|E?n?; U?|E??= 0, U?|E?n?=|n,??, (11)\nnamely\nU =\n?summationdisplay\nn=0,?\n|E?n??n,?|, U? =\n?summationdisplay\nn=0,?\n|n,???E?n|. (12)\nClearly we have\nUV =V; U?V =V, U?V=V. (13)\n3\nNote that even though neither U nor U? is unitary on the full Hilbert space V, they are the\nadjoint of one another, hence the notation.\nIt is of interest to apply these operators onto the quantum Hamiltonian (3). One obtains\nHred =U?HredU =\n?summationdisplay\nn=0,?\n|n,??E?n ?n,?|, (14)\nand conversely,\nUHredU? =\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|=Hred ?|E??E??E?|. (15)\nThe energy eigenstates spanning V may be organized into two subspaces referred to as\n?towers?, namely {|E+n?,n?N} and {|E?n?,n?N}. The states in the tower {|E+n?,n?N}\nare associated to strictly increasing eigenvalues so that they constitute a nondegenerate set\nof eigenstates. The second group does not necessarily possess the same feature depending\non the values for the parameters ? and ?. It is possible [16] to identify a range of values\nfor these parameters such that {|E?n?,n?N} only contains nondegenerate states of strictly\nincreasing eigenvalues with n. Some of the considerations discussed hereafter may require a\nnondegenerate spectrum, which may always be achieved by properly ?detuning? the parameters\n? and ? away from a degenerate case, but not necessarily a strictly increasing spectrum in the\nlabel n?N. Whatever the case may be though, bounded from below spectra such that E?n > E?0\nfor n = 1,2,???are always assumed implicitly.\nIt is possible to consider ladder operators acting between successive energy eigenstates\nwithin each of the above two towers, irrespective of whether the spectral values are strictly\nincreasing or not1. Namely, let us first consider operators M? and M+ given as\nM? =\n?summationdisplay\nn=0,?\n|n?1,??K?(n)?n,?|; M+ =\n?summationdisplay\nn=0,?\n|n+ 1,??K??(n+ 1)?n,?|, (16)\nwhere K?(n) are, at this stage, arbitrary complex coefficients such that K?(0) = 0. Then,\nintroduce the ladder operators\nM? =UM?U? =\n?summationdisplay\nn=0,?\n|E?n?1?K?(n)?E?n|; M+ =UM+U? =\n?summationdisplay\nn=0,?\n|E?n+1?K??(n+ 1)?E?n|,\n(17)\nwhich are thus such that, for all n = 0,1,2,???,\nM?|E??= 0, M?|E?n?= K?(n)|E?n?1?; M+|E??= 0, M+|E?n?= K??(n+ 1)|E?n+1?.\n(18)\nNote thatM? andM+ are adjoint of one another but in effect only act on the subspaceV.\nGeneral vector coherent states (VCS) may then be introduced [29]?[32] on the space V\nas eigenstates of the lowering operator M? with as eigenvalue an arbitrary complex number\nz?C. Furthermore, these VCS are also parametrized by two real quantities ?? which account\nfor their stability under time evolution generated by the operator expbraceleftbig?i?0tHredbracerightbig, as well as\nthe two spherical coordinates (?,?)?[0,?]?[0,2?[ parametrizing a unit vector in the 2-sphere\n1We differ on this point with [14], where strictly increasing energy spectra in each tower are required.\n4\nS2 (hence the name of ?vector? coherent states). Explicitly, one has [14]\n|z;??;?,?? = N+(|z|)cos?\n?summationdisplay\nn=0\nzn\nK+(n)!e\n?i?0?+E+n |E+\nn?\n+ N?(|z|)ei? sin?\n?summationdisplay\nn=0\nzn\nK?(n)!e\n?i?0??E?n |E?\nn?, (19)\nwhere K?(n)! =producttextnk=1 K?(k) (with, by convention, K?(0)! = 1), while the normalization factors\nare defined as\nN?(|z|) =\nbracketleftBigg ?summationdisplay\nn=0\n|z|2n\n|K?(n)!|2\nbracketrightBigg?1/2\n(20)\nin order that the VCS be of unit norm. The smallest value, R, of the two convergence radii of\nthese two series in |z| also defines the disk DR in z ?C for which these VCS are well defined.\nThese states are clearly such that\nM?|z;??;?,??= z|z;??;?,??, e?i?0tHred|z;??;?,??=|z;t +??;?,??. (21)\nFurther restrictions are necessary to finally specify in a unique fashion the factors K?(n),\nand then solve the moment problem implied by the requirement of overcompleteness overV for\nthe VCS (19) given a choice of a SU(2) matrix-valued integration measure over C?S2 [30]-[32].\nDifferent choices are available [14], each leading to a different set of VCS. Furthermore, taking\nthe limit case ??0 or the zero-detuning limit (resonance case) ??0, different models arise\nwith their associated VCS.\nFor the sake of illustration, let us consider one such choice explicitly [14]. The factors\nK?(n) may be restricted for example by requiring that the ladder operatorsM? andM+ obey\nthe usual Fock algebra of annihilation and creation operators on the spaceV,\nbracketleftbigM?,M+bracketrightbig=M?M+ ?M+M? = I\nV =\n?summationdisplay\nn=0,?\n|E?n??E?n|. (22)\nFrom the expressions in (18) and the initial conditions K?(0) = 0, it follows that the quantities\nK?(n) are now determined up to arbitrary phase factors ??(n) as\nK?(n) = ei??(n)?n, n = 0,1,2,???. (23)\nConsequently, one has N?(|z|) = e?|z|2/2, which is well-defined for all z?C. Hence so are then\nall the VCS|z;??;?,??.\n3 The (p,q)-Deformed JCm in the Rotating Wave Approxima-\ntion\nLet us now introduce a (p,q)-deformation of the JCm Hamiltonian (3), namely (p,q)-JCm\nmodels. The eigenstates and spectrum are first identified, before considering the construction\nof ladder operators following the same rationale as in Section 2. A study of the associated VCS\nand examples of exactly solvable reduced models is differed to Section 4.\n5\n3.1 Energy spectrum and eigenstates\nGiven the (p,q)-deformation (2) of the ordinary Fock algebra (see the Appendix for further\ndetails and identities pertaining to such deformations), we now consider (p,q)-deformations of\nthe Hamiltonian (3) of the form2\nHred = (1 +?)\nbraceleftbigg\nh(p,q)[N] + 12\nbracerightbigg\n+ 12?3 +?\nparenleftBig\na??? +a?+\nparenrightBig\n, (24)\nwhere [N] = (p?N ?qN)/(p?1?q), and h(p,q) is some arbitrary positive function of the real\nparameters p > 1 and 0 < q < 1 (with pq < 1) such that limp,q?1 h(p,q) = 1 in order to recover\n(3) in the non-deformed case.\nThe Hilbert space V of quantum states of the model is again the tensor product of the\n(p,q)-deformed Fock space spanned by the states3 |n?(n?N) such as a|n?= radicalbig[n]|n?1?and\na?|n?=radicalbig[n+ 1]|n+1?(see the Appendix), with the 2-dimensional representation of the SU(2)\nalgebra associated to the Pauli matrices ?i (i = 1,2,3). Hence the diagonalization of (24) is\nreadily achieved in the same way as in the non-deformed case, on the basis|n,??=|n??|??of\nV.\nFor any n?N, let us introduce the following quantities,\nE([n+1]) = (1+?)h(p,q)\nparenleftBig\n[n+1]?[n]\nparenrightBig\n?1, Q([n+1]) =\nradicalbigg\n1\n4E\n2([n +1]) + ?2 [n+1], (25)\nas well as the mixing angles ?([n]) defined by\nsin?([n]) = sign(?)\nradicalBigg\nQ([n+ 1])?E([n + 1])/2\n2Q([n + 1]) , cos?([n]) =\nradicalBigg\nQ([n + 1]) +E([n+ 1])/2\n2Q([n +1]) .\n(26)\nThe energy eigenspectrum of (24) is then obtained as follows. First, there exists a singleton\nstate|E??=|0,??such that\nHred|E??= E?|E??, E? = 12?, (27)\nwith an eigenvalue which is thus independent of the deformation parameters p and q. Next, one\nalso finds two infinite discrete towers of states for all n?N such that\n|E+n? = sin?([n])|n,+? + cos?([n])|n + 1,??, (28)\n|E?n? = cos?([n])|n,+?? sin?([n])|n + 1,??, (29)\nwith\nHred|E?n?= E?n |E?n?, E?n = 12 (1 +?)\nbraceleftBig\nh(p,q)\nparenleftBig\n[n+ 1] + [n]\nparenrightBig\n+1\nbracerightBig\n? Q([n+ 1]). (30)\nNote that the energy spectrum of these states is deformed by the parameters p and q as compared\nto the ordinary case. In particular, the Zeeman spin splitting ?En = E+n ?E?n = 2Q([n + 1]),\n2Make no mistake that henceforth, all quantities correspond to the (p,q)-deformed analysis even though the\nnotations used coincide with those of Section 2 and do not make explicit the fact that all expressions correspond\nnow to the deformed case. When wanting to make the difference explicit, notations such as for instance [N] ?\n[N](p,q) = (p?N ?qN)/(p?1 ?q) and [n] ? [n](p,q) = (p?n ?qn)/(p?1 ?q) are used.\n3Once again, the states |n? = |n?(p,q) are not to be confused with the number operator eigenstates of the\nordinary Fock algebra as in Section 2, in spite of an identical notation.\n6\nproportional to the Rabi frequency, is function of the values for p and q. In terms of these\nresults, the reduced Hamiltonian (24) possesses the spectral resolution\nHred =|E??E??E?| +\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|. (31)\nLet us again introduce the following notations and operators. LetV0 denote the subspace\nof the Hilbert space V spanned by the singleton state |E??= |0,??, and V its complement in\nV, namely the subspace spanned by{|E?n?,n?N}, with of courseV=V0?V. Acting on these\nspaces, let us consider the operators\nU =\n?summationdisplay\nn=0,?\n|E?n??n,?|; U? =\n?summationdisplay\nn=0,?\n|n,???E?n|, (32)\nsuch that, for all n = 0,1,2,???,\nU|n,??=|E?n?; U?|E??= 0, U?|E?n?=|n,??, (33)\nand thus\nUV=V; U?V=V, U?V =V. (34)\nHence once again the operators U and U?, even though non unitary on V, are adjoint of one\nanother. More specifically, one has\nU?U =\n?summationdisplay\nn=0,?\n|n,???n,?|= IV, UU? =\n?summationdisplay\nn=0,?\n|E?n??E?n|= IV. (35)\nApplying these operators to the reduced Hamiltonian, one finds\nHred =U?HredU =\n?summationdisplay\nn=0,?\n|n,??E?n ?n,?|, (36)\nand conversely,\nUHredU? =\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|=Hred ?|E??E??E?|. (37)\nSome remarks on the spectrum are in order. First, as in the ordinary JCm, except\nfor the singleton state |E?? = |0,??, the spectrum is the direct sum of two towers of states\n{|E?n?,n?N}. However, in contradistinction to the non-deformed case or even the q-deformation\nwith p = 1, the (p,q)-basic numbers [n] = [n](p,q) are not strictly increasing as a function of\nn?N when p > 1, 0 < q < 1 and pq < 1. There always exists a finite positive value n0 ?N\nsuch that [n] decreases once n > n0. Hence, depending on the values for the parameters ? and ?\nas well as the positive function h(p,q), parts of the spectrum E?n may turn negative or present\nsome degeneracies (as in [16]). Without exploring this issue any further in the present work,\nhenceforth we shall assume that parameter values are such that no degeneracies occur and that\nthe spectrum E?n remains bounded from below (E+n is obviously positive). The definition of the\nladder operators to be considered next does not require a strictly increasing spectrum, while it\nis only for one of possible choices leading to vector coherent states to be discussed hereafter that\nthe condition of non degeneracy in E?n > E?0 , for n?1, becomes relevant. Since it has been\n7\nshown [16] that such conditions may be met in the non-deformed case for appropriate ranges\nof values for the available parameters, through an argument of continuity in the deformation\nparameters p and q, similar ranges ought to exist also for the (p,q)-deformed realizations of the\nJCm model.\nAnother feature of potential interest related to these facts, and which will also not be\npursued here, is the possibility that through the (p,q)-deformation of theJCm, the levels E+n\nand E?n+1 cross one another. Such a property may lead to effects similar to the phenomenon\nof resonant spin-Hall conductance at the Fermi level recently observed in spintronics [27, 28].\nNote that this (p,q)-dependent crossing phenomenon is expected since the Zeeman splitting\n?En is also modified as a function of p and q. This remark is also in line with the recent\nsuggestion [33, 34, 35] that (p,q)-deformed or space noncommutative realizations of exactly\nsolvable systems may provide useful model approximations to more realistic complex interacting\ndynamics of collective phenomena.\n3.2 Ladder operators\nIn order to construct ladder operators mapping each of the successive states |E?n? into one\nanother separately within each of the towers, let us first introduce the following operators acting\nonV,\nA? =\n?summationdisplay\nn=0,?\n|n?1,??K?([n])?n,?|; A+ =\n?summationdisplay\nn=0,?\n|n+ 1,??K??([n +1])?n,?|, (38)\nwhere K?([n]) are arbitrary complex quantities such that K?([0]) = K?(0) = 0. Note that A?\nand A+ are adjoint of one another onV.\nThen the relevant ladder operators are obtained as\nA? =UA?U? =\n?summationdisplay\nn=0,?\n|E?n?1?K?([n])?E?n|; A+ =UA+U? =\n?summationdisplay\nn=0,?\n|E?n+1?K??([n+ 1])?E?n|.\n(39)\nConsequently, we have indeed, for all n?N,\nA?|E??= 0, A?|E?n?= K?([n])|E?n?1?; A+|E??= 0, A+|E?n?= K??([n+ 1])|E?n+1?.\n(40)\nNote thatA? andA+ are adjoint of one another, but that in effect they act only on the subspace\nV.\nIt is of course possible to express these ladder operators in the|n,??basis. In the case of\nthe lowering operator, one finds\nA? = summationtext?n=0 |n,+?A?++(n)?n+ 1,+| + summationtext?n=0 |n,+?A?+?(n)?n+ 2,?|\n+ summationtext?n=0 |n,??A??+(n)?n,+| + summationtext?n=0 |n,??A???(n)?n+ 1,?|\n(41)\nwhere\nA?++(n) = sin?([n]) sin?([n+ 1])K+([n + 1]) + cos?([n]) cos?([n+ 1])K?([n + 1]),\nA?+?(n) = sin?([n]) cos?([n+ 1])K+([n + 1]) ? cos?([n]) sin?([n+ 1])K?([n + 1]),\n8\nA??+(n) = cos?([n?1]) sin?([n])K+([n]) ? sin?([n?1]) cos?([n])K?([n]),\nA???(n) = cos?([n?1]) cos?([n])K+([n]) + sin?([n?1]) sin?([n])K?([n]). (42)\nLikewise for the raising operator,\nA+ = summationtext?n=0 |n+ 1,+?parenleftbigA?++(n)parenrightbig? ?n,+| + summationtext?n=0 |n,+?parenleftbigA??+(n)parenrightbig? ?n,?|\n+ summationtext?n=0 |n+ 2,??parenleftbigA?+?(n)parenrightbig? ?n,+| + summationtext?n=0 |n+ 1,??parenleftbigA???(n)parenrightbig? ?n,?|.\n(43)\nNote that we haveA??+(0) = 0 =A???(0), since K?([0]) = 0.\nThe quantities K?([n]) parametrize the freedom available in the choice of such ladder\noperators. Further restrictions arise when considering first the possible existence of vector\ncoherent states meeting a series of general conditions charateristic of such states [30]-[32], starting\nwith one involving the lowering operatorA? itself.\n4 (p,q)-Vector Coherent States for the (p,q)-JCm\nBy considering the action of the lowering operatorA?, we are able to construct an overcomplete\nset of vectors in V, so-called vector coherent states [30]-[32] for the (p,q)-JCm. Since these\nstates are associated to unit vectors in the 2-sphere S2 [29], they are referred to as (p,q)-vector\ncoherent states ((p,q)-VCS). As in Section 2, these (p,q)-VCS are parametrized by a complex\nvariable z ?C, two real parameters ?? to track a stable time evolution of the (p,q)-VCS, and\nfinally the spherical angle coordinates (?,?) on S2,|z;??;?,??. In the double limit that p,q?1,\nthese (p,q)-VCS reduce to those of [14] discussed in Section 2. The dependence of the (p,q)-VCS\non all these quantities is introduced as follows, according to the discussion in [30].\n4.1 Identifying (p,q)-VCS\nAs a slight extension of the analysis so far, given two real parameters ? and ?, let us consider\nthe operator\nQV =|E???E?| +\n?summationdisplay\nn=0,?\n|E?n?\nparenleftbiggq?\np?\nparenrightbiggn\n?E?n|. (44)\nHence, the energy eigenstates of the (p,q)-JCm are also eigenstates of this operator QV, with\neigenvalues given through the above spectral decomposition.\nWe are now in a position to successively identify the dependence of the (p,q)-VCS to be\nconstructed on each of the parameters of which they are functions, first z, then ??, and finally,\n? and ?. Having defined both the operatorsA? and QV, let us consider the following eigenvalue\nproblem in z for the (p,q)-VCS,\nA?|z;??;?,??= zQV|z;??;?,?? (45)\nwhich generalizes to a two-level system the definition of coherent states as advocated in [30]-\n[32]. The particular case ? = 0 = ? yields also a consistent definition of (p,q)-VCS viewed as\nthe limit ?,? ?0 of the present definition (note that their domain of definition in z, required\n9\nfor the convergence of the infinite series to be considered hereafter, may have to be adapted\naccordingly).\nBy expanding the (p,q)-VCS in the Hamiltonian eigenstate basis as\n|z;??;?,??= C?(z)|E??+\n?summationdisplay\nn=0,?\nC?n (z)|E?n?, (46)\nwhere C?(z) and C?n (z) are complex continuous functions of z to be specified presently, the\ncondition (45) then requires, for all n?N,\nC?(z) = 0, C?n+1(z)K?([n+ 1]) = z q\n?n\np?n C\n?\nn (z), (47)\nof which the solution is\nC?n (z) =\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK?([n])! C\n?\n0 (z), (48)\nwhere C?0 (z) are arbitrary complex functions of z, while we defined K?([n])! = producttextnk=1 K?([k])\nwith, by convention, K?([0])! = 1. Hence, the general solution to (45) defines states lying only\nwithin the subspaceV, of the form\n|z;??;?,??=\n?summationdisplay\nn=0,?\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK?([n])! C\n?\n0 (z)|E\n?\nn?. (49)\nNote that the eigenvalue problem (45) is singular at the particular value z = 0, since its solution\nis an arbitrary superposition of the three states|E??and|E?0 ?. Nevertheless, we shall consider\nthe (p,q)-VCS associated to z = 0, |z = 0;??;?,??, as being defined through the continuous\nlimit in z?0 of the construction in (49), namely|z = 0;??;?,??= C+0 (0)|E+0 ?+C?0 (0)|E?0 ?.\nLet us now turn to the issue of the stability of the (p,q)-VCS under time evolution gener-\nated by the Hamiltonian (24). Namely, we now require furthermore that (p,q)-VCS are trans-\nformed into one another under time evolution according to the following dependence on the real\nparameters ??, for all t?R,\ne?i?0tHred|z;??;?,??=|z;t +??;?,??. (50)\nSince one has, for all n?N,\ne?i?0tHred|E?n?= e?i?0tE?n |E?n?, (51)\none needs to factor out their complex phases from the quantities K?([n]),\nK?([n]) = ei??([n])K0?([n]), (52)\nwhere K0?([n]) > 0 are now real positive scalars. The stability condition (50) is then solved by\nchoosing, for all n = 1,2,???,\n??([n]) = ?0??bracketleftbigE?n ?E?n?1bracketrightbig, (53)\nand redefining\nC?0 (z) =C?0 (z)e?i?0??E?0 , (54)\n10\nwhereC?0 (z) are new complex functions of z. Hence,\n|z;??;?,??=\n?summationdisplay\nn=0,?\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK0?([n])!C\n?\n0 (z)e\n?i?0??E?n |E?\nn?. (55)\nHaving identified both the z and ?? dependences of the coherent states, finally let us\naccount for their (?,?) dependence and S2 vector character implicit so far through the two\nfunctionsC?0 (z). The latter are now chosen to be given as\nC+0 (z) = N+(|z|) cos?, C?0 (z) = N?(|z|)ei? sin?, (56)\nN?(|z|) being factors such that the constructed (p,q)-VCS be of unit norm,\nN?(|z|) =\nbraceleftBigg ?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2\nbracerightBigg?1/2\n. (57)\nThe convergence radii R? of these two series in z,\nR? = limn??\nbraceleftBig\n(q?p??)?(n?1) K0?([n])\nbracerightBig\n, (58)\ndepend on the choice of functions K0?([n]) as well as on (?,?) possibly. Specific cases are\nconsidered hereafter.\nConsequently, the (p,q)-VCS constructed here are properlydefined provided z?DR where\nDR denotes the disk in the complex plane centered at z = 0 and of radius R = min(R+,R?).\nTheir general structure is thus of the form\n|z;??;?,?? = N+(|z|) cos?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK0+([n])! e\n?i?0?+ E+n |E+\nn?\n+ N?(|z|)ei? sin?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK0?([n])! e\n?i?0??E?n |E?\nn?. (59)\nOnly the real positive functions K0?([n]) still need to be specified. They parametrize the remain-\ning freedom in the construction. Particular examples will be considered hereafter by imposing\nfurther requirements on these (p,q)-VCS. Note that the double limit p,q?1 yields the VCS of\nthe non-deformedJCm as obtained by Hussin and Nieto [14], briefly described in Section 2.\n4.2 Some expectation values\nBefore dealing with further requirements on the family of (p,q)-VCS, among which their over-\ncompleteness in the space V, let us consider some relevant expectation values for these states.\nGiven (59), the mean value ofHred for any of the (p,q)-VCS is simply\n?Hred? = |N+(|z|)|2 cos2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n+([n])!\nparenrightbig2 E+n\n+|N?(|z|)|2 sin2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2 E?n . (60)\n11\nLikewise for the ?number? operator associated to the ladder operators A? and A+, one finds\nthe expectation value\n?A+A?? = |z|2\nbraceleftBigg\n|N+(|z|)|2 cos2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n+1) |z|2n\nparenleftbigK0\n+([n])!\nparenrightbig2\n+|N?(|z|)|2 sin2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n+1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2\nbracerightBigg\n. (61)\nFinally, the average atomic spin time evolution ??3(t)? = ?U?1(t)?3U(t)?, with U(t) =\nexp{?i?0tHred}being the time evolution operator, has the form\n??3(t)?= 12\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1)\n|z|2nE([n+ 1])Q([n+ 1])\nbraceleftBigg\n?|N\n+(|z|)|2\nparenleftbigK0\n+([n])!\nparenrightbig2 cos2 ? + |N\n?(|z|)|2\nparenleftbigK0\n?([n])!\nparenrightbig2 sin2 ?\nbracerightBigg\n+?N+(|z|)N?(|z|)sin2?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nK0+([n])!K0?([n])!\n[n+ 1]\nQ([n+ 1]) cos?n(t), (62)\nwith\n?n(t) = ?0bracketleftbig(t+?+)E+n ? (t +??)E?nbracketrightbig + ? = ?0?En t + ?0bracketleftbig?+E+n ???E?nbracketrightbig+?. (63)\nAs is the case in the non-deformed model, the explicit time dependence which arises for the\natomic inversion ??3(t)? is due to the mixed state sector, namely the fact that the mixed-spin\nmatrix elements of the Heisenberg picture operator ?3(t) do not vanish when ? negationslash= 0. Hence,\nthe proposition which states that the time dependence of atomic inversion consists of Rabi\noscillations when a system is prepared in a coherent state of the radiation field [17] extends to\n(p,q)-VCS. However, in the limit where ??0, no such oscillations occur. Let us also point out\nthat the time dependence of??3(t)?diplays chaotic behaviour for appropriate values of the model\nparameters, as was previously mentioned for the q-deformation of the model, with 0 < q < 1, in\nthe work by Naderi et al. [24].\n4.3 Overcompleteness and the moment problem\nAn important property that coherent states ought to meet is that of overcompleteness in the\nspace over which they are defined [30]. In the present case, this means that the (p,q)-VCS in\n(59) must also provide a resolution of the identity operator over the subspaceV, namely\nIV = IV0 + IV =|E???E?| + IV, (64)\nwhile\nIV =\n?summationdisplay\nn=0,?\n|E?n??E?n|=\nintegraldisplay\nDR?S2\nd?(z;?,?)|z;??;?,???z;??;?,?|, (65)\nwhere d?(z;?,?) is some SU(2) matrix-valued integration measure over DR?S2 to be determined\nfrom the above requirement.\nLet us thus consider the following parametrization of that measure,\nd?(z;?,?) = d2zd? sin?d?\nbraceleftBigg\nW+(|z|)\n?summationdisplay\nn=0\n|E+n??E+n| + W?(|z|)\n?summationdisplay\nn=0\n|E?n??E?n|\nbracerightBigg\n, (66)\n12\nin terms of real weight functions W?(|z|) to be identified. Using the radial parametrization\nz = rei? and d2z = drrd? where r ? [0,?[ and ? ? [0,2?[, a direct substitution in (65)\nleads to the moment problem associated to the overcompleteness relation (65). In terms of the\nfunctions h?(r2) defined through\nh+(r2) = 4?\n2\n3 |N\n+(r)|2W+(r), h?(r2) = 8?2\n3 |N\n?(r)|2W?(r), (67)\nthe following two infinite sets of moment identities must be met, for all n?N,\nintegraldisplay R2\n0\nduun h?(u) =\nparenleftbiggq?\np?\nparenrightbigg?n(n?1) parenleftbig\nK0?([n])!parenrightbig2 . (68)\nIn conclusion, the resolution of the identity operator over V in terms of the (p,q)-VCS\nis achieved provided the Stieljes moment problem (68) can be solved [36, 37]. This requires a\nchoice of functions K0?([n]) > 0 such that not only the conditions (68) may all be met, but also\nsuch that the normalization factors N?(|z|) converge in a non-empty disc of the complex plane.\nAs a result of this analysis, a priori there may exist a large number of sets of (p,q)-VCS\nwhich fulfill all the above properties, namely continuity in the complex parameter z, temporal\nstability through a simple additive time dependence in the real parameters ??, a unit vector\nvalued characterization on the sphere S2 in terms of the spherical coordinates ? and ?, and the\ncompleteness propertyof a resolution of the unit operator with a SU(2) matrix-valued integration\nmeasure over these spaces. These sets of (p,q)-VCS are distinguished from one another by\ndifferent choices of real positive weight factors K0?([n]), in agreement with the considerations\ndeveloped in [30, 38]. The above construction of (p,q)-VCS is general, but can admit explicit\nexact solutions to the moment problem(68) for particular cases. Concrete examples are discussed\nin Section 5..\n4.4 Action-angle variables\nOne of the useful properties that general coherent states constructed according to the arguments\nof [38] possess, is that action-angle variables are readily identified in relation to the continuous\nparameters ensuring stability of the coherent states under time evolution. In the present case,\ncanonical reduced action-angle variables (J?(t),??(t)) are such that for the previously evaluated\nexpectation values of the reduced Hamiltonian (24) in the (p,q)-VCS, one has\n?Hred?= J+ ?+ + J? ?? =\nsummationdisplay\n?\nJ? ??, (69)\nin relation to the action-angle variational principle of the form\nintegraldisplay\ndt\nsummationdisplay\n?\nbracketleftbiggd?\n?\ndt J? ? ??J?\nbracketrightbigg\n??\nintegraldisplay\ndt\nbracketleftbigg\n? i?\n0\nd\ndt???H\nred?\nbracketrightbigg\n, (70)\nwhere ?? are two constant factors to be chosen appropriately. Consequently\nd??\ndt =\n??Hred?\n?J? = ??,\ndJ?\ndt =?\n??Hred?\n??? = 0. (71)\n13\nGiven the time evolution, ??(t) = t + ??(0), one simply finds ?? = 1. From the expression in\n(60), one then has the identifications\nJ+ = |N+(|z|)|2 cos2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n+([n])!\nparenrightbig2 E+n ,\nJ? = |N?(|z|)|2 sin2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2 E?n . (72)\nAs a final remark, let us mention that the saturated Heisenberg uncertainty relations\nwhich are obeyed by q- and (p,q)-coherent states are also well-known in q-mechanics (see for\ninstance [39]). Such minimal uncertainties may be characterized through small corrections to\ncanonical commutation relations defined in [39, 40]. Such properties in the case of the (p,q)-VCS\nconstructed here are deferred to a later study.\n5 Explicit Solutions\nIn order to completely specify the quantities K0?([n]), one last set of conditions needs to be\nimplemented. In the present Section, two such choices are discussed, one of which allows for an\nexact and explicit solution to the moment problem, hence the construction of a set of (p,q)-VCS.\nFirst, in line with the illustrative example of Section 2, we consider restricting the algebra of the\nladder operatorsA?. Then as a second and independent possibility, we apply a final additional\ncriterion developed in [30] in order to uniquely characterize a set of coherent states which meet\nalready all the requirements considered heretofore and having led to the representation (59),\neven though the moment problem remains unsolved for that choice.\n5.1 Constraining the ladder operator algebra\nIn order to uniquely identify the set of functions K0?([n]) > 0, let us consider the possibility\nthat this may be achieved by restricting the algebraic properties of the ladder operators. In line\nwith the general (p,q)-deformations of the Fock algebra in (2), let us constrain the algebra of\nthe operators A? acting onV to be such that\nA?A+ ? q0A+A? = p?N0 =\n?summationdisplay\nn=0,?\n|n,??p?n0 ?n,?|,\nA?A+ ? p?10 A+A? = qN0 =\n?summationdisplay\nn=0,?\n|n,??qn0 ?n,?|, (73)\nwhere p0 and q0 are again two real parameters such that p0 > 1, 0 < q0 < 1 and p0q0 < 1, which\nmay or may not be identical to p and q. For instance, we could have p0 = 1 and q0 = 1 thus\ncorresponding to an ordinary Fock algebra, or else p0 = p and q0 = q, but also more generally\np0 = p? and q0 = q?, ? being some real constant. As a matter of fact, exact solutions to the\nmoment problem are presented hereafter in all these situations.\nIn terms of the ladder operatorsA? =UA?U? acting on the subspaceV, the associated\nalgebraic constraint reads\nA?A+ ? q0A+A? =\n?summationdisplay\nn=0,?\n|E?n?p?n0 ?E?n|,\n14\nA?A+ ? p?10 A+A? =\n?summationdisplay\nn=0,?\n|E?n?qn0 ?E?n|. (74)\nWhether in terms of (73) or (74), these algebraic constraints translate into the following identi-\nties, for all n?N,\nparenleftbigK0\n?([n+ 1])\nparenrightbig2 ? q\n0\nparenleftbigK0\n?([n])\nparenrightbig2 = p?n\n0 ,\nparenleftbigK0\n?([n+ 1])\nparenrightbig2 ? p?1\n0\nparenleftbigK0\n?([n])\nparenrightbig2 = qn\n0. (75)\nGiven the initial values K0?([0]) = 0, the solution to these recursion relations is simply\nK0?([n]) =\nradicalBig\n[n](p0,q0) =\nradicalBig\n[n](q?1\n0 ,p\n?1\n0 )\n, (76)\nwhere4\n[n](p0,q0) = p\n?n\n0 ?qn0\np?10 ?q0 =\nparenleftbigq?1\n0\nparenrightbig?n?parenleftbigp?1\n0\nparenrightbign\nparenleftbigq?1\n0\nparenrightbig?1?parenleftbigp?1\n0\nparenrightbig = [n](q?10 ,p?10 ). (77)\nGiven this solution, the normalization factors are defined by the series\n|N?(|z|)|?2 =\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\n[n](p0,q0)!, (78)\nof which the convergence radius is\nR = limn??\nbracketleftBiggparenleftbigg\nq?\np?\nparenrightbigg?2(n?1) p?n\n0 ?qn0\np?10 ?q0\nbracketrightBigg1/2\n= limn??\nbracketleftbiggparenleftbig\np0p?2?q2?parenrightbig?(n?1) 1?(p0q0)\nn\n1?(p0q0)\nbracketrightbigg1/2\n. (79)\nProvided p0p?2?q2? < 1, a condition which we shall henceforth assume to be satisfied5, this\nradius of convergence is infinite, R =?, and the moment problem (68) then becomes, for all\nn?N, integraldisplay\n?\n0\nduun h?(u) =\nparenleftbiggq?\np?\nparenrightbigg?n(n?1) parenleftbig\n[n](p0,q0)!parenrightbig. (80)\nIn order to solve these equations, the Ramanujan integral (121) discussed in the Appendix\nsuggests itself quite naturally, through a simple but appropriate rescaling of its arguments in\nthe form of (123).\nAfter a little moment?s thought one comes to the conclusion that a solution to (80) based\non (123) is possible for the following choice of parameters,\n? = 12, ? = 0, p0 = p, q0 = q, (81)\nin which case p0p?2?q2? = pq < 1, hence corresponding indeed to an infinite radius of conver-\ngence. For this choice, one has (for definitions of the (p,q)-exponential functions appearing in\nthese expressions, see the Appendix),\nh?parenleftbig|z|2parenrightbig=\nparenleftbigp?1?qparenrightbig\nqlog(1/pq) e(p,q)\nparenleftBig\n?|z|2 p?1/2q?1parenleftbigp?1?qparenrightbig\nparenrightBig\n, (82)\n4Incidentally, it is because of this identity, corresponding to the exchange p0 ? q?1\n0 , that the two solutions to\nthe above two recursion relations are consistent, as are the two algebraic restrictions in (73) and (74).\n5If p0p?2?q2? = 1, the radius of convergence is finite with R = (1?p0q0)?1/2, while when p0p?2?q2? > 1 the\nradius of convergence vanishes, implying that (p,q)-VCS cannot be constructed in such a case.\n15\nas well as6\nparenleftbigK0\n?([n])\nparenrightbig2 = [n], |N?(|z|)|?2 =E(1/2,0)\n(p,q)\nparenleftBig\n|z|2q?1/2parenleftbigp?1?qparenrightbig\nparenrightBig\n, (83)\nwith for the weight functions W?(|z|) in the integration measure (66) of the overcompleteness\nrelation (65),\nW+ (|z|) = 34?2 |N+ (|z|)|?2 h+parenleftbig|z|2parenrightbig, W?(|z|) = 38?2 |N?(|z|)|?2 h?parenleftbig|z|2parenrightbig. (84)\nExplicit expressions for all previously computed quantities readily follow, beginning with the\ndefinition of the associated (p,q)-VCS which then meet all thenecessary requirements expected of\ncoherent states. Note that up to the coefficients 3/(2?) and 3/(4?), the reduced weights obtained\nare compatible with that of the q-shape invariant harmonic oscillator [20]. Furthermore, (82)\nis a (p,q)-generalization of the q-harmonic oscillator coherent state moment problem solution\nconstructed in [41]. Finally, in the double limit p,q?1, the results of [14] are recovered.\nThe functions (82) thus provide a complete and explicit solution to the moment problem of\nthe (p,q)-VCS for the (p,q)-JCm such that the ladder operatorsA? obey the same (p,q)-Fock\nalgebra as the original modes a and a? of the initial Hamiltonian (24), namely with the choice\np0 = p and q0 = q. It is also possible to construct an explicit solution when the ladder operators\nA? are constrained to rather obey the ordinary non-deformed Fock algebra onV, corresponding\nto the choice p0 = 1 and q0 = 1. One then has to consider7, for all n?N,\nK0?([n]) =?n,\nintegraldisplay ?\n0\nduun h?(u) =\nparenleftbiggq?\np?\nparenrightbigg?n(n?1)\n(n!), p??q??1. (85)\nAn obvious solution to this moment problem is obtained when ? = 0 = ?, in which case the\ncondition for an infinite radius of convergence is saturated. One then has\nh?parenleftbig|z|2parenrightbig= e?|z|2, |N? (|z|)|?2 = e|z|2, W+ (|z|) = 34?2, W?(|z|) = 38?2. (86)\nIn fact, the above two explicit solutions belong to a general class of solutions obtained\nby taking (p0,q0) = (p?,q?) with ? a positive real parameter, ? > 0, such that p??2?q2? < 1\nin order to ensure an infinite radius of convergence8 in z ?C. Once again based on (123), an\nexplicit solution to the moment problem (80) is achieved for the following choice of parameters,\n? = 12?, ? = 0, p0 = p?, q0 = q?, (87)\nfor which the radius of convergence is indeed infinite, p??2?q2? = (pq)? < 1. One then has\nh?parenleftbig|z|2parenrightbig= (p\n???q?)\nq? log(1/p?q?) e(p?,q?)\nparenleftBig\n?|z|2 p??/2q??parenleftbigp???q?parenrightbig\nparenrightBig\n, (88)\nwith\n|N?(|z|)|?2 =E(1/2,0)(p?,q?)\nparenleftBig\n|z|2q??/2parenleftbigp???q?parenrightbig\nparenrightBig\n, (89)\nleading finally to the weight functionsW?(|z|) given in terms of the latter two quantities through\nthe same relations as in (84). In the limits that ? ? 1 or ? ? 0, the previous two explicit\nsolutions are then recovered as particular cases.\n6Restricting to p0 = p and q0 = q but keeping ? and ? arbitrary such that p1?2?q2? < 1 in order to retain an\ninfinite radius of convergence, one has parenleftbigK0?([n])parenrightbig2 = [n] and |N? (|z|)|?2 = E(?,?)(p,q) parenleftbig|z|2 p? q??parenleftbigp?1 ?qparenrightbigparenrightbig, hence\nalso all other previous expressions given accordingly.\n7Leading to |N? (|z|)|?2 = e(?,?)\n(p,q)\nparenleftbig|z|2 p? q??parenrightbig, which converges for all |z| < ? provided p??q? ? 1.\n8Leading to |N? (|z|)|?2 = E(?/?,?/?)\n(p?,q?)\nparenleftbig|z|2p?q??(p?? ?q?)parenrightbig.\n16\n5.2 The action identity constraint\nAn alternative to fixingthe factors K0?([n]) through conditions on the algebra ofladder operators,\nis to consider the action identity constraint discussed in [30] as the one last requirement which\nsingles out coherent states uniquely. In the case of the ordinary Fock algebra, this action\nidentity constraint is equivalent to requiring that the ladder operators obey themselves the Fock\nalgebra as well. We shall establish that this is not the case for the (p,q)-VCS of the (p,q)-JCm\nconstructed above.\nGiven the relations (72), in the present model the action identity constraint is of the form\nJ+ = cos2 ?parenleftbig|z|2 +E+0 parenrightbig, J? = sin2 ?parenleftbig|z|2 +E?0 parenrightbig. (90)\nBy direct substitution into these constraints of the relations (72), the identification of the suc-\ncessive powers in|z|2 leads to the following solution for the factors K0?([n]),\nK0?([n]) =\nparenleftbiggq?\np?\nparenrightbigg(n?1) radicalBig\nE?n ? E?0 . (91)\nThese positive real quantities are thus well-defined provided one has E?n > E?0 for all n ? 1,\nas is implicitly assumed. It is noteworthy that, as (p,q) ? (1+,1?), these factors reduce to\nexactly those obtained in [16] by the factorization method. On the other hand, since the present\nsolution for K0?([n]) cannot be brought into the form of (76) for some choice of constants p0 and\nq0 meeting our assumptions for these quantities, it follows indeed that for the (p,q)-JCm the\naction identity constraint is not equivalent to requiring an algebraic constraint on the ladder\noperators of the (p0,q0)-deformed Fock algebra type.\nThis choice also allows for the factorization of the Hamiltonian in (36) in the form\nHred = A+\nparenleftbiggq?\np?\nparenrightbigg?2N\nA +\n?summationdisplay\nn=0,?\n|n,??E?0 ?n,?|, (92)\nextending a similar expression in [14].\nGiven this solution for the factors K0?([n]), the general moment problem (68) reduces to\nthe following conditions,\nintegraldisplay R2\n0\ndu h?(u) = 1;\nintegraldisplay R2\n0\nduun h?(u) =\nnproductdisplay\nk=1\nparenleftbigE?\nk ?E\n?\n0\nparenrightbig, n = 1,2,3,???, (93)\nwhere the radius of convergence R is given as\nR = min (R+,R?), R? = limn?+?\nradicalBig\nE?n ?E?0 . (94)\nIn the absence of a detailed analysis of the energy spectra E?n as functions of the parameters p,\nq, ? and ? and the function h(p,q), nothing more explicit may be said concerning this moment\nproblem. Since when p > 1 the quantities [n] always possess a turn-around behaviour as func-\ntions of n for n sufficiently large, it is to be expected generally that the radius of convergence\nR, hence the moment problem as well, are associated to a finite disk DR in the complex plane.\nNevertheless, one conclusion of the present discussion is that indeed for the (p,q)-VCS consid-\nered in this work, the action identity constraint leads to coherent states different from those\nconstructed in Section 5.1 and for which explicit solutions to the moment problem have been\ngiven.\n17\n5.3 The spin decoupled limit ? = 0\nIn the limit that ? = 0, the two spin sectors of the model are decoupled, and the (p,q)-JCm\nreduces to the supersymmetric harmonic oscillator [43, 44, 18] with a (p,q)-deformation. Diago-\nnalization of the reduced Hamiltonian (24) is then of course straightforward in the ?3-eigenbasis,\nwith, for n = 0,1,2,???,\nHred?=0|n,??= ??n |n,??, ??n = (1 +?)h(p,q)[n] + 12(1 +?)?12. (95)\nFrom that point of view, one thus has two decoupled (p,q)-deformed Fock bases, for which\none could consider the usual (p,q)-coherent states in each spin sector separately. However, such\ncoherent states do not coincide with any of those constructed in this paper and obtained in the\nlimit ? = 0, because of the distinguished role played by the singleton state |E?? = |0,?? and\nthe S2 unit vector character of the (p,q)-VCS. In particular the ladder operators A? acting\nwithin each of the towers |E?n? do not coincide with the annihilation and creation operators a\nand a? defining the Hamiltonian (24), even in the decoupled limit ? = 0. As a matter of fact,\nthe action of the ladder operatorsA? may switch between the two spin sectors as a function of\nn depending on the sign of the quantityE([n+ 1]).\nMore specifically, let us introduce the notation\nsn = signE([n+ 1]), n?N. (96)\nIn the limit that ? = 0, one has Q([n + 1]) =|E([n + 1])|/2, so that the mixing angle ?([n]) is\nnow such that, for all n?N,\n? = 0 : sin?([n]) = 12(1?sn)(sign?), cos?([n]) = 12(1 +sn). (97)\nConsequently, the towers of energy eigenstates|E?n?are then given as follows, for all n?N,\nIf sn = +1 : |E+n??=0 =|n+1,??, |E?n??=0 =|n,+?;\nIf sn =?1 : |E+n??=0 = (sign?)|n,+?, |E?n??=0 =?(sign?)|n + 1,??,\n(98)\nwhile the energy eigenvalues are given as\nIf sn = +1 : E+n (? = 0) = (1 +?)h(p,q)[n +1] + 12(1 +?) ? 12,\nE?n (? = 0) = (1 +?)h(p,q)[n] + 12(1 +?) + 12;\nIf sn =?1 : E+n (? = 0) = (1 +?)h(p,q)[n] + 12(1 +?) + 12,\nE?n (? = 0) = (1 +?)h(p,q)[n +1] + 12(1 +?) ? 12.\n(99)\nThese spectra do indeed coincide with those in (95), once the singleton state|E??=|0,??with\nE? = ?/2 is included as well.\nThese expressions show how, even in the decoupled spin limit ? = 0, the (p,q)-VCS\nconstructed here are not simply the juxtaposition of two separate (p,q)-coherent states of the\n(p,q)-deformed Fock algebra in each of the two spin sectors. Since the spectrum of the system\nis discrete infinite, by leaving aside the singleton state|0,??, all the remaining states still allow\nfor similar types of constructions of coherent states, but in such a way that different spin sectors\nare getting superposed, leading to the SU(2) vector coherent states of the type studied here. All\nthe expressions detailed in the previous sections for the (p,q)-VCS may readily be particularized\nto the limit ??0.\n18\n6 Conclusion\nIn this work, we considered (p,q)-deformations of the Jaynes-Cummings model in the rotating\nwave approximation, extending recent developments on this topic in the non-deformed case [14].\nHaving introduced (p,q)-deformed versions of the model, first its energy eigenspectrum has been\nidentified, enabling the definition of different relevant operators acting on Hilbert space and the\ncharacterization of the spectrum in terms of two separate infinite discrete towers and a singleton\nstate. Among these operators, ladder operators acting within each of the two towers separately\nmay be considered, defined up to some arbitrary normalization factors.\nSuch a structure sets the stage for the introduction of vector coherent states for the (p,q)-\ndeformed Jaynes-Cummings model, following the approach of [14] and the rationale outlined\nin [30]. These (p,q)-VCS are parametrized by elements of C?S2, and enjoy temporal sta-\nbility through a further action-angle identification. The moment problem associated to the\novercompleteness property of these (p,q)-VCS involves SU(2)-valued matrix weight functions.\nUsing (p,q)-arithmetic techniques, some explicit and exact solutions to the moment problem\nhave been displayed, hence characterizing specific classes of such (p,q)-VCS. All these solutions\nprovide (p,q)-extensions to the non-deformed vector coherent states of theJCm considered in\n[14]. These explicit solutions are obtained by requiring that specific algebraic constraints of the\n(p,q)-deformed Fock algebra type be obeyed by the ladder operators. However, in contradis-\ntinction to [14], we have not been able to display an explicit and exact solution to the moment\nproblem in the generic case by imposing an action identity constraint.\nFinally, the spin decoupled limit of these models was considered, corresponding to a (p,q)-\nsupersymmetric oscillator of which the two sectors are intertwined in a manner depending on\nthe sign of the energy level spacing between the two decoupled spin sectors as function of the\nexcitation level. In the non-deformed limit (p,q) = (1,1), this feature disappears, reproducing\nthe ordinary supersymmetric oscillator. Our results thus provide new classes of generalized\nversions of theJCm in the rotating wave approximation [20, 18]. Finally, the (p,q)-VCS built\nhere extend the q-coherent states obtained by other techniques involving supersymmetric shape\ninvariance and self-similar potential formalisms applied to the harmonic oscillator [20, 45].\nAcknowledgements\nJ. B. G. is grateful to the Abdus Salam International Centre for Theoretical Physics (ICTP,\nTrieste, Italy) for a Ph.D. fellowship under the grant Prj-15. M. N. H. is particularly indebted\nto V. Hussin for discussions relating to the JCm as well as for provided references during his\nstay at the Centre de Recherches Math?ematiques, Universit?e de Montr?eal, Canada. The ICMPA\nis in partnership with the Daniel Iagoniltzer Foundation (DIF), France.\nJ. G. acknowledges a visiting appointment as Visiting Professor in the School of Physics\n(Faculty of Science) at the University of New South Wales. He is grateful to Prof. Chris Hamer\nand the School of Physics for their hospitality during his sabbatical leave, and for financial sup-\nport through a Fellowship of the Gordon Godfrey Fund. His stay in Australia is also supported\nin part by the Belgian National Fund for Scientific Research (F.N.R.S.) through a travel grant.\nJ. G. acknowledges the Abdus Salam International Centre for Theoretical Physics (ICTP,\nTrieste, Italy) Visiting Scholar Programme in support of a Visiting Professorship at the ICMPA.\nHis work is also supported by the Belgian Federal Office for Scientific, Technical and Cultural\nAffairs through the Interuniversity Attraction Pole (IAP) P5/27.\n19\nAppendix\nThis appendix lists some useful facts related to the (p,q)-boson algebra and associated functions.\nThe (p,q)-deformed oscillator algebra introduced in [5] is generated by operators a, a? and N\nobeying the relations\n[N,a] =?a, [N,a?] = a?,\naa??qa?a = p?N, aa??p?1a?a = qN. (100)\nThroughout the text, we assume the real parameters p and q are such that p > 1, 0 < q < 1\nand pq < 1. The limit p ? 1+ yields the q-oscillator of Arik and Coon [3] while p = q gives\nthe q-deformed oscillator algebra of Biedenharn and MacFarlane [4]. Finally, the algebra (100)\nreduces to the ordinary harmonic oscillator Fock algebra as q ? 1 for p = 1+ or p = q. At\nany stage of the discussion, the (p,q)-deformed model readily reduces to its usual counterpart\nas (p,q)?(1,1).\nThe associated (p,q)-deformed Fock-Hilbert space representation is spanned by the vac-\nuum|0?annihilated by a and the orthonormalized states|n?, such that\na|0?= 0, ?0|0?= 1, |n?= 1radicalBig\n[n](p,q)!\nparenleftBig\na?\nparenrightBign\n|0?,\na|n?=\nradicalBig\n[n](p,q)|n?1?, a?|n?=\nradicalBig\n[n+ 1](p,q)|n+ 1?, N|n?= n|n?, (101)\nwhere the symbol [n](p,q) = (p?n?qn)/parenleftbigp?1?qparenrightbigis called (p,q)-basic number with, by conven-\ntion, [0](p,q) = 0, and its (p,q)-factorial is defined through [n](p,q)! = [n](p,q)parenleftbig[n?1](p,q)!parenrightbig and\nthe convention [0](p,q)! = 1. There exists a formal (p,q)-number operator denoted by [N](p,q), or\nsimply by [N] when no confusion arises. As a matter of fact, from the second pair of relations\nin (100), it follows that [N] = a?a as well as [N + 1] = aa?. One has of course [N]|n?= [n]|n?.\nHence, (101) provides a well defined Fock-Hilbert representation space of the algebra (100).\nThe following relations hold for any function f ?f(N) and consequently for any function\nof [N],\naf(N?1) = f(N)a, a?f(N) = f(N?1)a?. (102)\nLet us define q-shifted products and factorials and their (p,q)-analogues. Using the nota-\ntions of [46], for any quantity x, (x;q)? is constructed as follows,\n(x;q)0 = 1, (x;q)? = (x;q)?(xq?;q)\n?\n, (x;q)? =\n?productdisplay\nn=0\n(1?xqn). (103)\nFurthermore, in the notations of [10], (p,q)-shifted products and factorials are defined as follows,\nfor any real quantities a and b such that anegationslash= 0,\n[a,b;p,q]0 = 1, [a,b;p,q]? = [a,b;p,q]?[ap?,bq?;p,q]\n?\n, [a,b;p,q]? =\n?productdisplay\nn=0\nparenleftbigg 1\napn ?bq\nn\nparenrightbigg\n. (104)\nFor ? = n?N, we have\n[p?,q?;p,q]n =\nparenleftbigg 1\np? ?q\n?\nparenrightbiggparenleftbigg 1\np?+1 ?q\n?+1\nparenrightbigg\n...\nparenleftbigg 1\np?+n?1 ?q\n?+n?1\nparenrightbigg\n20\n= p??n?n(n?1)/2(p?q?;pq)n. (105)\nThis identity is a central formula since it defines a bridge between q- and (p,q)-analogue quan-\ntities and functions.\nLet us now introduce q-analogues of the ordinary exponential funtion. There exist many\ntypes of q-deformations of the exponential function ez, z ?C (see, for instance, [9]). For any\n(z,?)?C?R, the (?,q)-exponential is the complex function [9]\nE(?)q (z) =\n?summationdisplay\nn=0\nq?n2\n(q;q)nz\nn. (106)\nThis series has an infinite radius of convergence for ? > 0. For ? = 0 its domain of definition\nreduces to the unit disk, |z| < 1, while it is nowhere convergent in C for ? < 0. Rescaling\nz?z(1?q) and taking the limit limq?1 E?q (z(1?q)), one recovers ez. For some specific values\nof ?, (106) reproduces some standard q-exponentials [9, 11],\nE(0)q (z) = eq(z) = 1(z;q)\n?\n=\n?summationdisplay\nn=0\nzn\n(q;q)n, |z|< 1, (107)\nE(1/2)q (z) = Eq(q1/2z) = (?q1/2z;q)?, z?C, (108)\nwhere\nEq(z) =\n?summationdisplay\nn=0\nqn(n?1)/2zn\n(q;q)n , z?C, (109)\nis known as the Jackson q-exponential [6]. Note that whereas E(?)q (z) is defined in the entire\ncomplex plane, |z| < ?, for any ? > 0, its reduction eq(z) is only defined on the unit disc.\nFinally, it is also well established that [11]\nEq(?z)eq(z) = 1. (110)\n(p,q)-analogues of the usual exponential function ez, z?C may also be introduced (see,\nfor instance, [10]). Given any (z,?,?)?C?R?R, consider the (?,?,p,q)-exponential function\nE(?,?)(p,q) (z) =\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn2 zn\n[p,q;p,q]n. (111)\nKeeping in mind the condition pq < 1, the radius of convergence R of this series is such that\nR1 =\n?\n?\n?\n?, if q2?p1?2? < 1;\np??1q??, if q2?p1?2? = 1;\n0, if q2?p1?2? > 1.\n(112)\nThus the functionE(?,?)(p,q) (z) exists only provided q2?p1?2? ?1.\nIn order to recover the usual exponential function, one has to rescale z?z(p?1?q), for\nexample, and then take the limit lim(p,q)?(1,1)E?,?(p,q)(z(p?1?q)) = ez. For particular values of\nthe parameters ? and ?, (111) reproduces known (p,q)-exponentials,\nE(1/2,1/2)(p,q) (z) = E(p,q)\nparenleftBiggparenleftbigg\nq\np\nparenrightbigg1/2\nz\nparenrightBigg\n=\n?summationdisplay\nn=0\nparenleftbiggq\np\nparenrightbiggn2/2 zn\n[p,q;p,q]n, (113)\n21\nwhere\nE(p,q)(z) =\n?summationdisplay\nn=0\nparenleftbiggq\np\nparenrightbiggn(n?1)/2 zn\n[p,q;p,q]n. (114)\nThe function E(p,q) may be found in [10]. Note that (114) coincides with (109) as p?1. In the\nsame limit, (111) reproduces the (?,q)-deformed exponential map E(?)q (z) [9]. If ? = 0 = ? the\nseries (111) is not defined since then R = 0, unless one has taken p = 1 in which case the radius\nof convergence is unity. A (p,q)-analogue of (107) is given by\ne(p,q)(z) =\n?summationdisplay\nn=0\n1\npn2/2\nzn\n[p,q;p,q]n, |z|< p\n?1/2, (115)\nwhich reproduces exactly eq(z) converging in the unit disc as p ? 1+. Furthermore, we have\nfrom (105)\ne(p,q)(z) =\n?summationdisplay\nn=0\n(p1/2z)n\n(pq;pq)n = epq(p\n1/2z). (116)\nUsing (105) and (109), we may also write\nE(p,q)(z) =\n?summationdisplay\nn=0\nparenleftbiggq\np\nparenrightbiggn(n?1)/2 zn\np?n(n+1)/2(pq;pq)n\n=\n?summationdisplay\nn=0\nqn(n?1)/2 (zp)\nn\n(pq;pq)n = Epq(pz). (117)\nThen taking into account (110), (116) and (117), a (p,q)-analogue of (110) is given by\nEpq(?pz)epq(pz) = E(p,q)(?z)e(p,q)(p1/2z) = 1. (118)\nFinally, consider\ne(?,?)(p,q)(z) =\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn2 zn\nn!. (119)\nTherefore, e(?,?)(p,q)(z), which converges to ez as (p,q) ? (1,1), provides a (p,q)-deformed ex-\nponential analogue to the q-function used by Penson and Solomon [42] which coincides with\ne(1,?)(1,q)(q?1/2z). The radius of convergence of (119) is given as\nR2 =\nbraceleftbigg ?, if q?p?? ?1;\n0, if q?p?? > 1. (120)\nFinally, consider the Ramanujan integral [7, 19], valid for any integer n?N,\nintegraldisplay ?\n0\ndttn eq(?t) =? (q;q)nqn(n+1)/2 logq. (121)\nThrough the change of variables\nq?pq, t??0 p?1/2 t, ?0 > 0, (122)\nand using once again (105), the following identity is obtained, for any n?N,\nintegraldisplay ?\n0\ndttn e(p,q)\nparenleftBig\n??0p?1/2t\nparenrightBig\n= [p,q;p,q]n?n+1\n0 qn(n+1)/2\nlog\nparenleftbigg 1\npq\nparenrightbigg\n. (123)\nThis result is indeed a (p,q)-analogue of the Ramanujan integral (121).\n22\nReferences\n[1] S. Majid, Quantum Groups (Cambridge Univ. Press, Cambridge, 1995);\nV. G. Drinfeld, Quantum Groups, Lecture Notes in Mathematics, Ed. P. P. Kulish (Springer,\nBerlin, 1992).\n[2] See for example,\nJ. Wess and B. Zumino, Nucl. Phys. B (Proceedings Supplements) 18, 302-312 (1991);\nA. Lorek and J. Wess, Z. Phys. C 67, 671-680 (1995).\n[3] M. Arik and D. D. Coon, J. Math. Phys. 17, 524-527 (1976).\n[4] A. J. Macfarlane, J. Phys. A: Math. Gen. 22, 4581-4588 (1989);\nL. C. Biedenharn, J. Phys A: Math. Gen. 22, L873-L878 (1989).\n[5] R. Chakrabarti and R. Jagannathan, J. Phys. A: Math. Gen. 26, L711-L719 (1991).\n[6] F. Jackson, Mess. Math. 38, 57 (1909).\n[7] S. Ramanujan, Mess. Math. 44, 10-18 (1915).\n[8] H. Exton, q-Hypergeometric Functions and Application (John Wiley and Sons, New York,\n1983).\n[9] F. Floreanini and L. Vinet, Lett. Math. Phys. 22, 45-54 (1991);\nF. Floreanini, J. LeTourneux and L. Vinet, J. Phys. A: Math. Gen. 28, L287-L239 (1995).\n[10] R. Floreanini, L. Lapointe and L. Vinet, J. Phys. A: Math. Gen. 26, L611-L614 (1993).\n[11] R. Koekoek and R. F. Swarttouw, The Askey-scheme of hypergeometric orthogonal polyno-\nmials and its q-analogue, Delft University Technology, Report 94-05 (1994).\n[12] E. T. Jaynes and F. Cummings, FW Proc. IEEE 51, 89-109 (1963).\n[13] P. Meystre and E. M. Wright, Phys. Rev. A 37, 2524 (1988).\n[14] V. Hussin and L. M. Nieto, J. Math. Phys. 46, 122102 (2005).\n[15] Y. B?erub?e-Lauziere, V. Hussin and L. M. Nieto, Phys. Rev. A 50, 1725 (1994).\n[16] L. Dello Sbarba and V. Hussin, in Group of Theoretical Methods in Physics: Proceeding\nof the XXV International Colloqium on Group Theoretical Methods in Physics, Institute\nof Physics Conferences Series, Vol. 185, Eds. G. S. Pogosyan, L. E. Vincent and K. B. Wolf\n(IOP, Bristol, 2005).\n[17] M. Daoud and V. Hussin, J. Phys. A: Math. Gen. 35, 7381-7402 (2002).\n[18] M. Daoud and J. Douari, Int. J. Mod. Phys. B 17, 2473-2486 (2003).\n[19] A. B. Balantekin, To be published in the Proceedings of ?Computational And Group The-\noretical Methods In Nuclear Physics: Symposium In Honor Of Jerry P. Draayer?s 60th\nBirthday, 18-21 Feb 2003, Playa del Carmen, Mexico?; e-print arXiv:nucl-th/0309038.\n23\n[20] A. N. F. Aleixo, A. B. Balantekin and M. A. Candido Ribeiro, J. Phys. A: Math. Gen. 35,\n9063-9070 (2002);\nA. N. F. Aleixo, A. B. Balantekin and M. A. Candido Ribeiro, J. Phys. A: Math. Gen. 36,\n11631-11642 (2003);\nA. N. F. Aleixo and A. B. Balantekin, J. Phys. G 30, 1225-1230 (2004).\n[21] B. Buck and C. V. Sukumar, Phys. Lett. A 81, 132 (1981).\n[22] M. Chaichan, D. Ellinas and P. Kulish, Phys. Rev. Lett. 65, 980-983 (1990).\n[23] Z. Chan, Phys. Rev. A 47, 5017-5023 (1993).\n[24] M. H. Naderi, M. Soltanolkotabi and R. Roknizadeh, Journal of the Physical Society of\nJapan 73, 2413-2423 (2004).\n[25] G. Dresselhaus, Phys. Rev. 100, 580 (1955).\n[26] For a recent review on spintronics, see\nJ. Schliemann, e-print arXiv:cond-mat/0602330.\n[27] S-Q. Shen, Y-J Bao, M. Ma, X. C. Xie and F. C. Zhang, Phys. Rev. B 71, 155316 (2005).\n[28] S-Q. Shen, M. Ma, X. C. Xie and F. C. Zhang, Phys. Rev. Lett. 92, 256603 (2004).\n[29] S. T. Ali and F. Bagarello, J. Math. Phys. 46, 053518 (2004).\n[30] J-P. Gazeau and J. R. Klauder, J. Phys. A: Math. Gen. 32, 123 (1999).\n[31] J-P. Antoine, J-P. Gazeau, P. Monceau, J. R. Klauder and K. A. Penson, J. Math. Phys.\n42, 2349 (2001).\n[32] S. T. Ali, J-P. Antoine and J-P. Gazeau, Coherent States, Wavelets and their Generaliza-\ntions (Springer-Verlag, Berlin, 2000).\n[33] F. G. Scholtz, B. Chakraborty, S. Gangopadhyay and J. Govaerts, J. Phys. A: Math. Gen.\n38, 9849-9858 (2005).\n[34] F. G. Scholtz, B. Chakraborty, S. Gangopadhyay and A. Ghosh Hazra, Phys. Rev. D 71,\n085005 (2005).\n[35] J. Ben Geloun, J. Govaerts and M. N. Hounkonnou, A (p,q)-deformed Landau problem\nin a spherical harmonic well: spectrum and noncommuting coordinates, preprint ICMPA-\nMPA/2006/22, CP3-06-12, e-print arXiv:hep-th/0609120, submitted to J. Phys. A: Math.\nGen.\n[36] M. N. Hounkonnou and K. Sodoga, J. Phys. A: Math. Gen. 38, 7851-7862 (2005).\n[37] For an exhaustive dicussion on the moment problem, see for instance\nB. Simon, Adv. Math. 137, 82-203 (1998).\n[38] J. R. Klauder, Contribution to the 7th ICSSUR Conference, June 2001, e-print\narXiv:quant-ph/0110108.\n[39] A. Kempf, J. Math. Phys. 35, 4483 (1994);\nH. Hinrichsen and A. Kempf, J. Math. Phys. 37, 2121 (1996).\n24\n[40] C. Quesne, K. A. Penson and V. M. Tkachuk, Phys. Lett. A 313, 29-36 (2003).\n[41] C. Quesne, J. Phys. A: Math. Gen. 35, 9213-9226 (2002).\n[42] K. A. Penson and A. I. Solomon, J. Math. Phys. 40, 2354 (1999).\n[43] C. Aragone and F. Zypman, J. Phys. A: Math. Gen. 19, 2267-2279 (1986).\n[44] M. Orszag and S. Salamo, J. Phys. A: Math. Gen. 21, L1059-L1064 (1988).\n[45] F. Cooper, A. Khare and U. Sukhatme, Supersymmetry in Quantum Mechanics 2nd Ed.\n(World Scientific, Singapore, 2004).\n[46] G. Gasper and M. Rahman, Basic Hypergeometric Series (Cambridge Univ. Press, Cam-\nbridge, 1990).\n25\n"}
{"id":"oai:arXiv.org:quant-ph/0602178","text":"arXiv:quant-ph/0602178v2  17 May 2006\nDuality, Phase Structures and Dilemmas in Symmetric Quantum Games\nTsubasa Ichikawa and Izumi Tsutsui\nHigh Energy Accelerator Research Organization (KEK), Tsukuba, Ibaraki 305-0801, Japan\n(Dated: February 22, 2006)\nSymmetric quantum games for 2-player, 2-qubit strategies are analyzed in detail by using a scheme\nin which all pure states in the 2-qubit Hilbert space are utilized for strategies. We consider two\ndifferent types of symmetric games exemplified by the familiar games, the Battle of the Sexes (BoS)\nand the Prisoners? Dilemma (PD). These two types of symmetric games are shown to be related by a\nduality map, which ensures that they share common phase structures with respect to the equilibria\nof the strategies. We find eight distinct phase structures possible for the symmetric games, which\nare determined by the classical payoff matrices from which the quantum games are defined. We\nalso discuss the possibility of resolving the dilemmas in the classical BoS, PD and the Stag Hunt\n(SH) game based on the phase structures obtained in the quantum games. It is observed that\nquantization cannot resolve the dilemma fully for the BoS, while it generically can for the PD and\nSH if appropriate correlations for the strategies of the players are provided.\nPACS numbers: 02.50.Le, 03.67.-a, 87.23.Ge\nKeywords: quantum mechanics, game theory, entanglement\nI. INTRODUCTION\nQuantum game theory has attracted much attention\nin recent years as an interesting attempt to expand the\nscope of the conventional (classical) game theory, which\nis now a standard tool in various fields, most notably in\neconomics, for analyzing decision making processes. The\nmain thrust in the investigation of quantum game has\ncome from the remarkable observation by Eisert et al. [1]\nthat the famous dilemma in the Prisoners?Dilemma (PD)\ngame can be resolved if the players resort to strategies\navailable in quantum theory. Subsequently, Marinatto\nand Weber [2] examined the dilemma in the Battle of\nthe Sexes (BoS) game, another typical dilemma in game\ntheory, and observed that this, too, could be resolved\nby adopting a quantum strategy involving a maximally\nentangled state. Application of quantum strategies to\nvarious other games, such as the Stag Hunt (SH) or the\nSamaritan?s Dilemma game, has also been discussed in\n[3].\nThese studies of the quantum games presented in [1, 3]\nand [2] employ different schemes of quantum strategies,\nand it has turned out that the outcome of the analysis is\nhighly dependent on the scheme used. In fact, it has been\npointed out in [4, 5, 6] that in the scheme used in [1, 3]\nthe dilemma in PD can be resolved only if the strategic\nspace is restricted artificially, while a more recent study\n[7] shows that there exists a new scheme in which the\ndilemma can be resolved even with a full strategic space.\nSimilarly, the resolution of the dilemma in the BoS has\nbeen argued using different reasonings depending on the\nschemes [3, 8, 9] (for a generalized scheme, with no analy-\nsis on dilemmas, see [10]), casting a doubt on the genuine\nnature of the resolution and, more importantly, the uni-\nversality of the outcomes of quantum game in general.\nThe distinction among these schemes can be found in\nthe definitions of quantum strategy, the strategic space\nwhich the players can exploit, and the way the quan-\ntum correlation (entanglement) is furnished. These dif-\nferences are crucial, because (as observed in [4, 5, 6])\ndifferent strategic spaces admit different stable solutions,\nand moreover the amount of entanglement required to\nresolve the dilemma will depend on the stage in the pro-\ncess it is measured. Despite of this scheme-dependence,\nwe have found in [7] an intriguing phase structure for the\nquantum PD game, which is reminiscent of the ?phase\ntransition? of equilibrium solutions discovered earlier in\n[11] in a different scheme. This suggests that the phase\nstructures may exhibit a scheme-independent, intrinsic\nfeatures of quantum games under consideration.\nThe aim of the present paper is to support this idea by\nproviding a convenient tool to analyze quantum games\nin general terms. We consider 2-player, 2-qubit strategy\ngames, which are the simplest nontrivial and yet have not\nbeen fully analyzed. Using the scheme introduced in [7],\nwe study in detail two types of ?symmetric games?, exem-\nplified by the BoS and PD games, respectively. We show\nthat these two types of games are actually related by a\nduality map, which brings a game in one symmetric type\ninto a game in the other symmetric type without chang-\ning the payoff in effect. This is convenient because then\nwe can use the outcome of the analysis of the BoS for the\nstudy of the PD, for instance. A quantum game may be\nregarded as a family of games provided by quantum cor-\nrelations which are absent in classical settings, and our\ngeometric picture used to portray the correlation-family\nin this paper turns out to be quite convenient, espe-\ncially for analyzing the phase structures of the game. We\nshall then see that symmetric games admit eight differ-\nent types of phase structures with regard to the possible\nstable strategies (related to classical strategies) preferred\nby the players, and that these types are determined by\nthe original classical games. With these phase structures,\nwe find that the dilemma in the BoS cannot be resolved\nfully in our scheme, albeit alleviated to some extent [2],\nirrespective of the amount of entanglement provided. In\n2\ncontrast, the dilemma of the PD game can be resolved if\na certain amount of correlationsare introduced. An anal-\nogous conclusion will also be drawn for the SH game, for\nwhich we find rather intricate phase structures for the full\nstable strategies compared to the BoS and PD games.\nThe plan of the paper is as follows. We first introduce\nour scheme of quantum gamein section II and present the\nduality map between the two types of symmetric games.\nThe phase structures of the symmetric games are studied\nin section III. Section IV is devoted to the analysis of the\nBoS, PD and SH games, where we examine the resolution\nof the dilemmas based on the results obtained in section\nIII. Finally, we give our conclusion and discussions in\nsection V.\nII. QUANTUM GAME AND DUALITY FOR\nSYMMETRIC GAMES\nTo begin with, we first recapitulate the classical 2-\nplayer, 2-strategy game and then introduce its quantum\nversion following [7]. Let i = 0,1, j = 0,1 be the la-\nbels of the strategies available for the players, Alice and\nBob, respectively, and let also Aij and Bij be their pay-\noffs when their joint strategy is (i,j). In classical game\ntheory, the game is said to be ?symmetric? if Bji = Aij,\nthat is, if their payoffs coincide when their strategies are\nswapped (i,j) ? (j,i). To make a distinction from the\nother symmetry discussed shortly, we call such a game\nS-symmetric in this paper. The PD and other famil-\niar games such as the SH and the Chicken game (see,\ne.g., [3, 12]) are S-symmetric games. Similarly, we call\nthe game T-symmetric if B1?j,1?i = Aij, that is, if the\npayoff matrices coincide when the strategies of the two\nplayers are ?twisted? as (i,j) ? (1 ? j,1 ? i). The BoS\nis an example of T-symmetric games with the additional\nproperty A01 = A10. The payoffs in these S-symmetric\nand T-symmetric games are displayed in the form of the\nbi-matrix (Aij,Bij) in Table I.\nGiven a payoff matrix, each player tries to maximize\nhis/her payoff by choosing the best possible strategy, and\nif there exists a pair of strategies in which no player can\nbring him/her in a better position by deviating from it\nunilaterally, we call it a Nash equilibrium (NE) of the\ngame. The players will be happy if the NE is unique\nand fulfills certain conditions attached to the game (e.g.,\nPareto-optimality or risk-dominance as mentioned later).\nEven when there are more than one NE, the players will\nstill be satisfied if a particular NE can be selected over\nthe other upon using some reasonings. Otherwise, the\nplayers may face a dilemma, as they do in the case of the\nBoS and the PD.\nTo introduce a quantum version of the classical game,\nwe first regard Alice?s strategies i as vectors in a Hilbert\nspace HA of a qubit. Namely, corresponding to the clas-\nsical strategies i we consider vectors |i?A for i = 0 and 1\nwhich are orthonormal in HA. A general quantum strat-\negyavailablefor Alice is then representedbya normalized\nS-symmetric:\nstrategy Bob 0 Bob 1\nAlice 0 (A00,A00) (A01,A10)\nAlice 1 (A10,A01) (A11,A11)\nT-symmetric:\nstrategy Bob 0 Bob 1\nAlice 0 (A00,A11) (A01,A01)\nAlice 1 (A10,A10) (A11,A00)\nTABLE I: Payoff bi-matrices (Aij,Bij) of the S-symmetric\ngame (above) and the T-symmetric game (below).\nvector |??A (with the overall phase ignored, i.e., a unit\nray) in HA. Bob?s strategy is similarly represented by\na normalized vector |??B in another qubit Hilbert space\nHB spanned by orthonormal vectors |j?B for j = 0 and\n1 in HB. The strategies of the players can thus be ex-\npressed in the linear combinations,\n|??A =\nsummationdisplay\ni\n?i(?)|i?A ,\n|??B =\nsummationdisplay\nj\n?j(?)|j?B ,\n(2.1)\nusing the bases |i?A, |j?B which correspond to the clas-\nsical strategies, with complex coefficients ?i(?), ?j(?)\nwhich are functions of the parameters ? and ? normal-\nized as summationtexti|?i|2 = summationtextj |?j|2 = 1. The strategies of the\nindividual players are, therefore, realized by local actions\nimplemented by the players independently.\nThe joint strategy of the players, on the other hand,\nis given by a vector in the direct product Hilbert space\nH = HA ?HB. Here lies one of the crucial differences\nbetween the classical and quantum games: in quantum\ngame theory, the joint strategy is specified not just by the\nchoice of the strategies of the players but also by furnish-\ning the quantum correlation (essentially the entangle-\nment) between the individual strategies. Consequently,\nthe outcome of a quantum game rests also on a third\nparty (or referee) that determines the correlation. To be\nmore explicit, using the product vector|?,?? = |??A|??B\nwhich is uniquely specified by the individual strategies,\na vector in the total strategy space H is written as\n|?,?;?? = J(?)|?,?? = J(?)|??A|??B , (2.2)\nwhere J(?) is a unitary operator providing the quantum\ncorrelation between the individual strategies. The corre-\nlation factor J(?) with the parameter set ? is designed to\nexhaust all possible joint strategies available in H. The\npayoffs for Alice and Bob are then given by the expecta-\ntion values of some appropriate self-adjoint operators A\nand B, respectively:\n?A(?,?;?) = ??,?;?|A|?,?;??,\n?B(?,?;?) = ??,?;?|B|?,?;??. (2.3)\nTo sum up, a quantum game is defined formally by the\ntriplet {H,A,B}.\n3\nTo choose the payoff operators A and B, we require\nthat, in the absence of quantum correlations J(?) = I\n(I is the identity operator in H), the payoff values re-\nduce to the classical ones when the players choose the\n?semiclassical (pure) strategies? |i,j? = |i?A|j?B,\n?i?,j?|A|i,j? = Aij?i?i?j?j,\n?i?,j?|B|i,j? = Bij?i?i?j?j. (2.4)\nAdopting, for simplicity, the value ? = 0 for the refer-\nence point at which J(?) = I holds, we find that, for\nthe uncorrelated product strategies |?,?;0? = |?,??, the\npayoffs (2.3) become\n?A(?,?;0) = ??,?;0|A|?,?;0? =\nsummationdisplay\ni,j\nxiAijyj,\n?B(?,?;0) = ??,?;0|B|?,?;0? =\nsummationdisplay\ni,j\nxiBijyj,\n(2.5)\nwhere xi = |?i|2, yj = |?j|2 represent the probability\nof realizing the strategies |i?A, |j?B under the general\nchoice |??A, |??B (see (2.1)). This ensures the exis-\ntence of a classical limit at which the quantum game\nreduces to the classical game defined by the payoff ma-\ntrix Aij, where now Alice and Bob are allowed to adopt\nmixed strategies (see, e.g., [13]) with probability distri-\nbutions xi, yj (summationtextxi = summationtextyj = 1) for strategies i, j.\nWe thus see that the quantum game is an extension of\nthe classical game, in which the correlation parameter ?\nplays a role similar to the Planck constant planckover2pi1 in quantum\nphysics in the technical sense that the classical limit is\nobtained by their vanishing limit. Note that, since the set\n{|i,j?, i,j = 0,1} forms a basis set in the entire Hilbert\nspace H, the payoff operators A and B are uniquely de-\ntermined from the classical payoff matrices by (2.4); in\nother words, our quantization is unique.\nThe aforementioned symmetries in classical game can\nalso be incorporated into quantum game by using cor-\nresponding appropriate symmetry operators. Indeed, by\nintroducing the swap operator\nS|i,j? = |j,i?, (2.6)\nwe see immediately that in the classical limit the game\nis S-symmetric, ?B(?,?;0) = ?A(?,?;0), provided that\nthe payoff operators A and B fulfill\nB = SAS. (2.7)\nAnalogously, if we introduce the notation ?i = 1 ? i for\ni = 0,1 (i.e., ?0 = 1 and ?1 = 0) and thereby the twist\noperator,\nT|i,j? = |?j,?i?, (2.8)\nand the twisted states,\nvextendsinglevextendsingle??, ??angbracketrightbig := T |?,?? = summationdisplay\ni,j\n?i(?)?j(?)|?j,?i?, (2.9)\nwe find that in the classial limit the game is T-symmetric,\n?B(??, ??;0) = ?A(?,?;0), provided that the operators\nfulfill\nB = T AT. (2.10)\nThe symmetries can be elevated to the full quantum\nlevel if we adopt the correlation factor in the form [7],\nJ(?) = ei?1S/2ei?2T/2, (2.11)\nwith real parameters ?i ? [0,2pi) for i = 1,2 [17]. In fact,\none can readily confirm, using [S,T] = ST ? TS = 0,\nthat under (2.10) the game is S-symmetric\n?B(?,?;?) = ?A(?,?;?), (2.12)\neven in the presence of the correlation (2.11). Similarly,\nthe game is T-symmetric\n?B(??, ??;?) = ?A(?,?;?), (2.13)\nif (2.10) is fulfilled. Since the correlation parameters in\n? are arbitrary, the properties (2.12), (2.13) imply that\na symmetric quantum game consists of a (?-parameter)\nfamily of games with the (S or T) symmetry exhibited\nfor each ?.\nIt is interesting to observe that these two types of sym-\nmetric games are actually related by unitary transforma-\ntions. To see this, let us introduce the operator CA which\nimplements the conversion for Alice?s strategies,\nCA|i,j? = |?i,j?. (2.14)\nNote that CA satisfies\nCA SCA = T, CA T CA = S. (2.15)\nConsider then the transformation of strategy by unilat-\neral conversion by Alice,\n|?,?;??? CA|?,?;??. (2.16)\nOn account of the relation (2.14) and the form of the\ncorrelation (2.11), we find\nCA|?,?;?? = |??,?;???, (2.17)\nwith ?? given by\n(??1,??2) = (?2,?1). (2.18)\nIn addition, one may also consider the transformation\non the payoff operators,\nA ? ?A = CA ACA, B ? ?B = CA BCA. (2.19)\nOne then observesthat, if the game is S-symmetricfulfill-\ning (2.7), the game defined by the transformed operators\nbecomes T-symmetric,\n?B = T ?AT. (2.20)\n4\nAnalogously, if the game is T-symmetric fulfilling (2.10),\nthen the transformed operators define an S-symmetric\ngame,\n?B = S ?AS. (2.21)\nThis shows that the conversion CA in (2.14) provides\na one-to-one correspondence, or duality, between an S-\nsymmetric game and a T-symmetric game. Some quan-\ntities in quantum game are invariant under the duality\nmap while other are not. For instance, the trace of the\npayoff,\nTrA =\nsummationdisplay\ni,j\nAij = A00 +A01 +A10 +A11, (2.22)\nremains invariant TrA ? Tr ?A = TrA, whereas the al-\nternate trace defined by\n?(A) =\nsummationdisplay\ni,j\n(?)i+jAij = A00 ?A01 ?A10 +A11, (2.23)\nchanges the sign ?(A) ? ?( ?A) = ??(A).\nIn formal terms, the two games given by {H,A,B}and\n{H, ?A, ?B} are dual to each other in the sense that the\npayoff under the strategy |?,?;?? in one game is equiva-\nlent to the payoff under the dual strategy CA|?,?;?? =\n|??,?;??? in the other. In particular, if the former\ngame happens to be S-symmetric, then the latter is T-\nsymmetric, and vice versa. This allows us to regard any\ntwo games as ?identical? if their payoff operators are re-\nlated by the duality map (2.19).\nEvidently, the other conversionofthe strategiesby Bob\nCB|i,j? = |i,1?j? can also be used to provide a similar\nbut different duality. Besides, their combination,\nC = CA ?CB, (2.24)\nimplements the renaming of the strategies 0 ? 1 for both\nof the players, and yields a duality map which does not\nalter the type of symmetries of the game. These dual-\nity maps CA, CB and C are used later to identify games\ndefined from different classical payoff matrices. We men-\ntion that these dualities are actually a special case of the\nmore general ?gauge symmetry? in quantum game the-\nory, which is that the two games defined by {H,A,B}\nand {H,UAU?,UBU?} with some unitary operator U\nare dual to each other under the corresponding strategies\n|?,?;?? and U|?,?;??. Thus the identification of games\ncan be extended to those which are unitarily equivalent.\nIII. CLASSIFICATION OF T-SYMMETRIC\nGAMES\nThe foregoing argument suggeststhat in order to study\nthe two types of symmetric games it is sufficient to con-\nsider either one of the two. Moreover, even if the two\ngames are of the same symmetric type, a further identi-\nfication may be possible using the full conversion C. In\nview of this, in the following we choose the T-symmetric\ngames and analyze the pattern of the allowed equilibria\nthere. To start with, we furnish the definition of an equi-\nlibrium which corresponds to the NE in classical game\n[18]. A joint strategy |??,??? is called quantum Nash\nequilibrium (QNE), if it satisfies\n?A(??,??;?) ? ?A(?,??;?), (3.1)\nfor all ?, and also\n?B(??,??;?) ? ?B(??,?;?), (3.2)\nfor all ?. Note that the QNE is defined for a given ?\ntreated as a set of external parameters. Below, we study\nthe conditions for ? under which a QNE appears.\nTo evaluate the payoffs explicitly, we write the strate-\ngies as\n|??A = cos(?1/2)|0?A + sin(?1/2)ei?2|1?A,\n|??B = cos(?1/2)|0?B + sin(?1/2)ei?2|1?B, (3.3)\nwith angle parameters ?1,?1 ? [0,pi] and ?2,?2 ? [0,2pi).\nFor convenience, we henceforth adopt both of the ket\nnotations |?? and |i? with the convention that |0? and |1?\nrefer always to the latter notations. Using (3.3) we find\nthat, for a T-symmetric game fulfilling (2.10), the payoff\nfor Alice reads\n?A(?,?;?) = 14{TrA+?(A)cos?1 cos?1\n+I?+(?)cos?1 +I??(?)cos?1\n?I+(?)sin?1 sin?1 sin?2 cos?2\n?I?(?)sin?1 sin?1 cos?2 sin?2},\n(3.4)\nwhere we have defined\nI?(?) = G+(?)?G?(?),\nI??(?) = G?+(?)?G??(?), (3.5)\nwith\nG+(?) = (A00 ?A11)sin?2,\nG?+(?) = (A00 ?A11)cos?2,\nG?(?) = (A01 ?A10)sin?1,\nG??(?) = (A01 ?A10)cos?1.\n(3.6)\nThe payoff ?B(?,?;?) for Bob is readily obtained from\n(3.4) using the relation (2.13). The conditions for QNE\n(3.1) and (3.2) imply\n??i?A(?,??;?)|?? = 0,\n??i?B(??,?;?)|?? = 0, (3.7)\nfor i = 1,2. Besides, the Hessian matrices PA and PB\ngiven by\nPA(?,?;?)ij = ??i??j?A(?,?;?),\nPB(?,?;?)ij = ??i??j?B(?,?;?), (3.8)\n5\n|??,??? Hessian conditions ?A(??,??;?)\n|0,0? H+ > 0, H? > 0 [TrA+?(A)+ 2G?+]/4\n|0,1? H? < 0 [TrA??(A)+ 2G??]/4\n|1,0? H+ < 0 [TrA??(A)? 2G??]/4\n|1,1? H+ > 0, H? > 0 [TrA+?(A)? 2G?+]/4\nTABLE II: Hessian conditions and Alice?s payoffs for edge\nstrategies in T-symmetric games. Bob?s payoffs can be ob-\ntained from ?B(??,??;?) = ?A(???, ???;?).\nmust be both negative semi-deifinite,\nPA(??,??;?) ? 0, PB(??,??;?) ? 0. (3.9)\nUsing (3.4) we obtain, for example,\n??2?A(?,??;?)|?? = ???2?B(??,?;?)|??\n= 14 sin??1 sin??1 [I?(?)sin??2 sin??2\n?I+(?)cos??2 cos??2]. (3.10)\nThese conditions (3.7) and (3.9) will now be analyzed in\ndetail.\nA. Edge strategies\nFrom (3.10) we see that an obvious set of solutions for\n(3.7) are obtained if\nsin??1 = sin??1 = 0. (3.11)\nThese have solutions given by the semiclassical pure\nstrategies |i,j? for i,j = 0,1, i.e., the four ?edge? strate-\ngies,\n|0,0?, |1,1?, |0,1?, |1,0?, (3.12)\nwhich correspond to classical pure strategies (i,j). Note,\nhowever, that these quantum edge strategies differ from\nthe classical counterparts because the joint strategy is\ndetermined with the additional correlation factor J(?).\nNote also that on the edge strategies the unitary opera-\ntion J(?) yields only a one-parameter family of correla-\ntions for joint states |i,j;?? in (2.2), since one of the two\nfactors in (2.11) gives merely an overall phase.\nFor the edge states to become QNE, they also need to\nobey the Hessian conditions (3.9), which pose different\nrequirements for the states as\n|0,0? : H+(?) > 0, H?(?) > 0,\n|0,1? : H?(?) < 0,\n|1,0? : H+(?) < 0,\n|1,1? : H+(?) > 0, H?(?) > 0,\n(3.13)\nwhere we have used\nH?(?) = ?(A)?I?+(?), (3.14)\nlabel QNE characteristics\nBoS |0,0? and |1,1? none\nPD |1,0? or |0,1? not Pareto optimal\nSH |1,0? and |0,1? either payoff or risk dominant\nTABLE III: QNE and their characteristics in the domains\non the G?+-G?? plane classified by the labels of the classi-\ncal games. Both PD and SH games are mapped to their T-\nsymmetric dual versions.\nand ignored the cases of equalities for brevity. These con-\nditions and the payoffs for the edge solutions are sum-\nmarized in Table II. To see when these conditions are\nfulfilled for different ?, it is convenient to consider the\nplane coordinated by (G?+,G??) with G?? given in (3.6).\nOne then sees that, as shown in Figure 1, the entire pa-\nrameter region of ? is mapped to a rectangular area in\nthe centre of the G?+-G?? plane with the horizontal length\nLh and the vertical length Lv given by\nLh = 2|A00 ?A11|, Lv = 2|A01 ?A10|. (3.15)\nIt is worth noting that, at each of the midpoints of\nthe four edges, the operation J(?) can yield a maximally\nentangled joint strategy state. For instance, for A01 >\nA10 the midpoint (G?+,G??) = (0,Lv/2) corresponds\nto J(pi/2,0) under which the edge state |01? becomes\n(|01? + i|10?)/?2. Similarly, for A00 > A11 the mid-\npoint (G?+,G??) = (Lh/2,0) corresponds to J(0,pi/2) un-\nder which the edge state |00? becomes (|00?+i|11?)/?2.\nThe four corners of the rectangle, on the other hand, cor-\nrespond to J(mpi,npi) for m,n = 0,1, which are S, T, C,\nand I operations, and hence the resultant joint strategies\nare all unentangled. On the G?+-G?? plane, the Hessian\nconditions determine the domains of allowed edge QNE\nwhich are separated by the parallel lines H?(?) = 0 (see\nFigure 1). Observe that the allowed edge QNE are differ-\nent depending onthe domains, and that the combinations\nof the QNE change when the sign of ?(A) is reversed.\nNote that for ?(A) > 0 all edge strategies in (3.12) could\narise as a QNE for some ?, whereas for ?(A) < 0 only\n|0,1? and/or |1,0? become QNE.\nAs will be seen shortly, as long as the edge strategies\nareconcerned our quantum gameis simulated by classical\ngames possessing the corresponding NE. In view of this,\nwe may characterize the domains on the G?+-G?? plane\nby the typical classical games sharing the same NE. We\ndo this by using the BoS, PD and SH as the representa-\ntives (see Table III). Here, the label ?BoS? is chosen to\ndesignate the domain of games possessing two edge QNE\nat |0,0? and |1,1?, which is an obvious choice because\nthe classical BoS game is T-symmetric and has the cor-\nresponding NE at (i,j) = (0,0) and (1,1). None of these\nNE admits better payoffs to both of the players, simulta-\nneously, leading to the dilemma that they cannot decide\non which strategy the should choose. The domain ?BoS?\narises only for ?(A) > 0 and the required conditions are\nBoS : H+ < 0, H? < 0. (3.16)\n6\nG?+\nG??\n? > 0\nH? = 0H+ = 0\n|0,1?\n|1,0?\nBoS\nPD\nPD\nG?+\nG??\n? < 0\nH+ = 0H? = 0\n|0,1?\n|1,0?\nSH\nSH\nPD\nPD\nFIG. 1: Phase structures of QNE in terms of edge strategies: ?(A) > 0 (above), ?(A) < 0 (below). The names of the domains\nare borrowed from the classical games sharing the same characteristic dilemmas (see Table III). Games in the domains without\nnames are free from dilemmas within edge strategies and possess a single stable strategy |1,0? or |0,1? among at most two QNE.\nThe correlation family of a quantum game forms a rectangle on the plane, as shown by the dotted line for the case ?(A) > 0.\nThe domain fulfilling these forms a diagonal strip be-\ntween the parallel lines H? = 0 on the G?+-G?? plane\n(see Figure 1).\nTo justify the assignment of the other labels, recall\nthat the classical PD game is an S-symmetric game and\nhas a NE at (1,1) which is unique. The problem of the\ngame is that the NE is not Pareto optimal, i.e., there\nexists another strategy which improves the payoffs for\nthe two players, simultaneously, and this constitutes the\ndilemma. Upon quantization, the quantum PD, in the\nclassical limit, will have one edge QNE at |1,1?, which\nturns into |0,1? by the duality map (2.14) when it is\nemployed to convert the PD into the T-symmetric dual\nversion. For this reason, we use ?PD? to label the do-\nmain of those T-symmetric games possessing the edge\nQNE at |0,1? which is not Pareto optimal. The Pareto\noptimality can be examined by comparing the payoff val-\nues with other strategies, and in the present case this\nis done essentially by comparing the payoffs between the\ntwo strategies|1,0? and |0,1?. From Table II, we see that\nthis situation occurs when\nPD : H+ > 0, H? < 0, G?? < 0. (3.17)\nWe also use the same label ?PD? for the domain of games\npossessing a QNE at |1,0? which is not Pareto optimal,\nsince thoseareidentified bythe full conversionC in (2.24)\nwith the standard quantum PD. This is the case when\nwe have\nPD : H+ < 0, H? > 0, G?? > 0. (3.18)\nAs shown in Figure 1, the domains of PD appear both\nfor ?(A) > 0 and ?(A) < 0.\nThe classical SH game, on the other hand, is an S-\nsymmetric game which has two NE at (0,0) and (1,1),\nin which (0,0) is payoff dominant (i.e., better than (1,1)\nin the payoff) and (1,1)is risk dominant (i.e., better than\n(0,0) in the ?average? over the choice of the other player).\nThe dilemma is that, while (0,0) is Pareto optimal, (1,1)\nis preferable for the minimal risk, which makes the play-\ners uncertain to decide which to choose. Now, after the\nquantization and the application of the duality map to\nget the T-symmetric quantum version of the game, we\nwill have two edge QNE at |1,0? and |0,1? in the classi-\ncal limit, with payoff dominant |1,0? and risk dominant\n|0,1?. We therefore use the label ?SH? to name the do-\nmain in which the games possess the same QNE with the\nabove property. In the presence of correlations, we find\nfrom Table II that the payoff dominance of |1,0? requires\nG?? < 0. The risk dominance of |0,1? demands that the\naverage payoff Alice receives under the choice |0?A be\nlarger than that obtained under the choice |1?A, which\nis ensured if G?+ + G?? > 0. As in the case of the PD,\nthe label ?SH? is also used for the domain of games pos-\nsessing the two QNE with payoff dominant |0,1? and risk\ndominant |1,0? for Alice, which are possible if G?? > 0\nand G?+ + G?? < 0. These domains ?SH? are allowed\nonly for ?(A) < 0 where |1,0? and |0,1? arise as QNE\nbetween the two parallel lines H? = 0 on the G?+-G??\nplane. Combined with the above additional conditions,\nthe SH domains are characterized by\nSH : H+ > 0, H? > 0, G??(G?+ +G??) < 0. (3.19)\nAs shown in Figure 1, the classification of the games\nleavesunlabeled domains on the G?+-G?? plane for each of\nthe cases ?(A) > 0 and ?(A) < 0. For ?(A) > 0, we find\ntwo separate domains which contain games possessing a\nunique QNE, either at |0,1? or |1,0?. These QNE are\nPareto optimal, and hence the games are free from the\ndilemma of the PD type. For ?(A) < 0, we have two ad-\nditional domains of games possessing QNE at |0,1? and\n|1,0?, which are free from the dilemma of the SH. This\nresult suggests that, if the game under consideration can\nbe driven to lie in these unlabeled domains by adjusting\nthe correlations appropriately, then the original dilemma\nmay be resolved under these correlations, at least within\nthe realm of edge strategies. In this respect, the phase\ndiagram given by Figure 1 provides a convenient basis to\nexamine the problem of optimality of strategies in quan-\ntum games.\nSince the correlation-family of a symmetric quantum\ngame is mapped to a rectangle on the G?+-G?? plane, we\ncan classify quantum games in terms of the patterns of\nthe rectangle formed on the plane. As shown in Figure\n7\nFIG. 2: Four patterns of rectangles which are possible in re-\nlation to the parallel lines H? = 0 provide distinct phase\nstructures for symmetric quantum games. The rectangle may\nreduce to a line as we see in the case of the BoS later.\n2, there are four types of rectangles, determined from\nthe values of Lh and Lv in (3.15), which are different\nin position with respect to the parallel lines H?(?) = 0\nappearing in Figure 1. Combining the two cases ?(A) > 0\nand?(A) < 0 whichoffer different structuresfor domains,\nwe find that there are altogether eight classes of quantum\ngames which have distinct phase structures of QNE in\nterms of edge strategies.\nOne of the advantages of the present quantization\nscheme is that it allows us to establish the connection\nbetween the classical and quantum games in a simple\nmanner and thereby examine how ?quantum? the game\nactually is. To see this, let us introduce the correlated\npayoff matrices\nA(?) = J?(?)AJ(?), B(?) = J?(?)BJ(?). (3.20)\nWith these, the payoffs (2.3) are expressed in terms of\nseparable (uncorrelated) states\n?A(?,?;?) = ??,?|A(?)|?,??,\n?B(?,?;?) = ??,?|B(?)|?,??. (3.21)\nOne may decompose each of the correlated payoffs into\n?pseudo-classical? and ?interference? terms as\nA(?) = Apc(?)+Ain(?), (3.22)\nwith\nApc(?) = cos2 ?12 A+ (cos2 ?22 ?cos2 ?12 )SAS\n+ sin2 ?22 C AC,\n(3.23)\nwhere C is given in (2.24) and\nAin(?) = i2 sin?1 [A,S] + i2 sin?2[A,T]. (3.24)\nThe pointis thatthe pseudo-classicalpartApc isdiagonal\nand hence for separable strategies it can be interpreted\nas a classical payoff matrix. In contrast, the interference\npart Apc is non-diagonal and represents a non-classical\ncontribution. Accordingly, the payoff for Alice in a T-\nsymmetric game is decomposed into the sum ?A = ?pcA +\n?inA, where we have\n?inA(?,?;?) = 0, (3.25)\nfor edge strategies. This observation confirms that our\nquantum game with edge strategies are, in effect, equiv-\nalent to the classical game with the payoff matrices Apc\nand Bpc (the latter can be defined analogously for the\ncorrelated payoff B(?)). Possible game theoretical inter-\npretations of the pseudo-classical payoff based on altru-\nism and value-conversion have been noted in Ref.[7].\nB. Non-edge strategies\nTo discuss QNE beyond the edge strategies (3.12), we\nrecall (2.13) and seek solutions which are T-symmetric,\n|??,??? = |???, ????. In the representation (3.3) of the\nstate (which is defined up to an overall phase), this trans-\nlates into\n??1 ???1 = pi, ??2 +??2 = pi. (3.26)\nUnder the T-symmetric ansatz and the non-edge require-\nment sin??1 negationslash= 0, the conditions in (3.7) imply\ncos??1 [?(A)?G?(?)sin2??2]?I?+(?) = 0,\nG?(?)cos2??2 +G+(?) = 0. (3.27)\nBesides, the Hessian condition (3.9) implies\nG? sin2??2 ? 0. (3.28)\nBefore analyzing the solutions in detail, we observe\nthat at the classical limit ? = 0 the above conditions are\nsimplified to the single condition,\ncos??1 = ?+(A)?(A) , (3.29)\nwith ?+(A) defined as\n??(A) = (A00 ?A11)?(A01 ?A10). (3.30)\nThe condition (3.29) has a solution when |?(A)| ?\n|?+(A)|, which is equivalent to\nA00 ? A10 and A11 ? A01, or\nA00 ? A10 and A11 ? A01. (3.31)\nThe solution for (3.29) corresponds to the NE for mixed\nstrategies in classical games with x?1 = y?1 = cos2(??1/2),\nand (3.31) agrees precisely with the conditions for such\nnontrivial NE to arise. It is important to note, how-\never, that the non-edge QNE in quantum game and the\nmixed NE in classical game are completely different in\nthe meaning of strategies. Namely, the NE in classical\ngame is relevant only for the situation where the games\n8\nFIG. 3: Possible patterns of allowed regions by (3.33) in the\nrectangle of the game under Lh < Lv (left), Lh = Lv (middle)\nand Lh > Lv (right). These regions are shaded, and the dot\nin the centre represents the origin of the G?+-G?? plane.\nare repeated many times in which the players can con-\nsider probability distributions in choosing their strategies\n? the mixed NE and pure NE belong to different cate-\ngories conceptually. In contrast, the non-edge QNE in\nquantum game is a pure strategy and meaningful with-\nout repeating the game ? it belongs to the same category\nas the edge QNE.\nTo discuss solutions for generic ?, we notice first that\nthe second condition in (3.27) determines ??2, which can\nbe used to determine ??1 in the first condition. In terms\nof ?(?) :=\nradicalBig\nG2? ?G2+ for which we have\n?2 = (G?+)2 ?(G??)2 ??+ ??, (3.32)\nthe condition for the existence of ??2 reads\n? ? 0. (3.33)\nNotice that ?+ ?? = (L2h ?L2v)/4 measures the squared\ndifference in length between the two edges of the rectan-\ngle of the game. It follows that the regions allowed by\n(3.33) are those enclosed by the two hyperbolae ?2 = 0\nand the edges of the rectangle, which vary depending on\nthe types of the rectangle (see Figure 3).\nOn the other hand, by combining the two conditions\nin (3.27) and (3.28) we see that the solution for ??1 exists\nif\n(H+ + ?)(H? + ?) ? 0. (3.34)\nUsing (3.32), one can readily depict the regions where\n(3.34) is fulfilled on the G?+-G?? plane. The games be-\nlonging to the overlapped areas of the above two regions\nadmit non-edge QNE, and this is indeed possible if the\npayoff A meets certain conditions, as illustrated by the\nSH game later. When this happens, the non-edge QNE,\nwhich we denote by |??,??;?? = |?ne,?ne;??, offers the\nsame payoff (as ensured by the T-symmetry) for Alice\nand Bob,\n?A(?ne,?ne;?) = ?B(?ne,?ne;?)\n= 14\nbracketleftbigg\nTrA+ ?(A)?(?)??+(A)??(A)?(A) + ?(?)\nbracketrightbigg\n. (3.35)\nIn particular, at the classical limit the payoff becomes\n?A(?ne,?ne;0) = A00A11 ?A01A10A\n00 +A11 ?A01 ?A10\n, (3.36)\nwhich is the familiar payoff expression for the mixed NE\nin classicalT-symmetricgames. This showsthat the non-\nedge QNE are actually an extension of the classicalmixed\nNE. In fact, at the classical limit, we find from ?(0) = 0\nthat the condition (3.33) is trivially fulfilled, and that\n(3.34) reduces to\nH+(0)H?(0) = 4(A00 ?A10)(A11 ?A01) ? 0, (3.37)\nwhich is exactly the condition for mixed NE (3.31). In\nother words, if the classical game admits a mixed NE,\nthen the quantum game defined from the classical game\nadmits a QNE for a certain range of correlations includ-\ning the classical limit.\nTo summarize, non-edge QNE may exist as an exten-\nsion of mixed NE under various correlations in quantum\ngame theory, and their existence can be examined from\nthe rectangle of the game specified from the classical pay-\noff matrix Aij. Game theoretical analysis, including the\nresolution of dilemma in classical game, should be made\nbased on the combination of edge and non-edge QNE.\nIV. DILEMMAS IN BOS, PD AND SH\nHaving obtained the phase structures of symmetric\nquantum games for edge QNE as well as the conditions\nfor non-edgeQNE,we nowexamineif andhowthe typical\ndilemmas familiar in classical game theory ? the dilem-\nmas in the BoS, the PD and the SH game ? can be re-\nsolved in quantum game theory. All of the dilemmas\nin these cases are intrinsically different, and there is no\nunique criterion for the resolution. We thus consider the\nresolution based on the conventional requirements which\nare attached to the respective classical games, and find\nthat the quantization of the games lead to considerably\ndifferent outcomes for the three cases.\nA. Battle of the Sexes\nThe BoS game is a special case of the T-symmetric\ngame specified by the payoff matrix,\nA00 > A11 > A01 = A10. (4.1)\nThe degeneracy A01 = A10 provides the T-symmetric\ngame with an extra symmetry between the payoff matri-\nces, that is,\nB = T AT = C AC. (4.2)\nOnaccountofthe degeneracy,we haveG?(?) = G??(?) =\n0, which implies that the parameter ?1 drops out from\nour consideration of QNE. Notice that the BoS defined\nby (4.1) has ?(A) > 0 and that, as shown in Figure 4, the\nrectangle of the game in the G?+-G?? plane is smashed to\na line on the G?+-axis with length Lh. Notice also from\nA00 > A11 that the classical limit is found at the right\n9\nend of the line. Now, an important point to observe is\nthat since\n?(A)?(A00 ?A11) = 2(A11 ?A01) > 0, (4.3)\nthe line segment of the game lies entirely within the BoS\ndomain (see Figure 4). This shows that, so far as the edge\nstrategies are concerned, even in the presence of the cor-\nrelation J(?), the dilemma in the BoS does not disappear\nin quantum game. Using (3.21) and (3.23), Alice finds\nher payoff ?A(i,i;?) at the edge QNE |??,??? = |i,i? for\ni = 0,1 as\n?A(i,i;?) = cos2 ?22 Aii + sin2 ?22 A?i?i. (4.4)\nNote that the correlationinterpolates between the largest\ntwo payoff values A00 and A11, and hence ?A(i,i;?) ?\nA11 for both of the edge QNE, i = 0,1.\nTo see if the dilemma can be resolved by taking non-\nedge QNE into account, we first observe that for BoS the\nconditions (3.27) are fulfilled for ?2 = 0, pi with arbitrary\n?1. For that non-edge QNE, the payoff ?A(?ne,?ne;?) in\n(3.35) reduces to (3.36) with A01 = A10. At ?1 = 0 this\nnon-edge QNE corresponds to the known mixed strategy\nNE in classical BoS, which cannot resolve the dilemma\nsince the payoffs are strictly less than those obtained un-\nder the two edge QNE for both of the players. The situa-\ntion doesnot improveevenfor?1 negationslash= 0, because the payoffs\nare independent of ?1 for all strategies. Moreover, on the\ngeneral basis of the assignments (4.1) (i.e., without mak-\ning use of the ansatz (3.26)), one can confirm by looking\nat the Hessian condition (3.9) that there is no non-edge\nQNE for BoS except for the one mentioned above. Thus\nwe find that under any correlations ? for the non-edge\nQNE we have ?A(?ne,?ne;?) < A11 and hence\n?A(i,i;?) > ?A(?ne,?ne;?), for i = 0,1. (4.5)\nAlthough the dilemma does not disappear even in\nquantum BoS, one may argue that the problem is some-\nwhat mitigated at?2 = pi/2 wherethe joint strategystate\nis maximally entangled. Indeed, under this correlation\nthe payoffs for the two edge QNE (4.18) for i = 0,1 coin-\ncide and hence the choice of strategies becomes irrelevant\nfor the players. The dilemma still remains in essence [16],\nhowever, because the players, who cannot communicate,\nmay inadvertently end up with a wrong strategy, |0,1? or\n|1,0?, yielding the worst payoff ?A = ?B = A01 (for all\n?). A similar conclusion has been drawn for BoS in [2, 8]\nusing a different quantization scheme with mixed quan-\ntum states, while a way out is suggested in an extended\nscheme [9]. The analysis [3] made in the scheme of [1]\nyields a considerably different outcome, with infinitely\nmany QNE with the payoffs lower than those of our edge\nQNE, indicating that the dilemma is unresolved unless\nsome subtle reasoning (focal point effect) is invoked.\nG?+\nG??\nCL\nME\nFIG. 4: Phase structure of edge QNE in the BoS game. The\nrectangle of the game is smashed to a line segment lying at the\ncentre as shown by the dotted line, which is entirely contained\nin the BoS domain. The right end point CL is the classical\nlimit and the middle point ME represents the point where the\nmaximally entangled correlation is realized.\nB. Prisoners? Dilemma\nThe PD game can also be analyzed in our scheme by\nconverting it to a dual T-symmetric game using the map\n(2.19). The general S-symmetric PD in classical game\ntheory may be defined by the payoff matrix for Alice Aij\nsatisfying\nA10 > A00 > A11 > A01, (4.6)\ntogether with Bob?s payoff given by Bij = Aji. Supple-\nmental conditions (which is inessential for the following\nargument),\n2A00 > A01 +A10 > 2A11, (4.7)\nmay also be imposed in order to render the strategies\n(i,j) = (0,0) and (1,1) the best and the worst of all\npossible strategies with respect to the sum of the payoffs\n[13]. The quantum PD is obtained by considering the\nself-adjointoperatorsA, B fulfilling (2.4), and the duality\nmap (2.19) yieldsthe T-symmetricversionof the PD with\nthe payoff operator ?A possessing the diagonal (classical)\nvalues\n( ?A00, ?A01, ?A10, ?A11) = (A10,A11,A00,A01). (4.8)\nIn terms of the converted payoff values, the conditions\n(4.6) and (4.7) turn out to be\n?A00 > ?A10 > ?A01 > ?A11, (4.9)\nand\n2 ?A10 > ?A00 + ?A11 > 2 ?A01. (4.10)\nNote that under the duality map for strategies (2.16) the\nparameters of the states (3.3) acquire the change\n(??1, ??2) = (?1 +pi, pi ??2). (4.11)\nIn addition, the duality relation in the correlation (2.18)\namounts to ?1 ? ?2 in G? and G??. To accommodate\nthese changes caused by the duality map, we use nota-\ntions such as\n?G? = G?|A? ?A,????, ?H? = H?|A? ?A,????, (4.12)\n10\nG?+\nG??\nCL\nG?+\nG??\nCL\nFIG. 5: Phase structure of edge QNE in the (T-symmetrized)\nPD game for the cases ?( ?A) > 0 (left) and ?( ?A) < 0 (right).\nFor both of the cases, the rectangle of the game, whose edges\nare shown by dotted lines, extends to domains of no dilemmas.\nfor our discussion of T-symmetric games.\nTo examine the possible phase structures of the game,\nwe observe that neither of the conditions (4.9) and (4.10)\ndetermines the sign of ?( ?A). However, since (4.9) implies\nthat the classical limit ? = 0 locates at the lower right\ncorner of the rectangle of the game, the inequalities\n?H+(0) = 2( ?A00 ? ?A10) > 0,\n?H?(0) = 2( ?A11 ? ?A10) < 0, (4.13)\nobtained at the classical limit ? = 0 from (4.9) are suf-\nficient to specify where the corner lies on the G?+-G??\nplane. The phase structures of the quantum PD game\nare then determined from the patterns of the rectangle\nin both of the cases ?( ?A) > 0 and ?( ?A) < 0, as illustrated\nin Figure 5. The outcome indicates that the correlation-\nfamily given by the rectangle does extend to domains of\nno dilemmas. It follows that, as long as edge QNE are\nconcerned, the quantum PD can be made dilemma-free\nwhen the correlations are furnished appropriately.\nFor a full resolution of the dilemma, we need to see\nwhether a non-edge QNE, if any, alters our conclusion\ndrawn from the edge QNE. This can be examined from\nthe analysis given in the previous section. We then learn\nthat, since the condition (3.31) is violated for (4.9), there\nis no non-edge QNE at the classical limit. We also re-\nalize that, for generic ?, the existence of non-edge QNE\nis dependent on the actual classical values of Aij, and\nthat for a wide range of payoff values centered at the\nstandard ones (A10,A00,A11,A01) = (5,3,1,0) used in\nthe literature (e.g., [1]), there exists no region fulfilling\n(3.33) and (3.34) simultaneously, and hence no non-edge\nQNE. Thus, our conclusion concerning the resolution of\nthe dilemma does not change in these standard settings\nof the PD game.\nC. Stag Hunt\nThe classical SH game is an S-symmetric game in\nwhich the payoff matrix for Alice fulfills the conditions,\nA00 > A10 ? A11 > A01, (4.14)\nwhich ensure that the strategies (0,0) and (1,1) are clas-\nsical NE. Among them, (0,0) is payoff dominant while\nG?+\nG??\nCL\nH+ + ? = 0\nH? + ? = 0\nFIG. 6: Phase structures of edge QNE (left) and non-edge\nQNE (right) in the (T-symmetrized) SH game. For edge\nQNE, the rectangle of the game extends to domains of no\ndilemmas. For non-edge QNE, the allowed regions by (3.33)\nare of the third type in Figure 3, and the two narrow regions\noverlapped with (3.34) shown in thick gray indicate the do-\nmains where a non-edge QNE appears.\nthe other (1,1) becomes risk dominant if\nA10 +A11 > A00 +A01. (4.15)\nAnalogously to the PD, we quantize the SH according to\n(2.4) and then T-symmetrizeit by the duality map (2.19).\nThis yields the payoffoperator ?A with the diagonalvalues\n(4.8) obeying\n?A10 > ?A00 ? ?A01 > ?A11, (4.16)\nand\n?A00 + ?A01 > ?A10 + ?A11. (4.17)\nNote that (4.16) implies ?( ?A) < 0. It also shows that\nthe classical limit is at the lower right corner of the rect-\nangle of the game, and that we have ?H?(0) < 0. From\nthis we can determine the position of the rectangle on the\nG?+-G?? plane as shown in Figure 6. The phase structure\nof the quantum SH game then suggests that, as in PD,\nthe correlation-family given by the rectangle extends to\ndomains without dilemmas. Within the edge strategies,\nthe dilemma of the SH can therefore be resolved in quan-\ntum game, if one adjusts the correlations appropriately.\nThe payoffs ?A(i,?i;?) at the edge QNE |??,??? = |i,?i?\nfor i = 0,1 read\n?A(i,?i;?) = cos2 ?12 ?Ai?i + sin2 ?12 ?A?ii, (4.18)\nwhich fall within the range of the payoffs of the two clas-\nsical NE, ?A10 ? ?A(i,?i;?) ? ?A01.\nThe classical SH game admits a mixed NE, and ac-\ncordingly the quantum SH admits a non-edge QNE for\na range of correlations including the classical limit, as\ncan be confirmed explicitly by examining the condition\n(3.37). To see where such correlations occur on the G?+-\nG?? plane, we consider the lines of equality H? + ? = 0\ndetermined by the condition (3.34), which are rewritten\nas\nG?+ = ?G?? ? ?\n2 +?+??\n2(G?? ??). (4.19)\n11\nCL:\nstrategy Bob |0? Bob |1? Bob |?ne?\nAlice |0? (3,0) (3,3) (3,3/4)\nAlice |1? (4,4) (0,3) (3,15/4)\nAlice |?ne? (15/4,3) (3/4,3) (3,3)\nME:\nstrategy Bob |0? Bob |1? Bob |?ne?\nAlice |0? (3,0) (7/2,7/2) (3,0)\nAlice |1? (7/2,7/2) (0,3) (7/2,7/2)\nAlice |?ne? (7/2,7/2) (0,3) (7/2,7/2)\nTABLE IV: Quantum payoff bi-matrices (?A,?B) of the SH\ngame for edge QNE and non-edge QNE. We used the values\n?A10 = 4, ?A00 = ?A01 = 3 and ?A11 = 0 (obtained from those\nmentioned in the text) to evaluate the payoffs at the classi-\ncal limit CL and the maximally entangled point ME, which\nare given by (G?+,G??) = (3,?1) and (3,0), respectively. The\npresence of the non-edge QNE worsens the risk balance be-\ntween the two edge QNE as we increase the amount of en-\ntanglement, but the dilemma disappears at ME where their\npayoffs become identical, for which the non-edge QNE does\nnot contribute.\nFor the SH we find ?2+?+?? > 0 from (4.16) and (4.17).\nThe domains where the non-edge QNE arise are then\nfound to be surrounded by the hyperbolae ? = 0 and\nthe curves (4.19), both of which come in contact at\n(G?+,G??) = ? 12? parenleftbig?2 +?+??,?2 ??+??parenrightbig. (4.20)\nAs illustrated in Figure 6, these domains are given by\ntwo narrow regions along the left and right edges of the\nrectangle of the game, indicating that under generic cor-\nrelations the non-edge QNE does not spoil the resolution\nof the dilemma in terms of edge QNE. It is, however,\nconceivable that the non-edge QNE, in the region where\nit is allowed, could alter the nature of the dilemmas, that\nis, the non-edge QNE could be both payoff and risk dom-\ninant under some particular correlations in the domains\nof SH, or it could pose a new dilemma in the domains\nwhere there was no dilemma originally. These possibili-\nties should be examined for the actual values of the payoff\nmatrix (4.16), but the analysis with the standard values\n(A00,A10,A11,A01) = (4,3,3,0) given in Table IV sug-\ngests that these are not likely to occur unless the payoff\nvalues are fine-tuned.\nV. CONCLUSION AND DISCUSSIONS\nIn this paper, we studied the phase structures of sym-\nmetric quantum games with respect to the stable strate-\ngies (QNE) available by pure states in quantum mechan-\nics. For quantization of classical games we adopted the\nscheme [7] which defines a unique correlation-family of\nquantum games from a classical game, allowing for all\npossible strategies realized by pure states, entangled or\nnot. The correlation-family is projected onto a rectangu-\nlar area in the G?+-G?? plane, where the phase structures\nof both the edge and non-edge QNE in the game can\nreadily be recognized. We have found that for symmet-\nric games there arise altogether eight different classes of\nphase structures for edge QNE depending on the payoff\nmatrices of the classical game we started with. This re-\nsult gives a more detailed account of the phase structures\nmentioned in [1] and discussed later in [5, 11].\nThe symmetric games considered in this paper consist\nof two types, T-symmetric and S-symmetric. We have\npresented a unified framework to treat them by means\nof a duality map, which enables us to use the results\nof the analysis of T-symmetric games for studying S-\nsymmetric games and vice versa. As an example of the\nT-symmetric game, we studied the BoS which is known\nto be a?icted with a dilemma classically. We have found\nthat the dilemma in the BoS cannot be resolved fully\n(albeit it can be alleviated) with strategies given by pure\nstates, even if we go over to quantum game where arbi-\ntrarily entangled states are utilized. Thus, the previous\nobservation made in [2, 8] remains essentially unchanged\neven in our enlarged scheme of quantum game, while the\noutcome is considerably different from those obtained in\nother schemes [3, 9]. As for the S-symmetric game, we\nexamined the PD and the SH to observe that for both of\nthe games the correlation-family contains a phase which\nis free from dilemmas under edge QNE. Since the stan-\ndard PD does not admit non-edge QNE, we concluded\nthat for the PD the classical dilemma disappears after\nquantization. For the SH, on the other hand, there ex-\nists a non-edge QNE which does not affect the resolution\nrealized by the edge QNE, generically. In short, quantum\nentanglement can resolve classical dilemmas for certain\ngames, and the games for which this is possible can be\njudged from the classical payoff matrices. We remark\nthat entanglement is necessary for the resolution of the\ndilemmas in our scheme, and that this is so in any other\nschemes of quantum games in which the resolution is pos-\nsible and the classical games are recovered in the limit\nwhere the joint strategies become separable as in (2.5).\nHowever, the actual amount of entanglement required de-\npends on the scheme used (because the class of families\nconsidered may be scheme-dependent) as well as on the\nvalues of the classical payoffs.\nCompared to most other schemes proposed so far, our\nscheme of quantum game is distinguished in the specifica-\ntion of strategies and correlations which are expressed in\nthe ordering of operations implementing them. Namely,\nin our scheme the players first make their choice of strate-\ngies independently, by performing the corresponding lo-\ncal unitary transformations on a fixed separable state,\nbefore a third party furnishes a correlation for the local\nstates. The player?s strategy is represented by a quantum\nstate, not by the local unitary transformation as consid-\nered in [1]. The advantage for this is that different pure\nstates used to specify the strategies yield different out-\ncomes of the payoff in general, while this is not ensured\nif unitary transformations are regarded as strategies. In\n12\nfact, it has been pointed out [6] that unitary transfor-\nmations become redundant (i.e., different unitary oper-\nations give the same quantum states) when the strate-\ngies are maximally entangled. Obviously, the choice of\nquantization scheme is directly related to the question of\nthe role of the third party which provides the quantum\ncorrelation in the game, and this has not been fully ex-\nplored yet. In this regard, we have found here a number\nof interesting features of quantum games which are com-\nmonly observed in various different schemes, in the phase\nstructures of the QNE and the resolution of dilemmas in\nsome of the familiar games. We hope that these findings\nwill help uncover the core elements ? independent of the\nscheme employed ? in quantum games, which are crucial\nfor laying a solid foundation of quantum game theory.\nAcknowledgments\nWe thank T. Cheon for helpful discussions. This work\nis supported by the Grant-in-Aid for Scientific Research,\nNo.13135206and No.16540354,ofthe JapaneseMinistry\nof Education, Science, Sports and Culture.\n[1] J. Eisert, M. Wilkens and M. Lewenstein, Quantum\ngames and quantum strategies, Phys. Rev. Lett. 83\n(1999) 3077-3080.\n[2] L. Marinatto and T. Weber, A quantum approach to\nstatic games of complete information, Phys. Lett. A272\n(2000) 291-303.\n[3] J. Shimamura, S. K. ?Ozdemir, F. Morikoshi and N.\nImoto, Quantum and classical correlations between play-\ners in game theory, Int.Journ. Quant.Inf.2(2004) 79-89.\n[4] J. Eisert and M. Wilkens, Quantum Games, J. Mod. Opt.\n47 (2000) 2543-2556.\n[5] J. Du, X. Xu, H. Li, X. Zhou and R. Han, Playing Pris-\noner?s Dilemma with Quantum Rules, Fluct. and Noise\nLett. 2 (2002) 189-203.\n[6] S. C. Benjamin and P. M. Hayden, Comment on ?Quan-\ntum Games and Quantum Strategies?, Phys. Rev. Lett.\n87 (2001) 069801.\n[7] T. Cheon and I. Tsutsui, Classical and Quantum Con-\ntents of Solvable Game Theory on Hilbert Space, Phys.\nLett. A348 (2006) 147-152\n[8] L. Marinatto and T. Weber, Reply to ?Comment on: A\nQuantum Approach to Static Games of Complete Infor-\nmation?, Phys. Lett. A277 (2000) 183-184.\n[9] A. Nawaz and A. H. Toor, Dilemma and Quantum Battle\nof Sexes, J. Phys. A: Math. Gen. 37 (2004) 4437-4443.\n[10] A. Nawaz and A. H. Toor, Generalized Quantization\nScheme for Two-Person Non-Zero-Sum Games, J. Phys.\nA: Math. Gen. 37 (2004) 11457-11463.\n[11] J. Du, X. Xu, H. Li, X. Zhou and R. Han, Experimental\nrealization of quantum games on a quantum computer,\nPhys. Rev. Lett. 88 (2002) 137902.\n[12] A. P. Flitney and D. Abbott, Advantage of a quantum\nplayer over a classical one in 2x2 quantum games, Poc\n.R. Soc. (London) A459 (2003) 2463-2474.\n[13] E. Rasmusen, An Introduction to Game Theory, Cam-\nbridge Univ. Press, Cambridge, 1989.\n[14] J. F. Nash, Equilibrium points in N-person games, Proc.\nNat. Acad. Sci. U.S.A. 36 (1950) 48-49.\n[15] C. F. Lee and N. Johnson, Quantum Game Theory, Phys.\nRev. A67 (2003) 022311.\n[16] S. C. Benjamin, Comment on ?A quantum approach to\nstatic games of complete information?, Phys. Lett. A277\n(2000) 180-182.\n[17] Apart from the irrelevant freedoms concerning the over-\nall phase and the normalization, the dimensionality of the\njoint strategy space is dimH ? 2 = 6 in real variables.\nSince the individual strategies |??A and |??B are specified\nby 2 + 2 = 4 parameters (e.g., see (3.3)), the correlation\nfactor must have another 2 parameters to cover the full\njoint strategy space. The actual construction of the cor-\nrelation factor is far from unique, and our form (2.11) is\nadopted based on the convenience for the duality map.\n[18] In the present paper, we consider quantum joint strate-\ngies given by pure states only. The space of pure states is\nnot convex, and hence the Nash theorem [14], which en-\nsures the existence of NE for a classical game with mixed\nstrategies, is no longer available. The existence of QNE\nin quantum game is, therefore, non-trivial [15].\n"}
{"id":"oai:arXiv.org:quant-ph/0602178","text":"arXiv:hep-ph/0610379v2  12 Jul 2007\nDirect detection of neutralino dark matter in non-standard\ncosmologies\nGraciela B. Gelmini,1, ? Paolo Gondolo,2, ? Adrian Soldatenko,1, ? and Carlos E. Yaguna1, ?\n1Department of Physics and Astronomy, UCLA,\n475 Portola Plaza, Los Angeles, CA 90095, USA\n2Department of Physics, University of Utah,\n115 S 1400 E # 201, Salt Lake City, UT 84112, USA\nAbstract\nWe compute the neutralino direct detection rate in non-standard cosmological scenarios where\nneutralinos account for the dark matter of the Universe. Significant differences are found when\nsuch rates are compared with those predicted by the standard cosmological model. For bino-\nlike neutralinos, the main feature is the presence of additional light (m? lessorsimilar 40 GeV) and heavy\n(m? greaterorsimilar 600 GeV) neutralinos with detection rates within the sensitivity of future dark matter\nexperiments. For higgsino- and wino-like neutralinos lighter than m? ? 1 TeV, enhancements of\nmore than two orders of magnitude in the largest detection rates are observed. Thus, if dark matter\nis made up of neutralinos, the prospects for their direct detection are in general more promising\nthan in the standard cosmology.\n?Electronic address: gelmini@physics.ucla.edu\n?Electronic address: paolo@physics.utah.edu\n?Electronic address: asold@physics.ucla.edu\n?Electronic address: yaguna@physics.ucla.edu\n1\nI. INTRODUCTION\nThe Large Hadron Collider is now in its final preparation stages and may soon be search-\ning for supersymmetric particles. Among them, the lightest neutralino in the minimal su-\npersymmetric standard model plays a distinctive role as a dark matter candidate [1]. It is\nneutral, weakly interacting, and stable (provided it is the lightest supersymmetric particle).\nIf evidence for low energy supersymmetry is found, it will strongly support the idea that\nneutralinos constitute the dark matter of the Universe. A logical next step would then be\nthe use of neutralinos as cosmological probes of the early Universe. Neutralinos could, in\nparticular, test the standard cosmological model well before big bang nucleosynthesis. Being\nan observable sensitive to the conditions in the early Universe, the neutralino direct detec-\ntion rate provides a plausible way of discriminating between different cosmological models,\nand therefore an indirect way of testing the standard scenario. Most studies on the direct\ndetection of neutralinos already assume the standard cosmology so it is not known what to\nexpect in a more general cosmological framework.\nThe vastness of the supersymmetric parameter space is the most compelling reason to\nassume the standard cosmological model. In a general setup, neither the neutralino mass\nor gauge composition nor its interaction rate, for example, can be determined a priori. To\nreduce such uncertainties, the dark matter constraint is usually imposed on supersymmetric\nmodels. That is, the neutralino relic density is computed within the standard cosmological\nmodel and only models with ?std < ?DM are considered (here ?std is the neutralino density\nin the standard cosmological model, and ?DM is the cold dark matter density, both in units\nof the critical density). This bound, it turns out, is very effective in restricting the parameter\nspace of supersymmetric models. In minimal supergravity models (mSUGRA), for instance,\nthe neutralino typically has a small annihilation rate in the early Universe, thus its relic\ndensity tends to be larger than observed. At the end, the requirement ?std < ?DM is found\nto be satisfied only along four narrow regions: the ?bulk? (with a light neutralino and tight\naccelerator constraints), the ?coannihilation region? (where the stau is almost degenerate\nwith the neutralino and coannihilation effects suppress the relic density), the ?funnel region?\n(where m? ?mA/2 and resonance effects enhance the ?-? annihilation rate) and the ?focus\npoint region? (where the neutralino acquires a non-negligible higgsino fraction). Accounting\nfor the dark matter provides, in fact, the most stringent constraint on supersymmetric\n2\nmodels, well over precision data or accelerator searches (see e.g. [2]).\nThough useful in reducing the supersymmetric parameter space, the dark matter con-\nstraint should not be taken for granted, as it relies on untested assumptions about the early\nUniverse. In particular, it postulates that the entropy of matter and radiation is conserved\nand that the Universe is radiation dominated at high temperatures (T ? m?). Several sce-\nnarios where such assumptions do not hold and, more generally, where the evolution of the\nUniverse before big bang nucleosynthesis deviates from the standard cosmological model,\nhave been studied in the literature. They are generically known as non-standard cosmolo-\ngies and include models with gravitino [3], moduli [4] or Q-ball decay [5], thermal inflation\n[6], the Brans-Dicke-Jordan [7] cosmological model, models with anisotropic expansion [8]\nor quintessence domination [9]. Non-standard cosmological models are viable alternatives\nagainst which the predictions of the standard scenario may be compared.\nIn non-standard cosmological scenarios, the neutralino relic density ?? may be larger or\nsmaller than ?std [11]-[20]. Smaller densities are usually the result of an episode of entropy\nproduction that dilutes the neutralino abundance. Larger densities are due either to ad-\nditional contributions to the expansion rate of the Universe, or to non-thermal neutralino\nproduction mechanisms. Usually these scenarios contain additional parameters that can be\nadjusted to modify the neutralino relic density. A distinctive feature of non-standard\ncosmologies is that the new physics they incorporate does not manifest in ac-\ncelerator or detection experiments. That is certainly the case, for instance, for\nthe several models mentioned above. Neutralino scattering rates, therefore, are\nnot affected by the cosmological model.\nA prototype non-standard cosmological model is that of a scalar field ? with\ncouplings of gravitational strength whose late decay reheats the Universe to\na low reheating temperature. The reheating temperature in this scenario can\nbe lower than the standard neutralino freeze-out temperature without spoiling\nprimordial nucleosynthesis [10]. Such scalar fields are common in superstring\nmodels where they appear as moduli fields. In these models, the decay of ?\ninto radiation increases the entropy, diluting the neutralino number density.\nInstead, the decay of ? into supersymmetric particles, which eventually decay\ninto neutralinos, increases the neutralino number density. In this non-standard\ncosmological model it has been shown that practically all neutralinos can have\n3\nthe density of the dark matter, provided the right combination of two parameters\ncan be achieved in the high energy theory: the reheating temperature, and\nthe ratio of the number of neutralinos produced per ? decay over the ? field\nmass [19, 20].\nIn this paper, we compute the neutralino direct detection rate in generic cosmological\nscenarios where neutralinos constitute the dark matter of the Universe. That is, we assume\nthat, independently of the supersymmetric spectrum, the parameters of the non-standard\ncosmological model can always be chosen so that ?? = ?DM. By randomly scanning the\nsupersymmetric parameter space, we obtain a large sample of models and compute their\ndetection rates in non-standard cosmologies. These predictions are then compared with\nthose obtained within the standard cosmological model. Our goal is twofold. First, we\nexplore the possibility of using the neutralino direct detection rate as a test of the standard\ncosmological model. Second, we establish the potential of future dark matter detectors in\nprobing the parameter space of supersymmetric models in a cosmology-independent setup.\nII. THE SUPERSYMMETRIC MODELS\nIn the MSSM, neutralinos are linear combinations of the fermionic partners of the neutral\nelectroweak bosons, called bino ( ?B0) and wino ( ?W03), and of the fermionic partners of the\nneutral Higgs bosons, called higgsinos ( ?H0u, ?H0d). We assume that the lightest neutralino, ?,\nis the dark matter candidate. Its composition can be parameterized as\n? = N11 ?B0 +N12 ?W03 +N13 ?H0d +N14 ?H0u . (1)\nBecause the neutralino interactions are determined by its gauge content, it is useful to\ndistinguish between bino-like (N211 > N212, N213 + N214), wino-like (N212 > N211, N213 + N214),\nand higgsino-like (N213 + N214 > N211, N212) neutralinos according to the hierarchy of terms\nin (1). This classification implies that even so-called mixed neutralinos, those with two or\nmore comparable components, are considered as either binos, winos or higgsinos.\nBino-like neutralinos annihilate mainly into fermion-antifermion pairs through sfermion\nexchange. Such annihilation cross-section is helicity suppressed and gives rise to a standard\nrelic density that is usually larger than observed. Agreement with the observed dark matter\nabundance can still be achieved in standard cosmological scenarios but only in restricted\n4\nregions of the parameter space where special mechanisms such as coannihilations or resonant\nannihilations help reduce the relic density. Owing to the gaugino unification condition, bino-\nlike neutralinos are a generic prediction of minimal supergravity models.\nWino-like andhiggsino-like neutralinos annihilate mostly into gaugebosons (W+W?, ZZ,\nif kinematically allowed) through neutralino or chargino exchange; otherwise they annihilate\ninto fermions. Due to coannihilations with the lightest chargino (and, for higgsinos, with the\nnext-to-lightest neutralino), their standard relic density is rather small. Neutralino masses\nas large as 1 TeV for higgsinos or 2 TeV for winos are required to bring their thermal density\nwithin the observed range. Wino-like and higgsino-like neutralinos can be obtained in models\nwith non-universal gaugino masses; models with anomaly mediated supersymmetry breaking\n(AMSB) [21], for instance, feature a wino-like neutralino.\nWe consider a general class of MSSM models defined in terms of the parameter set M3,\nM2, M1, mA, ?, tan?, m?q, m?? At, and Ab. Here Mi are the three gaugino masses, mA\nis the mass of the pseudoscalar higgs boson, and tan? denotes the ratio v2/v1. The soft\nbreaking scalar masses are defined through the simplifying ansatz MQ = MU = MD = m?q\nand ME = ML = m??, whereas the trilinear couplings are given by AU = diag(0,0,At),\nAD = diag(0,0,Ab), and AE = 0. All these parameters are defined at the weak scale.\nSpecific realizations of supersymmetry breaking such as mSUGRA, mAMSB [21] or split-\nSUSY [22] are similar to - though not necessarily coincide with - particular examples of these\nmodels.\nWe performed a random scan of such parameter space within the following ranges\n10 GeV < M1,M2,M3 < 50 TeV (2)\n40 GeV < mA,?,m?q,m?? < 50 TeV (3)\n?3m0 < At,Ab < 3m0 (4)\n1 < tan? < 60 (5)\nA logarithmic distribution was used for Mi, mA, ?, m?q and m??, and a linear one for At, Ab,\nand tan?; the sign of ? was randomly chosen. After imposing accelerator constraints, as\ncontained in DarkSUSY version 4.1 [23], a sample of about 105 viable models was obtained.\nThe following analysis is based on such a sample of supersymmetric models.\n5\n10 100 1000 10000\nNeutralino mass (GeV)\n0.0001\n0.01\n1\n100\n10000\n1e+06\n?h\n2\nBinos\nWinos\nHiggsinos\nFIG. 1: The standard neutralino relic density as a function of the neutralino mass for our sample\nof models. The models are differentiated according to the bino, wino, or higgsino character of the\nlightest neutralino. The horizontal band indicates the dark matter range.\nIII. RESULTS\nFigure 1 shows the standard relic density as a function of the neutralino mass for our\nsample of models. Each cell -triangle, circle or dot- represents a small region around which at\nleast one model was found. The models are classified as binos, winos, or higgsinos, according\nto the gauge composition of the lightest neutralino. The horizontal band corresponds to\nthe observed dark matter density ?stdh2 = ?dmh2 = 0.109+0.003?0.006, obtained for a ?CDM\nmodel with scale-invariant primordial perturbation spectrum through a global fit of cosmic\nmicrowave background, supernovae, and large scale structure data [24]. Several observations\ncan be made from this figure. Models with bino-like neutralinos are spread over a wide area\nand usually give a rather large relic density. Models with wino- and higgsino-like neutralinos,\non the contrary, are concentrated over narrow bands and their relic density exceeds the dark\nmatter density only for large masses, m? greaterorsimilar 1 TeV. Finally, notice that in our sample the\n6\nneutralino relic density varies between 106 and 10?4.\nWe now want to compute, for our set of models, the neutralino interaction rates in generic\ncosmologies where the neutralino accounts for the dark matter and compare them with those\nobtained in the standard cosmology. Since spin-dependent searches are harder than spin-\nindependent ones, we will focus on the latter. The neutralino interaction rate in direct\ndark matter detection experiments is proportional to the product of the spin-independent\nneutralino-nucleus cross section ?SI and the number density of neutralinos passing through\nthe detector, f. We assume that, as expected for collisionless cold dark matter, f = ??/?dm.\n?SI is determined only by the supersymmetric spectrum but ?? is sensitive to the cosmo-\nlogical setup. Thus, the neutralino detection rate depends on the cosmology only through\nf.\nIf the standard cosmological model is assumed, then all models above the horizontal band\nin figure 1 are rejected. They have a standard relic density larger than the observed dark\nmatter density (?std > ?DM) and therefore are considered incompatible with cosmological\nobservations. Models with a relic density below the dark matter density are still viable,\nthough neutralinos make up only a fraction of the dark matter. They have f < 1, so their\ndetection rate is typically suppressed. Finally, those models with a neutralino relic density\nwithin the observed dark matter range are viable and have f = 1. They have been the focus\nof the large majority of studies on neutralino direct detection.\nIn non-standard cosmologies, ?? = ?DM may be ensured and the previous picture is\nmodified in two important ways. On the one hand, the viable parameter space is different. In\nfact, overdense models, those with ?std > ?DM, canno longer be rejected. On theother hand,\nunderdense models, those with ?std < ?DM, no longer will have the f < 1 suppression factor\nin the detection rate. Hence, in non-standard cosmologies, we expect more viable models\nand larger detection rates. A priori, however, it is not possible to predict the detection rate\nfor the new viable models or to know whether the enhanced detection rates are within the\nsensitivity of future dark matter detection experiments. Thus, a careful analysis is required\nto establish the implications of non-standard cosmologies for dark matter searches. In the\nfollowing, such an analysis will be carried out.\nFigure 2 displays the detection rate in standard and non-standard cosmologies for bino-\nlike neutralinos as a function of the neutralino mass. As before, the figure has been divided\ninto a rectangular grid and each occupied cell denotes the existence of at least one model\n7\n10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 2: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM for bino-like neutralinos in the standard and non-standard cosmological\nmodels. The solid line indicates the CDMS II present limit [25]. The dashed lines show sensitivity\nlimits for -from top to bottom on the right- CDMS II,ZEPLINIV , XENON-1Ton, and SuperCDMS\nphase C [26].\naround it. For comparison, we also show the current limit from the CDMS II experiment [25]\naswell asthe expected sensitivity of CDMS II, ZEPLIN IV , XENON-1Ton, andSuperCDMS\nphase C [26]. In the standard scenario, both the lower and the upper limit on the bino\nmass are set by the relic density constraint. That is why the range of neutralino masses\nextends to lower and higher values in non-standard cosmologies. They yield many more\nviable models, though most of them have rather small detection rates. This fact is not\nentirely surprising. Small annihilation rates, as those associated with bino-like neutralinos,\nare generically correlated with small scattering rates. Regarding dark matter searches, the\nmost remarkable difference observed in the figure is the existence of new viable models with\nneutralino masses not allowed in the standard cosmology and detection rates within the\nreach of future experiments. Such models feature either m? lessorsimilar 40 GeV or m? greaterorsimilar 600 GeV\n8\n10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 3: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM for higgsino-like neutralinos in the standard and non-standard cosmological\nmodels. The solid line indicates the CDMS II present limit [25]. The dashed lines show sensitivity\nlimits for -from top to bottom on the right- CDMS II,ZEPLINIV , XENON-1Ton, and SuperCDMS\nphase C [26].\nand may be detected in ZEPLIN IV, XENON-1Ton, or SuperCDMS phase C.\nThe detection rate for higgsino-like neutralinos is shown in figure 3 as a function of\nthe neutralino mass in standard and non-standard cosmologies. The lower limit on the\nhiggsino mass is now set by the experimental constraint on the chargino mass and is therefore\nindependent of the cosmological scenario. Two features clearly distinguish the standard and\nthe non-standard cosmologies. One of them is the existence of viable models with heavy\nneutralinos, m? greaterorsimilar 1 TeV. A sizable fraction of them has detection rates large enough\nto be observed in ZEPLINIV, XENON-1Ton, or SuperCDMS phase C. The other feature\nis the significant enhancement in the detection rate of neutralinos lighter than lessorsimilar 1 TeV.\nIn the standard scenario, such neutralinos are usually underdense (see figure 1) and have\nsuppressed detection rates. From the figure we see that non-standard cosmologies yield an\n9\n10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 4: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM for wino-like neutralinos in the standard and non-standard cosmological\nmodels. The solid line indicates the CDMS II present limit [25]. The dashed lines show sensitivity\nlimits for -from top to bottom on the right- CDMS II,ZEPLINIV , XENON-1Ton, and SuperCDMS\nphase C [26].\nenhancement of up to two orders of magnitude for the neutralinos with the largest detection\nrates. Some of them are already ruled out by the present limit and many more will be within\nthe expected sensitivity of the CDMSII experiment.\nA compelling signature of non-standard cosmologies would be the detection of a wino-\nlike neutralino by the CDMSII experiment, as revealed in figure 4. Indeed, in the standard\nscenario, winos with m? lessorsimilar 1-2 TeV are usually underdense and therefore their detection rate\nis suppressed by the factor f = ?std/?DM. In non-standard cosmologies, such suppression\nis nonexistent and light winos have larger detection rates. The enhancement in the largest\ndetection rates are typically larger than for higgsinos, amounting in some cases to three\norders of magnitude. As for higgsinos, the lower bound on m? is not set by the dark matter\nbound but rather by the experimental constraint on the chargino mass, so no additional\n10\n1 10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 5: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM in the standard cosmological model and in the late decaying scalar field\nmodel. Here the lower limit of M1 in Eq. (2) has been lowered to 0.1 MeV The solid upper line\nindicates the CDMS II present limit [25] and the lower solid line the XENON limit [27]. The\ndashed lines show sensitivity limits for -from top to bottom on the right- CDMS II, ZEPLIN IV ,\nXENON-1Ton, and SuperCDMS phase C [26].\nmodels are found at low neutralino masses. For m? greaterorsimilar 2 TeV we do find new viable models\ncorresponding to overdense neutralinos in the standard cosmology. Most of them, however,\nhave small scattering rates, lying below the sensitivity of future detection experiments.\nFigure 5 summarizes the potential increase in neutralino candidates in the\nmodels studied in references [19] and [20]. For this figure the lower limit on M1 in\nEq. (2) has been lowered to 0.1 GeV (which is compatible with all experimental\nlimits (while no assumption is made on the relation between M1 and M2). In the\nlate decaying scalar field scenario most neutrinos can be brought to have the\ndark matter density (provided the value of the two relevant parameters of the\nphysics at the high scale can be suitably arranged). One exception is that of\n11\nvery light neutralinos which would be very overdense in the standard cosmology.\nRequiring the reheating temperature to be above 4 MeV [10], in order not to\nmodify nucleosynthesis, from the equations of reference [19] it is immediate to\nsee that neutralinos of mass m? should have a standard density smaller than\nthe dark matter density times (m?/120MeV)4 for it to be possible to bring their\ndensity to be that of the dark matter in the late decaying scalar field scenario.\nThis constraint is included in figure 5 where it is clearly shown the increase\nin potential neutralino candidates in the particular non-standard cosmological\nmodel considered with respect to the standard cosmological model.\nIV. CONCLUSION\nTo summarize, in this paper we computed the direct detection rate of MSSM neutralinos\nin generic cosmological scenarios where they constitute the dark matter of the Universe.\nWhen compared with the predictions of the standard cosmology, considerable differences\nwere encountered. If the neutralino is bino-like, as in msugra models, additional light m? lessorsimilar\n40 GeV and heavy m? greaterorsimilar 600 GeV neutralinos with non-negligible detection rates were found.\nThey could be detected in a variety of dark matter experiments such as ZEPLINIV, XENON-\n1Ton, or SuperCDMS phase C. For higgsino-like neutralinos, we found enhancements of up\nto two orders of magnitude in the largest detection rates as well as new viable models with\nheavy m? greaterorsimilar 1 TeV neutralinos. Both effects yielding detection rates within the sensitivity\nof future experiments. Wino-like neutralinos provide the clearest signature of non-standard\ncosmologies. Their detection rates may be enhanced by up to three orders of magnitude and\nthey could be detected in CDMSII. Thus, the prospects for the direct detection of neutralinos\nin non-standard cosmologies are significantly more promising than in the standard scenario.\nAcknowledgments\nWe thank Oleg Kalashev for allowing us to use the graphreader program. G.G., A.S. and\nC.Y. were supported in part by the US Department of Energy Grant DE-FG03-91ER40662,\nTask C and G.G. also by NASA grants NAG5-13399 and ATP03-0000-0057 at UCLA. P.G.\n12\nwas supported in part by the NFS grant PHY-0456825 at the University of Utah.\n[1] K. Griest and M. Kamionkowski, Phys. Rept. 333 (2000) 167.\n[2] J. R. Ellis, K. A. Olive, Y. Santoso and V. C. Spanos, Phys. Lett. B 565, 176 (2003).\n[3] T. Moroi, M. Yamaguchi and T. Yanagida, Phys. Lett.B 342,105 (1995); M Kawasaki, T.\nMoroi and T. Yanagida, Phys. Lett.B 370,52 (1996).\n[4] T. Moroi and L. Randall, Nucl. Phys. B570, 455 (2000).\n[5] M. Fujii, K. Hamaguchi, Phys. Rev. D 66, 083501 (2002); M. Fujii, M. Ibe, Phys. Rev. D 69,\n035006 (2004).\n[6] D. H. Lyth, E.D. Stewart, Phys. Rev. D 53, 1784 (1996).\n[7] M. Kamionkowski and M. S. Turner, Phys. Rev. D 42, 3310 (1990).\n[8] J. D. Barrow, Nucl. Phys. B 208, 501 (1982).\n[9] P. Salati, Phys. Lett. B 571, 121 (2003) [arXiv:astro-ph/0207396]; S. Profumo and P. Ullio,\nJCAP 0311, 006 (2003) [arXiv:hep-ph/0309220]. S. Profumo and C. E. Yaguna,\nPhys. Rev. D 70, 095004 (2004)\n[arXiv:hep-ph/0407036].\n[10] M. Kawasaki, K. Kohri, and N. Sugiyama, Phys. Rev. Lett. 82, 4168 (1999); Phys. Rev. D\n62, 023506 (2000); S. Hannestad, Phys. Rev. D 70, 043506 (2004).\n[11] M. Kamionkowski, M. Turner, Phys. Rev. D 42 3310 (1990); R. Jeannerot, X. Zhang, R.\nBrandenberger, JHEP 12, 003 (1999); W. B. Lin, D. H. Huang, X. Zhang, R. Brandenberger,\nPhys. Rev. Lett. 86 954 (2001).\n[12] T. Moroi, M. Yamaguchi and T. Yanagida, Phys. Lett.B 342,105 (1995); M Kawasaki, T.\nMoroi and T. Yanagida, Phys. Lett.B 370,52 (1996).\n[13] D. J.H. Chung, E. W. Kolb and A. Riotto, Phys. Rev. D60, 063504 (1999).\n[14] G. F. Giudice, E. W. Kolb and A. Riotto, Phys. Rev. D64, 023508 (2001).\n[15] R. Allahverdi and M. Drees, Phys. Rev. Lett. 89, 091302 (2002) and Phys. Rev. D66, 063513\n(2002).\n[16] S. Khalil, C. Mu?noz and E. Torrente-Lujan, New Journal of Physics 4, 27 (2002); E. Torrente-\nLujan, hep-ph/0210036 (2002).\n[17] N. Fornengo, A. Riotto, and S. Scopel, Phys. Rev. D67, 023514 (2003).\n13\n[18] C. Pallis, Astrop. Phys. 21, 689 (2004).\n[19] G. B. Gelmini and P. Gondolo, Phys. Rev. D 74, 023510 (2006)\n[20] G. Gelmini, P. Gondolo, A. Soldatenko and C. E. Yaguna, Phys. Rev. D 74, 083514 (2006).\n[21] L. Randall and R. Sundrum, Nucl. Phys. B 557, 79 (1999) [arXiv:hep-th/9810155].\nG. F. Giudice, M. A. Luty, H. Murayama and R. Rattazzi, JHEP 9812, 027 (1998)\n[arXiv:hep-ph/9810442].\n[22] N. Arkani-Hamed, S. Dimopoulos, G. F. Giudice and A. Romanino, Nucl. Phys. B 709,\n3 (2005) [arXiv:hep-ph/0409232]. G. F. Giudice and A. Romanino, Nucl. Phys. B 699, 65\n(2004) [Erratum-ibid. B 706, 65 (2005)] [arXiv:hep-ph/0406088].\n[23] P. Gondolo, J. Edsjo, P. Ullio, L. Bergstrom, M. Schelke and E. A. Baltz, JCAP 0407, 008\n(2004).\n[24] D.N. Spergel et al. Astrophys. J., Suppl. Ser. 148, 175 (2003); D.N.\nSpergel it et al., astro-ph/0603449 (2006); http:// lambda.gsfc.nasa.gov/ prod-\nuct/map/current/parameters.cfm.\n[25] D. S. Akerib et al. [CDMS Collaboration], Phys. Rev. Lett. 96, 011302 (2006)\n[arXiv:astro-ph/0509259].\n[26] R. J. Gaitskell, Ann. Rev. Nucl. Part. Sci. 54, 315 (2004).\n[27] D. N. McKinsey [XENON Collaboration], AIP Conf. Proc. 870 (2006) 202; J. Angle et al.\n[XENON Collaboration], arXiv:0706.0039 [astro-ph].\n14\n"}
{"id":"oai:arXiv.org:quant-ph/0602178","text":"arXiv:hep-ph/0612309v1  22 Dec 2006\nProbing the octant of ?23 with very long baseline neutrino\noscillation experiments: a global look\nGuey-Lin Lina,b? and Yoshiaki Umedaa?\naInstitute of Physics, National Chiao-Tung University, Hsinchu 300, Taiwan\nbPhysics Division, National Center for Theoretical Sciences, Hsinchu 300, Taiwan\n(Dated: February 7, 2008)\nAbstract\nWe investigate the baseline range in which the ?23 degeneracy in neutrino oscillation probabilities\nis absent for fixed values of ?13 and CP violation phase ?CP. We begin by studying sensitivities\nof neutrino oscillation probabilities to ?13, ?23 and ?CP for very-long-baseline neutrino oscillations.\nWe show contour graphs of the muon-neutrino survival probability P(?? ? ??) and the appearance\nprobability P(?e ? ??) on the cos2?23?sin2?13 plane for baseline lengths L = 1000, 5000, 10000,\nand 12000 km. For each baseline length, it is found that P(?? ? ??) is more sensitive to sin2?13 at\nenergies around its local maximum while it is more sensitive to cos2?23 at energies around its local\nminimum. On the other hand, the appearance probability P(?e ? ??) is sensitive to sin2?13 and\ncos2?23 only near its local maximum. We observe that the ?23 degeneracy in P(?? ? ??) is absent\nat energies around the local maximum of this probability, provided ?13 is sufficiently large. The\n?23 degeneracy is also absent in general near the local maximum of P(?e ? ??). Using analytic\napproximations for neutrino oscillation probabilities, we demonstrate that the above observations\nfor L = 1000, 5000, 10000, and 12000 km are in fact valid for all distances. The implications of\nthese results on probing the octant of ?23 are discussed in details.\nPACS numbers: 14.60.Pq, 13.15.+g, 14.60.Lm\n? E-mail: glin@cc.nctu.edu.tw\n? E-mail: umeda@faculty.nctu.edu.tw\n1\nI. INTRODUCTION\nThe understanding of neutrino masses and mixing matrix is crucial to unveil the mystery\nof lepton flavor structures. The updated SK analysis of the atmospheric neutrino data gives\n[1]\n1.5?10?3 eV2 < |?m231| < 3.4?10?3 eV2, sin2 2?23 > 0.92. (1)\nThis is a 90%C.L. range with the best fit values given by sin2 2?23 = 1 and ?m231 =\n2.1?10?3 eV2 respectively. An earlier result based upon L/E analysis gives [2]\n1.9?10?3 eV2 < |?m231| < 3.0?10?3 eV2, sin2 2?23 > 0.9. (2)\nat 90%C.L. where the best fit values are given by sin2 2?23 = 1 and ?m231 = 2.4?10?3 eV2\nrespectively. The scenario of ?? ? ?? oscillation for atmospheric neutrinos has been con-\nfirmed by the K2K experiment [3, 4]. Furthermore the results in the solar neutrino oscillation\nmeasurements are also confirmed by KamLAND reactor measurements [5, 6]. Combining\nthese measurements, the LMA solution of the solar neutrino problem is established and the\nupdated 2? parameter ranges are given by [7]\n7.21?10?5 eV2 < ?m221 < 8.63?10?5 eV2, 0.267 < sin2 ?12 < 0.371, (3)\nwith the best fit values ?m221 = 7.92?10?5 eV2 and sin2 ?12 = 0.314.\nDespite the achievements so far in measuring the neutrino mixing parameters, the sign\nof ?m231, the mixing angle ?13 and the CP violating parameter ?CP in the mixing matrix\nremain to be determined. Furthermore, one is keen to resolve the octant degeneracy of ?23\n[8].\nThe mixing angle ?13 is constrained by the reactor experiments [9, 10]. The CHOOZ\nexperiment [9] gives a more stringent constraint on ?13 with sin2 2?13 < 0.1 for a large\n?m231 (90% C.L.). A recent global fit based upon three-flavor neutrino oscillation gives the\n2? upper bound, sin2 2?13 < 0.124 [7]. It is well known that the mixing angle ?13 can be\nenhanced by the matter effect in Earth. The appearance oscillations ?? ? ?e, ?e ? ??,\nand the survival mode ?? ? ?? performed in a very-long baseline have been proposed\n[11] to probe the angle ?13 and the sign of ?m231. Furthermore, the aforementioned very\nlong baseline neutrino experiments as well as future atmospheric neutrino experiments are\nproposed to determine the deviation of ?23 to maximality [12]. In this work, we focus on\n2\nthe mixing angle ?23. We shall provide a global survey on ideal neutrino energies in the\nGeV range and baseline lengths from 103 km to 104 km for probing the octant of the mixing\nangle ?23. The muon neutrino survival probability P(?? ? ??) ? P?? and electron neutrino\nappearance probability P(?e ? ??) ? Pe? are both studied for this purpose. We observe\nthat the muon neutrino survival probability P?? has complementary dependencies on mixing\nangles ?13 and ?23 as the neutrino energy varies. This property is established by studying\nthe dependencies of P?? on cos2?23 and sin2?13 while keeping other parameters fixed. The\nchoice of the parameter cos2?23 is appropriate as\n1\n2 cos2?23 =\n1\n2 ?sin\n2 ?23, (4)\nwhich is a probe to the deviation of ?23 to the best-fit value pi/4. We find that the de-\npendencies of P?? on cos2?23 and sin2?13 at energies near local maxima of this probability\ndiffer drastically from those at energies near local maxima of the same probability. In the\nformer case, the probability P?? is always more sensitive to sin2?13. Furthermore, the ?23\ndegeneracy is absent in this case. In the latter case, the probability P?? is more sensitive to\ncos2?23 while the ?23 degeneracy is generally present. Such information is useful for probing\nthe octant of ?23. We also study sensitivities of the probability Pe? to cos2?23 and sin2?13\nwith other parameters fixed. We only focus on energies near the local maximum of Pe? as\nthis probability is not sensitive to mixing parameters for energies near its local minimum.\nThis paper is organized as follows. In Section II, we compare results on the oscillation\nprobability Pe? obtained by the full calculation with those obtained by various analytic\napproximations. This comparison is essential since analytic approximations will be employed\nfor discussions in later sessions. To set up the analytic approximation, we introduce the\nconcept of average density which varies with the total neutrino path-length inside the Earth.\nApplying full calculations and the two-layer analytic approximations [13], we identify the\nenergy values for local maxima and local minima of neutrino oscillation probabilities P?? and\nPe? for baseline lengths 1000 ? L/km ? 12000. It is found that the two-layer approximation\nis quite satisfactory compared to the full calculation for computing these energy values. In\nSection III, we first present the dependencies of P?? and Pe? on the CP violation phase\n?CP. It will be shown that, unlike Pe?, P?? is not sensitive to the CP violation phase ?CP.\nWe study numerically the effect of CP violation phase to the appearance probability Pe?.\nThe result confirms the so-called magic baseline [14, 15, 16] at L ? 7600 km where Pe? is\n3\nrather insensitive to the CP violation phase. After discussions on the CP violation phase,\nwe present the contour graphs of probabilities P?? and Pe? on cos2?23 ?sin2?13 plane for\nbaseline lengths L = 1000, 5000, 10000, and 12000 km. At all these baseline lengths, we\nshall see that P?? is more sensitive to sin2?13 at energies around its local maximum while\nit is more sensitive to cos2?23 at energies around its local minimum. Such observations\nare then justified by using the two-layer analytic approximations for neutrino oscillation\nprobabilities. With this approximation, the baseline lengths and neutrino energies allowing\nan unambiguous determination of ?23 through measuring P?? are identified. In Section IV,\nwe discuss the prospects of probing the ?23 octant via measuring Pe? and P??. We then\nconclude in the same section.\nII. THE COMPARISON OF FULL CALCULATIONSAND ANALYTICAPPROX-\nIMATIONS\nWe begin the discussions with the relation connecting flavor and mass eigenstates of\nneutrinos, ?? =summationtexti U?i?i, with U the Maki-Nakagawa-Sakata mixing matrix [17] given by\nU =\n?\n??\n??\nc12c13 s12c13 s13e?i?CP\n?s12c23 ?c12s13s23ei?CP c12c23 ?s12s13s23ei?CP c13s23\ns12s23 ?c12s13c23ei?CP ?c12s23 ?s12s13c23ei?CP c13c23\n?\n??\n?? , (5)\nwhere sij and cij denote sin?ij and cos?ij, respectively. The value for the Dirac type CP-\nphase ?CP ranges from 0 to 2pi. The evolutions of neutrino flavor eigenstates are governed\nby the equation\ni ddt|?(t)? =\n?\n????\n????\n1\n2E?U\n?\n??\n??\n0 0 0\n0 ?m221 0\n0 0 ?m231\n?\n??\n??U? +\n?\n??\n??\nV 0 0\n0 0 0\n0 0 0\n?\n??\n??\n?\n????\n????|?(t)?, (6)\nwhere |?(t)? = (?e(t),??(t),??(t))T, ?m2ij ? m2i ?m2j is the mass-squared difference between\nthe i-th and j-th mass eigenstates, and V ? ?2GFNe is the effegtive potential arising\nfrom the charged current interaction between ?e and electrons in the medium with Ne the\nelectron number density. Numerically V = 7.56?10?14 (?/[g/cm3])Ye [eV] with Ye denoting\nthe number of electrons per nucleon. We take Ye ? 0.5 in our calculations. One solves\nEq. (6) by diagonalizing the Hamiltonian on its right hand side. This amounts to writing\n4\n0 5000 10000\nbaseline length L[km]\n0\n5\n10\n? [g/cm\n3 ]\naverage density\ndensity in the mantle\ndensity in the core\naverage density\nFIG. 1: The average Earth density along the path traversed by the neutrino as a function of the\npath length L.\nthe right hand side of Eq. (6) as U?H?U??|?(t)? with U? the neutrino mixing matrix in the\nmatter and H? ? diag(E1,E2,E3) the Hamiltonian after diagonalization. To obtain various\noscillation probabilities described later, we have used the parametrization in [18] for the\nEarth density profile.\nFor analytic calculations, we employ the two-layer approximation for the Earth density\nprofile [13]. Given a path-length L for a neutrino traversing the Earth medium, one can\ndivide L into the sum L = L1 + L2 + ???Ln with each Li corresponding to a region with\na specific matter density. The average density for this path-length is then given by ? =\n(?1L1 + ?2L2 + ????nLn)/L. The Earth medium can be categorized as the Earth mantle\nand the Earth core. If a neutrino only traverses the Earth mantle, we shall use the one-\ndensity approximation for the analytic calculation with the density defined by the above\nprescription. However, if a neutrino traverses both the Earth mantle and the Earth core,\none should write the total neutrino path-length as L = 2Lm + Lc with\nLm = R\nparenleftBigg\ncos?n ?\nradicalbigg\nr2c\nR2 ?sin\n2 ?n\nparenrightBigg\n,\nLc = 2R\nradicalbigg\nr2c\nR2 ?sin\n2 ?n, (7)\n5\nwhere R = 6371 km and rc = 3480 km are the radii of the entire Earth and the Earth core\nrespectively while ?n is the incident Nadir angle of the neutrino. We note that the critical\nNadir angle for a neutrino to pass the Earth core is 33.17? corresponding to L = 10674 km.\nFor L > 10674 km, one separately defines average densities within the path-length Lm and\nthe path-length Lc respectively. The average densities as functions of the neutrino path-\nlength is shown in Fig. 1. For L ? 10674 km, there is only one curve for the average density,\nwhich is represented by the solid line in the figure. Beyond this distance, one can define the\naverage density in the core and the average density in the mantle, which are represented\nby dashed and dotted lines respectively. Alternatively, one can also define single average\ndensity for L > 10674 km by ignoring the distinction between the mantle and the core. This\nis seen from the solid line for L > 10674 km. However, in our analytic calculations, we shall\nadopt the two-density approach for L > 10674 km.\nFor analytic calculations, we only compute oscillation probabilities up to the lowest order\nin ? ? ?m221/?m231. In other words, we set ?m221=0 in analytic calculations and conse-\nquently the mixing angle ?12 and the CP phase ?CP dropout fromthe oscillation probabilities.\nThe probabilities P?? and Pe? in the two-layer approximations are given by[19, 20, 21, 22, 23]:\nP?? = cos4 ?23 +parenleftbigu2 + v2parenrightbigsin4 ?23 + 2cos2 ?23 sin2 ?23 (ucost+ vsint),\nPe? = sin2 ?23parenleftbig1?u2 ?v2parenrightbig. (8)\nThe quantities u, v and t are defined as\nu = cos(2?m)cos(?c)?cos(2?c13 ?2?m13)sin(2?m)sin(?c),\nv = ?cos(2?m13)[sin(?c)cos(2?m)cos(2?c13 ?2?m13) + cos(?c)sin(2?m)]\n+sin(2?m13)sin(?c)sin(2?c13 ?2?m13),\nt = (M\n2\n13)\nm + (m2\n13)\nm\n4E ?2L\nm + (M\n2\n13)\nc + (m2\n13)\nc\n4E ?L\nc, (9)\nwhere\n?m(c) = ?\nm(c)\n31\n4E L\nm(c),\n(M213)m(c) = (?m231 + Am(c)e + ?m(c)31 )/2,\n(m213)m(c) = (?m231 + Am(c)e ??m(c)31 )/2, (10)\nwith\n?m(c)31 =\nradicalBig\n(?m231 sin2?13)2 + (Am(c)e ??m231 cos2?13)2. (11)\n6\n0 5 10\nE [GeV]\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nP e?\nFull\nTwo-Layer\nOne-Layer\n(First order)\nOne-Layer\n(Second order)\nFull (?m212 =0)\nPe? for L=11400 km, sin2?13=0.3, cos2?23=0\nFIG. 2: A comparison of Pe? obtained by the full numerical calculation and various approximations.\nThe thick solid curve denotes the result by the full numerical calculation. The dotted-dashed\ncurve denotes the result by setting ?m221 = 0 in the full numerical calculation. The dashed\ncurve represents the result obtained by the two-layer approximation in the leading order of ? ?\n?m221/?m231. The dotted curve denotes the result obtained by one-density approximation in the\nleading order of ? while the thin solid curve is that obtained by the one-density approximation in\nthe next-to-leading order of ?.\nThe superscripts m and c denote quantities defined in the Earth mantle and the Earth\ncore respectively. For neutrinos traversing only the Earth mantle, one simply sets Lc =\n0, 2Lm = L in the above equations and recovers well known expressions for P?? and Pe? in\nthe one-density approximation [24].\nThe accuracy of two-layer approximation is shown in Fig. 2 with a comparison of this\napproximation to the full numerical calculation and other approximations. In the calcula-\ntions, we have assumed the normal mass hierarchy and taken sin2?13 = 0.3, cos2?23 = 0,\n?CP = 0, ?m231 = 2.4?10?3 eV2, ?m221 = 8.2?10?5 eV2, and tan2 ?12 = 0.39 [25]. This\nset of parameters will be adopted for later calculations unless specific mentioning of other\nchoices. This set of parameters differ from the most updated best-fit values quoted right\nafter Eq. (3). However, both set of parameters give undistinguishable results on Pe? and P??\n7\n0 5000 10000\nbaseline length L[km]\n0\n5\n10\n15\nenergy [GeV]\nFull calculation\nTwo-Layer\nThe energy at local maximum of Pe?\nmax1\nmax2\n0 5000 10000\nbaseline length L[km]\n0\n5\n10\n15\n20\nenergy [GeV]\nFull calculation\nTwo-Layer calculation\nThe energies at local maximum and local minimum of P??\nmin2\nmax1\nmin1\nmax2\nFIG. 3: Left panel: the energy at the local maximum of Pe?, as a function of L. Right panel:\nenergies at local maxima and local minima of P??, as functions of L.\nin the energy range concerned here. A comparison made at L = 11400 km has two purposes.\nFirst of all, it is known that the series expansion in the parameter ? is valid for L/E? ? 104\n(km/GeV) [24, 26]. Hence analytic calculations performed at this baseline length test the\nmarginal region of the condition L/E? ? 104 (km/GeV). Secondly this path-length implies\nthat the neutrino traverses both the Earth mantle and the Earth core. Therefore it is also\na good test to the two-layer approximation. It is seen that the two-layer approximation,\nunlike the one-layer approximation, reproduces well the peak energies of Pe?, while it gives\npeak probabilities deviating from those obtained from the full calculation by 15% ?20%.\nWe also see that the two-layer approximation agrees well with the full calculation in the\nlimit ?m221 = 0.\nFor later analysis, we compute energies at local maxima of Pe? and those at local maxima\nand local minima of P?? for the baseline range 1000 ? L/km ? 12000. The results are\ndepicted in Fig. 3. We do not study local minima of Pe? since their values are not sensitive\nto mixing angles ?13 and ?23. It is seen that the analytic approximation is satisfactory for\ncomputing energies at local maxima and local minima of neutrino oscillation probabilities.\nWe point out that the energy curves in Fig. 3 are calculated with sin2?13 = 0.3 and cos2?23 =\n0. It is found that these curves are not sensitive to the values of sin2?13 and cos2?23.\n8\n0 1 2 3 4 5\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n(P ??\n)\n?CP=0\n?CP=0.5pi\n?CP=pi\n?CP=1.5pi\nP?? and Pe? for L=1000 km, sin2?13=0.3, cos2?23=0\nPe?P??\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=5000 km, sin2?13=0.3, cos2?23=0\n0 5 10 15 20\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=10000 km, sin2?13=0.3, cos2?23=0\n0 5 10 15 20\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=12000 km, sin2?13=0.3, cos2?23=0\nFIG. 4: The CP phase dependencies of P?? and Pe? for L = 1000 km, 5000 km, 10000 km and\n12000 km respectively. The probability P?? is described by the thick curve while Pe? is described\nby the thin curve.\nIII. CONDITIONS FOR THE ABSENCE OF ?23 DEGENERACY IN P?? AND Pe?\nAT DIFFERENT ENERGIES\nA. The dependencies of P?? and Pe? on ?CP\nBefore concentrating on ?13 and ?23 dependencies of neutrino oscillation probabilities,\nwe first study the CP phase dependencies with the full numerical calculations. It is easily\nseen from Fig. 4 that P?? is not sensitive to the CP phase for all distances displayed. On\nthe other hand, Pe? is rather sensitive to the CP phase for L = 1000 km and 5000 km.\nIn order to quantify the CP phase dependence of Pe?, we study peak values of Pe?, which\noccur at energies described by the curve max1 in Fig. 3 for different baseline lengths. This\npeak value for a specific baseline length depends on the CP violation phase ?CP and we\n9\n0 2000 4000 6000 8000 10000\nbaseline length L [km]\n0\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\nP e?max\n?  P\ne?min\nPe?max ?  Pe?min,  sin2?13=0.3, cos2?23=0\n0 2000 4000 6000 8000 10000\nbaseline length L [km]\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nP e?min\n/  P\ne?max\nPe?min /  Pe?max,  sin2?13=0.3, cos2?23=0\nFIG. 5: The difference and the ratio of Pmaxe? and Pmine? as functions of the baseline length.\ndenote the maximum and the minimum of this value as Pmaxe? and Pmine? respectively. The\ndifference and the ratio of these two values as functions of the baseline length L are shown\nin Fig. 5. It is interesting to note that the ratio Pmine? /Pmaxe? increases monotonically with the\nbaseline length until L = 7600 km. The ratio begins to decrease for a larger baseline but\nremains larger than 90%. In fact, one can see that Pmaxe? and Pmine? differ by less than 10%\nfor L ? 6500 km. We point out that 1?Pmine? /Pmaxe? reaching to minimum at L = 7600 km\nconfirms the so-called magic baseline for the probability Pe? [14, 15, 16].\nB. The dependencies of P?? and Pe? on mixing angles ?13 and ?23\nHaving studied CP phase dependencies of oscillation probabilities, we now focus on ?13\nand ?23 dependencies. In this study we set the CP phase ?CP equal to zero. The results\nare presented in Fig. 6. It is easily seen that the values of P?? at its local maximum and\nlocal minimum depend on mixing angles ?13 and ?23 while only the local maximum of Pe?\ndepends on these parameters. This confirms our earlier comments concerning the left panel\nof Fig. 3. We point out that the differences between solid and dotted curves in Fig. 6 reflect\nthe effect of sin2?13; while the differences between solid and dashed curves there reflect the\neffect of cos2?23.\nWe now present contour graphs of P?? and Pe? on the cos2?23 ? sin2?13 plane. The\nrange for cos2?23 is chosen such that sin2?23 > 0.9 [2], i.e., ?0.316 < cos2?23 < 0.316; while\nsin2 2?13 is chosen to be less than 0.1, i.e., sin2?13 < 0.316. The contour graphs of P?? at\n10\n0 1 2 3 4 5\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nsin2?13=0.3,   cos2?23=0\nsin2?13=0.15, cos2?23=0\nsin2?13=0.3,   cos2?23=0.3\nsin2?13=0.3,   cos2?23=?0.3\nP?? and Pe? for L=1000 km\nPe?P??\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=5000 km\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=10000 km\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=12000 km\nFIG. 6: The ?13 and ?23 dependencies of P?? and Pe? for L = 1000 km, 5000 km, 10000 km and\n12000 km respectively. The probability P?? is described by the thick curve while Pe? is described\nby the thin curve.\ndifferent baseline lengths are presented in Fig. 7. Except for L = 1000 km, we have shown\ncontours of P?? for energies in the vicinity of both local maximum and local minimum of\nthis probability. The contour for the local maximum of P?? at L = 1000 km is not shown\nsince P?? at this energy and baseline length is not sensitive to mixing angles ?13 and ?23. For\nL = 5000 km, 10000 km and 12000 km, it is seen that the contours at local maxima of P??\nand those at local minima of P?? behave rather differently. The former are in general more\nparallel to the cos2?23-axis while the latter are generally more parallel to the sin2?13-axis.\nWe note that the local maximum (max2) of P?? at L = 12000 km can vary from 0.9 to a\nmuch smaller value, 0.45, which is a result of significant matter effects. Similarly, due to\nlarge matter effects, the local minimum (min2) of P?? at L = 10000 km can vary from 0\nto a much larger value, 0.4. We also notice that, at this baseline length, the ?23 degeneracy\n11\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=1.39-2.39 GeV (min1), L=1000 km\n0.065\n0.08\n0.08\n0.1\n0.1\n0.13\n0.13\n0.16\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=4.25-5.25 GeV (max1, solid)\nand E=8.74-9.74 GeV (min1, dashed), L= 5000 km\n0.005\n0.02\n0.02\n0.05\n0.05\n0.08\n0.08\n0.12\n0.96 0.93 0.9 0.85\n0.8\n0.75\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=8.71-9.71 GeV (max1, solid)\nand E=5.74-6.74 GeV (min2, dashed), L=10000 km\n0.06\n0.05\n0.3\n0.04\n0.1\n0.1\n0.15 0.40.2\n0.93\n0.982 0.97\n0.95\n0.9\n0.87\n0.84\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=5.00-6.00 GeV (max2, solid)\nand E=6.65-7.65 GeV (min2, dashed), L=12000 km\n0.12\n0.09\n0.450.15\n0.15\n0.6\n0.18\n0.7\n0.86\n0.86\n0.8\n0.06\n0.03\n0.18\nFIG. 7: The contour graphs of the muon neutrino survival probability P?? on the cos2?23?sin2?13\nplane. At L = 1000 km, the local minimum of P?? on the curve min1 occurs at E = 1.89 GeV. We\nplot the contour graph of P?? by averaging this probability over an 1 GeV energy range centered\nat the above local minimum. At L = 5000 km, the local maximum of P?? on the curve max1\noccurs at E = 4.75 GeV while the local minimum of this probability on the curve min1 occurs at\nE = 9.24 GeV. We plot the contour graphs of P?? in the energy range 4.25 ? E/GeV ? 5.25 for\nthe former case and 8.74 ? E/GeV ? 9.74. The same type of convention applies to L = 10000 km\nand 12000 km.\nis absent for P?? > 0.1. In general, such a degeneracy is also absent for energies near local\nmaxima of P??. However, the probabilities are not sensitive to cos2?23 in those cases. For\ncomparisons, we also present contour graphs for the appearance probability Pe? at different\nbaseline lengths. It is clearly seen that Pe? is only sensitive to sin2?13 for most cases. The\nsensitivity to cos2?23 only occurs at very long baseline lengths and large values of sin2?13.\n12\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=1.39-2.39 GeV (max1), L=1000 km\n0.002\n0.01 0.02\n0.03 0.04\n0.06\n0.08\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=5.31-6.31 GeV (max1), L=5000 km\n0.01 0.05\n0.1\n0.15\n0.2\n0.25\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=5.49-6.49 GeV (max1), L=10000 km\n0.03 0.1 0.2\n0.4\n0.5\n0.3\n0.6\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=2.64-3.64 GeV (max1), L=12000 km\n0.01 0.1 0.2\n0.4\n0.5\n0.3\nFIG. 8: The contour graphs for the oscillation probability Pe? on the cos2?23 ?sin2?13 plane. We\nplot contours of Pe? at energies near the local maximum (max1) of this probability.\nFor example, at L = 10000 km, Pe? becomes sensitive to cos2?23 as sin2?13 approaches 0.3.\nAt L = 12000 km, Pe? becomes sensitive to cos2?23 when sin2?13 is greater than 0.2.\nC. A global look at the absence of ?23 degeneracy\nIn this subsection, we focus on ?23 dependencies of P?? and Pe? for general baseline\nlengths. The two-layer analytic approximations for P?? and Pe? will be employed for our\ndiscussions, and observations in the previous subsection shall be justified. It is instructive\nto rewrite Eq. (8) in polynomials of cos2?23:\nf(y,z) = ??y2 + (? + ?)y + (1??),\ng(y,z) = ??(y ?1), (12)\n13\n2000 4000 6000 8000 10000 12000\nbaseline length L [km]\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n?+?\nsin2?13=0.1\nsin2?13=0.2\nsin2?13=0.3\nFIG. 9: The coefficient ?(z) + ?(z) calculated along the energy curve max1 in the left panel of\nFig. 3. The values of sin2?13 are taken to be 0.1, 0.2 and 0.3 respectively.\nwith f(y,z) ? P??, g(y,z) ? Pe?, y ? cos2?23 and z ? sin2?13. Furthermore,\n? = ?14bracketleftbig(u?cost)2 + (v?sint)2bracketrightbig,\n? = 12parenleftbig1?u2 ?v2parenrightbig+ 14bracketleftbig(u?cost)2 + (v ?sint)2bracketrightbig,\n? = 12parenleftbig1?u2 ?v2parenrightbig. (13)\nWe note that the sin2?13 dependencies of P?? and Pe? reside in quantities u, v, cost and\nsint. These quantities also depend on the baseline length L and the neutrino energy E.\nHence the coefficients ?, ? and ? also depend on the baseline length L and the neutrino\nenergy E. It is interesting to note that ? + ? = ?. Therefore we have\nP?? = ?parenleftbigy2 ?1parenrightbig, (14)\nusing P?e +P?? +P?? = 1 and P?e = Pe? with our choice of ?CP = 0. The contour structure\nof Pe? is straightforward as g(y,z) is only a linear function of y. Hence no ?23 degeneracy\npresents in the contour graphs depicted in Fig. 8. Additionally, the sensitivity of Pe? to\ncos2?23 is dg(y,z)/dy = ?(?(z) + ?(z)). The coefficient ? + ? evaluated along the energy\ncurve max1 in the left panel of Fig. 3 are plotted in Fig. 9 for sin2?13 = 0.1, 0.2 and 0.3. For\nsin2?13 = 0.3, ?+? reaches to the maximal value, 0.5, for L ? 10500 km. For sin2?13 = 0.1\n14\n0 5000 100000\n0.2\n0.4\n0.6\n0.8\n1\nmin1\nmax1\nmin2\nmax2\nbaseline length L [km]\n-? and ?+?, sin2?13=0.2, cos2?23=0\n-? and ?+?, sin2?13=0.2, cos2?23=0\n?? ?+?\n0 5000 10000\nbaseline length L [km]\n0\n0.2\n0.4\n0.6\n0.8\n1\nmin1\nmax1\nmin2\nmax2\n?? and ?+?, sin2?13=0.3, cos2?23=0\n?+???\nFIG. 10: The coefficients ?? and ?+? evaluated along energy curves in the right panel of Fig. 3.\nThe coefficients are calculated with sin2?13 = 0.2 and 0.3 on the left and right panels respectively.\nThe thick curves denote values of ?? while thin curves denote those of ?+?. For solid and dotted\ncurves, the thick curves generally dominate over the corresponding thin ones. For dashed and\ndotted-dashed curves, the thin curves generally dominate over the thick ones.\nand 0.2, ?+? rises quickly as the baseline length L surpasses 10674 km. We note that the\nvalue of Pe? is proportional to ?+?. Hence ?+? shown in Fig. 9 is its own maximal value\nfor each baseline length L.\nThe contour structure of P?? can be analyzed through the quadratic polynomial f(y,z)\nin y. If ?? ? ?+?, generally there are two solution curves for f(y,z) = p compatible with\nthe ranges of y and z where p is a given value for P??. Let us suppose that z ? sin2?13\nis measured in the future [27, 28] with a central value z0. The two solution curves for the\nequation f(y,z) = p then intersect with the straight line z ? sin2?13 = z0 at two points\n(y1,z0) and (y2,z0). This is actually what we have seen in Fig. 7 for local minima of P??. If,\non the other hand, ?? ? ? + ? or even ?? ? ? + ?, there exists only one solution curve\nfor the equation f(y,z) = p. This is because that the two points (y1,z0) and (y2,z0) can not\nsimultaneously satisfy the constraint ?0.316 < y < 0.316 since |y1 +y2| = ?(?+?)/? ? 1.\nThis is actually what we have seen in Fig. 7 for local maxima of P??. To justify this\nobservation, it remains to show that the coefficient ?? dominates over ? + ? at energies\ncorresponding to local minima of P?? while the latter dominates over the former at energies\ncorresponding to local maxima of P??. This is clearly demonstrated in Fig. 10 where the\n15\ncoefficients ?? and ? + ? are evaluated along energy curves in the right panel of Fig. 3.\nWe have calculated the coefficients with cos2?23 = 0 and sin2?13 = 0.2, 0.3 respectively.\nWe remark that other choices for cos2?23 do not produce noticeable changes on the energy\ncurves where ?? and ? + ? are evaluated.\nIt is easily seen that ?+? always dominates over ?? when these coefficients are evaluated\natenergies alongmax1 ormax2inthe right panelofFig.3. Insuch cases, the ?23 degeneracy\nis absent in the solutions of f(y,z) = p. Namely there exists only one solution curve for\nthe above equation. Reversely, ?? always dominates over ?+? when these coefficients are\nevaluated at energies along min1. The situation is slightly more complicated when these\ncoefficients are evaluated at energies along min2. In this case ?? no longer dominates\nover ? + ? for baseline lengths around 104 km. In fact, with sin2?13 = 0.3, ? + ? is even\nlarger than ?? for 9000 ? L/km ? 10500. This explains the contour structure of P??\nat L = 10000 km (see Fig. 7) where the straight line z = 0.3 only intersects one equal\nprobability curve f(y,z = 0.3) = p. The straight line z = 0.2 also behaves the same except\nfor a very small p. We reiterate that the range for y ? cos2?23 is ?0.316 < y < 0.316 due\nto the constraint sin2 2?23 > 0.9 [2]. Therefore, given z = z0, the equation f(y,z0) = p could\nhave only one solution for y if ?(?(z0) +?(z0))/?(z0) > 0.632. In other words, such values\nof ?(?(z0) + ?(z0))/?(z0) lead to the absence of ?23 degeneracy. In fact, the condition for\nthe absence of ?23 degeneracy is even more relaxed. To see this, let us divide our discussions\naccording to the true octant of ?23.\n1. min2, ?23 < pi/4\nSince ? < 0 and ? + ? > 0, the two solutions for y in f(y,z0) = p are both negative for\n1??(z0)?p > 0 while they have opposite signs for 1??(z0)?p < 0. If the true value of\n?23 is less than pi/4, i.e., the true value of y is positive, then the experimental measurement\nshould give 1??(z0)?p < 0 so that a positive solution for y exists. With 1??(z0)?p <\n0, the two solutions for f(y,z0) = p have opposite signs and the negative solution has\na larger absolute value. The negative solution will violate the constraint ?0.316 < y if\n?(?(z0) + ?(z0))/?(z0) > 0.316. For z0 = 0.2, ?(?(z0) + ?(z0))/?(z0) > 0.316 is valid\nfor 8300 ? L/km ? 10770. For z = 0.3, the above baseline range is extended to 7410 ?\nL/km ? 10790.\n16\n2. min2, ?23 > pi/4\nWith a true value of ?23 greater than pi/4, i.e., the true value of y less than zero, the\nvalue of 1 ? ?(z0) ? p can either be positive or negative. The condition 1 ? ?(z0) ? p >\n(<)0 is equivalent to the condition |y| < (>)(?(z0) +?(z0))/(??(z0)). For ?(?(z0) +\n?(z0))/?(z0) > 0.316, one must have 1 ? ?(z0) ? p > 0. Hence there exist two negative\nsolutions for y. In this case, the corresponding solutions for ?23 are both located in the same\noctant. For 0.316 < ?(?(z0)+?(z0))/?(z0) < 0.632, the spurious solution for y may or may\nnot violate the constraint y > ?0.316. For ?(?(z0) + ?(z0))/?(z0) > 0.632, the spurious\nsolution for y must violate the constraint y > ?0.316, hence the ?23 degeneracy is surely\nabsent. For sin2?13 = 0.2, the condition ?(?(z0)+?(z0))/?(z0) > 0.632 can not be achieved\nalong min2. For sin2?13 = 0.3, the above condition is satisfied for 8270 ? L/km ? 10720.\nFor ?(?(z0) + ?(z0))/?(z0 < 0.316, 1 ? ?(z0) ?p can either be positive or negative. For\n1??(z0)?p > 0, both solutions for y are negative and satisfying the constraint y > ?0.316.\nFor 1 ? ?(z0) ? p < 0, both solutions for y satisfy the constraint ?0.316 < y < 0.316.\nHowever their corresponding ?23 angles are situated in different octants.\nLet us summarize the results obtained in this subsection. The coefficient ?+? dominates\nover ?? for energy values along curves max1 and max2 for all baseline lengths. Hence the\n?23 degeneracy is absent along these energy curves for all baseline lengths. The situation\nalong the curve min1 is just the opposite, the coefficient ?? dominates over ? + ? for all\nbaseline lengths. Hence the ?23 degeneracy is present for all baseline lengths in this case.\nThe issue of ?23 degeneracy becomes more complicated along min2, which we have discussed\naccording to the true octant of ?23. Along the energy curve min2, the non-degeneracy\nbaseline range is larger for the ?23 < pi/4 case.\nIV. DISCUSSIONS AND CONCLUSIONS\nWe have presented the baselines and energies ideal for probing the octant of ?23 through\nneutrino oscillations. The appearance mode ?e ? ?? can be studied in a very long baseline\nwith the facility of neutrino factory [29] or the more recent proposed ? beam [30]. As said,\nthe sensitivity of Pe? to ?23 is dg(y,z)/dy = ?(?(z) + ?(z)) where g(y,z) represents Pe? in\nthe analytic approximation given by Eq. (12). The maximal value of ?+? for each baseline\n17\nlength is shown in Fig. 9. At the magic baseline, L = 7600 km, ?+? = 0.06, 0.21 and 0.38\nfor sin2?13 = 0.1, 0.2 and 0.3 respectively. For a sufficiently large sin2?13 and a baseline\nlength close to the magic value [14, 15, 16], Pe? is ideal for probing the octant of ?23.\nThe probability P?? is also relevant in neutrino oscillation experiments with neutrino\nfactories. The sensitivity of this probability to ?23 is determined by the derivative\nr ? dP??dcos2?\n23\n= ?2?cos2?23 + (? + ?). (15)\nSince ? is negative, the sensitivity r is larger for cos2?23 > 0, i.e., ?23 < pi/4. For a\nmeasurement performed around a local maximum of P??, the sensitivity to ?23 is completely\ndetermined by the coefficient ?+?, since the coefficient ? is generally rather suppressed in\nthis case. Along the energy curve denoted by max1, ?+? peaks at 7480 km for sin2?13 = 0.2\nand it peaks at L = 7350 km for sin2?13 = 0.3. The values of ?+? at those peaks are 0.17\nand 0.32 respectively. Along the curve max2, ? + ? peaks around L = 10750 km for both\nsin2?13 = 0.2 and 0.3 with values 0.43 and 0.48 respectively.\nFor a measurement performed around a local minimum of P??, the sensitivity to ?23 is\ndetermined by both coefficients ?? and ? + ?. Along the energy curve denoted by min1,\nthe coefficient ?? is always close to unity while the coefficient ? + ? is always suppressed\nfor all baseline lengths. It is understood that the magnitude of ? + ? determines the size\nof matter effects. Hence the matter effect is small at energies along the curve min1. The\nsuppression of ? + ? compared to ?? leads to the ?23 degeneracy as discussed before. The\nbehavior of P?? along the energy curve min2 is more interesting. If the true value of ?23\nis less than pi/4, the ?23 degeneracy from the measurement of P?? is absent in the baseline\nrange 8300 ? L/km ? 10770 for sin2?13 = 0.2. The above non-degeneracy baseline range\nextends to 7410 ? L/km ? 10790 for sin2?13 = 0.3. On the other hand, if the true ?23\nis greater than pi/4, the non-degeneracy baseline range does not exist along the energy\ncurve min2 for sin2?13 = 0.2. For sin2?13 = 0.3, the non-degeneracy baseline range is\n8270 ? L/km ? 10720.\nThe existence of non-degeneracy baseline range along the energy curve min2 has impor-\ntant implications. It can be seen from Fig. 3 that the curve min2 lies in between curves\nmax1 and max2. Since the degeneracy of ?23 is absent on both max1 and max2 for all\nbaselines, it is possible that there exists a non-degeneracy region spanned by ranges of the\nbaseline length and the neutrino energy. For example, with sin2?13 = 0.2 and a true value of\n18\nTABLE I: The baseline range in which the ?23 degeneracy is absent in the probability P?? for all\nenergy values between the curves max2 and max1. The entry corresponding to ?23 > pi/4 and\nsin2?13 = 0.2 is left blank since, with such set of parameters, there exists no baseline length where\nthe condition for the absence of ?23 degeneracy can be satisfied.\n?23 octant sin2?13 = 0.2 sin2?13 = 0.3\n?23 < pi/4 8550 ? L/km ? 10680 7950 ? L/km ? 10700\n?23 > pi/4 8450 ? L/km ? 10680\n?23 less than pi/4, the ?23 degeneracy is absent for 8300 ? L/km ? 10770 for energies along\ncurves max2, min2 and max1. It is of great interest to investigate if the ?23 degeneracy is\nalso absent for any neutrino energy larger than the value on max2 and smaller than that on\nmax1. By taking all these energies into account, we find that the ?23 degeneracy is absent\nfor 8550 ? L/km ? 10680. For a true value of ?23 greater than pi/4 and sin2?13 = 0.3,\nthe ?23 degeneracy is absent for 8270 ? L/km ? 10720 for energies along curves max2,\nmin2 and max1. However, with all energies between curves max2 and max1 considered,\nwe find that the ?23 degeneracy is absent for 8450 ? L/km ? 10680. The non-degeneracy\nbaseline range corresponding to different combinations of ?23 and ?13 values are summarized\nin Table I.\nIt is interesting to compare measurements on Pe? and P?? since both oscillations appear\nin experiments with neutrino factories [29]. The main issue for comparison is on the deter-\nmination of the true ?23 value under the assumption that both the sign of ?m231 and the\nvalue of sin2?13 are known. Let us begin the discussion with a true value of ?23 less than pi/4\nand sin2?13 = 0.2. For L < 8550 km, the appearance mode ?e ? ?? is useful for probing the\noctant of ?23, in particular for L close to the magic value, 7600 km. However, the survival\nmode ?? ? ?? is not as useful since the ?23 degeneracy is absent only at energies near max1\nand max2. Concerning the sensitivity to ?23, we note that the differentiation of Pe? with\nrespect to cos2?23 is ?(?+?). The value of ?+? increases with L as shown in Fig. 9. It is\n0.21 at L = 7600 km, and 0.26 at L = 8550 km. For 8550 ? L/km ? 10680, both ?e ? ??\nand ?? ? ?? are useful for probing the octant of ?23. We note that peak positions of Pe?\nare mostly around 6 GeV. Hence they overlap with the non-degeneracy energy range of P??.\nFrom Eq. (15) and our assumption of ?23 < pi/4, we find that P?? is more sensitive to ?23\n19\nas compared to Pe? for the same neutrino energy. For L > 10680 km, ?e ? ??, is again the\nonly useful mode for probing the octant of ?23.\nLet us turn to the case where the true value of ?23 is greater than pi/4 and sin2?13 = 0.2.\nIn such a case, the value for Pe? is enhanced compared to that with y > 0. Furthermore\nPe? is always more sensitive to cos2?23 as compared to P?? for the same neutrino energy.\nIt is clear that the ?e ? ?? appearance mode is more useful for probing ?23 regardless the\nbaseline length. Although there exists a baseline range where the ?23 degeneracy is absent\nin P?? for neutrino energies between curves max2 and max1. However this requires a large\nvalue of sin2?13, such as sin2?13 = 0.3.\nIt is essential to remark that the above non-degeneracy baseline range is not sensitive to\nthe value of ?m231, which we have so far taken to be 2.4 ? 10?3 eV2. Changing the value\nof ?m231 only shifts the probability curves in Fig. 4 and Fig. 6 so that positions for local\nmaxima and local minima of these probabilities shift accordingly. However, the maximal or\nminimal values of these probabilities remain unchanged. In other words, although the energy\ncurves in Fig. 3 are shifted, the coefficients ?? and ?+? plotted in Fig. 10, which combine\nto form Pe? and P?? (see Eq. (12)), remain the same. The values of these coefficients as\nfunctions of the baseline length L then determine the non-degeneracy baseline range.\nInconclusion, we have studied theprobabilities Pe? andP?? forvery longbaseline neutrino\noscillations. We focus on sensitivities of these probabilities to mixing angles ?13, ?23 and the\nCP violation phase ?CP. Taking ?CP = 0 as an example, we presented contour graphs of\nPe? and P?? in the sin2?13 ? cos2?23 plane for baseline lengths L = 1000 km, 5000 km,\n10000 km and 12000 km. The energy values chosen for such studies are in the vicinities of\neither local minima or local maxima of neutrino oscillation probabilities. For each baseline\nlength, we have found that P?? is more sensitive to sin2?13 at energies around its local\nmaxima while it is more sensitive to cos2?23 at energies around its local minima. On the\nother hand, the appearance probability Pe? is sensitive to sin2?13 and cos2?23 only near its\nlocal maximum. Such findings have been applied to probe the octant of mixing angle ?23\nassuming that the angle ?13 and the sign of ?m231 are known. The appearance probability\nPe? is non-degenerate in ?23. The sensitivity of Pe? to cos2?23 is studied for baseline lengths\nfrom 1000 km to 12000 km. We also studied the sensitivity of P?? to cos2?23 for the same\nrange of baseline length. We have identified the ranges of neutrino energy and baseline\nlengths where the ?23 degeneracy is absent. We have pointed out that, for a true value of ?23\n20\nless than pi/4 and a baseline length between 8000 and 10000 km, the survival mode ?? ? ??\nis equally good as the appearance mode ?e ? ?? for probing the octant of ?23.\nAcknowledgements\nG.L.L likes to thank D. Indumathi for informative discussions. This work is supported\nby National Science Council of Taiwan under the grant number NSC 94-2112-M-009-026.\n[1] Y. Ashie et al. [Super-Kamiokande Collaboration], Phys. Rev. D 71, 112005 (2005)\n[arXiv:hep-ex/0501064].\n[2] Y. Ashie et al. [Super-Kamiokande Collaboration], Phys. Rev. Lett. 93 (2004) 101801\n[arXiv:hep-ex/0404034].\n[3] E. Aliu et al. [K2K Collaboration], Phys. Rev. Lett. 94 (2005) 081802 [arXiv:hep-ex/0411038].\n[4] M. H. Ahn et al. [K2K Collaboration], Phys. Rev. D74, 072003 (2006) [arXiv:hep-ex/0606032].\n[5] K. Eguchi et al. [KamLAND Collaboration], Phys. Rev. Lett. 90 (2003) 021802\n[arXiv:hep-ex/0212021].\n[6] T. Araki et al. [KamLAND Collaboration], Phys. Rev. Lett. 94 (2005) 081801\n[arXiv:hep-ex/0406035].\n[7] See G. L. Fogli, E. Lisi, A. Marrone and A. Palazzo, Prog. Part. Nucl. Phys. 57, 742 (2006)\n[arXiv:hep-ph/0506083], which contains a list of original references on solar neutrino oscilla-\ntions.\n[8] G. L. Fogli and E. Lisi, Phys. Rev. D 54, 3667 (1996) [arXiv:hep-ph/9604415].\n[9] M. Apollonio et al. [CHOOZ Collaboration], Phys. Lett. B 466, 415 (1999)\n[arXiv:hep-ex/9907037].\n[10] F. Boehm et al., Phys. Rev. D 64, 112001 (2001) [arXiv:hep-ex/0107009].\n[11] I. Mocioiu and R. Shrock, Phys. Rev. D 62, 053017 (2000) [arXiv:hep-ph/0002149];\nV. D. Barger, S. Geer, R. Raja and K. Whisnant, Phys. Lett. B 485, 379 (2000)\n[arXiv:hep-ph/0004208]; V. D. Barger, S. Geer, R. Raja and K. Whisnant, Phys. Rev. D\n62, 013004 (2000) [arXiv:hep-ph/9911524]; M. Freund, M. Lindner, S. T. Petcov and A. Ro-\nmanino, Nucl. Phys. B 578, 27 (2000) [arXiv:hep-ph/9912457]; M. Freund, P. Huber and\n21\nM. Lindner, Nucl. Phys. B 585, 105 (2000) [arXiv:hep-ph/0004085]; A. Cervera, A. Donini,\nM. B. Gavela, J. J. Gomez Cadenas, P. Hernandez, O. Mena and S. Rigolin, Nucl. Phys. B\n579, 17 (2000) [Erratum-ibid. B 593, 731 (2001)] [arXiv:hep-ph/0002108].\n[12] D. Choudhury and A. Datta, JHEP 0507, 058 (2005) [arXiv:hep-ph/0410266]; D. Indu-\nmathi and M. V. N. Murthy, Phys. Rev. D 71, 013001 (2005) [arXiv:hep-ph/0407336];\nS. Choubey and P. Roy, Phys. Rev. D 73, 013006 (2006) [arXiv:hep-ph/0509197]. D. In-\ndumathi, M. V. N. Murthy, G. Rajasekaran and N. Sinha, Phys. Rev. D 74, 053004 (2006)\n[arXiv:hep-ph/0603264].\n[13] We adopt the approach of M. Freund and T. Ohlsson, Mod. Phys. Lett. A 15, 867 (2000)\n[arXiv:hep-ph/9909501], by dividing the Earth density regions into the Earth mantle and the\nEarth core. However we have further introduced the concept of average density to be discussed\nin details later.\n[14] V. Barger, D. Marfatia and K. Whisnant, Phys. Rev. D 65, 073023 (2002)\n[arXiv:hep-ph/0112119].\n[15] P. Huber and W. Winter, Phys. Rev. D 68, 037301 (2003) [arXiv:hep-ph/0301257].\n[16] A. Y. Smirnov, arXiv:hep-ph/0610198.\n[17] Z. Maki, M. Nakagawa and S. Sakata, Prog. Theor. Phys. 28, 870 (1962); see also , B. Pon-\ntecorvo, Zh. Eksp. Teor. Fiz. 53, 1717 (1967) [Sov. Phys. JETP 26, 984 (1968)].\n[18] A. Dziewonski, Earth Structure, Global, in: The Encyclopedia of Solid Earth Geophysics,\nDavid E. James, ed. (Van Nostrand Reinhold, New York 1989) p. 331.\n[19] M. V. Chizhov and S. T. Petcov, Phys. Rev. D 63, 073003 (2001) [arXiv:hep-ph/9903424];\nM. V. Chizhov and S. T. Petcov, Phys. Rev. Lett. 83, 1096 (1999) [arXiv:hep-ph/9903399].\n[20] E. K. Akhmedov, Nucl. Phys. B 538, 25 (1999) [arXiv:hep-ph/9805272].\n[21] S. T. Petcov, Phys. Lett. B 214, 259 (1988).\n[22] J. Bernabeu, S. Palomares-Ruiz, A. Perez and S. T. Petcov, Phys. Lett. B 531, 90 (2002)\n[arXiv:hep-ph/0110071].\n[23] Y. C. Hsu, Master Thesis, NCTU (2005).\n[24] See E. K. Akhmedov, R. Johansson, M. Lindner, T. Ohlsson and T. Schwetz, JHEP 0404,\n078 (2004) [arXiv:hep-ph/0402175] and earlier works cited in this paper.\n[25] J. N. Bahcall, M. C. Gonzalez-Garcia and C. Pena-Garay, JHEP 0408 (2004) 016\n[arXiv:hep-ph/0406294].\n22\n[26] I. Mocioiu and R. Shrock, JHEP 0111, 050 (2001) [arXiv:hep-ph/0106139].\n[27] F. Ardellier et al. [Double Chooz Collaboration], arXiv:hep-ex/0606025.\n[28] Y. Wang, arXiv:hep-ex/0610024.\n[29] S. Geer, Phys. Rev. D 57, 6989 (1998) [Erratum-ibid. D 59, 039903 (1999)]\n[arXiv:hep-ph/9712290]; A. De Rujula, M. B. Gavela and P. Hernandez, Nucl. Phys. B 547,\n21 (1999) [arXiv:hep-ph/9811390]; V. D. Barger, S. Geer and K. Whisnant, Phys. Rev. D 61,\n053004 (2000) [arXiv:hep-ph/9906487].\n[30] P. Zucchelli, Phys. Lett. B 532, 166 (2002).\n23\n"}
{"id":"oai:arXiv.org:hep-ph/0610379","text":"arXiv:q-bio/0601020v1  [q-bio.BM]  14 Jan 2006\nComputation of protein geometry and its applications: Packing and\nfunction prediction\nJie Liang\nFebruary 9, 2008\nContents\n6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n6.2 Theory and Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n6.2.1 The idealized ball model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n6.2.2 Surface models: Lee-Richards and Connolly?s surfaces . . . . . . . . . . . . . . . . . . 2\n6.2.3 Geometric constructs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n6.2.4 Topological structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n6.2.5 Metric measurement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n6.3 Computation and software . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n6.4 Applications: Packing analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n6.5 Applications: Protein function prediction from structures. . . . . . . . . . . . . . . . . . . . . 13\n6.6 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n6.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n6.8 Further reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n6.9 Acknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n6.1 Introduction\nThree-dimensional atomic structures of protein molecules provide rich information for understanding how\nthese working molecules of a cell carry out their biological functions. With the amount of solved protein\nstructures rapidly accumulating, computation of geometric properties of protein structure becomes an indis-\npensable component in studies of modern biochemistry and molecular biology. Before we discuss methods for\ncomputing the geometry of protein molecules, we first briefly describe how protein structures are obtained\nexperimentally.\nThereareprimarilythree experimentaltechniques for obtainingprotein structures: X-raycrystallography,\nsolution nuclear magnetic resonance (NMR), and recently freeze-sample electron microscopy (cryo-EM). In\nX-ray crystallography, the diffraction patterns of X-ray irradiation of a high quality crystal of the protein\nmolecule are measured. Since the diffraction is due to the scattering of X-rayby the electrons of the molecules\nin the crystal, the position, the intensity, and the phase of each recorded diffraction spot provide information\nfor the reconstruction of an electron density map of atoms in the protein molecule. Based on independent\ninformation of the amino acid sequence, a model of the protein conformation is then derived by fitting model\nconformations of residues to the electron density map. An iterative process called refinement is then applied\nto improve the quality of the fit of the electron density map. The final model of the protein conformation\nconsists of the coordinates of each of the non-hydrogen atoms [1].\nThe solution NMR technique for solving protein structure is based on measuring the tumbling and\nvibrating motion of the molecule in solution. By assessing the chemical shifts of atomic nuclei with spins due\nto interactions with other atoms in the vicinity, a set of estimated distances between specific pairs of atoms\ncan be derived from NOSEY spectra. When a large number of such distances are obtained, one can derive\na set of conformations of the protein molecule, each is consistent with all of the distance constraints [2].\nAlthough determining conformations from either X-ray diffraction patterns or NMR spectra is equivalent to\nsolving an ill-posed inverse problem, technique such as Bayesian Markov chain Monte Carlo with parallel\n1\ntempering has been shown to be effective in obtaining protein structures from NMR spectra [3]. The cryo-EM\ntechnique for obtaining protein structure is described in more details in Chapter 11.\n6.2 Theory and Model\n6.2.1 The idealized ball model\nThe shape of a protein molecule is complex. The chemical properties of atoms in a molecule are determined\nby their electron charge distribution. It is this distribution that generates the scattering patterns of the\nX-ray diffraction. Chemical bonds between atoms lead to transfer of electronic charges from one atom to\nanother, and the resulting isosurfaces of the electron density distribution depend not only on the location of\nindividual nuclei but also on interactions between atoms. This results in an overall complicated isosurface\nof electron density [4].\nThe geometric model of macromolecule amenable to convenient computation is an idealized model, where\nthe shapes of atoms are approximated by three-dimensional balls. The shape of a protein or a DNA molecule\nconsisting of many atoms is then the space-filling shape taken by a set of atom balls. This model is often\ncalled the interlocking hard-sphere model, the fused ball model, the space filling model [5?8], or the union\nof ball model [9]. In this model, details in the distribution of electron density, e.g., the differences between\nregions of covalent bonds and non-covalent bonds, are ignored. This idealization is quite reasonable, as it\nreflects the fact that the electron density reaches maximum at a nucleus, and its magnitude decays almost\nspherically away from the point of the nucleus. Despite possible inaccuracy, this idealized model has found\nwide acceptance, because it enables quantitative measurement of important geometric properties (such as\narea and volume) of molecules. Insights gained from these measurements correlate well with experimental\nobservations [5,8,10?13].\nIn this idealization, the shape of each atom is that of a ball, and its size parameter is the ball radius.\nThere are many possible choices for the parameter set of atomic radii [14,15]. Frequently, atomic radii are\nassigned the values of their van der Waals radii [16]. Among all these atoms, hydrogen atom has the smallest\nmass, and has a much smaller radius than those of other atoms. For simplification, the model of united\natom is often employed to approximate the union of a heavy atom and the hydrogen atoms connected by a\ncovalent bond. In this case, the radius of the heavy atom is increased to approximate the size of the union of\nthe two atoms. This practice significantly reduces the total number of atom balls in the molecule. However,\nthis approach has been questioned for possible inadequacy [17].\nThe mathematical model of this idealized model is that of the union of balls [9]. For a molecule M of n\natoms, the i-th atom is modeled as a ball bi, whose center is located at zi ? R3, and the radius of this ball\nis ri ? R, namely, we have bi ? {x|x ? R3,||x?zi|| ? ri} parameterized by (zi,ri). The molecule M is\nformed by the union of a finite number n of such balls defining the set B:\nM =\nuniondisplay\nB =\nnuniondisplay\ni=1\n{bi}.\nIt creates a space-filling body corresponding to the union of the excluded volumes vol(uniontextni=1 bi) [9]. When\nthe atoms are assigned the van der Waals radii, the boundary surface ?uniontextB of the union of balls is called\nthe van der Waals surface.\n6.2.2 Surface models: Lee-Richards and Connolly?s surfaces\nProtein folds into native three-dimensional shape to carry out its biological functional roles. The interac-\ntions of a protein molecule with other molecules (such as ligand, substrate, or other protein) determine its\nfunctional roles. Such interactions occur physically on the surfaces of the protein molecule.\nThe importance of protein surface was recognized very early on. Lee and Richards developed the widely\nused solvent accessible surface (SA) model, which is also often called the Lee-Richards surface model [5].\n2\nba c\nFigure 6.1: Geometric models of protein surfaces. (a) The solvent accessible surface (SA surface) is shown\nin the front. The van der Waals surface (beneath the SA surface) can be regarded as a shrunken version\nof the SA surface by reducing all atomic radii uniformly by the amount of the radius of the solvent probe\nrs = 1.4?A. The elementary pieces of the solvent accessible surface are the three convex spherical surface\npieces, the three arcs, and the vertex where the three arcs meet. (b) The molecular surface (MS, beneath\nthe SA surface) also has three types of elementary pieces: the convex spheric pieces, which are shrunken\nversion of the corresponding pieces in the solvent accessible surface, the concave toroidal pieces, and concave\nspheric surface. The latter two are also called the re-entrant surface. (c) The toroidal surface pieces in the\nmolecular surface, correspond to the arcs in the solvent accessible surface, and the concave spheric surface\nto the vertex. The set of elements in one surface can be continuously deformed to the set of elements in the\nother surface.\nIntuitively, this surface is obtained by rolling a ball of radius rs everywhere along the van der Waals surface of\nthe molecule. The center of the solvent ball will then sweep out the solvent accessible surface. Equivalently,\nthe solvent accessible surface can be viewed as the boundary surface ?uniontextBrs of the union of a set of inflated\nballs Brs, where each ball takes the position of an atom, but with an inflated radius ri + rs (Fig. 6.1a).\nThe solvent accessible surface in general has many sharp crevices and sharp corners. In hope of obtaining\na smoother surface, one can take the surface swept out by the front instead of the center of the solvent ball.\nThis surface is the molecular surface (MS model), which is often called the Connolly?s surface after Michael\nConnolly who developed the first algorithm for computing molecular surface [11]. Both solvent accessible\nsurface and molecular surface are formed by elementary pieces of simpler shape.\nElementary pieces. For the solvent accessible surface model, the boundary surface of a molecule consists\nof three types of elements: the convex spherical surface pieces, arcs or curved line segments (possibly a\nfull circle) formed by two intersecting spheres, and a vertex that is the intersection point of three atom\nspheres. The whole boundary surface of the molecules can be thought of as a surface formed by stitching\nthese elements together.\nSimilarly, the molecular surface swept out by the front of the solvent ball can also be thought of as being\nformed by elementary surface pieces. In this case, they are the convex spherical surface pieces, the toroidal\nsurface pieces, and the concave or inverse spherical surface pieces (Fig. 6.1b) . The latter two types of surface\npieces are often called the ?re-entrant surfaces? [8,11].\nThe surface elements of the solvent accessible surface and the molecular surface are closely related.\nImagine a process where atom balls are shrunk or expanded. The vertices in solvent accessible surface\nbecomes the concave spherical surface pieces, the arcs becomes the toroidal surfaces, and the convex surface\npieces become smaller convex surface pieces (Fig. 6.1c). Because of this mapping, these two type of surfaces\nare combinatorically equivalent and have similar topological properties, i.e., they are homotopy equivalent.\nHowever, the SA surface and the MS surface differ in their metric measurement. In concave regions of a\nmolecule, often the front of the solvent ball can sweep out a larger volume than the center of the solvent ball.\nA void of size close to zero in solvent accessible surface model will correspond to a void of the size of a solvent\nball (4pir3s/3). It is therefore important to distinguish these two types of measurement when interpreting the\nresults of volume calculations of protein molecules. The intrinsic structures of these fundamental elementary\n3\nvoid\na cb\nFigure 6.2: Geometry of a simplified two dimensional model molecule, to illustrate the geometric constructs\nand the procedure mapping the Voronoi diagram to the Delaunay triangulation. (a) The molecule formed by\nthe union of atom disks of uniform size. Voronoi diagram is in dashed lines. (b) The shape enclosed by the\nboundary polygon is the convex hull. It is tessellated by the Delaunay triangulation. (c) The alpha shape of\nthe molecule is formed by removing those Delaunay edges and triangles whose corresponding Voronoi edges\nand Voronoi vertices do not intersect with the body of the molecule. A molecular void is represented in the\nalpha shape by two empty triangles.\npieces are closely related to several geometric constructs we describe below.\n6.2.3 Geometric constructs\nVoronoi diagram. Voronoi diagram (Fig 6.2a), also known as Voronoi tessellation, is a geometric construct\nthat has been used for analyzing protein packing in the early days of protein crystallography [6,18,19]. For\ntwo dimensional Voronoi diagram, we consider the following analogy. Imagine a vast forset containing a\nnumber of fire observation towers. Each fire ranger is responsible for putting out any fire closer to his/her\ntower than to any other tower. The set of all trees for which a ranger is responsible constitutes the Voronoi\ncell associated with his/hertower, and the map of rangerresponsibilities, with towersand boundariesmarked,\nconstitutes the Voronoi diagram.\nWe formalize this for three dimensional space. Consider the point set S of atom centers in three dimen-\nsional space R3. The Voronoi region or Voronoi cell Vi of an atom bi with atom center zi ? R3 is the set of\nall points that are at least as close to zi than to any other atom centers in S:\nVi = {x ?R3|||x?zi|| ? ||x?zj||,zj ? S}. (6.1)\nWe can have an alternative view of the Voronoi cell of an atom bi. Considering the distance relationship of\natom center zi with the atom center zk of another atom bk. The plane bisecting the line segment connecting\npoints zi and zk divides the full R3 space into two half spaces, where points in one half space is closer to\nzi than to zk, and points in the other allspice is closer to zk than to zi. If we repeat this process and take\nzk in turn from the set of all atom centers other than zi, we will have a number of halfspaces where points\nare closer to zi than to each of the atom center zk. The Voronoi region Vi is then the common intersections\nof these half spaces, which is convex. When we consider atoms of different radii, we replace the Euclidean\ndistance ||x?zi|| with the power distance defined as: pii(x) ? ||x?zi||2 ?r2i .\nDelaunay tetrahedrization. Delaunay triangulation in R2 or Delaunay tetrahedrization in R3 is a geo-\nmetric construct that is closely related to the Voronoi diagram (Fig 6.2b). In general, it uniquely tessellates\nor tile up the space of the convex hull of the atom centers in R3 with tetrahedra. Convex hull for a point\n4\nset is the smallest convex body that contains the point set 1. The Delaunay tetrahedrization of a molecule\ncan be obtained from the Voronoi diagram. Consider that the Delaunay tetrahedrization is formed by gluing\nfour types of primitive elements together: vertices, edges, triangles, and tetrahedra. Here vertices are just\nthe atom centers. We obtain a Delaunay edge by connecting atom centers zi and zj if and only if the\nVoronoi regions Vi and Vj have a common intersection, which is a planar piece that may be either bounded\nor extend to infinity. We obtain a Delaunay triangle connecting atom centers zi, zj, and zk if the common\nintersection of Voronoi regions Vi,Vj and Vk exists, which is either a line segment, or a half-line, or a line\nin the Voronoi diagram. We obtain a Delaunay tetrahedra connecting atom centers zi,zj,zk and zl if and\nonly if the Voronoi regions Vi,Vj,Vk and Vl intersect at a point.\n6.2.4 Topological structures\nDelaunay complex. The structures in both Voronoi diagram and Delaunay tetrahedrization are better\ndescribed with concepts from algebraic topology. We focus on the intersection relationship in the Voronoi\ndiagram and introduce concepts formalizing the primitive elements. In R3, between two to four Voronoi re-\ngions may have common intersections. We use simplices of various dimensions to record these intersection or\noverlap relationships. We have vertices ?0 as 0-simplices, edges ?1 as 1-simplices, triangles ?2 as 2-simplices,\nand tetrahedra ?3 as 3-simplices. Each of the Voronoi plane, Voronoi edge, and Voronoi vertices corresponds\nto a 1-simplex (Delaunay edge), 2-simplex (Delaunay triangle), and 3-simplex (Delaunay tetrahedron), re-\nspectively. If we use 0-simplices to represent the Voronoi cells, and add them to the simplices induced by\nthe intersection relationship, we can think of the Delaunay tetrahedrization as the structure obtained by\n?glueing? these simplices properly together. Formally, these simplices form a simplicial complex K:\nK = {?|I|?1|\nintersectiondisplay\ni?I\nVi negationslash= ?}, (6.2)\nwhere I is an index set for the vertices representing atoms whose Voronoi cells overlap, and |I|? 1 is the\ndimension of the simplex.\nAlpha shape and protein surfaces. Imagine we can turn a knob to increase or decrease the size of all\natoms simultaneously. We can then have a model of growing balls and obtain further information from the\nDelaunay complex about the shape of a protein structure. Formally, we use a parameter ? ? R to control\nthe size of the atom balls. For an atom ball bi of radius ri, we modified its radius ri at a particular ? value\nto ri(?) = (r2i +?)1/2. When ?ri < ? < 0, the size of an atom is shrunk. The atom could even disappear if\n? < 0 and |?| > ri. We start to collect the simplices at different ? value as we increase ? from ?? to +?\n(see Fig 6.3 for a two-dimensional example). At the beginning, we only have vertices. When ? is increased\nsuch that two atoms are close enough to intersect, we collect the corresponding Delaunay edge that connects\nthese two atom centers. When three atoms intersect, we collect the correspondingDelaunay triangle spanning\nthese three atom centers. When four atoms intersect, we collect the corresponding Delaunay tetrahedron.\nAt any specific ? value, we have a dual simplicial complex or alpha complex K? formed by the collected\nsimplices. If all atoms take the incremented radius of ri +rs and ? = 0, we have the dual simplicial complex\nK0 of the protein molecule. When ? is sufficiently large, we have collected all simplices and we get the full\nDelaunay complex. This series of simplicial complexes at different ? value form a family of shapes (Fig 6.3),\ncalled alpha shapes, each faithfully represents the geometric and topological property of the protein molecule\nat a particular resolution parametrized by the ? value.\nAn equivalent way to obtain the alpha shape at ? = 0 is to take a subset of the simplices, with the\nrequirement that the corresponding intersections of Voronoi cells must overlap with the body of the union\n1For a two dimensional toy molecule, we can imagine that we put nails at the locations of the atom centers, and tightly wrap\na rubber band around these nails. The rubber band will trace out a polygon. This polygon and the region enclosed within\nis the convex hull of the set of points corresponding to the atom centers. Similarly, imagine if we can tightly wrap a tin-foil\naround a set of points in three dimensional space, the resulting convex body formed by the tin-foil and space enclosed within\nis the convex hull of this set of points in R3.\n5\na b c\nd e f\nFigure 6.3: The family of alpha shapes or dual simplicial complexes for a two-dimensional toy molecule.\n(a) We collect simplices from the Delaunay triangulation as atoms grow by increasing the ? value. At the\nbeginning as ? grows from ??, atoms are in isolation and we only have vertices in the alpha shape. (b) and\n(c) When ? is increased such that some atom pairs start to intersect, we collect the corresponding Delaunay\nedges. (d) When three atoms intersect as ? increases, we collect the corresponding Delaunay triangles.\nWhen ? = 0, the collection of vertices, edges, and triangles form the dual simplicial complex K0, which\nreflecting the topological structure of the protein molecule. (e) More edges and triangles from the Delaunay\ntriangulation are now collected as atoms continue to grow. (d) Finally, all vertices, edges, and triangles are\nnow collected as atoms are grown to large enough size. We get back the full original Delaunay complex.\nof the balls. We obtain the dual complex or alpha shape K0 of the molecule at ? = 0 (Fig 6.2c):\nK0 = {?|I|?1|\nintersectiondisplay\ni?I\nVi ?\nuniondisplay\nB negationslash= ?}. (6.3)\nAlpha shape provides a guide map for computing geometric properties of the structures of biomolecules.\nTake the molecular surface as an example, the re-entrant surfaces are formed by the concave spherical patch\nand the toroidal surface. These can be mapped from the boundary triangles and boundary edges of the\nalpha shape, respectively [20]. Recall that a triangle in the Delaunay tetrahedrization corresponds to the\nintersection of three Voronoi regions, i.e., a Voronoi edge. For a triangle on the boundary of the alpha shape,\nthe corresponding Voronoi edge intersects with the body of the union of balls by definition. In this case,\nit intersects with the solvent accessible surface at the common intersecting vertex when the three atoms\noverlap. This vertex corresponds to a concave spherical surface patch in the molecular surface. For an\nedge on the boundary of the alpha shape, the corresponding Voronoi plane coincides with the intersecting\nplane when two atoms meet, which intersect with the surface of the union of balls on an arc. This line\nsegment corresponds to a toroidal surface patch. The remaining part of the surface are convex pieces, which\ncorrespond to the vertices, namely, the atoms on the boundary of the alpha shape.\nThe numbers of toroidal pieces and concave spherical pieces are exactly the numbers of boundary edges\nand boundary triangles in the alpha shape, respectively. Because of the restriction of bond length and the\nexcluded volume effects, the number of edges and triangles in molecules are roughly in the order of O(n)\n[21].\n6.2.5 Metric measurement\nWe have described the relationship between the simplices and the surface elements of the molecule. Based\non this type of relationship, we can compute efficiently size properties of the molecule. We take the problem\n6\nof volume computation as an example.\nConsider a grossly incorrect way to compute the volume of a protein molecule using the solvent accessible\nsurface model. We could define that the volume of the molecule is the summation of the volumes of individual\natoms, whose radii are inflated to account for solvent probe. By doing so we would have significantly inflated\nthe value of the true volume, because we neglected to consider volume overlaps. We can explicitly correct\nthis by following the inclusion-exclusion formula: when two atoms overlap, we subtract the overlap; when\nthree atoms overlap, we first subtract the pair overlaps, we then add back the triple overlap, etc. This\ncontinues when there are four, five, or more atoms intersecting. At the combinatorial level, the principle\nof inclusion-exclusion is related to the Gauss-Bonnet theorem used by Connolly [11]. The corrected volume\nV (B) for a set of atom balls B can then be written as:\nV (B) =\nsummationdisplay\nvol(intersectiontext T)>0\nT?B\n(?1)dim(T)?1 vol(\nintersectiondisplay\nT), (6.4)\nwhere vol(intersectiontextT) represents volume overlap of various degree, T ? B is a subset of the balls with non-zero\nvolume overlap: vol(intersectiontextT) > 0.\nHowever, the straightforward application of this inclusion-exclusion formula does not work. The degree\nof overlap can be very high: theoretical and simulation studies showed that the volume overlap can be up\nto 7-8 degrees [22,23]. It is difficult to keep track of these high degree of volume overlaps correctly during\ncomputation, and it is also difficult to compute the volume of these overlaps because there are many different\ncombinatorial situations, i.e., to quantify how large is the k-volume overlap of which one of the parenleftbig7kparenrightbig or parenleftbig8kparenrightbig\noverlapping atoms for all of k = 2,??? ,7 [23]. It turns out that for three-dimensional molecules, overlaps\nof five or more atoms at a time can always be reduced to a ?+? or a ??? signed combination of overlaps\nof four or fewer atom balls [9]. This requires that the 2-body, 3-body, and 4-body terms in Eqn 6.4 enter\nthe formula if and only if the corresponding edge ?ij connecting the two balls (1-simplex), triangles ?ijk\nspanning the three balls (2-simplex), and tetrahedron ?ijkl cornered on the four balls (3-simplex) all exist in\nthe dual simplicial complex K0 of the molecule [9,21]. Atoms corresponding to these simplices will all have\nvolume overlaps. In this case, we have the simplified exact expansion:\nV (B) =\nsummationdisplay\n?i?K\nvol(bi)?\nsummationdisplay\n?ij?K\nvol(bi ?bj)\n+\nsummationdisplay\n?ijk?K\nvol(bi ?bj ?bk)?\nsummationdisplay\n?ijkl?K\nvol(bi ?bj ?bk ?bl).\nThe same idea is applicable for the calculation of surface area of molecules.\nAn example. An example of area computation by alpha shape is shown in Fig 6.4. Let b1,b2,b3,b4 be the\nfour disks. To simplify the notation we write Ai for the area of bi, Aij for the area of bi ?bj, and Aijk for\nthe area of bi ?bj ?bk. The total area of the union, b1 ?b2 ?b3 ?b4, is\nAtotal = (A1 + A2 + A3 + A4)\n? (A12 + A23 + A24 + A34)\n+ A234.\nWe add the area of bi if the corresponding vertex belongs to the alpha complex (Fig 6.4), we subtract the\narea of bi ?bj if the corresponding edge belongs to the alpha complex, and we add the area of bi ?bj ?bk if\nthe corresponding triangle belongs to the alpha complex. Note without the guidance of the alpha complex,\nthe inclusion-exclusion formula may be written as:\nAtotal = (A1 + A2 + A3 + A4)\n? (A12 + A13 + A14 + A23 + A24 + A34)\n+ (A123 + A124 + A134 + A234)\n? A1234.\n7\nb1\nb2\nb3\nb4\nA\nb1\nb2\nb3\nb4\nB\nFigure 6.4: An example of analytical area calculation. (a) Area can be computed using the direct inclusion-\nexclusion. (b) The formula is simplified without any redundant terms when using alpha shape.\nThis contains 6 canceling redundant terms: A13 = A123, A14 = A124, and A134 = A1234. Computing these\nterms would be wasteful. Such redundancy does not occur when we use the alpha complex: the part of the\nVoronoi regions contained in the respective atom balls for the redundant terms do not intersect. Therefore,\nthe corresponding edges and triangles do not enter the alpha complex. In two dimensions, we have terms of at\nmost three disk intersections, corresponding to triangles in the alpha complex. Similarly, in three dimensions\nthe most complicated terms are intersections of four spherical balls, and they correspond to tetrahedra in\nthe alpha complex.\nVoids and pockets. Voids and pockets represent the concave regions of a protein surface. Because shape-\ncomplementarity is the basis of many molecular recognition processes, binding and other activities frequently\noccur in pocket or void regions of protein structures. For example, the majority of enzyme reactions take\nplace in surface pockets or interior voids.\nThe topological structure of the alpha shape also offers an effective method for computing voids and\npockets in proteins. Consider the Delaunay tetrahedra that are not included in the alpha shape. If we\nrepeatedly merge any two such tetrahedra on the condition that they share a 2-simplex triangle, we will\nend up with discrete sets of tetrahedra. Some of them will be completely isolated from the outside, and\nsome of them are connected to the outside by triangle(s) on the boundary of the alpha shape. The former\ncorresponds to voids (or cavities) in proteins, the latter corresponds to pockets and depressions in proteins.\nA pocket differs from a depression in that it must have an opening that is at least narrower than one\ninterior cross-section. Formally, the discrete flow [24] explains the distinction between a depression and a\npocket. In a two dimensional Delaunay triangulation, the empty triangles that are not part of the alpha\nshape can be classified into obtuse triangles and acute triangles. The largest angle of an obtuse triangle is\nmore than 90 degrees, and the largest angle of an acute triangle is less than 90 degrees. An empty obtuse\ntriangle can be regarded as a ?source? of empty space that ?flows? to its neighbor, and an empty acute\ntriangle a ?sink? that collects flow from its obtuse empty neighboring triangle(s). In Figure 6.5a, obtuse\ntriangles 1, 3, 4 and 5 flow to the acute triangle 2, which is a sink. Each of the discrete empty spaces on\nthe surface of protein can be organized by the flow systems of the corresponding empty triangles: Those\nthat flow together belong to the same discrete empty space. For a pocket, there is at least one sink among\nthe empty triangles. For a depression, all triangles are obtuse, and the discrete flow goes from one obtuse\ntriangle to another, from the innermost region to outside the convex hull. The discrete flow of a depression\ntherefore goes to infinity. Figure 6.5b gives an example of a depression formed by a set of obtuse triangles.\nOnce voids and pockets are identified, we can apply the inclusion-exclusion principle based on the sim-\nplices to compute the exact size measurement (e.g., volume and area) of each void and pocket [24,25].\nThe distinction between voids and pockets depends on the specific set of atomic radii and the solvent\n8\n1\n2 34\n5\n1\n345\nInfinity\n2\na b\nFigure 6.5: Discrete flow of empty space illustrated for two dimensional disks. (a) Discrete flow of a pocket.\nTriangles 1, 3, 4 and 5 are obtuse. The free volume flows to the ?sink? triangle 2, which is acute. (b) In a\ndepression, the flow is from obtuse triangles to the outside.\nradius. When a larger solvent ball is used, the radii of all atoms will be inflated by a larger amount. This\ncould lead to two different outcomes. A void or pocket may become completely filled and disappear. On the\nother hand, the inflated atoms may not fill the space of a pocket, but may close off the opening of the pocket.\nIn this case, a pocket becomes a void. A widely used practice in the past was to adjust the solvent ball\nand repeatedly compute voids, in the hope that some pockets will become voids and hence be identified by\nmethods designed for cavity/void computation. The pocket algorithm [24] and tools such as CastP [26,27]\noften makes this unnecessary.\n6.3 Computation and software\nComputing Delaunay tetrahedrization and Voronoi diagram. It is easier to discuss the computation\nof tetrahedrization first. The incremental algorithm developed in [28] can be used to compute the weighted\ntetrahedrization for a set of atoms of different radii. For simplicity, we sketch the outline of the algorithm\nbelow for two dimensional unweighted Delaunay triangulation.\nThe intuitive idea of the algorithm can be traced back to the original observation of Delaunay. For the\nDelaunay triangulation of a point set, the circumcircle of an edge and a third point forming a Delaunay\ntriangle must not contain a fourth point. Delaunay showed that if all edges in a particular triangulation\nsatisfy this condition, the triangulation is a Delaunay triangulation. It is easy to come up with an arbitrary\ntriangulation for a point set. A simple algorithm to covert this triangulation to the Delaunay triangulation is\ntherefore to go through each of the triangles, and make corrections using ?flips? discussed below if a specific\ntriangle contains an edge violating the above condition. The basic ingredients for computing Delaunay\ntetrahedrization are generalizations of these observations. We discuss the concept of locally Delaunay edge\nand the edge-flip primitive operation below.\nLocally Delaunay edge. We say an edge ab is locally Delaunay if either it is on the boundary of the convex\nhull of the point set, or if it belongs to two triangles abc and abd, and the circumcircle of abc does not contain\nd (e.g., edge cd in Fig 6.6a).\nEdge-flip. If ab is not locally Delaunay (edge ab in Fig 6.6a), then the union of the two triangles abc?abd\nis a convex quadrangle acbd, and edge cd is locally Delaunay. We can replace edge ab by edge cd. We call\nthis an edge-flip or 2-to-2 flip, as two old triangles are replaced by two new triangles.\nWe recursively check each boundary edge of the quadrangle abcd to see if it is also locally Delaunay after\nreplacing ab by cd. If not, we recursively edge-flip it.\nIncremental algorithm for Delaunay triangulation. Assume we have a finite set of points (namely, atom\ncenters) S = {z1,z2,??? ,zi,??? ,zn}. We start with a large auxiliary triangle that contains all these points.\nWe insert the points one by one. At all times, we maintain a Delaunay triangulation Di upto insertion of\n9\n1?to?3 flip\nb\n2?to?2 flip\na\nb\nc\nd\na\nb\nc\nd\na\nFigure 6.6: An illustration of locally Delaunay edge and flips. (a) For the quadrilateral abcd, edge ab is not\nlocally Delaunay, as the circumcircle passing through edge ab and a third point c contains a fourth point d.\nEdge cd is locally Delaunay, as b is outside the circumcircle adc. An edge-flip or 2-to-2 flip replaces edge ab\nby edge cd, and replace the original two triangles abc and adb with two new triangles acd and bcd. (b) When\na new vertex is inserted, we replace the old triangle containing this new vertex with three new triangles.\nThis is called 1-to3 flips.\npoint zi.\nAfter inserting point zi, we search for the triangle ?i?1 that contains this new point. We then add zi to\nthe triangulation and split the original triangle ?i?1 into three smaller triangles. This split is called 1-to-3\nflip, as it replaces one old triangle with three new triangles. We then check if each of the three edges in ?i?1\nstill satisfies the locally Delaunay requirement. If not, we perform a recursive edge-flip. This algorithm is\nsummarized in Algorithm 1.\nAlgorithm 1 Delaunay triangulation\nObtain random ordering of points {z1,??? ,zn};\nfor i = 1 to n do\nfind ?i?1 such zi ? ?i?1;\nadd zi, and split ?i?1 into three triangles (1-to-3 flip);\nwhile any edge ab not locally Delaunay do\nflip ab to other diagonal cd (2-to-2 edge flip);\nend while\nend for\nIn R3, the algorithm of tetrahedrization becomes more complex, but the same basic ideas apply. In this\ncase, we need to locate a tetrahedron instead of a triangle that contains the newly inserted point. The\nconcept of locally Delaunay is replaced by the concept of locally convex, and there are flips different than the\n2-to-2 flip in R3 [28]. Although an incremental approach, i.e., sequentially adding points, is not necessary\nfor Delaunay triangulation in R2, it is necessary in R3 to avoid non-flippable cases and to guarantee that\nthe algorithm will terminate. This incremental algorithm has excellent expected performance [28].\nThe computation of Voronoi diagram is conceptually easy once the Delaunay triangulation is available.\nWe can take advantage of the mathematical duality and compute all of the Voronoi vertices, edges, and\nplanar faces from the Delaunay tetrahedra, triangles, and edges. Because one point zi may be an vertex of\nmany Delaunay tetrahedra, the Voronoi region of zi therefore may contain many Voronoi vertices, edges,\nand planar faces. The efficient quad-edge data structure can be used for software implementation [29].\nVolume and area computation. Let V and A denote the volume and area of the molecule, respectively,\nK? for the alpha complex, ? for a simplex in K, i for a vertex, ij for an edge, ijk for a triangle, and ijkl for\na tetrahedron. The algorithm for volume and area computation can be written as Algorithm 2. Additional\ndetails of volume and area computation can be found in [20,21].\nSoftware. The software package Delcx for computing weighted Delaunay tetrahedrization, Mkalf for\ncomputing the alpha shape, Volbl for computing volume and area of both molecules and interior voids\n10\nAlgorithm 2 Volume and area measurement\nV := A := 0.0;\nfor all ? ? K do\nif ? is a vertex i then\nV := V +vol(bi); A := A+area(bi);\nend if\nif ? is an edge ij then\nV := V ?vol(bi ?bj); A := A?area(bi ?bj);\nend if\nif ? is a triangle ijk then\nV := V +vol(bi ?bj ?bk); A := A +area(bi ?bj ?bk);\nend if\nif ? is a tetrahedron ijkl then\nV := V ?vol(bi ?bj ?bk ?bl); A := A?area(bi ?bj ?bk ?bl);\nend if\nend for\nand be found at www.alphashape.org. The CastP webserver for pocket computation can be found at\ncast.engr.uic.edu. There are other studies that compute or use Voronoi diagrams of protein structures\n[30?32], although not all computes the weighted version which allows atoms to have different radii.\nIn this short description of algorithm, we have neglected many details important for geometric compu-\ntation. For example, the problem of how to handle geometric degeneracy, namely, when three points are\nco-linear, or when four points are co-planar. Interested readers should consult the excellent monograph by\nEdelsbrunner for a detailed treatise of these and other important topics in computational geometry [33].\n6.4 Applications: Packing analysis.\nAn important application of the Voronoi diagram and volume calculation is the measurement of protein\npacking. Tight packing is an important feature of protein structure [6,10], and is thought to play important\nroles in protein stability and folding dynamics [34]. The packing density of a protein is measured by the\nratio of its van der Waals volume and the volume of the space it occupies. One approach is to calculate the\npacking density of buried residues and atoms using Voronoi diagram [6,10]. This approach was also used to\nderive radii parameters of atoms [15].\nBased on the computation of voids and pockets in proteins, a detailed study surveying major represen-\ntatives of all known protein structural folds showed that there is a substantial amount of voids and pockets\nin proteins [35]. On average, every 15 residues introduces a void or a pocket (Fig 6.7a). For a perfectly\nsolid three-dimensional sphere of radius r, the relationship between volume V = 4pir3/3 and surface area\nA = 4pir2 is: V ? A3/2. In contrast, Figure 6.7b shows that the van der Waals volume scales linearly with\nthe van der Waals surface areas of proteins. The same linear relationship holds irrespective of whether we\nrelate molecular surface volume and molecular surface area, or solvent accessible volume and solvent acces-\nsible surface area. This and other scaling behavior point out that protein interior is not packed as tight as\nsolid [35]. Rather, packing defects in the form of voids and pockets are common in proteins.\nIf voids and pockets are prevalent in proteins, an interesting question is what is then the origin of the\nexistence of these voids and pockets. This question was studied by examining the scaling behavior of packing\ndensity and coordination number of residues through the computation of voids, pockets, and edge simplices\nin the alpha shapes of random compact chain polymers [36]. For this purpose, a 32-state discrete state\nmodel was used to generate a large ensemble of compact self-avoiding walks. This is a difficult task, as it is\nvery challenging to generate a large number of independent conformations of very compact chains that are\nself-avoiding. The results in [36] showed that it is easy for compact random chain polymers to have similar\nscaling behavior of packing density and coordination number with chain length. This suggests that proteins\n11\nNumber of Residues\nNum of Voids and Pockets\n0 200 600 1000\n0\n50\n100\n150\nA x 1000\nV x 1000\n0 200 400 600 800\n0\n100\n300\n500\nFigure 6.7: Voids and pockets for a set of 636 proteins representing most of the known protein folds, and\nthe scaling behavior of the geometric properties of proteins. (a) The number of voids and pockets detected\nwith a 1.4 ?A probe is linearly correlated with the number of residues in a protein. Only proteins with\nless than 1,000 residues are shown. Solid triangles and empty circles represent the pockets and the voids,\nrespectively. (b) The van der Waals (vdw) volume and van der Waals area of proteins scale linearly with\neach other. Similarly, molecular surface (ms) volume also scales linearly with molecular surface area using\na probe radius of 1.4?A. (Data not shown. Figure adapted after [35])\n12\nare not optimized by evolution to eliminate voids and pockets, and the existence of many pockets and voids is\nrandom in nature, and is due to the generic requirement of compact chain polymers. The frequent occurrence\nand the origin of voids and pockets in protein structures raise a challenging question: How can we distinguish\nvoids and pockets that perform biological functions such as binding from those formed by random chance?\nThis question is related to the general problem of protein function prediction.\n6.5 Applications: Protein function prediction from structures.\nConservation of protein structures often reveals very distant evolutionary relationship, which are otherwise\ndifficult to detect by sequence analysis [37]. Comparing protein structures can provide insightful ideas about\nthe biochemical functions of proteins (e.g., active sites, catalytic residues, and substrate interactions) [38?40].\nA fundamental challenge in inferring protein function from structure is that the functional surface of\na protein often involves only a small number of key residues. These interacting residues are dispersed in\ndiverse regions of the primary sequences and are difficult to detect if the only information available is the\nprimary sequence. Discovery of local spatial motifs from structures that are functionally relevant has been\nthe focus of many studies.\nGraph based methods for spatial patterns in proteins. To analyze local spatial patterns in proteins.\nArtymiuk et al developed an algorithm based on subgraph isomorphism detection [41]. By representing\nresidue side-chains as simplified pseudo-atoms, a molecular graph is constructed to represent the patterns of\nside-chain pseudo-atoms and their inter-atomic distances. A user defined query pattern can then be searched\nrapidly against the Protein Data Bank for similarity relationship. Another widely used approach is the\nmethod of geometric hashing. By examining spatial patterns of atoms, Fischer et al developed an algorithm\nthat can detect surface similarity of proteins [42,43]. This method has also been applied by Wallace et al for\nthe derivation and matching of spatial templates [44]. Russell developed a different algorithm that detects\nside-chain geometric patterns common to two protein structures [45]. With the evaluation of statistical\nsignificance of measured root mean square distance, several new examples of convergent evolution were\ndiscovered, where common patterns of side-chains were found to reside on different tertiary folds.\nThese methods have a number of limitations. Most require a user-defined template motif, restricting their\nutility for automated database-wide search. In addition, the size of the spatial pattern related to protein\nfunction is also often restricted.\nPredicting protein functions by matching pocket surfaces. Protein functional surfaces are frequently\nassociated with surface regions of prominent concavity [26,46]. These include pockets and voids, which can\nbe accurately computed as we have discussed. Computationally, one wishes to automatically identify voids\nand pockets on protein structures where interactions exist with other molecules such as substrate, ions,\nligands, or other proteins.\nBinkowski et al. developed a method for predicting protein function by matching a surface pocket or void\non a protein of unknown or undetermined function to the pocket or void of a protein of known function\n[47,48]. Initially, the Delaunay tetrahedrization and alpha shapes for almost all of the structures in the\nPDB databank are computed [27]. All surface pockets and interior voids for each of the protein structure\nare then exhaustively computed [24,25]. For each pocket and void, the residues forming the wall are then\nconcatenated to form a short sequence fragment of amino acid residues, while ignoring all intervening residues\nthat do not participate in the formation of the wall of the pocket or void. Two sequence fragments, one\nfrom the query protein and another from one of the proteins in the database, both derived from pocket or\nvoid surface residues, are then compared using dynamic programming. The similarity score for any observed\nmatch is assessed for statistical significance using an empirical randomization model constructed for short\nsequence patterns.\nFor promising matches of pocket/void surfaces showing significant sequence similarity, we can further\nevaluate their similarity in shape and in relative orientation. The former can be obtained by measuring\nthe coordinate root mean square distance (rmsd) between the two surfaces. The latter is measured by\n13\nfirst placing a unit sphere at the geometric center z0 ? R3 of a pocket/void. The location of each residue\nz = (x,y,z)T is then projected onto the unit sphere along the direction of the vector from the geometric\ncenter: u = (z ?z0)/||z ?z0||. The projected pocket is represented by a collection of unit vectors located\non the unit sphere, and the original orientation of residues in the pocket is preserved. The rmsd distance of\nthe two sets of unit vectors derived from the two pockets are then measured, which is called the ormsd for\norientation rmsd [47]. This allows similar pockets with only minor conformational changes to be detected\n[47].\nThe advantage of the method of Binkowski et al is that it does not assume prior knowledge of functional\nsite residues, and does not require a priori any similarity in either the full primary sequence or the backbone\nfold structures. It has no limitation in the size of the spatially derived motif and can successfully detect\npatterns small and large. This method has been successfully applied to detect similar functional surfaces\namong proteins of the same fold but low sequence identities, and among proteins of different fold [47,49].\nFunction prediction through models of protein surface evolution. To match local surfaces such as\npockets and voids and to assess their sequence similarity, an effective scoring matrix is critically important.\nIn the original study of Binkowski et al, Blosum matrix was used. However, this is problematic, as Blosum\nmatrices were derivedfrom analysisof precomputed large quantities of sequences, while the information of the\nparticular protein of interest has limited or no influence. In addition, these precomputed sequences include\nburied residues in protein core, whose conservation reflects the need to maintain protein stability rather\nthan to maintain protein function. In reference [50,51], a continuous time Markov process was developed\nto explicitly model the substitution rates of residues in binding pockets. Using a Bayesian Markov chain\nMonte Carlo method, the residue substitution rates at functional pocket are estimated. The substitution\nrates are found to be very different for residues in the binding site and residues on the remaining surface of\nproteins. In addition, substitution rates are also very different for residues in the buried core and residues\non the solvent exposed surfaces.\nThese rates are then used to generate a set of scoring matrices of different time intervals for residues\nlocated in the functional pocket. Application of protein-specific and region-specific scoring matrices in\nmatching protein surfaces result in significantly improved sensitivity and specificity in protein function\nprediction [50,51].\nIn a large scale study of predicting protein functions from structures, a subset of 100 enzyme families are\ncollected from the total of 286 enzyme families containing between 10?50 member protein structures with\nknown Enzyme Classification (E.C.) labels. By estimating the substitution rate matrix for residues on the\nactive site pocket of a query protein, a series of scoring matrices of different evolutionary time is derived. By\nsearching for similar pocket surfaces from a database of 770,466 pockets derived from the CastP database\n(with the criterion that each must contain at least 8 residues), this method can recover active site surfaces\non enzymes similar to that on the query structure at an accuracy of > 92%. Fig 6.8 shows the Receiver\nOperating Characteristic Curve of this study. An example of identifying human amylase using template\nsurfaces from B. subtilis and from barley is shown in Fig 6.9.\nThe method of surface matching based on evolutionary model is also especially effective in solving the\nchallenging problems of protein function prediction of orphan structures of unknown function (such as those\nobtained in structural genomics projects), which have only sequence homologs that are themselves hypothet-\nical proteins with unknown functions.\n6.6 Discussion\nA major challenge in studying protein geometry is to understand our intuitive notions of various geometric\naspects of molecular shapes, and to quantify these notions with mathematical models that are amenable to\nfast computation. The advent of the union of ball model of protein structures enabled rigorous definition\nof important geometric concepts such as solvent accessible surface and molecular surface. It also led to\nthe development of algorithms for area and volume calculations of proteins. Deep understanding of the\ntopological structure of molecular shapes is also based on the idealized union of ball model [9]. A success\n14\n0.0 0.2 0.4 0.6 0.8 1.0\n0.75\n0.80\n0.85\n0.90\nnewy\nTrue Positive Rate(sensitivity)\nFalse Positve Rate(1?specificity)\nFigure 6.8: A large scale study of protein function prediction from structures by matching similar func-\ntional surfaces for 100 protein families. A correct prediction is made if the matched surface comes from a\nprotein structure with the same Enzyme Classification (E.C.) number (upto the 4-th digit) as that of the\nquery protein. The x-axis of the Receiver Operating Characteristics curve reflects the false positive rate\n(1?specificity) at different statistical significance p-value by cRMSD measurement, and the y-axis reflects\nthe true positive rate (sensitivity).\nin approaching these problems is exemplified in the development of the pocket algorithm [24]. Another\nexample is the recent development of a rigorous definition of protein-protein binding or interaction interface\nand algorithm for its computation [52].\nPerhaps a more fundamental problem we face is to identify important structural and chemical features\nthat are the determinants of biological problems of interest. For example, we would like to know what are the\nshape features that has significant influences on protein solvation, protein stability, ligand specific binding,\nand protein conformational changes. It is not clear whether our current geometric intuitions are sufficient,\nor are the correct or the most relevant ones. There may still be important unknown shape properties of\nmolecules that elude us at the moment.\nAn important application of geometric computation of protein structures is to detect patterns important\nfor protein function. The shape of local surface regions on a protein structure and their chemical texture are\nthe basis of its binding interactions with other molecules. Proteins fold into specific native structure to form\nthese local regions for carrying out various biochemical functions. The geometric shape and chemical pattern\nof the local surface regions, and how they change dynamically are therefore of fundamental importance in\ncomputational studies of proteins.\nAnother important application is the development of geometric potential functions. Potential functions\nare important for generating conformations, for distinguishing native and near native conformations from\nother decoy conformations in protein structure predictions [53?56] and in protein-protein docking [57]. They\nare also important for peptide and protein design [57,58]. Chapter 4 describes in details the development of\ngeometric potential and applications in decoy discrimination and in protein-protein docking prediction.\nWe havenot described in detail the approachof studying protein geometryusing graphtheory. In addition\nto side-chain pattern analysis briefly discussed earlier, graph based protein geometric model also has lead to\na number of important insights, including the optimal design of model proteins formed by hydrophobic and\npolar residues [59], and methods for optimal design of side-chain packing [60,61]. Another important topic\nwe did not touch upon is the analysis of the topology of protein backbones. Based on concepts from knot\ntheory, R?gen and Bohr developed a family of global geometric measures for protein structure classification\n[62]. These measures originate from integral formulas of Vassiliev knot invariants. With these measures,\nR?gen and Fain further constructed a system that can automatically classify protein chains into folds [63].\n15\nFigure 6.9: Protein function prediction as illustrated by the example of alpha amylases. Two template\nbinding surfaces are used to search database of protein surfaces to identify protein structures that are of\nsimilar functions. (a) The phylogenetic tree for the template Pdb structure 1bag from B. subtilis. (b)\nThe template binding pocket of alpha amylase on 1bag. (c) A matched binding surface on a different\nprotein structure (1b2y from human, full sequence identity 22%) obtained by querying with 1bag. (d) The\nphylogenetic tree for the template structure 1bg9 from H. vulgare. (e) The template binding pocket on 1bg9.\n(f) A matched binding surface on a different protein structure (1u2y from human, full sequence identity\n23%) obtained by querying with 1bg9 (Adapted from [51]).\nThis system can reproduce the Cath classification system that requires explicit structural alignment as well\nas human curation.\nFurther development of descriptions of geometric shape and topological structure, as well as algorithms\nfor their computation will provide a solid foundation for studying many important biological problems. The\nother important tasks are then to show how these descriptors may be effectively used to deepen our biological\ninsights and to develop accurate predictive models of biological phenomena. For example, in computing\nprotein-protein interfaces, a challenging task is to discriminate surfaces that are involved in protein binding\nfrom other non-binding surface regions, and to understand in what fashion this depends on the properties\nof the binding partner protein.\nUndoubtedly, evolution plays central roles in shaping up the function and stability of protein molecules.\nThe method of analyzing residue substitution rates using a continuous time Markov models [50,51], and\nthe method of surface mapping of conservation entropy and phylogeny [64,65] only scratches the surface of\n16\nthis important issue. Much remains to be done in incorporating evolutionary information in protein shape\nanalysis for understanding biological functions.\n6.7 Summary\nThe accumulation of experimentally solved molecular structures of proteins provides a wealth of information\nfor studying many important biological problems. With the development of a rigorous model of the structure\nof protein molecules, various shape properties, including surfaces, voids, and pockets, and measurements of\ntheir metric properties can be computed. Geometric algorithms have found important applications in protein\npacking analysis, in developing potential functions, in docking, and in protein function prediction. It is\nlikely further development of geometric models and algorithms will find important applications in answering\nadditional biological questions.\n6.8 Further reading\nThe original work of Lee and Richards surface can be found in [5], where they also formulated the molecular\nsurface model [8]. Michael Connolly developed the first method for the computation of the molecular surface\n[11]. Tsai et al. described a method for obtaining atomic radii parameter [15]. The mathematical theory of\nthe union of balls and alpha shape was developed by Herbert Edelsbrunner and colleague [9,66]. Algorithm\nfor computing weighted Delaunay tetrahedrization can be found in [28], or in a concise monograph with\nin-depth discussion of geometric computing [33]. Details of area and volume calculations can be found in\n[20,21,25]. The theory of pocket computation and applications can be found in [24,26]. Richards and Lim\noffered a comprehensive review on protein packing and protein folding [12]. A detailed packing analysis of\nproteins can be found in [35]. The study on inferring protein function by matching surfaces is described in\n[47]. The study of the evolutionary model of protein binding pocket and its application in protein function\nprediction can be found in [51].\n6.9 Acknowledgments\nThis work is supported by grants from the National Science Foundation (CAREER DBI0133856), the Na-\ntional Institute of Health (GM68958), the Office of Naval Research (N000140310329), and the Whitaker\nFoundation (TF-04-0023). The author thanks Jeffrey Tseng for help in preparing this chapter.\n17\nBibliography\n[1] G. Rhodes. Crystallography Made Crystal Clear: A Guide for Users of Macromolecular Models. Aca-\ndemic Press, 1999.\n[2] G. M. Crippen and T. F. Havel. Distance Geometry and Molecular Conformation. J. Wiley & Sons,\n1988.\n[3] W. Rieping, M. Habeck, and M. Nilges. Inferential structure determination. Science, 309(5732):303?6,\n2005.\n[4] R.F.W. Bader. Atoms in Molecules: A Quantum Theory. The international series of mongraphs on\nchemistry, No. 22. Oxford University Press, 1994.\n[5] B. Lee and F. M. Richards. The interpretation of protein structures: estimation of static accessibility.\nJ. Mol. Biol., 55:379?400, 1971.\n[6] F. M. Richards. The interpretation of protein structures: total volume, group volume distributions and\npacking density. J. Mol. Biol., 82:1?14, 1974.\n[7] T. J. Richmond. Solvent accessible surface area and excluded volume in proteins: analytical equations\nfor overlapping spheres and implications for the hydrophobic effect. J. Mol. Biol., 178:63?89, 1984.\n[8] F. M. Richards. Calculation of molecular volumes and areas for structures of known geometries. Methods\nin Enzymology, 115:440?464, 1985.\n[9] H. Edelsbrunner. The union of balls and its dual shape. Discrete Comput. Geom., 13:415?440, 1995.\n[10] F. M. Richards. Areas, volumes, packing, and proteinstructures. Ann. Rev. Biophys. Bioeng., 6:151?176,\n1977.\n[11] M. L. Connolly. Analytical molecular surface calculation. J. Appl. Cryst., 16:548?558, 1983.\n[12] F. M. Richards and W. A. Lim. An analysis of packing in the protein folding problem. Q. Rev. Biophys.,\n26:423?498, 1994.\n[13] M. Gerstein and F. M Richards. Protein Geometry: Distances, Areas, and Volumes, volume F, chap-\nter 22. International Union of Crystallography, 1999.\n[14] F. M. Richards. The interpretation of protein structures: total volume, group volume distributions and\npacking density. J. Mol. Biol., 82:1?14, 1974.\n[15] J. Tsai, R. Taylor, C. Chothia, and M. Gerstein. The packing density in proteins: standard radii and\nvolumes. J Mol Biol, 290(1):253?66, 1999.\n[16] A. Bondi. VDW volumes and radii. J. Phys. Chem., 68:441?451, 1964.\n[17] J.M. Word, S.C. Lovell, J.S. Richardson, and D.C. Richardson. Asparagine and glutamine: using\nhydrogen atom contacts in the choice of side-chain amide orientation. J Mol Biol, 285(4):1735?47, 1999.\n18\n[18] J. L. Finney. Volume occupation, environment and accessibility in proteins. The problem of the protein\nsurface. J. Mol. Biol., 96:721?732, 1975.\n[19] B. J. Gellatly and J.L. Finney. Calculation of protein volumes: an alternative to the Voronoi procedure.\nJ. Mol. Biol., 161:305?322, 1982.\n[20] H. Edelsbrunner, M. Facello, P. Fu, and J. Liang. Measuring proteins and voids in proteins. In Proc.\n28th Ann. Hawaii Int?l Conf. System Sciences, volume 5, pages 256?264, Los Alamitos, California, 1995.\nIEEE Computer Scociety Press.\n[21] J. Liang, H. Edelsbrunner, P. Fu, P. V. Sudhakar, and S. Subramaniam. Analytical shape computing\nof macromolecules I: Molecular area and volume through alpha-shape. Proteins, 33:1?17, 1998.\n[22] K. W. Kratky. Intersecting disks (and spheres) and statistical mechanics. I. mathematical basis. J. Stat.\nPhys., 25:619?634, 1981.\n[23] M. Petitjean. On the analytical calculation of van der waals surfaces and volumes: some numerical\naspects. J. Comput. Chem., 15:507?523, 1994.\n[24] H. Edeslbrunner, M. Facello, and J. Liang. On the definition and the construction of pockets in macro-\nmolecules. Disc. Appl. Math., 88:18?29, 1998.\n[25] J. Liang, H. Edelsbrunner, P. Fu, P. V. Sudhakar, and S. Subramaniam. Analytical shape computing\nof macromolecules II: Identification and computation of inaccessible cavities inside proteins. Proteins,\n33:18?29, 1998.\n[26] J. Liang, H. Edelsbrunner, and C. Woodward. Anatomy of protein pockets and cavities: Measurement\nof binding site geometry and implications for ligand design. Protein Sci, 7:1884?1897, 1998.\n[27] T. A. Binkowski, S. Naghibzadeh, and J. Liang. CASTp: Computed atlas of surface topography of\nproteins. Nucleic Acids Res., 31:3352?3355, 2003.\n[28] H. Edelsbrunner and N.R. Shah. Incremental topological flipping works for regular triangulations.\nAlgorithmica, 15:223?241, 1996.\n[29] L. Guibas and J. Stolfi. Primitives for the manipulation of general subdivisions and the computation of\nVoronoi diagrams. ACM Transactions on Graphiques, 4:74?123, 1985.\n[30] S. Chakravarty, A. Bhinge, and R. Varadarajan. A procedure for detection and quantitation of cavity\nvolumes proteins. application to measure the strength of the hydrophobic driving force in protein folding.\nJ Biol Chem, 277(35):31345?53, 2002.\n[31] A. Goede, R. Preissner, and C. Frommel. Voronoi cell: New method for allocation of space among\natoms: Elimination of avoidable errors in calculation of atomic volume and density. J. Comput. Chem.,\n18:1113?1123, 1997.\n[32] Y. Harpaz, M. Gerstein, and C. Chothia. Volume changes on protein folding. Structure, 2(7):641?9,\n1994.\n[33] H. Edelsbrunner. Geometry and Topology for Mesh Generation. Cambridge University Press, 2001.\n[34] M. Levitt, M. Gerstein, E. Huang, S. Subbiah, and J. Tsai. Protein folding: the endgame. Annu Rev\nBiochem, 66:549?579, 1997.\n[35] J. Liang and K. A. Dill. Are proteins well-packed? Biophys. J., 81:751?766, 2001.\n[36] J. Zhang, R. Chen, C. Tang, and J. Liang. Origin of scaling behavior of protein packing density: A\nsequential monte carlo study of compact long chain polymers. J. Chem. Phys., 118:6102?6109, 2003.\n19\n[37] A. E. Todd, C. A. Orengo, and J. M. Thornton. Evolution of function in protein superfamilies, from a\nstructural perspective. J. Mol. Biol., 307:1113?1143, 2001.\n[38] L. Holm and C. Sander. New structure: Novel fold? Structure, 5:165?171, 1997.\n[39] A. C. R. Martin, C. A. Orengo, E. G. Hutchinson, A. D. Michie, A. C. Wallace, M. L. Jones, and J. M.\nThornton. Protein folds and functions. Structure, 6:875?884, 1998.\n[40] C. A. Orengo, A. E. Todd, and J. M. Thornton. From protein structure to function. Curr. Opinion\nStructural Biology, 9(4):374?382, 1999.\n[41] P. J. Artymiuk, A. R. Poirrette, H. M. Grindley, D.W. Rice, and P. Willett. A graph-theoretic approach\nto the identification of three-dimensional patterns of amino acid side-chains in protein structure. J. Mol.\nBiol., 243:327?344, 1994.\n[42] D. Fischer, R. Norel, H. Wolfson, and R. Nussinov. Surface motifs by a computer vision technique:\nsearches, detection, and implications for protein- ligand recognition. Proteins: Structure, Function and\nGenetics, 16:278?292, 1993.\n[43] R. Norel, D. Fischer, H. J. Wolfson, and R. Nussinov. Molecualr surface recognition by computer\nvision-based technique. Protein Eng., 1994.\n[44] A. C. Wallace, N. Borkakoti, and J. M. Thornton. TESS: a geometric hashing algorithm for deriving\n3d coordinate templates for searching structural databases. Application to enzyme active sites. Protein\nSci., 6:2308?2323, 1997.\n[45] R. Russell. Detection of protein three-dimensional side-chain patterns: New examples of convergent\nevolution. J. Mol. Biol., 279:1211?1227, 1998.\n[46] R. A. Laskowski, N. M. Luscombe, M. B. Swindells, and J. M. Thornton. Protein clefts in molecular\nrecognition and function. Protein Sci., 5:2438?2452, 1996.\n[47] T. A. Binkowski, L. Adamian, and J. Liang. Inferring functional relationship of proteins from local\nsequence and spatial surface patterns. J. Mol. Biol., 332:505?526, 2003.\n[48] T.A. Binkowski, A. Joachimiak, and J. Liang. Protein surface analysis for function annotation in\nhigh-throughput structural genomics pipeline. Protein Sci, 14(12):2972?81, 2005.\n[49] T.A. Binkowski, P. Freeman, and J. Liang. pvSOAR: Detecting similar surface patterns of pocket and\nvoid surfaces of amino acid residues on proteins. Nucleic Acid Research, 32:W555?W558, 2004.\n[50] Y.Y. Tseng and J. Liang. Estimating evolutionary rate of local protein binding surfaces: a bayesian\nmonte carlo approach. Proceedings of 2005 IEEE-EMBC Conference, 2005.\n[51] Y.Y. Tseng and J. Liang. Estimation of amino acid residue substitution rates at local spatial regions\nand application in protein function inference: A Bayesian Monte Carlo approach. Mol. Biol. Evol.,\n23:421?436, 2006.\n[52] Y. Ban, H. Edelsbrunner, and J. Rudolph. Interface surfaces for protein-protein complexes. In RE-\nCOMB, pages 205?212, 2004.\n[53] R. K.Singh, A. Tropsha, and I. I. Vaisman. Delaunaytessellationof proteins: fourbody nearest-neighbor\npropensities of amino-acid residues. J. Comp. Bio., 3:213?221, 1996.\n[54] W. Zheng, S. J. Cho, I. I. Vaisman, and A. Tropsha. A new approach to protein fold recognition based\non Delaunay tessellation of protein structure. In R.B. Altman, A.K. Dunker, L. Hunter, and T.E. Klein,\neditors, Pacific Symposium on Biocomputing?97, pages 486?497, Singapore, 1997. World Scientific.\n20\n[55] X. Li, C. Hu, and J. Liang. Simplicial edge representation of protein structures and alpha contact\npotential with confidence measure. Proteins, 53:792?805, 2003.\n[56] X. Li and J. Liang. Geometric cooperativity and anticooperativity of three-body interactions in native\nproteins. Proteins, 60(1):46?65, 2005.\n[57] X. Li and J. Liang. Computational design of combinatorial peptide library for modulating protein-\nprotein interactions. Pac Symp Biocomput, pages 28?39, 2005.\n[58] C. Hu, X. Li, and J. Liang. Developing optimal nonlinear scoring function for protein design. Bioinfor-\nmatics, 20:3080?3098, 2004.\n[59] J. Kleinberg. Efficient algorithms for protein sequence design and the analysis of certain evolutionary\nfitness landscapes. In RECOMB, pages 205?212, 2004.\n[60] J. Xu. Rapid protein side-chain packing via tree decomposition. In RECOMB, pages 423?439, 2005.\n[61] A. Leaver-Fay, B. Kuhlman, and J. Snoeyink. An adaptive dynamic programming algorithm for the\nside chain placement problem. In Pacific Symposium on Biocomputing, pages 17?28, 2005.\n[62] P. R?gen and H. Bohr. A new family of global protein shape descriptors. Math Biosci, 182(2):167?81,\n2003.\n[63] P. R?gen and B. Fain. Automatic classification of protein structure by using gauss in tegrals. Proc Natl\nAcad Sci U S A, 100(1):119?24, 2003.\n[64] O. Lichtarge, H.R. Bourne, and F.E. Cohen. An evolutionary trace method defines binding surfaces\ncommon to protein families. J Mol Biol, 257(2):342?58, 1996.\n[65] F. Glaser, T. Pupko, I. Paz, R.E. Bell, D. Shental, E. Martz, and N. Ben-Tal. Consurf: identifica-\ntion of functional regions in proteins by surface-mapping of phylogenetic information. Bioinformatics,\n19(1):163?4, 2003.\n[66] H. Edelsbrunner and E.P. M?ucke. Three-dimensional alpha shapes. ACM Trans. Graphics, 13:43?72,\n1994.\n21\n"}
{"id":"oai:arXiv.org:hep-ph/0610379","text":"arXiv:quant-ph/0610192v1  23 Oct 2006\nICMPA-MPA/2006/20\nCP3-06-13\n(p,q)-Deformations and (p,q)-Vector Coherent States\nof the Jaynes-Cummings Model\nin the Rotating Wave Approximation\nJoseph Ben Geloun?, Jan Govaerts?,?,1 and M. Norbert Hounkonnou?\n?International Chair in Mathematical Physics and Applications (ICMPA-UNESCO)\n072 B.P. 50 Cotonou, Republic of Benin\nE-mail: jobengeloun@yahoo.fr, norbert?hounkonnou@cipma.net\n?Department of Theoretical Physics, School of Physics\nThe University of New South Wales, Sydney NSW 2052, Australia\nE-mail: Jan.Govaerts@fynu.ucl.ac.be\nFebruary 1, 2008\nAbstract\nClasses of (p,q)-deformations of the Jaynes-Cummings model in the rotating wave ap-\nproximation are considered. Diagonalization of the Hamiltonian is performed exactly, leading\nto useful spectral decompositions of a series of relevant operators. The latter include ladder\noperators acting between adjacent energy eigenstates within two separate infinite discrete\ntowers, except for a singleton state. These ladder operators allow for the construction of\n(p,q)-deformed vector coherent states. Using (p,q)-arithmetics, explicit and exact solutions\nto the associated moment problem are displayed, providing new classes of coherent states\nfor such models. Finally, in the limit of decoupled spin sectors, our analysis translates into\n(p,q)-deformations of the supersymmetric harmonic oscillator, such that the two supersym-\nmetric sectors get intertwined through the action of the ladder operators as well as in the\nassociated coherent states.\n1On sabbatical leave from the Center for Particle Physics and Phenomenology (CP3), Institute of Nuclear\nPhysics, Catholic University of Louvain, 2, Chemin du Cyclotron, B-1348 Louvain-la-Neuve, Belgium.\n1 Introduction\nIn recent years, quantum algebras and groups [1] which appear as a generalization of the sym-\nmetry concept [2] and the basics of so-called noncommutative theories, have been the subject of\nintensive research interest in both mathematics and physics. The q- and more generally (p,q)-\ndeformation of a pre-defined algebraic structure [3, 4, 5] proves to be a powerful tool widely used\nin the representation theory of quantum groups. The field of ?q-mathematics? has a long history\n[6, 7] dating back to over 150 years, and includes several famous names such as Cauchy, Jacobi\nand Heine to mention just a few. Its possible relation to physics has been considerably reinforced\nduring the last thirty years [3, 8]. In particular, great attention has been devoted to deformations\nof the bosonic Fock-Heisenberg algebra. The most commonly studied deformed bosons, with\nannihilation and creation operators a and a?, respectively, satisfy the q-commutation relation\n[3] (also called quommutation)\naa??qa?a = I, (1)\nor some variant forms of such a relation [4, 9]. Still more general deformations, which include in\nspecific limits the above standard q-deformed case and which also provides consistent extensions\nof the harmonic oscillator algebra, proceed from the two parameter deformation of the Fock\nalgebra introduced by Chakrabarty and Jagannathan [5], namely the so-called (p,q)-oscillator\nquantum algebras generated by three operators a, a? and N which obey [5, 10]\n[N,a] =?a, [N,a?] = a?, aa??qa?a = p?N, aa??p?1a?a = qN. (2)\nHere, p and q are free parameters, which henceforth are chosen to be both real and such that\np > 1, 0 < q < 1 and pq < 1. Clearly, one recovers the ordinary Fock algebra of the harmonic\noscillator algebra in the double limit p,q?1, with then [a,a?] = I and N = a?a. Furthermore,\nthese q- and (p,q)-deformed algebras have found a number of relevant applications and provide\nalgebraic interpretations of various q- and (p,q)-special functions [9, 10, 11].\nThe harmonic oscillator algebra is central in the construction of a number of models in\nphysics, among which the Jaynes?Cummings model (JCm) plays a significant role. Indeed ever\nsince Jaynes and Cummings? historical work [12], the JCm has been at the basis of many in-\nvestigations. This system belongs to a class of physically relevant models widely used in atomic\nphysics and quantum optics. As far as we know, a great deal of analytically solvable models of\nthis type have been studied in the rotating wave approximation (r.w.a.) within the framework\nof non-deformed commutative theories (see [12]?[17] and references therein). TheJCm has also\nbeen considered in the context of generalized intensity dependent oscillator algebras including\nnonlinear dynamical supersymmetry[18] or using shapeinvariance techniques [19, 20]. Compara-\ntively, much fewer papers have dealt with generalizations of these models including deformations.\nAmong the latter and mainly based on the generalized intensity-dependent coupling of Buck and\nSukumar [21], one may mention, on the one hand, the work by Chaichan et al. [22], and on the\nother hand, that by Chang [23], both dealing with a generalized q-deformed intensity-dependent\ninteraction Hamiltonian of theJCm given by the Holstein-Primakoff suq(1,1) or suq(2) quantum\nalgebra realizations of the Hamiltonian field operators and the related Peremolov, Glauber or\nBarut-Girardello group theoretical construction of coherent states. In the same vein, the paper\nby Naderi et al. considers the dynamical properties of a two-level atom in three variants of the\ntwo-photon q-deformedJCm [24]. In this latter work, the authors focused their attention onto\nthe time evolution of atomic properties including population inversion and quantum fluctuations\nof the atomic dipole variables. However, it is not clear to us how the main issues related to the\nmoment problem as well as the mathematical foundation of the coherent and squeezed states\nwhich they use and on which a great part of their analysis rests in a crucial way, are solved.\n1\nIn a recent publication [14], Hussin and Nieto have performed an interesting systematic\nsearch of different types of ladder operators for theJCm model in the r.w.a. and constructed\nassociated coherent states. In the present work, and in line with that investigation, we provide\na generalization of that analysis to (p,q)-deformations of the same model.\nThe outline of the paper is the following. In Section 2, we briefly recall the main results\nrelevant to theJCm in the r.w.a. in the non-deformed situation [14]. Section 3 then introduces\n(p,q)-deformations of the same model. By providing an explicit diagonalization of the (p,q)-\ndeformed Hamiltonian, the spectrum and its eigenstates are exactly identified. As in the non-\ndeformed case [14], except for a singleton state, all other energy eigenstates are organized into\ntwo separate discrete towers, for which ladder operators transforming states into one another\nwithin each tower separately may be introduced. Using properties of these ladder operators, in\nSection 4 we introduce general classes of (p,q)-deformed vector coherent states. The freedom\nafforded in their construction is fixed from two alternative points of view, discussed in Section 5,\nwhich in the ordinary case of the non-deformed Fock algebra coincide. However at all stages of\nour discussion, the double limit p,q?1 reproduces the corresponding results of [14]. Section 5\nalso briefly considers the situation in the uncoupled limit of theJCm, while Section 6 presents\nsome concluding remarks. An Appendix collects useful facts in connection with properties of\n(p,q)-deformed algebras and related functions.\n2 The Ordinary JCm in the Rotating Wave Approximation\nThe JCm describes the interaction between one mode of the quantized electromagnetic field\nand a two-level model of an atomic system [12, 14]?[16]. It has proved to be a theoretical\nlaboratory of great relevance to many topics in atomic physics and quantum optics, as well\nas in the study of ion traps, cavity QED theory and quantum information processing [13, 14].\nFurthermore, the spin-orbit interaction term which appears in the JCm is essentially the so-\ncalled Dresselhaus spin-orbit term [25]. The model is thus also widely used in condensed matter\nphysics for its relevance in spintronics [26] which exploits the electron spin rather than its charge\nto develop a new generation of electronic devices [27, 28]. The solution of the completeJCm is\nnot yet known in a closed form [14]. However, in the r.w.a., although the Hamiltonian remains\nnonlinear, the model becomes exactly solvable in closed form with explicit expressions for its\neigenenergy states. In this Section, we briefly recall, in a streamlined presentation, the main\nresults in the non-deformed case (see [14, 15] and references therein) of relevance to our analysis\nof (p,q)-deformations hereafter.\nIn the r.w.a., the reduced dimensionlessJCm Hamiltonian reads [15]\nHred = 1planckover2pi1?\n0\nH= (1+?)\nparenleftbigg\na?a+ 12\nparenrightbigg\n+ 12?3 +?\nparenleftBig\na??? +a?+\nparenrightBig\n, (3)\nwhere a and a? are the usual photon annihilation and creation operators, respectively, obeying\nthe ordinary Fock algebra, and (?1,?2,?3) are the Pauli matrices with ?? = ?1?i?2. The r.w.a.\nis related to the detuning parameter ? which is such that|?|?1, with ?0 being the fixed atomic\nfrequency and ? = ?0(1 + ?) the actual field mode frequency. The r.w.a. is reliable provided\n|???0|??,?0. Finally, ? is the reduced spin-orbit coupling modelling the interaction strength\nbetween the radiation field and the atom.\n2\nThe Hilbert spaceV of the system is the tensor product of the Fock space representation\nof the Fock algebra (a,a?) and the 2-dimensional representation of the SU(2) algebra associated\nto the Pauli matrices. A basis of the former is provided by the number operator, N = a?a,\northonormalized eigenstates |n? = (1/?n!)(a?)n|0? (n = 0,1,2,???), with a|n? = ?n|n?1?,\na?|n?=?n+ 1|n + 1?and N|n?= n|n?, while a basis of the latter spin sector is the orthonor-\nmalized set {|+?,|??} such that ?3|??=?|??. The tensor product space is thus spanned by\nthe states|n,??=|n??|??.\nThe diagonalization of the Hamiltonian (3) is readily achieved. The orthonormalized\nenergy eigenspectrum consists of a ?singleton? state|E??,\nHred|E??= E?|E??, (4)\nwith\nE? = 12?, |E??=|0,??, (5)\nand two infinite discrete towers of states |E?n? such that Hred|E?n? = E?n|E?n? for all n =\n0,1,2,???, expressed as [14]\n|E+n? = sin?(n)|n,+?+ cos?(n)|n+ 1,??, (6)\n|E?n? = cos?(n)|n,+??sin?(n)|n+ 1,??, (7)\nwhere, given Q(n+ 1) =radicalbig?2/4 +?2(n+ 1), the mixing angle ?(n) is such that\nsin?(n) = sign(?)\nradicalBigg\nQ(n+ 1)??/2\n2Q(n + 1) , cos?(n) =\nradicalBigg\nQ(n+ 1) +?/2\n2Q(n+ 1) , (8)\nwhile the energy eigenvalues are\nE?n = (1 +?)(n+ 1)?Q(n+ 1). (9)\nConsequently, one has the spectral decomposition of the reduced Hamiltonian (3),\nHred =|E??E??E?| +\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|. (10)\nIt proves useful to introduce the following notations. Let V0 be the (complex) one-\ndimensional subspace of the Hilbert space V spanned by the state |0,?? = |E??, and V be\nits complement in the Hilbert spaceV, spanned by{|E?n?,n?N}. We thus haveV=V0?V.\nFurthermore let us introduce [14] operatorsU andU? defined through their action on the\nabove two sets of basis vectors, for all n?N,\nU|n,??=|E?n?; U?|E??= 0, U?|E?n?=|n,??, (11)\nnamely\nU =\n?summationdisplay\nn=0,?\n|E?n??n,?|, U? =\n?summationdisplay\nn=0,?\n|n,???E?n|. (12)\nClearly we have\nUV =V; U?V =V, U?V=V. (13)\n3\nNote that even though neither U nor U? is unitary on the full Hilbert space V, they are the\nadjoint of one another, hence the notation.\nIt is of interest to apply these operators onto the quantum Hamiltonian (3). One obtains\nHred =U?HredU =\n?summationdisplay\nn=0,?\n|n,??E?n ?n,?|, (14)\nand conversely,\nUHredU? =\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|=Hred ?|E??E??E?|. (15)\nThe energy eigenstates spanning V may be organized into two subspaces referred to as\n?towers?, namely {|E+n?,n?N} and {|E?n?,n?N}. The states in the tower {|E+n?,n?N}\nare associated to strictly increasing eigenvalues so that they constitute a nondegenerate set\nof eigenstates. The second group does not necessarily possess the same feature depending\non the values for the parameters ? and ?. It is possible [16] to identify a range of values\nfor these parameters such that {|E?n?,n?N} only contains nondegenerate states of strictly\nincreasing eigenvalues with n. Some of the considerations discussed hereafter may require a\nnondegenerate spectrum, which may always be achieved by properly ?detuning? the parameters\n? and ? away from a degenerate case, but not necessarily a strictly increasing spectrum in the\nlabel n?N. Whatever the case may be though, bounded from below spectra such that E?n > E?0\nfor n = 1,2,???are always assumed implicitly.\nIt is possible to consider ladder operators acting between successive energy eigenstates\nwithin each of the above two towers, irrespective of whether the spectral values are strictly\nincreasing or not1. Namely, let us first consider operators M? and M+ given as\nM? =\n?summationdisplay\nn=0,?\n|n?1,??K?(n)?n,?|; M+ =\n?summationdisplay\nn=0,?\n|n+ 1,??K??(n+ 1)?n,?|, (16)\nwhere K?(n) are, at this stage, arbitrary complex coefficients such that K?(0) = 0. Then,\nintroduce the ladder operators\nM? =UM?U? =\n?summationdisplay\nn=0,?\n|E?n?1?K?(n)?E?n|; M+ =UM+U? =\n?summationdisplay\nn=0,?\n|E?n+1?K??(n+ 1)?E?n|,\n(17)\nwhich are thus such that, for all n = 0,1,2,???,\nM?|E??= 0, M?|E?n?= K?(n)|E?n?1?; M+|E??= 0, M+|E?n?= K??(n+ 1)|E?n+1?.\n(18)\nNote thatM? andM+ are adjoint of one another but in effect only act on the subspaceV.\nGeneral vector coherent states (VCS) may then be introduced [29]?[32] on the space V\nas eigenstates of the lowering operator M? with as eigenvalue an arbitrary complex number\nz?C. Furthermore, these VCS are also parametrized by two real quantities ?? which account\nfor their stability under time evolution generated by the operator expbraceleftbig?i?0tHredbracerightbig, as well as\nthe two spherical coordinates (?,?)?[0,?]?[0,2?[ parametrizing a unit vector in the 2-sphere\n1We differ on this point with [14], where strictly increasing energy spectra in each tower are required.\n4\nS2 (hence the name of ?vector? coherent states). Explicitly, one has [14]\n|z;??;?,?? = N+(|z|)cos?\n?summationdisplay\nn=0\nzn\nK+(n)!e\n?i?0?+E+n |E+\nn?\n+ N?(|z|)ei? sin?\n?summationdisplay\nn=0\nzn\nK?(n)!e\n?i?0??E?n |E?\nn?, (19)\nwhere K?(n)! =producttextnk=1 K?(k) (with, by convention, K?(0)! = 1), while the normalization factors\nare defined as\nN?(|z|) =\nbracketleftBigg ?summationdisplay\nn=0\n|z|2n\n|K?(n)!|2\nbracketrightBigg?1/2\n(20)\nin order that the VCS be of unit norm. The smallest value, R, of the two convergence radii of\nthese two series in |z| also defines the disk DR in z ?C for which these VCS are well defined.\nThese states are clearly such that\nM?|z;??;?,??= z|z;??;?,??, e?i?0tHred|z;??;?,??=|z;t +??;?,??. (21)\nFurther restrictions are necessary to finally specify in a unique fashion the factors K?(n),\nand then solve the moment problem implied by the requirement of overcompleteness overV for\nthe VCS (19) given a choice of a SU(2) matrix-valued integration measure over C?S2 [30]-[32].\nDifferent choices are available [14], each leading to a different set of VCS. Furthermore, taking\nthe limit case ??0 or the zero-detuning limit (resonance case) ??0, different models arise\nwith their associated VCS.\nFor the sake of illustration, let us consider one such choice explicitly [14]. The factors\nK?(n) may be restricted for example by requiring that the ladder operatorsM? andM+ obey\nthe usual Fock algebra of annihilation and creation operators on the spaceV,\nbracketleftbigM?,M+bracketrightbig=M?M+ ?M+M? = I\nV =\n?summationdisplay\nn=0,?\n|E?n??E?n|. (22)\nFrom the expressions in (18) and the initial conditions K?(0) = 0, it follows that the quantities\nK?(n) are now determined up to arbitrary phase factors ??(n) as\nK?(n) = ei??(n)?n, n = 0,1,2,???. (23)\nConsequently, one has N?(|z|) = e?|z|2/2, which is well-defined for all z?C. Hence so are then\nall the VCS|z;??;?,??.\n3 The (p,q)-Deformed JCm in the Rotating Wave Approxima-\ntion\nLet us now introduce a (p,q)-deformation of the JCm Hamiltonian (3), namely (p,q)-JCm\nmodels. The eigenstates and spectrum are first identified, before considering the construction\nof ladder operators following the same rationale as in Section 2. A study of the associated VCS\nand examples of exactly solvable reduced models is differed to Section 4.\n5\n3.1 Energy spectrum and eigenstates\nGiven the (p,q)-deformation (2) of the ordinary Fock algebra (see the Appendix for further\ndetails and identities pertaining to such deformations), we now consider (p,q)-deformations of\nthe Hamiltonian (3) of the form2\nHred = (1 +?)\nbraceleftbigg\nh(p,q)[N] + 12\nbracerightbigg\n+ 12?3 +?\nparenleftBig\na??? +a?+\nparenrightBig\n, (24)\nwhere [N] = (p?N ?qN)/(p?1?q), and h(p,q) is some arbitrary positive function of the real\nparameters p > 1 and 0 < q < 1 (with pq < 1) such that limp,q?1 h(p,q) = 1 in order to recover\n(3) in the non-deformed case.\nThe Hilbert space V of quantum states of the model is again the tensor product of the\n(p,q)-deformed Fock space spanned by the states3 |n?(n?N) such as a|n?= radicalbig[n]|n?1?and\na?|n?=radicalbig[n+ 1]|n+1?(see the Appendix), with the 2-dimensional representation of the SU(2)\nalgebra associated to the Pauli matrices ?i (i = 1,2,3). Hence the diagonalization of (24) is\nreadily achieved in the same way as in the non-deformed case, on the basis|n,??=|n??|??of\nV.\nFor any n?N, let us introduce the following quantities,\nE([n+1]) = (1+?)h(p,q)\nparenleftBig\n[n+1]?[n]\nparenrightBig\n?1, Q([n+1]) =\nradicalbigg\n1\n4E\n2([n +1]) + ?2 [n+1], (25)\nas well as the mixing angles ?([n]) defined by\nsin?([n]) = sign(?)\nradicalBigg\nQ([n+ 1])?E([n + 1])/2\n2Q([n + 1]) , cos?([n]) =\nradicalBigg\nQ([n + 1]) +E([n+ 1])/2\n2Q([n +1]) .\n(26)\nThe energy eigenspectrum of (24) is then obtained as follows. First, there exists a singleton\nstate|E??=|0,??such that\nHred|E??= E?|E??, E? = 12?, (27)\nwith an eigenvalue which is thus independent of the deformation parameters p and q. Next, one\nalso finds two infinite discrete towers of states for all n?N such that\n|E+n? = sin?([n])|n,+? + cos?([n])|n + 1,??, (28)\n|E?n? = cos?([n])|n,+?? sin?([n])|n + 1,??, (29)\nwith\nHred|E?n?= E?n |E?n?, E?n = 12 (1 +?)\nbraceleftBig\nh(p,q)\nparenleftBig\n[n+ 1] + [n]\nparenrightBig\n+1\nbracerightBig\n? Q([n+ 1]). (30)\nNote that the energy spectrum of these states is deformed by the parameters p and q as compared\nto the ordinary case. In particular, the Zeeman spin splitting ?En = E+n ?E?n = 2Q([n + 1]),\n2Make no mistake that henceforth, all quantities correspond to the (p,q)-deformed analysis even though the\nnotations used coincide with those of Section 2 and do not make explicit the fact that all expressions correspond\nnow to the deformed case. When wanting to make the difference explicit, notations such as for instance [N] ?\n[N](p,q) = (p?N ?qN)/(p?1 ?q) and [n] ? [n](p,q) = (p?n ?qn)/(p?1 ?q) are used.\n3Once again, the states |n? = |n?(p,q) are not to be confused with the number operator eigenstates of the\nordinary Fock algebra as in Section 2, in spite of an identical notation.\n6\nproportional to the Rabi frequency, is function of the values for p and q. In terms of these\nresults, the reduced Hamiltonian (24) possesses the spectral resolution\nHred =|E??E??E?| +\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|. (31)\nLet us again introduce the following notations and operators. LetV0 denote the subspace\nof the Hilbert space V spanned by the singleton state |E??= |0,??, and V its complement in\nV, namely the subspace spanned by{|E?n?,n?N}, with of courseV=V0?V. Acting on these\nspaces, let us consider the operators\nU =\n?summationdisplay\nn=0,?\n|E?n??n,?|; U? =\n?summationdisplay\nn=0,?\n|n,???E?n|, (32)\nsuch that, for all n = 0,1,2,???,\nU|n,??=|E?n?; U?|E??= 0, U?|E?n?=|n,??, (33)\nand thus\nUV=V; U?V=V, U?V =V. (34)\nHence once again the operators U and U?, even though non unitary on V, are adjoint of one\nanother. More specifically, one has\nU?U =\n?summationdisplay\nn=0,?\n|n,???n,?|= IV, UU? =\n?summationdisplay\nn=0,?\n|E?n??E?n|= IV. (35)\nApplying these operators to the reduced Hamiltonian, one finds\nHred =U?HredU =\n?summationdisplay\nn=0,?\n|n,??E?n ?n,?|, (36)\nand conversely,\nUHredU? =\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|=Hred ?|E??E??E?|. (37)\nSome remarks on the spectrum are in order. First, as in the ordinary JCm, except\nfor the singleton state |E?? = |0,??, the spectrum is the direct sum of two towers of states\n{|E?n?,n?N}. However, in contradistinction to the non-deformed case or even the q-deformation\nwith p = 1, the (p,q)-basic numbers [n] = [n](p,q) are not strictly increasing as a function of\nn?N when p > 1, 0 < q < 1 and pq < 1. There always exists a finite positive value n0 ?N\nsuch that [n] decreases once n > n0. Hence, depending on the values for the parameters ? and ?\nas well as the positive function h(p,q), parts of the spectrum E?n may turn negative or present\nsome degeneracies (as in [16]). Without exploring this issue any further in the present work,\nhenceforth we shall assume that parameter values are such that no degeneracies occur and that\nthe spectrum E?n remains bounded from below (E+n is obviously positive). The definition of the\nladder operators to be considered next does not require a strictly increasing spectrum, while it\nis only for one of possible choices leading to vector coherent states to be discussed hereafter that\nthe condition of non degeneracy in E?n > E?0 , for n?1, becomes relevant. Since it has been\n7\nshown [16] that such conditions may be met in the non-deformed case for appropriate ranges\nof values for the available parameters, through an argument of continuity in the deformation\nparameters p and q, similar ranges ought to exist also for the (p,q)-deformed realizations of the\nJCm model.\nAnother feature of potential interest related to these facts, and which will also not be\npursued here, is the possibility that through the (p,q)-deformation of theJCm, the levels E+n\nand E?n+1 cross one another. Such a property may lead to effects similar to the phenomenon\nof resonant spin-Hall conductance at the Fermi level recently observed in spintronics [27, 28].\nNote that this (p,q)-dependent crossing phenomenon is expected since the Zeeman splitting\n?En is also modified as a function of p and q. This remark is also in line with the recent\nsuggestion [33, 34, 35] that (p,q)-deformed or space noncommutative realizations of exactly\nsolvable systems may provide useful model approximations to more realistic complex interacting\ndynamics of collective phenomena.\n3.2 Ladder operators\nIn order to construct ladder operators mapping each of the successive states |E?n? into one\nanother separately within each of the towers, let us first introduce the following operators acting\nonV,\nA? =\n?summationdisplay\nn=0,?\n|n?1,??K?([n])?n,?|; A+ =\n?summationdisplay\nn=0,?\n|n+ 1,??K??([n +1])?n,?|, (38)\nwhere K?([n]) are arbitrary complex quantities such that K?([0]) = K?(0) = 0. Note that A?\nand A+ are adjoint of one another onV.\nThen the relevant ladder operators are obtained as\nA? =UA?U? =\n?summationdisplay\nn=0,?\n|E?n?1?K?([n])?E?n|; A+ =UA+U? =\n?summationdisplay\nn=0,?\n|E?n+1?K??([n+ 1])?E?n|.\n(39)\nConsequently, we have indeed, for all n?N,\nA?|E??= 0, A?|E?n?= K?([n])|E?n?1?; A+|E??= 0, A+|E?n?= K??([n+ 1])|E?n+1?.\n(40)\nNote thatA? andA+ are adjoint of one another, but that in effect they act only on the subspace\nV.\nIt is of course possible to express these ladder operators in the|n,??basis. In the case of\nthe lowering operator, one finds\nA? = summationtext?n=0 |n,+?A?++(n)?n+ 1,+| + summationtext?n=0 |n,+?A?+?(n)?n+ 2,?|\n+ summationtext?n=0 |n,??A??+(n)?n,+| + summationtext?n=0 |n,??A???(n)?n+ 1,?|\n(41)\nwhere\nA?++(n) = sin?([n]) sin?([n+ 1])K+([n + 1]) + cos?([n]) cos?([n+ 1])K?([n + 1]),\nA?+?(n) = sin?([n]) cos?([n+ 1])K+([n + 1]) ? cos?([n]) sin?([n+ 1])K?([n + 1]),\n8\nA??+(n) = cos?([n?1]) sin?([n])K+([n]) ? sin?([n?1]) cos?([n])K?([n]),\nA???(n) = cos?([n?1]) cos?([n])K+([n]) + sin?([n?1]) sin?([n])K?([n]). (42)\nLikewise for the raising operator,\nA+ = summationtext?n=0 |n+ 1,+?parenleftbigA?++(n)parenrightbig? ?n,+| + summationtext?n=0 |n,+?parenleftbigA??+(n)parenrightbig? ?n,?|\n+ summationtext?n=0 |n+ 2,??parenleftbigA?+?(n)parenrightbig? ?n,+| + summationtext?n=0 |n+ 1,??parenleftbigA???(n)parenrightbig? ?n,?|.\n(43)\nNote that we haveA??+(0) = 0 =A???(0), since K?([0]) = 0.\nThe quantities K?([n]) parametrize the freedom available in the choice of such ladder\noperators. Further restrictions arise when considering first the possible existence of vector\ncoherent states meeting a series of general conditions charateristic of such states [30]-[32], starting\nwith one involving the lowering operatorA? itself.\n4 (p,q)-Vector Coherent States for the (p,q)-JCm\nBy considering the action of the lowering operatorA?, we are able to construct an overcomplete\nset of vectors in V, so-called vector coherent states [30]-[32] for the (p,q)-JCm. Since these\nstates are associated to unit vectors in the 2-sphere S2 [29], they are referred to as (p,q)-vector\ncoherent states ((p,q)-VCS). As in Section 2, these (p,q)-VCS are parametrized by a complex\nvariable z ?C, two real parameters ?? to track a stable time evolution of the (p,q)-VCS, and\nfinally the spherical angle coordinates (?,?) on S2,|z;??;?,??. In the double limit that p,q?1,\nthese (p,q)-VCS reduce to those of [14] discussed in Section 2. The dependence of the (p,q)-VCS\non all these quantities is introduced as follows, according to the discussion in [30].\n4.1 Identifying (p,q)-VCS\nAs a slight extension of the analysis so far, given two real parameters ? and ?, let us consider\nthe operator\nQV =|E???E?| +\n?summationdisplay\nn=0,?\n|E?n?\nparenleftbiggq?\np?\nparenrightbiggn\n?E?n|. (44)\nHence, the energy eigenstates of the (p,q)-JCm are also eigenstates of this operator QV, with\neigenvalues given through the above spectral decomposition.\nWe are now in a position to successively identify the dependence of the (p,q)-VCS to be\nconstructed on each of the parameters of which they are functions, first z, then ??, and finally,\n? and ?. Having defined both the operatorsA? and QV, let us consider the following eigenvalue\nproblem in z for the (p,q)-VCS,\nA?|z;??;?,??= zQV|z;??;?,?? (45)\nwhich generalizes to a two-level system the definition of coherent states as advocated in [30]-\n[32]. The particular case ? = 0 = ? yields also a consistent definition of (p,q)-VCS viewed as\nthe limit ?,? ?0 of the present definition (note that their domain of definition in z, required\n9\nfor the convergence of the infinite series to be considered hereafter, may have to be adapted\naccordingly).\nBy expanding the (p,q)-VCS in the Hamiltonian eigenstate basis as\n|z;??;?,??= C?(z)|E??+\n?summationdisplay\nn=0,?\nC?n (z)|E?n?, (46)\nwhere C?(z) and C?n (z) are complex continuous functions of z to be specified presently, the\ncondition (45) then requires, for all n?N,\nC?(z) = 0, C?n+1(z)K?([n+ 1]) = z q\n?n\np?n C\n?\nn (z), (47)\nof which the solution is\nC?n (z) =\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK?([n])! C\n?\n0 (z), (48)\nwhere C?0 (z) are arbitrary complex functions of z, while we defined K?([n])! = producttextnk=1 K?([k])\nwith, by convention, K?([0])! = 1. Hence, the general solution to (45) defines states lying only\nwithin the subspaceV, of the form\n|z;??;?,??=\n?summationdisplay\nn=0,?\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK?([n])! C\n?\n0 (z)|E\n?\nn?. (49)\nNote that the eigenvalue problem (45) is singular at the particular value z = 0, since its solution\nis an arbitrary superposition of the three states|E??and|E?0 ?. Nevertheless, we shall consider\nthe (p,q)-VCS associated to z = 0, |z = 0;??;?,??, as being defined through the continuous\nlimit in z?0 of the construction in (49), namely|z = 0;??;?,??= C+0 (0)|E+0 ?+C?0 (0)|E?0 ?.\nLet us now turn to the issue of the stability of the (p,q)-VCS under time evolution gener-\nated by the Hamiltonian (24). Namely, we now require furthermore that (p,q)-VCS are trans-\nformed into one another under time evolution according to the following dependence on the real\nparameters ??, for all t?R,\ne?i?0tHred|z;??;?,??=|z;t +??;?,??. (50)\nSince one has, for all n?N,\ne?i?0tHred|E?n?= e?i?0tE?n |E?n?, (51)\none needs to factor out their complex phases from the quantities K?([n]),\nK?([n]) = ei??([n])K0?([n]), (52)\nwhere K0?([n]) > 0 are now real positive scalars. The stability condition (50) is then solved by\nchoosing, for all n = 1,2,???,\n??([n]) = ?0??bracketleftbigE?n ?E?n?1bracketrightbig, (53)\nand redefining\nC?0 (z) =C?0 (z)e?i?0??E?0 , (54)\n10\nwhereC?0 (z) are new complex functions of z. Hence,\n|z;??;?,??=\n?summationdisplay\nn=0,?\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK0?([n])!C\n?\n0 (z)e\n?i?0??E?n |E?\nn?. (55)\nHaving identified both the z and ?? dependences of the coherent states, finally let us\naccount for their (?,?) dependence and S2 vector character implicit so far through the two\nfunctionsC?0 (z). The latter are now chosen to be given as\nC+0 (z) = N+(|z|) cos?, C?0 (z) = N?(|z|)ei? sin?, (56)\nN?(|z|) being factors such that the constructed (p,q)-VCS be of unit norm,\nN?(|z|) =\nbraceleftBigg ?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2\nbracerightBigg?1/2\n. (57)\nThe convergence radii R? of these two series in z,\nR? = limn??\nbraceleftBig\n(q?p??)?(n?1) K0?([n])\nbracerightBig\n, (58)\ndepend on the choice of functions K0?([n]) as well as on (?,?) possibly. Specific cases are\nconsidered hereafter.\nConsequently, the (p,q)-VCS constructed here are properlydefined provided z?DR where\nDR denotes the disk in the complex plane centered at z = 0 and of radius R = min(R+,R?).\nTheir general structure is thus of the form\n|z;??;?,?? = N+(|z|) cos?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK0+([n])! e\n?i?0?+ E+n |E+\nn?\n+ N?(|z|)ei? sin?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK0?([n])! e\n?i?0??E?n |E?\nn?. (59)\nOnly the real positive functions K0?([n]) still need to be specified. They parametrize the remain-\ning freedom in the construction. Particular examples will be considered hereafter by imposing\nfurther requirements on these (p,q)-VCS. Note that the double limit p,q?1 yields the VCS of\nthe non-deformedJCm as obtained by Hussin and Nieto [14], briefly described in Section 2.\n4.2 Some expectation values\nBefore dealing with further requirements on the family of (p,q)-VCS, among which their over-\ncompleteness in the space V, let us consider some relevant expectation values for these states.\nGiven (59), the mean value ofHred for any of the (p,q)-VCS is simply\n?Hred? = |N+(|z|)|2 cos2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n+([n])!\nparenrightbig2 E+n\n+|N?(|z|)|2 sin2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2 E?n . (60)\n11\nLikewise for the ?number? operator associated to the ladder operators A? and A+, one finds\nthe expectation value\n?A+A?? = |z|2\nbraceleftBigg\n|N+(|z|)|2 cos2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n+1) |z|2n\nparenleftbigK0\n+([n])!\nparenrightbig2\n+|N?(|z|)|2 sin2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n+1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2\nbracerightBigg\n. (61)\nFinally, the average atomic spin time evolution ??3(t)? = ?U?1(t)?3U(t)?, with U(t) =\nexp{?i?0tHred}being the time evolution operator, has the form\n??3(t)?= 12\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1)\n|z|2nE([n+ 1])Q([n+ 1])\nbraceleftBigg\n?|N\n+(|z|)|2\nparenleftbigK0\n+([n])!\nparenrightbig2 cos2 ? + |N\n?(|z|)|2\nparenleftbigK0\n?([n])!\nparenrightbig2 sin2 ?\nbracerightBigg\n+?N+(|z|)N?(|z|)sin2?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nK0+([n])!K0?([n])!\n[n+ 1]\nQ([n+ 1]) cos?n(t), (62)\nwith\n?n(t) = ?0bracketleftbig(t+?+)E+n ? (t +??)E?nbracketrightbig + ? = ?0?En t + ?0bracketleftbig?+E+n ???E?nbracketrightbig+?. (63)\nAs is the case in the non-deformed model, the explicit time dependence which arises for the\natomic inversion ??3(t)? is due to the mixed state sector, namely the fact that the mixed-spin\nmatrix elements of the Heisenberg picture operator ?3(t) do not vanish when ? negationslash= 0. Hence,\nthe proposition which states that the time dependence of atomic inversion consists of Rabi\noscillations when a system is prepared in a coherent state of the radiation field [17] extends to\n(p,q)-VCS. However, in the limit where ??0, no such oscillations occur. Let us also point out\nthat the time dependence of??3(t)?diplays chaotic behaviour for appropriate values of the model\nparameters, as was previously mentioned for the q-deformation of the model, with 0 < q < 1, in\nthe work by Naderi et al. [24].\n4.3 Overcompleteness and the moment problem\nAn important property that coherent states ought to meet is that of overcompleteness in the\nspace over which they are defined [30]. In the present case, this means that the (p,q)-VCS in\n(59) must also provide a resolution of the identity operator over the subspaceV, namely\nIV = IV0 + IV =|E???E?| + IV, (64)\nwhile\nIV =\n?summationdisplay\nn=0,?\n|E?n??E?n|=\nintegraldisplay\nDR?S2\nd?(z;?,?)|z;??;?,???z;??;?,?|, (65)\nwhere d?(z;?,?) is some SU(2) matrix-valued integration measure over DR?S2 to be determined\nfrom the above requirement.\nLet us thus consider the following parametrization of that measure,\nd?(z;?,?) = d2zd? sin?d?\nbraceleftBigg\nW+(|z|)\n?summationdisplay\nn=0\n|E+n??E+n| + W?(|z|)\n?summationdisplay\nn=0\n|E?n??E?n|\nbracerightBigg\n, (66)\n12\nin terms of real weight functions W?(|z|) to be identified. Using the radial parametrization\nz = rei? and d2z = drrd? where r ? [0,?[ and ? ? [0,2?[, a direct substitution in (65)\nleads to the moment problem associated to the overcompleteness relation (65). In terms of the\nfunctions h?(r2) defined through\nh+(r2) = 4?\n2\n3 |N\n+(r)|2W+(r), h?(r2) = 8?2\n3 |N\n?(r)|2W?(r), (67)\nthe following two infinite sets of moment identities must be met, for all n?N,\nintegraldisplay R2\n0\nduun h?(u) =\nparenleftbiggq?\np?\nparenrightbigg?n(n?1) parenleftbig\nK0?([n])!parenrightbig2 . (68)\nIn conclusion, the resolution of the identity operator over V in terms of the (p,q)-VCS\nis achieved provided the Stieljes moment problem (68) can be solved [36, 37]. This requires a\nchoice of functions K0?([n]) > 0 such that not only the conditions (68) may all be met, but also\nsuch that the normalization factors N?(|z|) converge in a non-empty disc of the complex plane.\nAs a result of this analysis, a priori there may exist a large number of sets of (p,q)-VCS\nwhich fulfill all the above properties, namely continuity in the complex parameter z, temporal\nstability through a simple additive time dependence in the real parameters ??, a unit vector\nvalued characterization on the sphere S2 in terms of the spherical coordinates ? and ?, and the\ncompleteness propertyof a resolution of the unit operator with a SU(2) matrix-valued integration\nmeasure over these spaces. These sets of (p,q)-VCS are distinguished from one another by\ndifferent choices of real positive weight factors K0?([n]), in agreement with the considerations\ndeveloped in [30, 38]. The above construction of (p,q)-VCS is general, but can admit explicit\nexact solutions to the moment problem(68) for particular cases. Concrete examples are discussed\nin Section 5..\n4.4 Action-angle variables\nOne of the useful properties that general coherent states constructed according to the arguments\nof [38] possess, is that action-angle variables are readily identified in relation to the continuous\nparameters ensuring stability of the coherent states under time evolution. In the present case,\ncanonical reduced action-angle variables (J?(t),??(t)) are such that for the previously evaluated\nexpectation values of the reduced Hamiltonian (24) in the (p,q)-VCS, one has\n?Hred?= J+ ?+ + J? ?? =\nsummationdisplay\n?\nJ? ??, (69)\nin relation to the action-angle variational principle of the form\nintegraldisplay\ndt\nsummationdisplay\n?\nbracketleftbiggd?\n?\ndt J? ? ??J?\nbracketrightbigg\n??\nintegraldisplay\ndt\nbracketleftbigg\n? i?\n0\nd\ndt???H\nred?\nbracketrightbigg\n, (70)\nwhere ?? are two constant factors to be chosen appropriately. Consequently\nd??\ndt =\n??Hred?\n?J? = ??,\ndJ?\ndt =?\n??Hred?\n??? = 0. (71)\n13\nGiven the time evolution, ??(t) = t + ??(0), one simply finds ?? = 1. From the expression in\n(60), one then has the identifications\nJ+ = |N+(|z|)|2 cos2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n+([n])!\nparenrightbig2 E+n ,\nJ? = |N?(|z|)|2 sin2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2 E?n . (72)\nAs a final remark, let us mention that the saturated Heisenberg uncertainty relations\nwhich are obeyed by q- and (p,q)-coherent states are also well-known in q-mechanics (see for\ninstance [39]). Such minimal uncertainties may be characterized through small corrections to\ncanonical commutation relations defined in [39, 40]. Such properties in the case of the (p,q)-VCS\nconstructed here are deferred to a later study.\n5 Explicit Solutions\nIn order to completely specify the quantities K0?([n]), one last set of conditions needs to be\nimplemented. In the present Section, two such choices are discussed, one of which allows for an\nexact and explicit solution to the moment problem, hence the construction of a set of (p,q)-VCS.\nFirst, in line with the illustrative example of Section 2, we consider restricting the algebra of the\nladder operatorsA?. Then as a second and independent possibility, we apply a final additional\ncriterion developed in [30] in order to uniquely characterize a set of coherent states which meet\nalready all the requirements considered heretofore and having led to the representation (59),\neven though the moment problem remains unsolved for that choice.\n5.1 Constraining the ladder operator algebra\nIn order to uniquely identify the set of functions K0?([n]) > 0, let us consider the possibility\nthat this may be achieved by restricting the algebraic properties of the ladder operators. In line\nwith the general (p,q)-deformations of the Fock algebra in (2), let us constrain the algebra of\nthe operators A? acting onV to be such that\nA?A+ ? q0A+A? = p?N0 =\n?summationdisplay\nn=0,?\n|n,??p?n0 ?n,?|,\nA?A+ ? p?10 A+A? = qN0 =\n?summationdisplay\nn=0,?\n|n,??qn0 ?n,?|, (73)\nwhere p0 and q0 are again two real parameters such that p0 > 1, 0 < q0 < 1 and p0q0 < 1, which\nmay or may not be identical to p and q. For instance, we could have p0 = 1 and q0 = 1 thus\ncorresponding to an ordinary Fock algebra, or else p0 = p and q0 = q, but also more generally\np0 = p? and q0 = q?, ? being some real constant. As a matter of fact, exact solutions to the\nmoment problem are presented hereafter in all these situations.\nIn terms of the ladder operatorsA? =UA?U? acting on the subspaceV, the associated\nalgebraic constraint reads\nA?A+ ? q0A+A? =\n?summationdisplay\nn=0,?\n|E?n?p?n0 ?E?n|,\n14\nA?A+ ? p?10 A+A? =\n?summationdisplay\nn=0,?\n|E?n?qn0 ?E?n|. (74)\nWhether in terms of (73) or (74), these algebraic constraints translate into the following identi-\nties, for all n?N,\nparenleftbigK0\n?([n+ 1])\nparenrightbig2 ? q\n0\nparenleftbigK0\n?([n])\nparenrightbig2 = p?n\n0 ,\nparenleftbigK0\n?([n+ 1])\nparenrightbig2 ? p?1\n0\nparenleftbigK0\n?([n])\nparenrightbig2 = qn\n0. (75)\nGiven the initial values K0?([0]) = 0, the solution to these recursion relations is simply\nK0?([n]) =\nradicalBig\n[n](p0,q0) =\nradicalBig\n[n](q?1\n0 ,p\n?1\n0 )\n, (76)\nwhere4\n[n](p0,q0) = p\n?n\n0 ?qn0\np?10 ?q0 =\nparenleftbigq?1\n0\nparenrightbig?n?parenleftbigp?1\n0\nparenrightbign\nparenleftbigq?1\n0\nparenrightbig?1?parenleftbigp?1\n0\nparenrightbig = [n](q?10 ,p?10 ). (77)\nGiven this solution, the normalization factors are defined by the series\n|N?(|z|)|?2 =\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\n[n](p0,q0)!, (78)\nof which the convergence radius is\nR = limn??\nbracketleftBiggparenleftbigg\nq?\np?\nparenrightbigg?2(n?1) p?n\n0 ?qn0\np?10 ?q0\nbracketrightBigg1/2\n= limn??\nbracketleftbiggparenleftbig\np0p?2?q2?parenrightbig?(n?1) 1?(p0q0)\nn\n1?(p0q0)\nbracketrightbigg1/2\n. (79)\nProvided p0p?2?q2? < 1, a condition which we shall henceforth assume to be satisfied5, this\nradius of convergence is infinite, R =?, and the moment problem (68) then becomes, for all\nn?N, integraldisplay\n?\n0\nduun h?(u) =\nparenleftbiggq?\np?\nparenrightbigg?n(n?1) parenleftbig\n[n](p0,q0)!parenrightbig. (80)\nIn order to solve these equations, the Ramanujan integral (121) discussed in the Appendix\nsuggests itself quite naturally, through a simple but appropriate rescaling of its arguments in\nthe form of (123).\nAfter a little moment?s thought one comes to the conclusion that a solution to (80) based\non (123) is possible for the following choice of parameters,\n? = 12, ? = 0, p0 = p, q0 = q, (81)\nin which case p0p?2?q2? = pq < 1, hence corresponding indeed to an infinite radius of conver-\ngence. For this choice, one has (for definitions of the (p,q)-exponential functions appearing in\nthese expressions, see the Appendix),\nh?parenleftbig|z|2parenrightbig=\nparenleftbigp?1?qparenrightbig\nqlog(1/pq) e(p,q)\nparenleftBig\n?|z|2 p?1/2q?1parenleftbigp?1?qparenrightbig\nparenrightBig\n, (82)\n4Incidentally, it is because of this identity, corresponding to the exchange p0 ? q?1\n0 , that the two solutions to\nthe above two recursion relations are consistent, as are the two algebraic restrictions in (73) and (74).\n5If p0p?2?q2? = 1, the radius of convergence is finite with R = (1?p0q0)?1/2, while when p0p?2?q2? > 1 the\nradius of convergence vanishes, implying that (p,q)-VCS cannot be constructed in such a case.\n15\nas well as6\nparenleftbigK0\n?([n])\nparenrightbig2 = [n], |N?(|z|)|?2 =E(1/2,0)\n(p,q)\nparenleftBig\n|z|2q?1/2parenleftbigp?1?qparenrightbig\nparenrightBig\n, (83)\nwith for the weight functions W?(|z|) in the integration measure (66) of the overcompleteness\nrelation (65),\nW+ (|z|) = 34?2 |N+ (|z|)|?2 h+parenleftbig|z|2parenrightbig, W?(|z|) = 38?2 |N?(|z|)|?2 h?parenleftbig|z|2parenrightbig. (84)\nExplicit expressions for all previously computed quantities readily follow, beginning with the\ndefinition of the associated (p,q)-VCS which then meet all thenecessary requirements expected of\ncoherent states. Note that up to the coefficients 3/(2?) and 3/(4?), the reduced weights obtained\nare compatible with that of the q-shape invariant harmonic oscillator [20]. Furthermore, (82)\nis a (p,q)-generalization of the q-harmonic oscillator coherent state moment problem solution\nconstructed in [41]. Finally, in the double limit p,q?1, the results of [14] are recovered.\nThe functions (82) thus provide a complete and explicit solution to the moment problem of\nthe (p,q)-VCS for the (p,q)-JCm such that the ladder operatorsA? obey the same (p,q)-Fock\nalgebra as the original modes a and a? of the initial Hamiltonian (24), namely with the choice\np0 = p and q0 = q. It is also possible to construct an explicit solution when the ladder operators\nA? are constrained to rather obey the ordinary non-deformed Fock algebra onV, corresponding\nto the choice p0 = 1 and q0 = 1. One then has to consider7, for all n?N,\nK0?([n]) =?n,\nintegraldisplay ?\n0\nduun h?(u) =\nparenleftbiggq?\np?\nparenrightbigg?n(n?1)\n(n!), p??q??1. (85)\nAn obvious solution to this moment problem is obtained when ? = 0 = ?, in which case the\ncondition for an infinite radius of convergence is saturated. One then has\nh?parenleftbig|z|2parenrightbig= e?|z|2, |N? (|z|)|?2 = e|z|2, W+ (|z|) = 34?2, W?(|z|) = 38?2. (86)\nIn fact, the above two explicit solutions belong to a general class of solutions obtained\nby taking (p0,q0) = (p?,q?) with ? a positive real parameter, ? > 0, such that p??2?q2? < 1\nin order to ensure an infinite radius of convergence8 in z ?C. Once again based on (123), an\nexplicit solution to the moment problem (80) is achieved for the following choice of parameters,\n? = 12?, ? = 0, p0 = p?, q0 = q?, (87)\nfor which the radius of convergence is indeed infinite, p??2?q2? = (pq)? < 1. One then has\nh?parenleftbig|z|2parenrightbig= (p\n???q?)\nq? log(1/p?q?) e(p?,q?)\nparenleftBig\n?|z|2 p??/2q??parenleftbigp???q?parenrightbig\nparenrightBig\n, (88)\nwith\n|N?(|z|)|?2 =E(1/2,0)(p?,q?)\nparenleftBig\n|z|2q??/2parenleftbigp???q?parenrightbig\nparenrightBig\n, (89)\nleading finally to the weight functionsW?(|z|) given in terms of the latter two quantities through\nthe same relations as in (84). In the limits that ? ? 1 or ? ? 0, the previous two explicit\nsolutions are then recovered as particular cases.\n6Restricting to p0 = p and q0 = q but keeping ? and ? arbitrary such that p1?2?q2? < 1 in order to retain an\ninfinite radius of convergence, one has parenleftbigK0?([n])parenrightbig2 = [n] and |N? (|z|)|?2 = E(?,?)(p,q) parenleftbig|z|2 p? q??parenleftbigp?1 ?qparenrightbigparenrightbig, hence\nalso all other previous expressions given accordingly.\n7Leading to |N? (|z|)|?2 = e(?,?)\n(p,q)\nparenleftbig|z|2 p? q??parenrightbig, which converges for all |z| < ? provided p??q? ? 1.\n8Leading to |N? (|z|)|?2 = E(?/?,?/?)\n(p?,q?)\nparenleftbig|z|2p?q??(p?? ?q?)parenrightbig.\n16\n5.2 The action identity constraint\nAn alternative to fixingthe factors K0?([n]) through conditions on the algebra ofladder operators,\nis to consider the action identity constraint discussed in [30] as the one last requirement which\nsingles out coherent states uniquely. In the case of the ordinary Fock algebra, this action\nidentity constraint is equivalent to requiring that the ladder operators obey themselves the Fock\nalgebra as well. We shall establish that this is not the case for the (p,q)-VCS of the (p,q)-JCm\nconstructed above.\nGiven the relations (72), in the present model the action identity constraint is of the form\nJ+ = cos2 ?parenleftbig|z|2 +E+0 parenrightbig, J? = sin2 ?parenleftbig|z|2 +E?0 parenrightbig. (90)\nBy direct substitution into these constraints of the relations (72), the identification of the suc-\ncessive powers in|z|2 leads to the following solution for the factors K0?([n]),\nK0?([n]) =\nparenleftbiggq?\np?\nparenrightbigg(n?1) radicalBig\nE?n ? E?0 . (91)\nThese positive real quantities are thus well-defined provided one has E?n > E?0 for all n ? 1,\nas is implicitly assumed. It is noteworthy that, as (p,q) ? (1+,1?), these factors reduce to\nexactly those obtained in [16] by the factorization method. On the other hand, since the present\nsolution for K0?([n]) cannot be brought into the form of (76) for some choice of constants p0 and\nq0 meeting our assumptions for these quantities, it follows indeed that for the (p,q)-JCm the\naction identity constraint is not equivalent to requiring an algebraic constraint on the ladder\noperators of the (p0,q0)-deformed Fock algebra type.\nThis choice also allows for the factorization of the Hamiltonian in (36) in the form\nHred = A+\nparenleftbiggq?\np?\nparenrightbigg?2N\nA +\n?summationdisplay\nn=0,?\n|n,??E?0 ?n,?|, (92)\nextending a similar expression in [14].\nGiven this solution for the factors K0?([n]), the general moment problem (68) reduces to\nthe following conditions,\nintegraldisplay R2\n0\ndu h?(u) = 1;\nintegraldisplay R2\n0\nduun h?(u) =\nnproductdisplay\nk=1\nparenleftbigE?\nk ?E\n?\n0\nparenrightbig, n = 1,2,3,???, (93)\nwhere the radius of convergence R is given as\nR = min (R+,R?), R? = limn?+?\nradicalBig\nE?n ?E?0 . (94)\nIn the absence of a detailed analysis of the energy spectra E?n as functions of the parameters p,\nq, ? and ? and the function h(p,q), nothing more explicit may be said concerning this moment\nproblem. Since when p > 1 the quantities [n] always possess a turn-around behaviour as func-\ntions of n for n sufficiently large, it is to be expected generally that the radius of convergence\nR, hence the moment problem as well, are associated to a finite disk DR in the complex plane.\nNevertheless, one conclusion of the present discussion is that indeed for the (p,q)-VCS consid-\nered in this work, the action identity constraint leads to coherent states different from those\nconstructed in Section 5.1 and for which explicit solutions to the moment problem have been\ngiven.\n17\n5.3 The spin decoupled limit ? = 0\nIn the limit that ? = 0, the two spin sectors of the model are decoupled, and the (p,q)-JCm\nreduces to the supersymmetric harmonic oscillator [43, 44, 18] with a (p,q)-deformation. Diago-\nnalization of the reduced Hamiltonian (24) is then of course straightforward in the ?3-eigenbasis,\nwith, for n = 0,1,2,???,\nHred?=0|n,??= ??n |n,??, ??n = (1 +?)h(p,q)[n] + 12(1 +?)?12. (95)\nFrom that point of view, one thus has two decoupled (p,q)-deformed Fock bases, for which\none could consider the usual (p,q)-coherent states in each spin sector separately. However, such\ncoherent states do not coincide with any of those constructed in this paper and obtained in the\nlimit ? = 0, because of the distinguished role played by the singleton state |E?? = |0,?? and\nthe S2 unit vector character of the (p,q)-VCS. In particular the ladder operators A? acting\nwithin each of the towers |E?n? do not coincide with the annihilation and creation operators a\nand a? defining the Hamiltonian (24), even in the decoupled limit ? = 0. As a matter of fact,\nthe action of the ladder operatorsA? may switch between the two spin sectors as a function of\nn depending on the sign of the quantityE([n+ 1]).\nMore specifically, let us introduce the notation\nsn = signE([n+ 1]), n?N. (96)\nIn the limit that ? = 0, one has Q([n + 1]) =|E([n + 1])|/2, so that the mixing angle ?([n]) is\nnow such that, for all n?N,\n? = 0 : sin?([n]) = 12(1?sn)(sign?), cos?([n]) = 12(1 +sn). (97)\nConsequently, the towers of energy eigenstates|E?n?are then given as follows, for all n?N,\nIf sn = +1 : |E+n??=0 =|n+1,??, |E?n??=0 =|n,+?;\nIf sn =?1 : |E+n??=0 = (sign?)|n,+?, |E?n??=0 =?(sign?)|n + 1,??,\n(98)\nwhile the energy eigenvalues are given as\nIf sn = +1 : E+n (? = 0) = (1 +?)h(p,q)[n +1] + 12(1 +?) ? 12,\nE?n (? = 0) = (1 +?)h(p,q)[n] + 12(1 +?) + 12;\nIf sn =?1 : E+n (? = 0) = (1 +?)h(p,q)[n] + 12(1 +?) + 12,\nE?n (? = 0) = (1 +?)h(p,q)[n +1] + 12(1 +?) ? 12.\n(99)\nThese spectra do indeed coincide with those in (95), once the singleton state|E??=|0,??with\nE? = ?/2 is included as well.\nThese expressions show how, even in the decoupled spin limit ? = 0, the (p,q)-VCS\nconstructed here are not simply the juxtaposition of two separate (p,q)-coherent states of the\n(p,q)-deformed Fock algebra in each of the two spin sectors. Since the spectrum of the system\nis discrete infinite, by leaving aside the singleton state|0,??, all the remaining states still allow\nfor similar types of constructions of coherent states, but in such a way that different spin sectors\nare getting superposed, leading to the SU(2) vector coherent states of the type studied here. All\nthe expressions detailed in the previous sections for the (p,q)-VCS may readily be particularized\nto the limit ??0.\n18\n6 Conclusion\nIn this work, we considered (p,q)-deformations of the Jaynes-Cummings model in the rotating\nwave approximation, extending recent developments on this topic in the non-deformed case [14].\nHaving introduced (p,q)-deformed versions of the model, first its energy eigenspectrum has been\nidentified, enabling the definition of different relevant operators acting on Hilbert space and the\ncharacterization of the spectrum in terms of two separate infinite discrete towers and a singleton\nstate. Among these operators, ladder operators acting within each of the two towers separately\nmay be considered, defined up to some arbitrary normalization factors.\nSuch a structure sets the stage for the introduction of vector coherent states for the (p,q)-\ndeformed Jaynes-Cummings model, following the approach of [14] and the rationale outlined\nin [30]. These (p,q)-VCS are parametrized by elements of C?S2, and enjoy temporal sta-\nbility through a further action-angle identification. The moment problem associated to the\novercompleteness property of these (p,q)-VCS involves SU(2)-valued matrix weight functions.\nUsing (p,q)-arithmetic techniques, some explicit and exact solutions to the moment problem\nhave been displayed, hence characterizing specific classes of such (p,q)-VCS. All these solutions\nprovide (p,q)-extensions to the non-deformed vector coherent states of theJCm considered in\n[14]. These explicit solutions are obtained by requiring that specific algebraic constraints of the\n(p,q)-deformed Fock algebra type be obeyed by the ladder operators. However, in contradis-\ntinction to [14], we have not been able to display an explicit and exact solution to the moment\nproblem in the generic case by imposing an action identity constraint.\nFinally, the spin decoupled limit of these models was considered, corresponding to a (p,q)-\nsupersymmetric oscillator of which the two sectors are intertwined in a manner depending on\nthe sign of the energy level spacing between the two decoupled spin sectors as function of the\nexcitation level. In the non-deformed limit (p,q) = (1,1), this feature disappears, reproducing\nthe ordinary supersymmetric oscillator. Our results thus provide new classes of generalized\nversions of theJCm in the rotating wave approximation [20, 18]. Finally, the (p,q)-VCS built\nhere extend the q-coherent states obtained by other techniques involving supersymmetric shape\ninvariance and self-similar potential formalisms applied to the harmonic oscillator [20, 45].\nAcknowledgements\nJ. B. G. is grateful to the Abdus Salam International Centre for Theoretical Physics (ICTP,\nTrieste, Italy) for a Ph.D. fellowship under the grant Prj-15. M. N. H. is particularly indebted\nto V. Hussin for discussions relating to the JCm as well as for provided references during his\nstay at the Centre de Recherches Math?ematiques, Universit?e de Montr?eal, Canada. The ICMPA\nis in partnership with the Daniel Iagoniltzer Foundation (DIF), France.\nJ. G. acknowledges a visiting appointment as Visiting Professor in the School of Physics\n(Faculty of Science) at the University of New South Wales. He is grateful to Prof. Chris Hamer\nand the School of Physics for their hospitality during his sabbatical leave, and for financial sup-\nport through a Fellowship of the Gordon Godfrey Fund. His stay in Australia is also supported\nin part by the Belgian National Fund for Scientific Research (F.N.R.S.) through a travel grant.\nJ. G. acknowledges the Abdus Salam International Centre for Theoretical Physics (ICTP,\nTrieste, Italy) Visiting Scholar Programme in support of a Visiting Professorship at the ICMPA.\nHis work is also supported by the Belgian Federal Office for Scientific, Technical and Cultural\nAffairs through the Interuniversity Attraction Pole (IAP) P5/27.\n19\nAppendix\nThis appendix lists some useful facts related to the (p,q)-boson algebra and associated functions.\nThe (p,q)-deformed oscillator algebra introduced in [5] is generated by operators a, a? and N\nobeying the relations\n[N,a] =?a, [N,a?] = a?,\naa??qa?a = p?N, aa??p?1a?a = qN. (100)\nThroughout the text, we assume the real parameters p and q are such that p > 1, 0 < q < 1\nand pq < 1. The limit p ? 1+ yields the q-oscillator of Arik and Coon [3] while p = q gives\nthe q-deformed oscillator algebra of Biedenharn and MacFarlane [4]. Finally, the algebra (100)\nreduces to the ordinary harmonic oscillator Fock algebra as q ? 1 for p = 1+ or p = q. At\nany stage of the discussion, the (p,q)-deformed model readily reduces to its usual counterpart\nas (p,q)?(1,1).\nThe associated (p,q)-deformed Fock-Hilbert space representation is spanned by the vac-\nuum|0?annihilated by a and the orthonormalized states|n?, such that\na|0?= 0, ?0|0?= 1, |n?= 1radicalBig\n[n](p,q)!\nparenleftBig\na?\nparenrightBign\n|0?,\na|n?=\nradicalBig\n[n](p,q)|n?1?, a?|n?=\nradicalBig\n[n+ 1](p,q)|n+ 1?, N|n?= n|n?, (101)\nwhere the symbol [n](p,q) = (p?n?qn)/parenleftbigp?1?qparenrightbigis called (p,q)-basic number with, by conven-\ntion, [0](p,q) = 0, and its (p,q)-factorial is defined through [n](p,q)! = [n](p,q)parenleftbig[n?1](p,q)!parenrightbig and\nthe convention [0](p,q)! = 1. There exists a formal (p,q)-number operator denoted by [N](p,q), or\nsimply by [N] when no confusion arises. As a matter of fact, from the second pair of relations\nin (100), it follows that [N] = a?a as well as [N + 1] = aa?. One has of course [N]|n?= [n]|n?.\nHence, (101) provides a well defined Fock-Hilbert representation space of the algebra (100).\nThe following relations hold for any function f ?f(N) and consequently for any function\nof [N],\naf(N?1) = f(N)a, a?f(N) = f(N?1)a?. (102)\nLet us define q-shifted products and factorials and their (p,q)-analogues. Using the nota-\ntions of [46], for any quantity x, (x;q)? is constructed as follows,\n(x;q)0 = 1, (x;q)? = (x;q)?(xq?;q)\n?\n, (x;q)? =\n?productdisplay\nn=0\n(1?xqn). (103)\nFurthermore, in the notations of [10], (p,q)-shifted products and factorials are defined as follows,\nfor any real quantities a and b such that anegationslash= 0,\n[a,b;p,q]0 = 1, [a,b;p,q]? = [a,b;p,q]?[ap?,bq?;p,q]\n?\n, [a,b;p,q]? =\n?productdisplay\nn=0\nparenleftbigg 1\napn ?bq\nn\nparenrightbigg\n. (104)\nFor ? = n?N, we have\n[p?,q?;p,q]n =\nparenleftbigg 1\np? ?q\n?\nparenrightbiggparenleftbigg 1\np?+1 ?q\n?+1\nparenrightbigg\n...\nparenleftbigg 1\np?+n?1 ?q\n?+n?1\nparenrightbigg\n20\n= p??n?n(n?1)/2(p?q?;pq)n. (105)\nThis identity is a central formula since it defines a bridge between q- and (p,q)-analogue quan-\ntities and functions.\nLet us now introduce q-analogues of the ordinary exponential funtion. There exist many\ntypes of q-deformations of the exponential function ez, z ?C (see, for instance, [9]). For any\n(z,?)?C?R, the (?,q)-exponential is the complex function [9]\nE(?)q (z) =\n?summationdisplay\nn=0\nq?n2\n(q;q)nz\nn. (106)\nThis series has an infinite radius of convergence for ? > 0. For ? = 0 its domain of definition\nreduces to the unit disk, |z| < 1, while it is nowhere convergent in C for ? < 0. Rescaling\nz?z(1?q) and taking the limit limq?1 E?q (z(1?q)), one recovers ez. For some specific values\nof ?, (106) reproduces some standard q-exponentials [9, 11],\nE(0)q (z) = eq(z) = 1(z;q)\n?\n=\n?summationdisplay\nn=0\nzn\n(q;q)n, |z|< 1, (107)\nE(1/2)q (z) = Eq(q1/2z) = (?q1/2z;q)?, z?C, (108)\nwhere\nEq(z) =\n?summationdisplay\nn=0\nqn(n?1)/2zn\n(q;q)n , z?C, (109)\nis known as the Jackson q-exponential [6]. Note that whereas E(?)q (z) is defined in the entire\ncomplex plane, |z| < ?, for any ? > 0, its reduction eq(z) is only defined on the unit disc.\nFinally, it is also well established that [11]\nEq(?z)eq(z) = 1. (110)\n(p,q)-analogues of the usual exponential function ez, z?C may also be introduced (see,\nfor instance, [10]). Given any (z,?,?)?C?R?R, consider the (?,?,p,q)-exponential function\nE(?,?)(p,q) (z) =\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn2 zn\n[p,q;p,q]n. (111)\nKeeping in mind the condition pq < 1, the radius of convergence R of this series is such that\nR1 =\n?\n?\n?\n?, if q2?p1?2? < 1;\np??1q??, if q2?p1?2? = 1;\n0, if q2?p1?2? > 1.\n(112)\nThus the functionE(?,?)(p,q) (z) exists only provided q2?p1?2? ?1.\nIn order to recover the usual exponential function, one has to rescale z?z(p?1?q), for\nexample, and then take the limit lim(p,q)?(1,1)E?,?(p,q)(z(p?1?q)) = ez. For particular values of\nthe parameters ? and ?, (111) reproduces known (p,q)-exponentials,\nE(1/2,1/2)(p,q) (z) = E(p,q)\nparenleftBiggparenleftbigg\nq\np\nparenrightbigg1/2\nz\nparenrightBigg\n=\n?summationdisplay\nn=0\nparenleftbiggq\np\nparenrightbiggn2/2 zn\n[p,q;p,q]n, (113)\n21\nwhere\nE(p,q)(z) =\n?summationdisplay\nn=0\nparenleftbiggq\np\nparenrightbiggn(n?1)/2 zn\n[p,q;p,q]n. (114)\nThe function E(p,q) may be found in [10]. Note that (114) coincides with (109) as p?1. In the\nsame limit, (111) reproduces the (?,q)-deformed exponential map E(?)q (z) [9]. If ? = 0 = ? the\nseries (111) is not defined since then R = 0, unless one has taken p = 1 in which case the radius\nof convergence is unity. A (p,q)-analogue of (107) is given by\ne(p,q)(z) =\n?summationdisplay\nn=0\n1\npn2/2\nzn\n[p,q;p,q]n, |z|< p\n?1/2, (115)\nwhich reproduces exactly eq(z) converging in the unit disc as p ? 1+. Furthermore, we have\nfrom (105)\ne(p,q)(z) =\n?summationdisplay\nn=0\n(p1/2z)n\n(pq;pq)n = epq(p\n1/2z). (116)\nUsing (105) and (109), we may also write\nE(p,q)(z) =\n?summationdisplay\nn=0\nparenleftbiggq\np\nparenrightbiggn(n?1)/2 zn\np?n(n+1)/2(pq;pq)n\n=\n?summationdisplay\nn=0\nqn(n?1)/2 (zp)\nn\n(pq;pq)n = Epq(pz). (117)\nThen taking into account (110), (116) and (117), a (p,q)-analogue of (110) is given by\nEpq(?pz)epq(pz) = E(p,q)(?z)e(p,q)(p1/2z) = 1. (118)\nFinally, consider\ne(?,?)(p,q)(z) =\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn2 zn\nn!. (119)\nTherefore, e(?,?)(p,q)(z), which converges to ez as (p,q) ? (1,1), provides a (p,q)-deformed ex-\nponential analogue to the q-function used by Penson and Solomon [42] which coincides with\ne(1,?)(1,q)(q?1/2z). The radius of convergence of (119) is given as\nR2 =\nbraceleftbigg ?, if q?p?? ?1;\n0, if q?p?? > 1. (120)\nFinally, consider the Ramanujan integral [7, 19], valid for any integer n?N,\nintegraldisplay ?\n0\ndttn eq(?t) =? (q;q)nqn(n+1)/2 logq. (121)\nThrough the change of variables\nq?pq, t??0 p?1/2 t, ?0 > 0, (122)\nand using once again (105), the following identity is obtained, for any n?N,\nintegraldisplay ?\n0\ndttn e(p,q)\nparenleftBig\n??0p?1/2t\nparenrightBig\n= [p,q;p,q]n?n+1\n0 qn(n+1)/2\nlog\nparenleftbigg 1\npq\nparenrightbigg\n. (123)\nThis result is indeed a (p,q)-analogue of the Ramanujan integral (121).\n22\nReferences\n[1] S. Majid, Quantum Groups (Cambridge Univ. Press, Cambridge, 1995);\nV. G. Drinfeld, Quantum Groups, Lecture Notes in Mathematics, Ed. P. P. Kulish (Springer,\nBerlin, 1992).\n[2] See for example,\nJ. Wess and B. Zumino, Nucl. Phys. B (Proceedings Supplements) 18, 302-312 (1991);\nA. Lorek and J. Wess, Z. Phys. C 67, 671-680 (1995).\n[3] M. Arik and D. D. Coon, J. Math. Phys. 17, 524-527 (1976).\n[4] A. J. Macfarlane, J. Phys. A: Math. Gen. 22, 4581-4588 (1989);\nL. C. Biedenharn, J. Phys A: Math. Gen. 22, L873-L878 (1989).\n[5] R. Chakrabarti and R. Jagannathan, J. Phys. A: Math. Gen. 26, L711-L719 (1991).\n[6] F. Jackson, Mess. Math. 38, 57 (1909).\n[7] S. Ramanujan, Mess. Math. 44, 10-18 (1915).\n[8] H. Exton, q-Hypergeometric Functions and Application (John Wiley and Sons, New York,\n1983).\n[9] F. Floreanini and L. Vinet, Lett. Math. Phys. 22, 45-54 (1991);\nF. Floreanini, J. LeTourneux and L. Vinet, J. Phys. A: Math. Gen. 28, L287-L239 (1995).\n[10] R. Floreanini, L. Lapointe and L. Vinet, J. Phys. A: Math. Gen. 26, L611-L614 (1993).\n[11] R. Koekoek and R. F. Swarttouw, The Askey-scheme of hypergeometric orthogonal polyno-\nmials and its q-analogue, Delft University Technology, Report 94-05 (1994).\n[12] E. T. Jaynes and F. Cummings, FW Proc. IEEE 51, 89-109 (1963).\n[13] P. Meystre and E. M. Wright, Phys. Rev. A 37, 2524 (1988).\n[14] V. Hussin and L. M. Nieto, J. Math. Phys. 46, 122102 (2005).\n[15] Y. B?erub?e-Lauziere, V. Hussin and L. M. Nieto, Phys. Rev. A 50, 1725 (1994).\n[16] L. Dello Sbarba and V. Hussin, in Group of Theoretical Methods in Physics: Proceeding\nof the XXV International Colloqium on Group Theoretical Methods in Physics, Institute\nof Physics Conferences Series, Vol. 185, Eds. G. S. Pogosyan, L. E. Vincent and K. B. Wolf\n(IOP, Bristol, 2005).\n[17] M. Daoud and V. Hussin, J. Phys. A: Math. Gen. 35, 7381-7402 (2002).\n[18] M. Daoud and J. Douari, Int. J. Mod. Phys. B 17, 2473-2486 (2003).\n[19] A. B. Balantekin, To be published in the Proceedings of ?Computational And Group The-\noretical Methods In Nuclear Physics: Symposium In Honor Of Jerry P. Draayer?s 60th\nBirthday, 18-21 Feb 2003, Playa del Carmen, Mexico?; e-print arXiv:nucl-th/0309038.\n23\n[20] A. N. F. Aleixo, A. B. Balantekin and M. A. Candido Ribeiro, J. Phys. A: Math. Gen. 35,\n9063-9070 (2002);\nA. N. F. Aleixo, A. B. Balantekin and M. A. Candido Ribeiro, J. Phys. A: Math. Gen. 36,\n11631-11642 (2003);\nA. N. F. Aleixo and A. B. Balantekin, J. Phys. G 30, 1225-1230 (2004).\n[21] B. Buck and C. V. Sukumar, Phys. Lett. A 81, 132 (1981).\n[22] M. Chaichan, D. Ellinas and P. Kulish, Phys. Rev. Lett. 65, 980-983 (1990).\n[23] Z. Chan, Phys. Rev. A 47, 5017-5023 (1993).\n[24] M. H. Naderi, M. Soltanolkotabi and R. Roknizadeh, Journal of the Physical Society of\nJapan 73, 2413-2423 (2004).\n[25] G. Dresselhaus, Phys. Rev. 100, 580 (1955).\n[26] For a recent review on spintronics, see\nJ. Schliemann, e-print arXiv:cond-mat/0602330.\n[27] S-Q. Shen, Y-J Bao, M. Ma, X. C. Xie and F. C. Zhang, Phys. Rev. B 71, 155316 (2005).\n[28] S-Q. Shen, M. Ma, X. C. Xie and F. C. Zhang, Phys. Rev. Lett. 92, 256603 (2004).\n[29] S. T. Ali and F. Bagarello, J. Math. Phys. 46, 053518 (2004).\n[30] J-P. Gazeau and J. R. Klauder, J. Phys. A: Math. Gen. 32, 123 (1999).\n[31] J-P. Antoine, J-P. Gazeau, P. Monceau, J. R. Klauder and K. A. Penson, J. Math. Phys.\n42, 2349 (2001).\n[32] S. T. Ali, J-P. Antoine and J-P. Gazeau, Coherent States, Wavelets and their Generaliza-\ntions (Springer-Verlag, Berlin, 2000).\n[33] F. G. Scholtz, B. Chakraborty, S. Gangopadhyay and J. Govaerts, J. Phys. A: Math. Gen.\n38, 9849-9858 (2005).\n[34] F. G. Scholtz, B. Chakraborty, S. Gangopadhyay and A. Ghosh Hazra, Phys. Rev. D 71,\n085005 (2005).\n[35] J. Ben Geloun, J. Govaerts and M. N. Hounkonnou, A (p,q)-deformed Landau problem\nin a spherical harmonic well: spectrum and noncommuting coordinates, preprint ICMPA-\nMPA/2006/22, CP3-06-12, e-print arXiv:hep-th/0609120, submitted to J. Phys. A: Math.\nGen.\n[36] M. N. Hounkonnou and K. Sodoga, J. Phys. A: Math. Gen. 38, 7851-7862 (2005).\n[37] For an exhaustive dicussion on the moment problem, see for instance\nB. Simon, Adv. Math. 137, 82-203 (1998).\n[38] J. R. Klauder, Contribution to the 7th ICSSUR Conference, June 2001, e-print\narXiv:quant-ph/0110108.\n[39] A. Kempf, J. Math. Phys. 35, 4483 (1994);\nH. Hinrichsen and A. Kempf, J. Math. Phys. 37, 2121 (1996).\n24\n[40] C. Quesne, K. A. Penson and V. M. Tkachuk, Phys. Lett. A 313, 29-36 (2003).\n[41] C. Quesne, J. Phys. A: Math. Gen. 35, 9213-9226 (2002).\n[42] K. A. Penson and A. I. Solomon, J. Math. Phys. 40, 2354 (1999).\n[43] C. Aragone and F. Zypman, J. Phys. A: Math. Gen. 19, 2267-2279 (1986).\n[44] M. Orszag and S. Salamo, J. Phys. A: Math. Gen. 21, L1059-L1064 (1988).\n[45] F. Cooper, A. Khare and U. Sukhatme, Supersymmetry in Quantum Mechanics 2nd Ed.\n(World Scientific, Singapore, 2004).\n[46] G. Gasper and M. Rahman, Basic Hypergeometric Series (Cambridge Univ. Press, Cam-\nbridge, 1990).\n25\n"}
{"id":"oai:arXiv.org:hep-ph/0610379","text":"arXiv:quant-ph/0602178v2  17 May 2006\nDuality, Phase Structures and Dilemmas in Symmetric Quantum Games\nTsubasa Ichikawa and Izumi Tsutsui\nHigh Energy Accelerator Research Organization (KEK), Tsukuba, Ibaraki 305-0801, Japan\n(Dated: February 22, 2006)\nSymmetric quantum games for 2-player, 2-qubit strategies are analyzed in detail by using a scheme\nin which all pure states in the 2-qubit Hilbert space are utilized for strategies. We consider two\ndifferent types of symmetric games exemplified by the familiar games, the Battle of the Sexes (BoS)\nand the Prisoners? Dilemma (PD). These two types of symmetric games are shown to be related by a\nduality map, which ensures that they share common phase structures with respect to the equilibria\nof the strategies. We find eight distinct phase structures possible for the symmetric games, which\nare determined by the classical payoff matrices from which the quantum games are defined. We\nalso discuss the possibility of resolving the dilemmas in the classical BoS, PD and the Stag Hunt\n(SH) game based on the phase structures obtained in the quantum games. It is observed that\nquantization cannot resolve the dilemma fully for the BoS, while it generically can for the PD and\nSH if appropriate correlations for the strategies of the players are provided.\nPACS numbers: 02.50.Le, 03.67.-a, 87.23.Ge\nKeywords: quantum mechanics, game theory, entanglement\nI. INTRODUCTION\nQuantum game theory has attracted much attention\nin recent years as an interesting attempt to expand the\nscope of the conventional (classical) game theory, which\nis now a standard tool in various fields, most notably in\neconomics, for analyzing decision making processes. The\nmain thrust in the investigation of quantum game has\ncome from the remarkable observation by Eisert et al. [1]\nthat the famous dilemma in the Prisoners?Dilemma (PD)\ngame can be resolved if the players resort to strategies\navailable in quantum theory. Subsequently, Marinatto\nand Weber [2] examined the dilemma in the Battle of\nthe Sexes (BoS) game, another typical dilemma in game\ntheory, and observed that this, too, could be resolved\nby adopting a quantum strategy involving a maximally\nentangled state. Application of quantum strategies to\nvarious other games, such as the Stag Hunt (SH) or the\nSamaritan?s Dilemma game, has also been discussed in\n[3].\nThese studies of the quantum games presented in [1, 3]\nand [2] employ different schemes of quantum strategies,\nand it has turned out that the outcome of the analysis is\nhighly dependent on the scheme used. In fact, it has been\npointed out in [4, 5, 6] that in the scheme used in [1, 3]\nthe dilemma in PD can be resolved only if the strategic\nspace is restricted artificially, while a more recent study\n[7] shows that there exists a new scheme in which the\ndilemma can be resolved even with a full strategic space.\nSimilarly, the resolution of the dilemma in the BoS has\nbeen argued using different reasonings depending on the\nschemes [3, 8, 9] (for a generalized scheme, with no analy-\nsis on dilemmas, see [10]), casting a doubt on the genuine\nnature of the resolution and, more importantly, the uni-\nversality of the outcomes of quantum game in general.\nThe distinction among these schemes can be found in\nthe definitions of quantum strategy, the strategic space\nwhich the players can exploit, and the way the quan-\ntum correlation (entanglement) is furnished. These dif-\nferences are crucial, because (as observed in [4, 5, 6])\ndifferent strategic spaces admit different stable solutions,\nand moreover the amount of entanglement required to\nresolve the dilemma will depend on the stage in the pro-\ncess it is measured. Despite of this scheme-dependence,\nwe have found in [7] an intriguing phase structure for the\nquantum PD game, which is reminiscent of the ?phase\ntransition? of equilibrium solutions discovered earlier in\n[11] in a different scheme. This suggests that the phase\nstructures may exhibit a scheme-independent, intrinsic\nfeatures of quantum games under consideration.\nThe aim of the present paper is to support this idea by\nproviding a convenient tool to analyze quantum games\nin general terms. We consider 2-player, 2-qubit strategy\ngames, which are the simplest nontrivial and yet have not\nbeen fully analyzed. Using the scheme introduced in [7],\nwe study in detail two types of ?symmetric games?, exem-\nplified by the BoS and PD games, respectively. We show\nthat these two types of games are actually related by a\nduality map, which brings a game in one symmetric type\ninto a game in the other symmetric type without chang-\ning the payoff in effect. This is convenient because then\nwe can use the outcome of the analysis of the BoS for the\nstudy of the PD, for instance. A quantum game may be\nregarded as a family of games provided by quantum cor-\nrelations which are absent in classical settings, and our\ngeometric picture used to portray the correlation-family\nin this paper turns out to be quite convenient, espe-\ncially for analyzing the phase structures of the game. We\nshall then see that symmetric games admit eight differ-\nent types of phase structures with regard to the possible\nstable strategies (related to classical strategies) preferred\nby the players, and that these types are determined by\nthe original classical games. With these phase structures,\nwe find that the dilemma in the BoS cannot be resolved\nfully in our scheme, albeit alleviated to some extent [2],\nirrespective of the amount of entanglement provided. In\n2\ncontrast, the dilemma of the PD game can be resolved if\na certain amount of correlationsare introduced. An anal-\nogous conclusion will also be drawn for the SH game, for\nwhich we find rather intricate phase structures for the full\nstable strategies compared to the BoS and PD games.\nThe plan of the paper is as follows. We first introduce\nour scheme of quantum gamein section II and present the\nduality map between the two types of symmetric games.\nThe phase structures of the symmetric games are studied\nin section III. Section IV is devoted to the analysis of the\nBoS, PD and SH games, where we examine the resolution\nof the dilemmas based on the results obtained in section\nIII. Finally, we give our conclusion and discussions in\nsection V.\nII. QUANTUM GAME AND DUALITY FOR\nSYMMETRIC GAMES\nTo begin with, we first recapitulate the classical 2-\nplayer, 2-strategy game and then introduce its quantum\nversion following [7]. Let i = 0,1, j = 0,1 be the la-\nbels of the strategies available for the players, Alice and\nBob, respectively, and let also Aij and Bij be their pay-\noffs when their joint strategy is (i,j). In classical game\ntheory, the game is said to be ?symmetric? if Bji = Aij,\nthat is, if their payoffs coincide when their strategies are\nswapped (i,j) ? (j,i). To make a distinction from the\nother symmetry discussed shortly, we call such a game\nS-symmetric in this paper. The PD and other famil-\niar games such as the SH and the Chicken game (see,\ne.g., [3, 12]) are S-symmetric games. Similarly, we call\nthe game T-symmetric if B1?j,1?i = Aij, that is, if the\npayoff matrices coincide when the strategies of the two\nplayers are ?twisted? as (i,j) ? (1 ? j,1 ? i). The BoS\nis an example of T-symmetric games with the additional\nproperty A01 = A10. The payoffs in these S-symmetric\nand T-symmetric games are displayed in the form of the\nbi-matrix (Aij,Bij) in Table I.\nGiven a payoff matrix, each player tries to maximize\nhis/her payoff by choosing the best possible strategy, and\nif there exists a pair of strategies in which no player can\nbring him/her in a better position by deviating from it\nunilaterally, we call it a Nash equilibrium (NE) of the\ngame. The players will be happy if the NE is unique\nand fulfills certain conditions attached to the game (e.g.,\nPareto-optimality or risk-dominance as mentioned later).\nEven when there are more than one NE, the players will\nstill be satisfied if a particular NE can be selected over\nthe other upon using some reasonings. Otherwise, the\nplayers may face a dilemma, as they do in the case of the\nBoS and the PD.\nTo introduce a quantum version of the classical game,\nwe first regard Alice?s strategies i as vectors in a Hilbert\nspace HA of a qubit. Namely, corresponding to the clas-\nsical strategies i we consider vectors |i?A for i = 0 and 1\nwhich are orthonormal in HA. A general quantum strat-\negyavailablefor Alice is then representedbya normalized\nS-symmetric:\nstrategy Bob 0 Bob 1\nAlice 0 (A00,A00) (A01,A10)\nAlice 1 (A10,A01) (A11,A11)\nT-symmetric:\nstrategy Bob 0 Bob 1\nAlice 0 (A00,A11) (A01,A01)\nAlice 1 (A10,A10) (A11,A00)\nTABLE I: Payoff bi-matrices (Aij,Bij) of the S-symmetric\ngame (above) and the T-symmetric game (below).\nvector |??A (with the overall phase ignored, i.e., a unit\nray) in HA. Bob?s strategy is similarly represented by\na normalized vector |??B in another qubit Hilbert space\nHB spanned by orthonormal vectors |j?B for j = 0 and\n1 in HB. The strategies of the players can thus be ex-\npressed in the linear combinations,\n|??A =\nsummationdisplay\ni\n?i(?)|i?A ,\n|??B =\nsummationdisplay\nj\n?j(?)|j?B ,\n(2.1)\nusing the bases |i?A, |j?B which correspond to the clas-\nsical strategies, with complex coefficients ?i(?), ?j(?)\nwhich are functions of the parameters ? and ? normal-\nized as summationtexti|?i|2 = summationtextj |?j|2 = 1. The strategies of the\nindividual players are, therefore, realized by local actions\nimplemented by the players independently.\nThe joint strategy of the players, on the other hand,\nis given by a vector in the direct product Hilbert space\nH = HA ?HB. Here lies one of the crucial differences\nbetween the classical and quantum games: in quantum\ngame theory, the joint strategy is specified not just by the\nchoice of the strategies of the players but also by furnish-\ning the quantum correlation (essentially the entangle-\nment) between the individual strategies. Consequently,\nthe outcome of a quantum game rests also on a third\nparty (or referee) that determines the correlation. To be\nmore explicit, using the product vector|?,?? = |??A|??B\nwhich is uniquely specified by the individual strategies,\na vector in the total strategy space H is written as\n|?,?;?? = J(?)|?,?? = J(?)|??A|??B , (2.2)\nwhere J(?) is a unitary operator providing the quantum\ncorrelation between the individual strategies. The corre-\nlation factor J(?) with the parameter set ? is designed to\nexhaust all possible joint strategies available in H. The\npayoffs for Alice and Bob are then given by the expecta-\ntion values of some appropriate self-adjoint operators A\nand B, respectively:\n?A(?,?;?) = ??,?;?|A|?,?;??,\n?B(?,?;?) = ??,?;?|B|?,?;??. (2.3)\nTo sum up, a quantum game is defined formally by the\ntriplet {H,A,B}.\n3\nTo choose the payoff operators A and B, we require\nthat, in the absence of quantum correlations J(?) = I\n(I is the identity operator in H), the payoff values re-\nduce to the classical ones when the players choose the\n?semiclassical (pure) strategies? |i,j? = |i?A|j?B,\n?i?,j?|A|i,j? = Aij?i?i?j?j,\n?i?,j?|B|i,j? = Bij?i?i?j?j. (2.4)\nAdopting, for simplicity, the value ? = 0 for the refer-\nence point at which J(?) = I holds, we find that, for\nthe uncorrelated product strategies |?,?;0? = |?,??, the\npayoffs (2.3) become\n?A(?,?;0) = ??,?;0|A|?,?;0? =\nsummationdisplay\ni,j\nxiAijyj,\n?B(?,?;0) = ??,?;0|B|?,?;0? =\nsummationdisplay\ni,j\nxiBijyj,\n(2.5)\nwhere xi = |?i|2, yj = |?j|2 represent the probability\nof realizing the strategies |i?A, |j?B under the general\nchoice |??A, |??B (see (2.1)). This ensures the exis-\ntence of a classical limit at which the quantum game\nreduces to the classical game defined by the payoff ma-\ntrix Aij, where now Alice and Bob are allowed to adopt\nmixed strategies (see, e.g., [13]) with probability distri-\nbutions xi, yj (summationtextxi = summationtextyj = 1) for strategies i, j.\nWe thus see that the quantum game is an extension of\nthe classical game, in which the correlation parameter ?\nplays a role similar to the Planck constant planckover2pi1 in quantum\nphysics in the technical sense that the classical limit is\nobtained by their vanishing limit. Note that, since the set\n{|i,j?, i,j = 0,1} forms a basis set in the entire Hilbert\nspace H, the payoff operators A and B are uniquely de-\ntermined from the classical payoff matrices by (2.4); in\nother words, our quantization is unique.\nThe aforementioned symmetries in classical game can\nalso be incorporated into quantum game by using cor-\nresponding appropriate symmetry operators. Indeed, by\nintroducing the swap operator\nS|i,j? = |j,i?, (2.6)\nwe see immediately that in the classical limit the game\nis S-symmetric, ?B(?,?;0) = ?A(?,?;0), provided that\nthe payoff operators A and B fulfill\nB = SAS. (2.7)\nAnalogously, if we introduce the notation ?i = 1 ? i for\ni = 0,1 (i.e., ?0 = 1 and ?1 = 0) and thereby the twist\noperator,\nT|i,j? = |?j,?i?, (2.8)\nand the twisted states,\nvextendsinglevextendsingle??, ??angbracketrightbig := T |?,?? = summationdisplay\ni,j\n?i(?)?j(?)|?j,?i?, (2.9)\nwe find that in the classial limit the game is T-symmetric,\n?B(??, ??;0) = ?A(?,?;0), provided that the operators\nfulfill\nB = T AT. (2.10)\nThe symmetries can be elevated to the full quantum\nlevel if we adopt the correlation factor in the form [7],\nJ(?) = ei?1S/2ei?2T/2, (2.11)\nwith real parameters ?i ? [0,2pi) for i = 1,2 [17]. In fact,\none can readily confirm, using [S,T] = ST ? TS = 0,\nthat under (2.10) the game is S-symmetric\n?B(?,?;?) = ?A(?,?;?), (2.12)\neven in the presence of the correlation (2.11). Similarly,\nthe game is T-symmetric\n?B(??, ??;?) = ?A(?,?;?), (2.13)\nif (2.10) is fulfilled. Since the correlation parameters in\n? are arbitrary, the properties (2.12), (2.13) imply that\na symmetric quantum game consists of a (?-parameter)\nfamily of games with the (S or T) symmetry exhibited\nfor each ?.\nIt is interesting to observe that these two types of sym-\nmetric games are actually related by unitary transforma-\ntions. To see this, let us introduce the operator CA which\nimplements the conversion for Alice?s strategies,\nCA|i,j? = |?i,j?. (2.14)\nNote that CA satisfies\nCA SCA = T, CA T CA = S. (2.15)\nConsider then the transformation of strategy by unilat-\neral conversion by Alice,\n|?,?;??? CA|?,?;??. (2.16)\nOn account of the relation (2.14) and the form of the\ncorrelation (2.11), we find\nCA|?,?;?? = |??,?;???, (2.17)\nwith ?? given by\n(??1,??2) = (?2,?1). (2.18)\nIn addition, one may also consider the transformation\non the payoff operators,\nA ? ?A = CA ACA, B ? ?B = CA BCA. (2.19)\nOne then observesthat, if the game is S-symmetricfulfill-\ning (2.7), the game defined by the transformed operators\nbecomes T-symmetric,\n?B = T ?AT. (2.20)\n4\nAnalogously, if the game is T-symmetric fulfilling (2.10),\nthen the transformed operators define an S-symmetric\ngame,\n?B = S ?AS. (2.21)\nThis shows that the conversion CA in (2.14) provides\na one-to-one correspondence, or duality, between an S-\nsymmetric game and a T-symmetric game. Some quan-\ntities in quantum game are invariant under the duality\nmap while other are not. For instance, the trace of the\npayoff,\nTrA =\nsummationdisplay\ni,j\nAij = A00 +A01 +A10 +A11, (2.22)\nremains invariant TrA ? Tr ?A = TrA, whereas the al-\nternate trace defined by\n?(A) =\nsummationdisplay\ni,j\n(?)i+jAij = A00 ?A01 ?A10 +A11, (2.23)\nchanges the sign ?(A) ? ?( ?A) = ??(A).\nIn formal terms, the two games given by {H,A,B}and\n{H, ?A, ?B} are dual to each other in the sense that the\npayoff under the strategy |?,?;?? in one game is equiva-\nlent to the payoff under the dual strategy CA|?,?;?? =\n|??,?;??? in the other. In particular, if the former\ngame happens to be S-symmetric, then the latter is T-\nsymmetric, and vice versa. This allows us to regard any\ntwo games as ?identical? if their payoff operators are re-\nlated by the duality map (2.19).\nEvidently, the other conversionofthe strategiesby Bob\nCB|i,j? = |i,1?j? can also be used to provide a similar\nbut different duality. Besides, their combination,\nC = CA ?CB, (2.24)\nimplements the renaming of the strategies 0 ? 1 for both\nof the players, and yields a duality map which does not\nalter the type of symmetries of the game. These dual-\nity maps CA, CB and C are used later to identify games\ndefined from different classical payoff matrices. We men-\ntion that these dualities are actually a special case of the\nmore general ?gauge symmetry? in quantum game the-\nory, which is that the two games defined by {H,A,B}\nand {H,UAU?,UBU?} with some unitary operator U\nare dual to each other under the corresponding strategies\n|?,?;?? and U|?,?;??. Thus the identification of games\ncan be extended to those which are unitarily equivalent.\nIII. CLASSIFICATION OF T-SYMMETRIC\nGAMES\nThe foregoing argument suggeststhat in order to study\nthe two types of symmetric games it is sufficient to con-\nsider either one of the two. Moreover, even if the two\ngames are of the same symmetric type, a further identi-\nfication may be possible using the full conversion C. In\nview of this, in the following we choose the T-symmetric\ngames and analyze the pattern of the allowed equilibria\nthere. To start with, we furnish the definition of an equi-\nlibrium which corresponds to the NE in classical game\n[18]. A joint strategy |??,??? is called quantum Nash\nequilibrium (QNE), if it satisfies\n?A(??,??;?) ? ?A(?,??;?), (3.1)\nfor all ?, and also\n?B(??,??;?) ? ?B(??,?;?), (3.2)\nfor all ?. Note that the QNE is defined for a given ?\ntreated as a set of external parameters. Below, we study\nthe conditions for ? under which a QNE appears.\nTo evaluate the payoffs explicitly, we write the strate-\ngies as\n|??A = cos(?1/2)|0?A + sin(?1/2)ei?2|1?A,\n|??B = cos(?1/2)|0?B + sin(?1/2)ei?2|1?B, (3.3)\nwith angle parameters ?1,?1 ? [0,pi] and ?2,?2 ? [0,2pi).\nFor convenience, we henceforth adopt both of the ket\nnotations |?? and |i? with the convention that |0? and |1?\nrefer always to the latter notations. Using (3.3) we find\nthat, for a T-symmetric game fulfilling (2.10), the payoff\nfor Alice reads\n?A(?,?;?) = 14{TrA+?(A)cos?1 cos?1\n+I?+(?)cos?1 +I??(?)cos?1\n?I+(?)sin?1 sin?1 sin?2 cos?2\n?I?(?)sin?1 sin?1 cos?2 sin?2},\n(3.4)\nwhere we have defined\nI?(?) = G+(?)?G?(?),\nI??(?) = G?+(?)?G??(?), (3.5)\nwith\nG+(?) = (A00 ?A11)sin?2,\nG?+(?) = (A00 ?A11)cos?2,\nG?(?) = (A01 ?A10)sin?1,\nG??(?) = (A01 ?A10)cos?1.\n(3.6)\nThe payoff ?B(?,?;?) for Bob is readily obtained from\n(3.4) using the relation (2.13). The conditions for QNE\n(3.1) and (3.2) imply\n??i?A(?,??;?)|?? = 0,\n??i?B(??,?;?)|?? = 0, (3.7)\nfor i = 1,2. Besides, the Hessian matrices PA and PB\ngiven by\nPA(?,?;?)ij = ??i??j?A(?,?;?),\nPB(?,?;?)ij = ??i??j?B(?,?;?), (3.8)\n5\n|??,??? Hessian conditions ?A(??,??;?)\n|0,0? H+ > 0, H? > 0 [TrA+?(A)+ 2G?+]/4\n|0,1? H? < 0 [TrA??(A)+ 2G??]/4\n|1,0? H+ < 0 [TrA??(A)? 2G??]/4\n|1,1? H+ > 0, H? > 0 [TrA+?(A)? 2G?+]/4\nTABLE II: Hessian conditions and Alice?s payoffs for edge\nstrategies in T-symmetric games. Bob?s payoffs can be ob-\ntained from ?B(??,??;?) = ?A(???, ???;?).\nmust be both negative semi-deifinite,\nPA(??,??;?) ? 0, PB(??,??;?) ? 0. (3.9)\nUsing (3.4) we obtain, for example,\n??2?A(?,??;?)|?? = ???2?B(??,?;?)|??\n= 14 sin??1 sin??1 [I?(?)sin??2 sin??2\n?I+(?)cos??2 cos??2]. (3.10)\nThese conditions (3.7) and (3.9) will now be analyzed in\ndetail.\nA. Edge strategies\nFrom (3.10) we see that an obvious set of solutions for\n(3.7) are obtained if\nsin??1 = sin??1 = 0. (3.11)\nThese have solutions given by the semiclassical pure\nstrategies |i,j? for i,j = 0,1, i.e., the four ?edge? strate-\ngies,\n|0,0?, |1,1?, |0,1?, |1,0?, (3.12)\nwhich correspond to classical pure strategies (i,j). Note,\nhowever, that these quantum edge strategies differ from\nthe classical counterparts because the joint strategy is\ndetermined with the additional correlation factor J(?).\nNote also that on the edge strategies the unitary opera-\ntion J(?) yields only a one-parameter family of correla-\ntions for joint states |i,j;?? in (2.2), since one of the two\nfactors in (2.11) gives merely an overall phase.\nFor the edge states to become QNE, they also need to\nobey the Hessian conditions (3.9), which pose different\nrequirements for the states as\n|0,0? : H+(?) > 0, H?(?) > 0,\n|0,1? : H?(?) < 0,\n|1,0? : H+(?) < 0,\n|1,1? : H+(?) > 0, H?(?) > 0,\n(3.13)\nwhere we have used\nH?(?) = ?(A)?I?+(?), (3.14)\nlabel QNE characteristics\nBoS |0,0? and |1,1? none\nPD |1,0? or |0,1? not Pareto optimal\nSH |1,0? and |0,1? either payoff or risk dominant\nTABLE III: QNE and their characteristics in the domains\non the G?+-G?? plane classified by the labels of the classi-\ncal games. Both PD and SH games are mapped to their T-\nsymmetric dual versions.\nand ignored the cases of equalities for brevity. These con-\nditions and the payoffs for the edge solutions are sum-\nmarized in Table II. To see when these conditions are\nfulfilled for different ?, it is convenient to consider the\nplane coordinated by (G?+,G??) with G?? given in (3.6).\nOne then sees that, as shown in Figure 1, the entire pa-\nrameter region of ? is mapped to a rectangular area in\nthe centre of the G?+-G?? plane with the horizontal length\nLh and the vertical length Lv given by\nLh = 2|A00 ?A11|, Lv = 2|A01 ?A10|. (3.15)\nIt is worth noting that, at each of the midpoints of\nthe four edges, the operation J(?) can yield a maximally\nentangled joint strategy state. For instance, for A01 >\nA10 the midpoint (G?+,G??) = (0,Lv/2) corresponds\nto J(pi/2,0) under which the edge state |01? becomes\n(|01? + i|10?)/?2. Similarly, for A00 > A11 the mid-\npoint (G?+,G??) = (Lh/2,0) corresponds to J(0,pi/2) un-\nder which the edge state |00? becomes (|00?+i|11?)/?2.\nThe four corners of the rectangle, on the other hand, cor-\nrespond to J(mpi,npi) for m,n = 0,1, which are S, T, C,\nand I operations, and hence the resultant joint strategies\nare all unentangled. On the G?+-G?? plane, the Hessian\nconditions determine the domains of allowed edge QNE\nwhich are separated by the parallel lines H?(?) = 0 (see\nFigure 1). Observe that the allowed edge QNE are differ-\nent depending onthe domains, and that the combinations\nof the QNE change when the sign of ?(A) is reversed.\nNote that for ?(A) > 0 all edge strategies in (3.12) could\narise as a QNE for some ?, whereas for ?(A) < 0 only\n|0,1? and/or |1,0? become QNE.\nAs will be seen shortly, as long as the edge strategies\nareconcerned our quantum gameis simulated by classical\ngames possessing the corresponding NE. In view of this,\nwe may characterize the domains on the G?+-G?? plane\nby the typical classical games sharing the same NE. We\ndo this by using the BoS, PD and SH as the representa-\ntives (see Table III). Here, the label ?BoS? is chosen to\ndesignate the domain of games possessing two edge QNE\nat |0,0? and |1,1?, which is an obvious choice because\nthe classical BoS game is T-symmetric and has the cor-\nresponding NE at (i,j) = (0,0) and (1,1). None of these\nNE admits better payoffs to both of the players, simulta-\nneously, leading to the dilemma that they cannot decide\non which strategy the should choose. The domain ?BoS?\narises only for ?(A) > 0 and the required conditions are\nBoS : H+ < 0, H? < 0. (3.16)\n6\nG?+\nG??\n? > 0\nH? = 0H+ = 0\n|0,1?\n|1,0?\nBoS\nPD\nPD\nG?+\nG??\n? < 0\nH+ = 0H? = 0\n|0,1?\n|1,0?\nSH\nSH\nPD\nPD\nFIG. 1: Phase structures of QNE in terms of edge strategies: ?(A) > 0 (above), ?(A) < 0 (below). The names of the domains\nare borrowed from the classical games sharing the same characteristic dilemmas (see Table III). Games in the domains without\nnames are free from dilemmas within edge strategies and possess a single stable strategy |1,0? or |0,1? among at most two QNE.\nThe correlation family of a quantum game forms a rectangle on the plane, as shown by the dotted line for the case ?(A) > 0.\nThe domain fulfilling these forms a diagonal strip be-\ntween the parallel lines H? = 0 on the G?+-G?? plane\n(see Figure 1).\nTo justify the assignment of the other labels, recall\nthat the classical PD game is an S-symmetric game and\nhas a NE at (1,1) which is unique. The problem of the\ngame is that the NE is not Pareto optimal, i.e., there\nexists another strategy which improves the payoffs for\nthe two players, simultaneously, and this constitutes the\ndilemma. Upon quantization, the quantum PD, in the\nclassical limit, will have one edge QNE at |1,1?, which\nturns into |0,1? by the duality map (2.14) when it is\nemployed to convert the PD into the T-symmetric dual\nversion. For this reason, we use ?PD? to label the do-\nmain of those T-symmetric games possessing the edge\nQNE at |0,1? which is not Pareto optimal. The Pareto\noptimality can be examined by comparing the payoff val-\nues with other strategies, and in the present case this\nis done essentially by comparing the payoffs between the\ntwo strategies|1,0? and |0,1?. From Table II, we see that\nthis situation occurs when\nPD : H+ > 0, H? < 0, G?? < 0. (3.17)\nWe also use the same label ?PD? for the domain of games\npossessing a QNE at |1,0? which is not Pareto optimal,\nsince thoseareidentified bythe full conversionC in (2.24)\nwith the standard quantum PD. This is the case when\nwe have\nPD : H+ < 0, H? > 0, G?? > 0. (3.18)\nAs shown in Figure 1, the domains of PD appear both\nfor ?(A) > 0 and ?(A) < 0.\nThe classical SH game, on the other hand, is an S-\nsymmetric game which has two NE at (0,0) and (1,1),\nin which (0,0) is payoff dominant (i.e., better than (1,1)\nin the payoff) and (1,1)is risk dominant (i.e., better than\n(0,0) in the ?average? over the choice of the other player).\nThe dilemma is that, while (0,0) is Pareto optimal, (1,1)\nis preferable for the minimal risk, which makes the play-\ners uncertain to decide which to choose. Now, after the\nquantization and the application of the duality map to\nget the T-symmetric quantum version of the game, we\nwill have two edge QNE at |1,0? and |0,1? in the classi-\ncal limit, with payoff dominant |1,0? and risk dominant\n|0,1?. We therefore use the label ?SH? to name the do-\nmain in which the games possess the same QNE with the\nabove property. In the presence of correlations, we find\nfrom Table II that the payoff dominance of |1,0? requires\nG?? < 0. The risk dominance of |0,1? demands that the\naverage payoff Alice receives under the choice |0?A be\nlarger than that obtained under the choice |1?A, which\nis ensured if G?+ + G?? > 0. As in the case of the PD,\nthe label ?SH? is also used for the domain of games pos-\nsessing the two QNE with payoff dominant |0,1? and risk\ndominant |1,0? for Alice, which are possible if G?? > 0\nand G?+ + G?? < 0. These domains ?SH? are allowed\nonly for ?(A) < 0 where |1,0? and |0,1? arise as QNE\nbetween the two parallel lines H? = 0 on the G?+-G??\nplane. Combined with the above additional conditions,\nthe SH domains are characterized by\nSH : H+ > 0, H? > 0, G??(G?+ +G??) < 0. (3.19)\nAs shown in Figure 1, the classification of the games\nleavesunlabeled domains on the G?+-G?? plane for each of\nthe cases ?(A) > 0 and ?(A) < 0. For ?(A) > 0, we find\ntwo separate domains which contain games possessing a\nunique QNE, either at |0,1? or |1,0?. These QNE are\nPareto optimal, and hence the games are free from the\ndilemma of the PD type. For ?(A) < 0, we have two ad-\nditional domains of games possessing QNE at |0,1? and\n|1,0?, which are free from the dilemma of the SH. This\nresult suggests that, if the game under consideration can\nbe driven to lie in these unlabeled domains by adjusting\nthe correlations appropriately, then the original dilemma\nmay be resolved under these correlations, at least within\nthe realm of edge strategies. In this respect, the phase\ndiagram given by Figure 1 provides a convenient basis to\nexamine the problem of optimality of strategies in quan-\ntum games.\nSince the correlation-family of a symmetric quantum\ngame is mapped to a rectangle on the G?+-G?? plane, we\ncan classify quantum games in terms of the patterns of\nthe rectangle formed on the plane. As shown in Figure\n7\nFIG. 2: Four patterns of rectangles which are possible in re-\nlation to the parallel lines H? = 0 provide distinct phase\nstructures for symmetric quantum games. The rectangle may\nreduce to a line as we see in the case of the BoS later.\n2, there are four types of rectangles, determined from\nthe values of Lh and Lv in (3.15), which are different\nin position with respect to the parallel lines H?(?) = 0\nappearing in Figure 1. Combining the two cases ?(A) > 0\nand?(A) < 0 whichoffer different structuresfor domains,\nwe find that there are altogether eight classes of quantum\ngames which have distinct phase structures of QNE in\nterms of edge strategies.\nOne of the advantages of the present quantization\nscheme is that it allows us to establish the connection\nbetween the classical and quantum games in a simple\nmanner and thereby examine how ?quantum? the game\nactually is. To see this, let us introduce the correlated\npayoff matrices\nA(?) = J?(?)AJ(?), B(?) = J?(?)BJ(?). (3.20)\nWith these, the payoffs (2.3) are expressed in terms of\nseparable (uncorrelated) states\n?A(?,?;?) = ??,?|A(?)|?,??,\n?B(?,?;?) = ??,?|B(?)|?,??. (3.21)\nOne may decompose each of the correlated payoffs into\n?pseudo-classical? and ?interference? terms as\nA(?) = Apc(?)+Ain(?), (3.22)\nwith\nApc(?) = cos2 ?12 A+ (cos2 ?22 ?cos2 ?12 )SAS\n+ sin2 ?22 C AC,\n(3.23)\nwhere C is given in (2.24) and\nAin(?) = i2 sin?1 [A,S] + i2 sin?2[A,T]. (3.24)\nThe pointis thatthe pseudo-classicalpartApc isdiagonal\nand hence for separable strategies it can be interpreted\nas a classical payoff matrix. In contrast, the interference\npart Apc is non-diagonal and represents a non-classical\ncontribution. Accordingly, the payoff for Alice in a T-\nsymmetric game is decomposed into the sum ?A = ?pcA +\n?inA, where we have\n?inA(?,?;?) = 0, (3.25)\nfor edge strategies. This observation confirms that our\nquantum game with edge strategies are, in effect, equiv-\nalent to the classical game with the payoff matrices Apc\nand Bpc (the latter can be defined analogously for the\ncorrelated payoff B(?)). Possible game theoretical inter-\npretations of the pseudo-classical payoff based on altru-\nism and value-conversion have been noted in Ref.[7].\nB. Non-edge strategies\nTo discuss QNE beyond the edge strategies (3.12), we\nrecall (2.13) and seek solutions which are T-symmetric,\n|??,??? = |???, ????. In the representation (3.3) of the\nstate (which is defined up to an overall phase), this trans-\nlates into\n??1 ???1 = pi, ??2 +??2 = pi. (3.26)\nUnder the T-symmetric ansatz and the non-edge require-\nment sin??1 negationslash= 0, the conditions in (3.7) imply\ncos??1 [?(A)?G?(?)sin2??2]?I?+(?) = 0,\nG?(?)cos2??2 +G+(?) = 0. (3.27)\nBesides, the Hessian condition (3.9) implies\nG? sin2??2 ? 0. (3.28)\nBefore analyzing the solutions in detail, we observe\nthat at the classical limit ? = 0 the above conditions are\nsimplified to the single condition,\ncos??1 = ?+(A)?(A) , (3.29)\nwith ?+(A) defined as\n??(A) = (A00 ?A11)?(A01 ?A10). (3.30)\nThe condition (3.29) has a solution when |?(A)| ?\n|?+(A)|, which is equivalent to\nA00 ? A10 and A11 ? A01, or\nA00 ? A10 and A11 ? A01. (3.31)\nThe solution for (3.29) corresponds to the NE for mixed\nstrategies in classical games with x?1 = y?1 = cos2(??1/2),\nand (3.31) agrees precisely with the conditions for such\nnontrivial NE to arise. It is important to note, how-\never, that the non-edge QNE in quantum game and the\nmixed NE in classical game are completely different in\nthe meaning of strategies. Namely, the NE in classical\ngame is relevant only for the situation where the games\n8\nFIG. 3: Possible patterns of allowed regions by (3.33) in the\nrectangle of the game under Lh < Lv (left), Lh = Lv (middle)\nand Lh > Lv (right). These regions are shaded, and the dot\nin the centre represents the origin of the G?+-G?? plane.\nare repeated many times in which the players can con-\nsider probability distributions in choosing their strategies\n? the mixed NE and pure NE belong to different cate-\ngories conceptually. In contrast, the non-edge QNE in\nquantum game is a pure strategy and meaningful with-\nout repeating the game ? it belongs to the same category\nas the edge QNE.\nTo discuss solutions for generic ?, we notice first that\nthe second condition in (3.27) determines ??2, which can\nbe used to determine ??1 in the first condition. In terms\nof ?(?) :=\nradicalBig\nG2? ?G2+ for which we have\n?2 = (G?+)2 ?(G??)2 ??+ ??, (3.32)\nthe condition for the existence of ??2 reads\n? ? 0. (3.33)\nNotice that ?+ ?? = (L2h ?L2v)/4 measures the squared\ndifference in length between the two edges of the rectan-\ngle of the game. It follows that the regions allowed by\n(3.33) are those enclosed by the two hyperbolae ?2 = 0\nand the edges of the rectangle, which vary depending on\nthe types of the rectangle (see Figure 3).\nOn the other hand, by combining the two conditions\nin (3.27) and (3.28) we see that the solution for ??1 exists\nif\n(H+ + ?)(H? + ?) ? 0. (3.34)\nUsing (3.32), one can readily depict the regions where\n(3.34) is fulfilled on the G?+-G?? plane. The games be-\nlonging to the overlapped areas of the above two regions\nadmit non-edge QNE, and this is indeed possible if the\npayoff A meets certain conditions, as illustrated by the\nSH game later. When this happens, the non-edge QNE,\nwhich we denote by |??,??;?? = |?ne,?ne;??, offers the\nsame payoff (as ensured by the T-symmetry) for Alice\nand Bob,\n?A(?ne,?ne;?) = ?B(?ne,?ne;?)\n= 14\nbracketleftbigg\nTrA+ ?(A)?(?)??+(A)??(A)?(A) + ?(?)\nbracketrightbigg\n. (3.35)\nIn particular, at the classical limit the payoff becomes\n?A(?ne,?ne;0) = A00A11 ?A01A10A\n00 +A11 ?A01 ?A10\n, (3.36)\nwhich is the familiar payoff expression for the mixed NE\nin classicalT-symmetricgames. This showsthat the non-\nedge QNE are actually an extension of the classicalmixed\nNE. In fact, at the classical limit, we find from ?(0) = 0\nthat the condition (3.33) is trivially fulfilled, and that\n(3.34) reduces to\nH+(0)H?(0) = 4(A00 ?A10)(A11 ?A01) ? 0, (3.37)\nwhich is exactly the condition for mixed NE (3.31). In\nother words, if the classical game admits a mixed NE,\nthen the quantum game defined from the classical game\nadmits a QNE for a certain range of correlations includ-\ning the classical limit.\nTo summarize, non-edge QNE may exist as an exten-\nsion of mixed NE under various correlations in quantum\ngame theory, and their existence can be examined from\nthe rectangle of the game specified from the classical pay-\noff matrix Aij. Game theoretical analysis, including the\nresolution of dilemma in classical game, should be made\nbased on the combination of edge and non-edge QNE.\nIV. DILEMMAS IN BOS, PD AND SH\nHaving obtained the phase structures of symmetric\nquantum games for edge QNE as well as the conditions\nfor non-edgeQNE,we nowexamineif andhowthe typical\ndilemmas familiar in classical game theory ? the dilem-\nmas in the BoS, the PD and the SH game ? can be re-\nsolved in quantum game theory. All of the dilemmas\nin these cases are intrinsically different, and there is no\nunique criterion for the resolution. We thus consider the\nresolution based on the conventional requirements which\nare attached to the respective classical games, and find\nthat the quantization of the games lead to considerably\ndifferent outcomes for the three cases.\nA. Battle of the Sexes\nThe BoS game is a special case of the T-symmetric\ngame specified by the payoff matrix,\nA00 > A11 > A01 = A10. (4.1)\nThe degeneracy A01 = A10 provides the T-symmetric\ngame with an extra symmetry between the payoff matri-\nces, that is,\nB = T AT = C AC. (4.2)\nOnaccountofthe degeneracy,we haveG?(?) = G??(?) =\n0, which implies that the parameter ?1 drops out from\nour consideration of QNE. Notice that the BoS defined\nby (4.1) has ?(A) > 0 and that, as shown in Figure 4, the\nrectangle of the game in the G?+-G?? plane is smashed to\na line on the G?+-axis with length Lh. Notice also from\nA00 > A11 that the classical limit is found at the right\n9\nend of the line. Now, an important point to observe is\nthat since\n?(A)?(A00 ?A11) = 2(A11 ?A01) > 0, (4.3)\nthe line segment of the game lies entirely within the BoS\ndomain (see Figure 4). This shows that, so far as the edge\nstrategies are concerned, even in the presence of the cor-\nrelation J(?), the dilemma in the BoS does not disappear\nin quantum game. Using (3.21) and (3.23), Alice finds\nher payoff ?A(i,i;?) at the edge QNE |??,??? = |i,i? for\ni = 0,1 as\n?A(i,i;?) = cos2 ?22 Aii + sin2 ?22 A?i?i. (4.4)\nNote that the correlationinterpolates between the largest\ntwo payoff values A00 and A11, and hence ?A(i,i;?) ?\nA11 for both of the edge QNE, i = 0,1.\nTo see if the dilemma can be resolved by taking non-\nedge QNE into account, we first observe that for BoS the\nconditions (3.27) are fulfilled for ?2 = 0, pi with arbitrary\n?1. For that non-edge QNE, the payoff ?A(?ne,?ne;?) in\n(3.35) reduces to (3.36) with A01 = A10. At ?1 = 0 this\nnon-edge QNE corresponds to the known mixed strategy\nNE in classical BoS, which cannot resolve the dilemma\nsince the payoffs are strictly less than those obtained un-\nder the two edge QNE for both of the players. The situa-\ntion doesnot improveevenfor?1 negationslash= 0, because the payoffs\nare independent of ?1 for all strategies. Moreover, on the\ngeneral basis of the assignments (4.1) (i.e., without mak-\ning use of the ansatz (3.26)), one can confirm by looking\nat the Hessian condition (3.9) that there is no non-edge\nQNE for BoS except for the one mentioned above. Thus\nwe find that under any correlations ? for the non-edge\nQNE we have ?A(?ne,?ne;?) < A11 and hence\n?A(i,i;?) > ?A(?ne,?ne;?), for i = 0,1. (4.5)\nAlthough the dilemma does not disappear even in\nquantum BoS, one may argue that the problem is some-\nwhat mitigated at?2 = pi/2 wherethe joint strategystate\nis maximally entangled. Indeed, under this correlation\nthe payoffs for the two edge QNE (4.18) for i = 0,1 coin-\ncide and hence the choice of strategies becomes irrelevant\nfor the players. The dilemma still remains in essence [16],\nhowever, because the players, who cannot communicate,\nmay inadvertently end up with a wrong strategy, |0,1? or\n|1,0?, yielding the worst payoff ?A = ?B = A01 (for all\n?). A similar conclusion has been drawn for BoS in [2, 8]\nusing a different quantization scheme with mixed quan-\ntum states, while a way out is suggested in an extended\nscheme [9]. The analysis [3] made in the scheme of [1]\nyields a considerably different outcome, with infinitely\nmany QNE with the payoffs lower than those of our edge\nQNE, indicating that the dilemma is unresolved unless\nsome subtle reasoning (focal point effect) is invoked.\nG?+\nG??\nCL\nME\nFIG. 4: Phase structure of edge QNE in the BoS game. The\nrectangle of the game is smashed to a line segment lying at the\ncentre as shown by the dotted line, which is entirely contained\nin the BoS domain. The right end point CL is the classical\nlimit and the middle point ME represents the point where the\nmaximally entangled correlation is realized.\nB. Prisoners? Dilemma\nThe PD game can also be analyzed in our scheme by\nconverting it to a dual T-symmetric game using the map\n(2.19). The general S-symmetric PD in classical game\ntheory may be defined by the payoff matrix for Alice Aij\nsatisfying\nA10 > A00 > A11 > A01, (4.6)\ntogether with Bob?s payoff given by Bij = Aji. Supple-\nmental conditions (which is inessential for the following\nargument),\n2A00 > A01 +A10 > 2A11, (4.7)\nmay also be imposed in order to render the strategies\n(i,j) = (0,0) and (1,1) the best and the worst of all\npossible strategies with respect to the sum of the payoffs\n[13]. The quantum PD is obtained by considering the\nself-adjointoperatorsA, B fulfilling (2.4), and the duality\nmap (2.19) yieldsthe T-symmetricversionof the PD with\nthe payoff operator ?A possessing the diagonal (classical)\nvalues\n( ?A00, ?A01, ?A10, ?A11) = (A10,A11,A00,A01). (4.8)\nIn terms of the converted payoff values, the conditions\n(4.6) and (4.7) turn out to be\n?A00 > ?A10 > ?A01 > ?A11, (4.9)\nand\n2 ?A10 > ?A00 + ?A11 > 2 ?A01. (4.10)\nNote that under the duality map for strategies (2.16) the\nparameters of the states (3.3) acquire the change\n(??1, ??2) = (?1 +pi, pi ??2). (4.11)\nIn addition, the duality relation in the correlation (2.18)\namounts to ?1 ? ?2 in G? and G??. To accommodate\nthese changes caused by the duality map, we use nota-\ntions such as\n?G? = G?|A? ?A,????, ?H? = H?|A? ?A,????, (4.12)\n10\nG?+\nG??\nCL\nG?+\nG??\nCL\nFIG. 5: Phase structure of edge QNE in the (T-symmetrized)\nPD game for the cases ?( ?A) > 0 (left) and ?( ?A) < 0 (right).\nFor both of the cases, the rectangle of the game, whose edges\nare shown by dotted lines, extends to domains of no dilemmas.\nfor our discussion of T-symmetric games.\nTo examine the possible phase structures of the game,\nwe observe that neither of the conditions (4.9) and (4.10)\ndetermines the sign of ?( ?A). However, since (4.9) implies\nthat the classical limit ? = 0 locates at the lower right\ncorner of the rectangle of the game, the inequalities\n?H+(0) = 2( ?A00 ? ?A10) > 0,\n?H?(0) = 2( ?A11 ? ?A10) < 0, (4.13)\nobtained at the classical limit ? = 0 from (4.9) are suf-\nficient to specify where the corner lies on the G?+-G??\nplane. The phase structures of the quantum PD game\nare then determined from the patterns of the rectangle\nin both of the cases ?( ?A) > 0 and ?( ?A) < 0, as illustrated\nin Figure 5. The outcome indicates that the correlation-\nfamily given by the rectangle does extend to domains of\nno dilemmas. It follows that, as long as edge QNE are\nconcerned, the quantum PD can be made dilemma-free\nwhen the correlations are furnished appropriately.\nFor a full resolution of the dilemma, we need to see\nwhether a non-edge QNE, if any, alters our conclusion\ndrawn from the edge QNE. This can be examined from\nthe analysis given in the previous section. We then learn\nthat, since the condition (3.31) is violated for (4.9), there\nis no non-edge QNE at the classical limit. We also re-\nalize that, for generic ?, the existence of non-edge QNE\nis dependent on the actual classical values of Aij, and\nthat for a wide range of payoff values centered at the\nstandard ones (A10,A00,A11,A01) = (5,3,1,0) used in\nthe literature (e.g., [1]), there exists no region fulfilling\n(3.33) and (3.34) simultaneously, and hence no non-edge\nQNE. Thus, our conclusion concerning the resolution of\nthe dilemma does not change in these standard settings\nof the PD game.\nC. Stag Hunt\nThe classical SH game is an S-symmetric game in\nwhich the payoff matrix for Alice fulfills the conditions,\nA00 > A10 ? A11 > A01, (4.14)\nwhich ensure that the strategies (0,0) and (1,1) are clas-\nsical NE. Among them, (0,0) is payoff dominant while\nG?+\nG??\nCL\nH+ + ? = 0\nH? + ? = 0\nFIG. 6: Phase structures of edge QNE (left) and non-edge\nQNE (right) in the (T-symmetrized) SH game. For edge\nQNE, the rectangle of the game extends to domains of no\ndilemmas. For non-edge QNE, the allowed regions by (3.33)\nare of the third type in Figure 3, and the two narrow regions\noverlapped with (3.34) shown in thick gray indicate the do-\nmains where a non-edge QNE appears.\nthe other (1,1) becomes risk dominant if\nA10 +A11 > A00 +A01. (4.15)\nAnalogously to the PD, we quantize the SH according to\n(2.4) and then T-symmetrizeit by the duality map (2.19).\nThis yields the payoffoperator ?A with the diagonalvalues\n(4.8) obeying\n?A10 > ?A00 ? ?A01 > ?A11, (4.16)\nand\n?A00 + ?A01 > ?A10 + ?A11. (4.17)\nNote that (4.16) implies ?( ?A) < 0. It also shows that\nthe classical limit is at the lower right corner of the rect-\nangle of the game, and that we have ?H?(0) < 0. From\nthis we can determine the position of the rectangle on the\nG?+-G?? plane as shown in Figure 6. The phase structure\nof the quantum SH game then suggests that, as in PD,\nthe correlation-family given by the rectangle extends to\ndomains without dilemmas. Within the edge strategies,\nthe dilemma of the SH can therefore be resolved in quan-\ntum game, if one adjusts the correlations appropriately.\nThe payoffs ?A(i,?i;?) at the edge QNE |??,??? = |i,?i?\nfor i = 0,1 read\n?A(i,?i;?) = cos2 ?12 ?Ai?i + sin2 ?12 ?A?ii, (4.18)\nwhich fall within the range of the payoffs of the two clas-\nsical NE, ?A10 ? ?A(i,?i;?) ? ?A01.\nThe classical SH game admits a mixed NE, and ac-\ncordingly the quantum SH admits a non-edge QNE for\na range of correlations including the classical limit, as\ncan be confirmed explicitly by examining the condition\n(3.37). To see where such correlations occur on the G?+-\nG?? plane, we consider the lines of equality H? + ? = 0\ndetermined by the condition (3.34), which are rewritten\nas\nG?+ = ?G?? ? ?\n2 +?+??\n2(G?? ??). (4.19)\n11\nCL:\nstrategy Bob |0? Bob |1? Bob |?ne?\nAlice |0? (3,0) (3,3) (3,3/4)\nAlice |1? (4,4) (0,3) (3,15/4)\nAlice |?ne? (15/4,3) (3/4,3) (3,3)\nME:\nstrategy Bob |0? Bob |1? Bob |?ne?\nAlice |0? (3,0) (7/2,7/2) (3,0)\nAlice |1? (7/2,7/2) (0,3) (7/2,7/2)\nAlice |?ne? (7/2,7/2) (0,3) (7/2,7/2)\nTABLE IV: Quantum payoff bi-matrices (?A,?B) of the SH\ngame for edge QNE and non-edge QNE. We used the values\n?A10 = 4, ?A00 = ?A01 = 3 and ?A11 = 0 (obtained from those\nmentioned in the text) to evaluate the payoffs at the classi-\ncal limit CL and the maximally entangled point ME, which\nare given by (G?+,G??) = (3,?1) and (3,0), respectively. The\npresence of the non-edge QNE worsens the risk balance be-\ntween the two edge QNE as we increase the amount of en-\ntanglement, but the dilemma disappears at ME where their\npayoffs become identical, for which the non-edge QNE does\nnot contribute.\nFor the SH we find ?2+?+?? > 0 from (4.16) and (4.17).\nThe domains where the non-edge QNE arise are then\nfound to be surrounded by the hyperbolae ? = 0 and\nthe curves (4.19), both of which come in contact at\n(G?+,G??) = ? 12? parenleftbig?2 +?+??,?2 ??+??parenrightbig. (4.20)\nAs illustrated in Figure 6, these domains are given by\ntwo narrow regions along the left and right edges of the\nrectangle of the game, indicating that under generic cor-\nrelations the non-edge QNE does not spoil the resolution\nof the dilemma in terms of edge QNE. It is, however,\nconceivable that the non-edge QNE, in the region where\nit is allowed, could alter the nature of the dilemmas, that\nis, the non-edge QNE could be both payoff and risk dom-\ninant under some particular correlations in the domains\nof SH, or it could pose a new dilemma in the domains\nwhere there was no dilemma originally. These possibili-\nties should be examined for the actual values of the payoff\nmatrix (4.16), but the analysis with the standard values\n(A00,A10,A11,A01) = (4,3,3,0) given in Table IV sug-\ngests that these are not likely to occur unless the payoff\nvalues are fine-tuned.\nV. CONCLUSION AND DISCUSSIONS\nIn this paper, we studied the phase structures of sym-\nmetric quantum games with respect to the stable strate-\ngies (QNE) available by pure states in quantum mechan-\nics. For quantization of classical games we adopted the\nscheme [7] which defines a unique correlation-family of\nquantum games from a classical game, allowing for all\npossible strategies realized by pure states, entangled or\nnot. The correlation-family is projected onto a rectangu-\nlar area in the G?+-G?? plane, where the phase structures\nof both the edge and non-edge QNE in the game can\nreadily be recognized. We have found that for symmet-\nric games there arise altogether eight different classes of\nphase structures for edge QNE depending on the payoff\nmatrices of the classical game we started with. This re-\nsult gives a more detailed account of the phase structures\nmentioned in [1] and discussed later in [5, 11].\nThe symmetric games considered in this paper consist\nof two types, T-symmetric and S-symmetric. We have\npresented a unified framework to treat them by means\nof a duality map, which enables us to use the results\nof the analysis of T-symmetric games for studying S-\nsymmetric games and vice versa. As an example of the\nT-symmetric game, we studied the BoS which is known\nto be a?icted with a dilemma classically. We have found\nthat the dilemma in the BoS cannot be resolved fully\n(albeit it can be alleviated) with strategies given by pure\nstates, even if we go over to quantum game where arbi-\ntrarily entangled states are utilized. Thus, the previous\nobservation made in [2, 8] remains essentially unchanged\neven in our enlarged scheme of quantum game, while the\noutcome is considerably different from those obtained in\nother schemes [3, 9]. As for the S-symmetric game, we\nexamined the PD and the SH to observe that for both of\nthe games the correlation-family contains a phase which\nis free from dilemmas under edge QNE. Since the stan-\ndard PD does not admit non-edge QNE, we concluded\nthat for the PD the classical dilemma disappears after\nquantization. For the SH, on the other hand, there ex-\nists a non-edge QNE which does not affect the resolution\nrealized by the edge QNE, generically. In short, quantum\nentanglement can resolve classical dilemmas for certain\ngames, and the games for which this is possible can be\njudged from the classical payoff matrices. We remark\nthat entanglement is necessary for the resolution of the\ndilemmas in our scheme, and that this is so in any other\nschemes of quantum games in which the resolution is pos-\nsible and the classical games are recovered in the limit\nwhere the joint strategies become separable as in (2.5).\nHowever, the actual amount of entanglement required de-\npends on the scheme used (because the class of families\nconsidered may be scheme-dependent) as well as on the\nvalues of the classical payoffs.\nCompared to most other schemes proposed so far, our\nscheme of quantum game is distinguished in the specifica-\ntion of strategies and correlations which are expressed in\nthe ordering of operations implementing them. Namely,\nin our scheme the players first make their choice of strate-\ngies independently, by performing the corresponding lo-\ncal unitary transformations on a fixed separable state,\nbefore a third party furnishes a correlation for the local\nstates. The player?s strategy is represented by a quantum\nstate, not by the local unitary transformation as consid-\nered in [1]. The advantage for this is that different pure\nstates used to specify the strategies yield different out-\ncomes of the payoff in general, while this is not ensured\nif unitary transformations are regarded as strategies. In\n12\nfact, it has been pointed out [6] that unitary transfor-\nmations become redundant (i.e., different unitary oper-\nations give the same quantum states) when the strate-\ngies are maximally entangled. Obviously, the choice of\nquantization scheme is directly related to the question of\nthe role of the third party which provides the quantum\ncorrelation in the game, and this has not been fully ex-\nplored yet. In this regard, we have found here a number\nof interesting features of quantum games which are com-\nmonly observed in various different schemes, in the phase\nstructures of the QNE and the resolution of dilemmas in\nsome of the familiar games. We hope that these findings\nwill help uncover the core elements ? independent of the\nscheme employed ? in quantum games, which are crucial\nfor laying a solid foundation of quantum game theory.\nAcknowledgments\nWe thank T. Cheon for helpful discussions. This work\nis supported by the Grant-in-Aid for Scientific Research,\nNo.13135206and No.16540354,ofthe JapaneseMinistry\nof Education, Science, Sports and Culture.\n[1] J. Eisert, M. Wilkens and M. Lewenstein, Quantum\ngames and quantum strategies, Phys. Rev. Lett. 83\n(1999) 3077-3080.\n[2] L. Marinatto and T. Weber, A quantum approach to\nstatic games of complete information, Phys. Lett. A272\n(2000) 291-303.\n[3] J. Shimamura, S. K. ?Ozdemir, F. Morikoshi and N.\nImoto, Quantum and classical correlations between play-\ners in game theory, Int.Journ. Quant.Inf.2(2004) 79-89.\n[4] J. Eisert and M. Wilkens, Quantum Games, J. Mod. Opt.\n47 (2000) 2543-2556.\n[5] J. Du, X. Xu, H. Li, X. Zhou and R. Han, Playing Pris-\noner?s Dilemma with Quantum Rules, Fluct. and Noise\nLett. 2 (2002) 189-203.\n[6] S. C. Benjamin and P. M. Hayden, Comment on ?Quan-\ntum Games and Quantum Strategies?, Phys. Rev. Lett.\n87 (2001) 069801.\n[7] T. Cheon and I. Tsutsui, Classical and Quantum Con-\ntents of Solvable Game Theory on Hilbert Space, Phys.\nLett. A348 (2006) 147-152\n[8] L. Marinatto and T. Weber, Reply to ?Comment on: A\nQuantum Approach to Static Games of Complete Infor-\nmation?, Phys. Lett. A277 (2000) 183-184.\n[9] A. Nawaz and A. H. Toor, Dilemma and Quantum Battle\nof Sexes, J. Phys. A: Math. Gen. 37 (2004) 4437-4443.\n[10] A. Nawaz and A. H. Toor, Generalized Quantization\nScheme for Two-Person Non-Zero-Sum Games, J. Phys.\nA: Math. Gen. 37 (2004) 11457-11463.\n[11] J. Du, X. Xu, H. Li, X. Zhou and R. Han, Experimental\nrealization of quantum games on a quantum computer,\nPhys. Rev. Lett. 88 (2002) 137902.\n[12] A. P. Flitney and D. Abbott, Advantage of a quantum\nplayer over a classical one in 2x2 quantum games, Poc\n.R. Soc. (London) A459 (2003) 2463-2474.\n[13] E. Rasmusen, An Introduction to Game Theory, Cam-\nbridge Univ. Press, Cambridge, 1989.\n[14] J. F. Nash, Equilibrium points in N-person games, Proc.\nNat. Acad. Sci. U.S.A. 36 (1950) 48-49.\n[15] C. F. Lee and N. Johnson, Quantum Game Theory, Phys.\nRev. A67 (2003) 022311.\n[16] S. C. Benjamin, Comment on ?A quantum approach to\nstatic games of complete information?, Phys. Lett. A277\n(2000) 180-182.\n[17] Apart from the irrelevant freedoms concerning the over-\nall phase and the normalization, the dimensionality of the\njoint strategy space is dimH ? 2 = 6 in real variables.\nSince the individual strategies |??A and |??B are specified\nby 2 + 2 = 4 parameters (e.g., see (3.3)), the correlation\nfactor must have another 2 parameters to cover the full\njoint strategy space. The actual construction of the cor-\nrelation factor is far from unique, and our form (2.11) is\nadopted based on the convenience for the duality map.\n[18] In the present paper, we consider quantum joint strate-\ngies given by pure states only. The space of pure states is\nnot convex, and hence the Nash theorem [14], which en-\nsures the existence of NE for a classical game with mixed\nstrategies, is no longer available. The existence of QNE\nin quantum game is, therefore, non-trivial [15].\n"}
{"id":"oai:arXiv.org:hep-ph/0610379","text":"arXiv:hep-ph/0610379v2  12 Jul 2007\nDirect detection of neutralino dark matter in non-standard\ncosmologies\nGraciela B. Gelmini,1, ? Paolo Gondolo,2, ? Adrian Soldatenko,1, ? and Carlos E. Yaguna1, ?\n1Department of Physics and Astronomy, UCLA,\n475 Portola Plaza, Los Angeles, CA 90095, USA\n2Department of Physics, University of Utah,\n115 S 1400 E # 201, Salt Lake City, UT 84112, USA\nAbstract\nWe compute the neutralino direct detection rate in non-standard cosmological scenarios where\nneutralinos account for the dark matter of the Universe. Significant differences are found when\nsuch rates are compared with those predicted by the standard cosmological model. For bino-\nlike neutralinos, the main feature is the presence of additional light (m? lessorsimilar 40 GeV) and heavy\n(m? greaterorsimilar 600 GeV) neutralinos with detection rates within the sensitivity of future dark matter\nexperiments. For higgsino- and wino-like neutralinos lighter than m? ? 1 TeV, enhancements of\nmore than two orders of magnitude in the largest detection rates are observed. Thus, if dark matter\nis made up of neutralinos, the prospects for their direct detection are in general more promising\nthan in the standard cosmology.\n?Electronic address: gelmini@physics.ucla.edu\n?Electronic address: paolo@physics.utah.edu\n?Electronic address: asold@physics.ucla.edu\n?Electronic address: yaguna@physics.ucla.edu\n1\nI. INTRODUCTION\nThe Large Hadron Collider is now in its final preparation stages and may soon be search-\ning for supersymmetric particles. Among them, the lightest neutralino in the minimal su-\npersymmetric standard model plays a distinctive role as a dark matter candidate [1]. It is\nneutral, weakly interacting, and stable (provided it is the lightest supersymmetric particle).\nIf evidence for low energy supersymmetry is found, it will strongly support the idea that\nneutralinos constitute the dark matter of the Universe. A logical next step would then be\nthe use of neutralinos as cosmological probes of the early Universe. Neutralinos could, in\nparticular, test the standard cosmological model well before big bang nucleosynthesis. Being\nan observable sensitive to the conditions in the early Universe, the neutralino direct detec-\ntion rate provides a plausible way of discriminating between different cosmological models,\nand therefore an indirect way of testing the standard scenario. Most studies on the direct\ndetection of neutralinos already assume the standard cosmology so it is not known what to\nexpect in a more general cosmological framework.\nThe vastness of the supersymmetric parameter space is the most compelling reason to\nassume the standard cosmological model. In a general setup, neither the neutralino mass\nor gauge composition nor its interaction rate, for example, can be determined a priori. To\nreduce such uncertainties, the dark matter constraint is usually imposed on supersymmetric\nmodels. That is, the neutralino relic density is computed within the standard cosmological\nmodel and only models with ?std < ?DM are considered (here ?std is the neutralino density\nin the standard cosmological model, and ?DM is the cold dark matter density, both in units\nof the critical density). This bound, it turns out, is very effective in restricting the parameter\nspace of supersymmetric models. In minimal supergravity models (mSUGRA), for instance,\nthe neutralino typically has a small annihilation rate in the early Universe, thus its relic\ndensity tends to be larger than observed. At the end, the requirement ?std < ?DM is found\nto be satisfied only along four narrow regions: the ?bulk? (with a light neutralino and tight\naccelerator constraints), the ?coannihilation region? (where the stau is almost degenerate\nwith the neutralino and coannihilation effects suppress the relic density), the ?funnel region?\n(where m? ?mA/2 and resonance effects enhance the ?-? annihilation rate) and the ?focus\npoint region? (where the neutralino acquires a non-negligible higgsino fraction). Accounting\nfor the dark matter provides, in fact, the most stringent constraint on supersymmetric\n2\nmodels, well over precision data or accelerator searches (see e.g. [2]).\nThough useful in reducing the supersymmetric parameter space, the dark matter con-\nstraint should not be taken for granted, as it relies on untested assumptions about the early\nUniverse. In particular, it postulates that the entropy of matter and radiation is conserved\nand that the Universe is radiation dominated at high temperatures (T ? m?). Several sce-\nnarios where such assumptions do not hold and, more generally, where the evolution of the\nUniverse before big bang nucleosynthesis deviates from the standard cosmological model,\nhave been studied in the literature. They are generically known as non-standard cosmolo-\ngies and include models with gravitino [3], moduli [4] or Q-ball decay [5], thermal inflation\n[6], the Brans-Dicke-Jordan [7] cosmological model, models with anisotropic expansion [8]\nor quintessence domination [9]. Non-standard cosmological models are viable alternatives\nagainst which the predictions of the standard scenario may be compared.\nIn non-standard cosmological scenarios, the neutralino relic density ?? may be larger or\nsmaller than ?std [11]-[20]. Smaller densities are usually the result of an episode of entropy\nproduction that dilutes the neutralino abundance. Larger densities are due either to ad-\nditional contributions to the expansion rate of the Universe, or to non-thermal neutralino\nproduction mechanisms. Usually these scenarios contain additional parameters that can be\nadjusted to modify the neutralino relic density. A distinctive feature of non-standard\ncosmologies is that the new physics they incorporate does not manifest in ac-\ncelerator or detection experiments. That is certainly the case, for instance, for\nthe several models mentioned above. Neutralino scattering rates, therefore, are\nnot affected by the cosmological model.\nA prototype non-standard cosmological model is that of a scalar field ? with\ncouplings of gravitational strength whose late decay reheats the Universe to\na low reheating temperature. The reheating temperature in this scenario can\nbe lower than the standard neutralino freeze-out temperature without spoiling\nprimordial nucleosynthesis [10]. Such scalar fields are common in superstring\nmodels where they appear as moduli fields. In these models, the decay of ?\ninto radiation increases the entropy, diluting the neutralino number density.\nInstead, the decay of ? into supersymmetric particles, which eventually decay\ninto neutralinos, increases the neutralino number density. In this non-standard\ncosmological model it has been shown that practically all neutralinos can have\n3\nthe density of the dark matter, provided the right combination of two parameters\ncan be achieved in the high energy theory: the reheating temperature, and\nthe ratio of the number of neutralinos produced per ? decay over the ? field\nmass [19, 20].\nIn this paper, we compute the neutralino direct detection rate in generic cosmological\nscenarios where neutralinos constitute the dark matter of the Universe. That is, we assume\nthat, independently of the supersymmetric spectrum, the parameters of the non-standard\ncosmological model can always be chosen so that ?? = ?DM. By randomly scanning the\nsupersymmetric parameter space, we obtain a large sample of models and compute their\ndetection rates in non-standard cosmologies. These predictions are then compared with\nthose obtained within the standard cosmological model. Our goal is twofold. First, we\nexplore the possibility of using the neutralino direct detection rate as a test of the standard\ncosmological model. Second, we establish the potential of future dark matter detectors in\nprobing the parameter space of supersymmetric models in a cosmology-independent setup.\nII. THE SUPERSYMMETRIC MODELS\nIn the MSSM, neutralinos are linear combinations of the fermionic partners of the neutral\nelectroweak bosons, called bino ( ?B0) and wino ( ?W03), and of the fermionic partners of the\nneutral Higgs bosons, called higgsinos ( ?H0u, ?H0d). We assume that the lightest neutralino, ?,\nis the dark matter candidate. Its composition can be parameterized as\n? = N11 ?B0 +N12 ?W03 +N13 ?H0d +N14 ?H0u . (1)\nBecause the neutralino interactions are determined by its gauge content, it is useful to\ndistinguish between bino-like (N211 > N212, N213 + N214), wino-like (N212 > N211, N213 + N214),\nand higgsino-like (N213 + N214 > N211, N212) neutralinos according to the hierarchy of terms\nin (1). This classification implies that even so-called mixed neutralinos, those with two or\nmore comparable components, are considered as either binos, winos or higgsinos.\nBino-like neutralinos annihilate mainly into fermion-antifermion pairs through sfermion\nexchange. Such annihilation cross-section is helicity suppressed and gives rise to a standard\nrelic density that is usually larger than observed. Agreement with the observed dark matter\nabundance can still be achieved in standard cosmological scenarios but only in restricted\n4\nregions of the parameter space where special mechanisms such as coannihilations or resonant\nannihilations help reduce the relic density. Owing to the gaugino unification condition, bino-\nlike neutralinos are a generic prediction of minimal supergravity models.\nWino-like andhiggsino-like neutralinos annihilate mostly into gaugebosons (W+W?, ZZ,\nif kinematically allowed) through neutralino or chargino exchange; otherwise they annihilate\ninto fermions. Due to coannihilations with the lightest chargino (and, for higgsinos, with the\nnext-to-lightest neutralino), their standard relic density is rather small. Neutralino masses\nas large as 1 TeV for higgsinos or 2 TeV for winos are required to bring their thermal density\nwithin the observed range. Wino-like and higgsino-like neutralinos can be obtained in models\nwith non-universal gaugino masses; models with anomaly mediated supersymmetry breaking\n(AMSB) [21], for instance, feature a wino-like neutralino.\nWe consider a general class of MSSM models defined in terms of the parameter set M3,\nM2, M1, mA, ?, tan?, m?q, m?? At, and Ab. Here Mi are the three gaugino masses, mA\nis the mass of the pseudoscalar higgs boson, and tan? denotes the ratio v2/v1. The soft\nbreaking scalar masses are defined through the simplifying ansatz MQ = MU = MD = m?q\nand ME = ML = m??, whereas the trilinear couplings are given by AU = diag(0,0,At),\nAD = diag(0,0,Ab), and AE = 0. All these parameters are defined at the weak scale.\nSpecific realizations of supersymmetry breaking such as mSUGRA, mAMSB [21] or split-\nSUSY [22] are similar to - though not necessarily coincide with - particular examples of these\nmodels.\nWe performed a random scan of such parameter space within the following ranges\n10 GeV < M1,M2,M3 < 50 TeV (2)\n40 GeV < mA,?,m?q,m?? < 50 TeV (3)\n?3m0 < At,Ab < 3m0 (4)\n1 < tan? < 60 (5)\nA logarithmic distribution was used for Mi, mA, ?, m?q and m??, and a linear one for At, Ab,\nand tan?; the sign of ? was randomly chosen. After imposing accelerator constraints, as\ncontained in DarkSUSY version 4.1 [23], a sample of about 105 viable models was obtained.\nThe following analysis is based on such a sample of supersymmetric models.\n5\n10 100 1000 10000\nNeutralino mass (GeV)\n0.0001\n0.01\n1\n100\n10000\n1e+06\n?h\n2\nBinos\nWinos\nHiggsinos\nFIG. 1: The standard neutralino relic density as a function of the neutralino mass for our sample\nof models. The models are differentiated according to the bino, wino, or higgsino character of the\nlightest neutralino. The horizontal band indicates the dark matter range.\nIII. RESULTS\nFigure 1 shows the standard relic density as a function of the neutralino mass for our\nsample of models. Each cell -triangle, circle or dot- represents a small region around which at\nleast one model was found. The models are classified as binos, winos, or higgsinos, according\nto the gauge composition of the lightest neutralino. The horizontal band corresponds to\nthe observed dark matter density ?stdh2 = ?dmh2 = 0.109+0.003?0.006, obtained for a ?CDM\nmodel with scale-invariant primordial perturbation spectrum through a global fit of cosmic\nmicrowave background, supernovae, and large scale structure data [24]. Several observations\ncan be made from this figure. Models with bino-like neutralinos are spread over a wide area\nand usually give a rather large relic density. Models with wino- and higgsino-like neutralinos,\non the contrary, are concentrated over narrow bands and their relic density exceeds the dark\nmatter density only for large masses, m? greaterorsimilar 1 TeV. Finally, notice that in our sample the\n6\nneutralino relic density varies between 106 and 10?4.\nWe now want to compute, for our set of models, the neutralino interaction rates in generic\ncosmologies where the neutralino accounts for the dark matter and compare them with those\nobtained in the standard cosmology. Since spin-dependent searches are harder than spin-\nindependent ones, we will focus on the latter. The neutralino interaction rate in direct\ndark matter detection experiments is proportional to the product of the spin-independent\nneutralino-nucleus cross section ?SI and the number density of neutralinos passing through\nthe detector, f. We assume that, as expected for collisionless cold dark matter, f = ??/?dm.\n?SI is determined only by the supersymmetric spectrum but ?? is sensitive to the cosmo-\nlogical setup. Thus, the neutralino detection rate depends on the cosmology only through\nf.\nIf the standard cosmological model is assumed, then all models above the horizontal band\nin figure 1 are rejected. They have a standard relic density larger than the observed dark\nmatter density (?std > ?DM) and therefore are considered incompatible with cosmological\nobservations. Models with a relic density below the dark matter density are still viable,\nthough neutralinos make up only a fraction of the dark matter. They have f < 1, so their\ndetection rate is typically suppressed. Finally, those models with a neutralino relic density\nwithin the observed dark matter range are viable and have f = 1. They have been the focus\nof the large majority of studies on neutralino direct detection.\nIn non-standard cosmologies, ?? = ?DM may be ensured and the previous picture is\nmodified in two important ways. On the one hand, the viable parameter space is different. In\nfact, overdense models, those with ?std > ?DM, canno longer be rejected. On theother hand,\nunderdense models, those with ?std < ?DM, no longer will have the f < 1 suppression factor\nin the detection rate. Hence, in non-standard cosmologies, we expect more viable models\nand larger detection rates. A priori, however, it is not possible to predict the detection rate\nfor the new viable models or to know whether the enhanced detection rates are within the\nsensitivity of future dark matter detection experiments. Thus, a careful analysis is required\nto establish the implications of non-standard cosmologies for dark matter searches. In the\nfollowing, such an analysis will be carried out.\nFigure 2 displays the detection rate in standard and non-standard cosmologies for bino-\nlike neutralinos as a function of the neutralino mass. As before, the figure has been divided\ninto a rectangular grid and each occupied cell denotes the existence of at least one model\n7\n10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 2: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM for bino-like neutralinos in the standard and non-standard cosmological\nmodels. The solid line indicates the CDMS II present limit [25]. The dashed lines show sensitivity\nlimits for -from top to bottom on the right- CDMS II,ZEPLINIV , XENON-1Ton, and SuperCDMS\nphase C [26].\naround it. For comparison, we also show the current limit from the CDMS II experiment [25]\naswell asthe expected sensitivity of CDMS II, ZEPLIN IV , XENON-1Ton, andSuperCDMS\nphase C [26]. In the standard scenario, both the lower and the upper limit on the bino\nmass are set by the relic density constraint. That is why the range of neutralino masses\nextends to lower and higher values in non-standard cosmologies. They yield many more\nviable models, though most of them have rather small detection rates. This fact is not\nentirely surprising. Small annihilation rates, as those associated with bino-like neutralinos,\nare generically correlated with small scattering rates. Regarding dark matter searches, the\nmost remarkable difference observed in the figure is the existence of new viable models with\nneutralino masses not allowed in the standard cosmology and detection rates within the\nreach of future experiments. Such models feature either m? lessorsimilar 40 GeV or m? greaterorsimilar 600 GeV\n8\n10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 3: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM for higgsino-like neutralinos in the standard and non-standard cosmological\nmodels. The solid line indicates the CDMS II present limit [25]. The dashed lines show sensitivity\nlimits for -from top to bottom on the right- CDMS II,ZEPLINIV , XENON-1Ton, and SuperCDMS\nphase C [26].\nand may be detected in ZEPLIN IV, XENON-1Ton, or SuperCDMS phase C.\nThe detection rate for higgsino-like neutralinos is shown in figure 3 as a function of\nthe neutralino mass in standard and non-standard cosmologies. The lower limit on the\nhiggsino mass is now set by the experimental constraint on the chargino mass and is therefore\nindependent of the cosmological scenario. Two features clearly distinguish the standard and\nthe non-standard cosmologies. One of them is the existence of viable models with heavy\nneutralinos, m? greaterorsimilar 1 TeV. A sizable fraction of them has detection rates large enough\nto be observed in ZEPLINIV, XENON-1Ton, or SuperCDMS phase C. The other feature\nis the significant enhancement in the detection rate of neutralinos lighter than lessorsimilar 1 TeV.\nIn the standard scenario, such neutralinos are usually underdense (see figure 1) and have\nsuppressed detection rates. From the figure we see that non-standard cosmologies yield an\n9\n10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 4: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM for wino-like neutralinos in the standard and non-standard cosmological\nmodels. The solid line indicates the CDMS II present limit [25]. The dashed lines show sensitivity\nlimits for -from top to bottom on the right- CDMS II,ZEPLINIV , XENON-1Ton, and SuperCDMS\nphase C [26].\nenhancement of up to two orders of magnitude for the neutralinos with the largest detection\nrates. Some of them are already ruled out by the present limit and many more will be within\nthe expected sensitivity of the CDMSII experiment.\nA compelling signature of non-standard cosmologies would be the detection of a wino-\nlike neutralino by the CDMSII experiment, as revealed in figure 4. Indeed, in the standard\nscenario, winos with m? lessorsimilar 1-2 TeV are usually underdense and therefore their detection rate\nis suppressed by the factor f = ?std/?DM. In non-standard cosmologies, such suppression\nis nonexistent and light winos have larger detection rates. The enhancement in the largest\ndetection rates are typically larger than for higgsinos, amounting in some cases to three\norders of magnitude. As for higgsinos, the lower bound on m? is not set by the dark matter\nbound but rather by the experimental constraint on the chargino mass, so no additional\n10\n1 10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 5: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM in the standard cosmological model and in the late decaying scalar field\nmodel. Here the lower limit of M1 in Eq. (2) has been lowered to 0.1 MeV The solid upper line\nindicates the CDMS II present limit [25] and the lower solid line the XENON limit [27]. The\ndashed lines show sensitivity limits for -from top to bottom on the right- CDMS II, ZEPLIN IV ,\nXENON-1Ton, and SuperCDMS phase C [26].\nmodels are found at low neutralino masses. For m? greaterorsimilar 2 TeV we do find new viable models\ncorresponding to overdense neutralinos in the standard cosmology. Most of them, however,\nhave small scattering rates, lying below the sensitivity of future detection experiments.\nFigure 5 summarizes the potential increase in neutralino candidates in the\nmodels studied in references [19] and [20]. For this figure the lower limit on M1 in\nEq. (2) has been lowered to 0.1 GeV (which is compatible with all experimental\nlimits (while no assumption is made on the relation between M1 and M2). In the\nlate decaying scalar field scenario most neutrinos can be brought to have the\ndark matter density (provided the value of the two relevant parameters of the\nphysics at the high scale can be suitably arranged). One exception is that of\n11\nvery light neutralinos which would be very overdense in the standard cosmology.\nRequiring the reheating temperature to be above 4 MeV [10], in order not to\nmodify nucleosynthesis, from the equations of reference [19] it is immediate to\nsee that neutralinos of mass m? should have a standard density smaller than\nthe dark matter density times (m?/120MeV)4 for it to be possible to bring their\ndensity to be that of the dark matter in the late decaying scalar field scenario.\nThis constraint is included in figure 5 where it is clearly shown the increase\nin potential neutralino candidates in the particular non-standard cosmological\nmodel considered with respect to the standard cosmological model.\nIV. CONCLUSION\nTo summarize, in this paper we computed the direct detection rate of MSSM neutralinos\nin generic cosmological scenarios where they constitute the dark matter of the Universe.\nWhen compared with the predictions of the standard cosmology, considerable differences\nwere encountered. If the neutralino is bino-like, as in msugra models, additional light m? lessorsimilar\n40 GeV and heavy m? greaterorsimilar 600 GeV neutralinos with non-negligible detection rates were found.\nThey could be detected in a variety of dark matter experiments such as ZEPLINIV, XENON-\n1Ton, or SuperCDMS phase C. For higgsino-like neutralinos, we found enhancements of up\nto two orders of magnitude in the largest detection rates as well as new viable models with\nheavy m? greaterorsimilar 1 TeV neutralinos. Both effects yielding detection rates within the sensitivity\nof future experiments. Wino-like neutralinos provide the clearest signature of non-standard\ncosmologies. Their detection rates may be enhanced by up to three orders of magnitude and\nthey could be detected in CDMSII. Thus, the prospects for the direct detection of neutralinos\nin non-standard cosmologies are significantly more promising than in the standard scenario.\nAcknowledgments\nWe thank Oleg Kalashev for allowing us to use the graphreader program. G.G., A.S. and\nC.Y. were supported in part by the US Department of Energy Grant DE-FG03-91ER40662,\nTask C and G.G. also by NASA grants NAG5-13399 and ATP03-0000-0057 at UCLA. P.G.\n12\nwas supported in part by the NFS grant PHY-0456825 at the University of Utah.\n[1] K. Griest and M. Kamionkowski, Phys. Rept. 333 (2000) 167.\n[2] J. R. Ellis, K. A. Olive, Y. Santoso and V. C. Spanos, Phys. Lett. B 565, 176 (2003).\n[3] T. Moroi, M. Yamaguchi and T. Yanagida, Phys. Lett.B 342,105 (1995); M Kawasaki, T.\nMoroi and T. Yanagida, Phys. Lett.B 370,52 (1996).\n[4] T. Moroi and L. Randall, Nucl. Phys. B570, 455 (2000).\n[5] M. Fujii, K. Hamaguchi, Phys. Rev. D 66, 083501 (2002); M. Fujii, M. Ibe, Phys. Rev. D 69,\n035006 (2004).\n[6] D. H. Lyth, E.D. Stewart, Phys. Rev. D 53, 1784 (1996).\n[7] M. Kamionkowski and M. S. Turner, Phys. Rev. D 42, 3310 (1990).\n[8] J. D. Barrow, Nucl. Phys. B 208, 501 (1982).\n[9] P. Salati, Phys. Lett. B 571, 121 (2003) [arXiv:astro-ph/0207396]; S. Profumo and P. Ullio,\nJCAP 0311, 006 (2003) [arXiv:hep-ph/0309220]. S. Profumo and C. E. Yaguna,\nPhys. Rev. D 70, 095004 (2004)\n[arXiv:hep-ph/0407036].\n[10] M. Kawasaki, K. Kohri, and N. Sugiyama, Phys. Rev. Lett. 82, 4168 (1999); Phys. Rev. D\n62, 023506 (2000); S. Hannestad, Phys. Rev. D 70, 043506 (2004).\n[11] M. Kamionkowski, M. Turner, Phys. Rev. D 42 3310 (1990); R. Jeannerot, X. Zhang, R.\nBrandenberger, JHEP 12, 003 (1999); W. B. Lin, D. H. Huang, X. Zhang, R. Brandenberger,\nPhys. Rev. Lett. 86 954 (2001).\n[12] T. Moroi, M. Yamaguchi and T. Yanagida, Phys. Lett.B 342,105 (1995); M Kawasaki, T.\nMoroi and T. Yanagida, Phys. Lett.B 370,52 (1996).\n[13] D. J.H. Chung, E. W. Kolb and A. Riotto, Phys. Rev. D60, 063504 (1999).\n[14] G. F. Giudice, E. W. Kolb and A. Riotto, Phys. Rev. D64, 023508 (2001).\n[15] R. Allahverdi and M. Drees, Phys. Rev. Lett. 89, 091302 (2002) and Phys. Rev. D66, 063513\n(2002).\n[16] S. Khalil, C. Mu?noz and E. Torrente-Lujan, New Journal of Physics 4, 27 (2002); E. Torrente-\nLujan, hep-ph/0210036 (2002).\n[17] N. Fornengo, A. Riotto, and S. Scopel, Phys. Rev. D67, 023514 (2003).\n13\n[18] C. Pallis, Astrop. Phys. 21, 689 (2004).\n[19] G. B. Gelmini and P. Gondolo, Phys. Rev. D 74, 023510 (2006)\n[20] G. Gelmini, P. Gondolo, A. Soldatenko and C. E. Yaguna, Phys. Rev. D 74, 083514 (2006).\n[21] L. Randall and R. Sundrum, Nucl. Phys. B 557, 79 (1999) [arXiv:hep-th/9810155].\nG. F. Giudice, M. A. Luty, H. Murayama and R. Rattazzi, JHEP 9812, 027 (1998)\n[arXiv:hep-ph/9810442].\n[22] N. Arkani-Hamed, S. Dimopoulos, G. F. Giudice and A. Romanino, Nucl. Phys. B 709,\n3 (2005) [arXiv:hep-ph/0409232]. G. F. Giudice and A. Romanino, Nucl. Phys. B 699, 65\n(2004) [Erratum-ibid. B 706, 65 (2005)] [arXiv:hep-ph/0406088].\n[23] P. Gondolo, J. Edsjo, P. Ullio, L. Bergstrom, M. Schelke and E. A. Baltz, JCAP 0407, 008\n(2004).\n[24] D.N. Spergel et al. Astrophys. J., Suppl. Ser. 148, 175 (2003); D.N.\nSpergel it et al., astro-ph/0603449 (2006); http:// lambda.gsfc.nasa.gov/ prod-\nuct/map/current/parameters.cfm.\n[25] D. S. Akerib et al. [CDMS Collaboration], Phys. Rev. Lett. 96, 011302 (2006)\n[arXiv:astro-ph/0509259].\n[26] R. J. Gaitskell, Ann. Rev. Nucl. Part. Sci. 54, 315 (2004).\n[27] D. N. McKinsey [XENON Collaboration], AIP Conf. Proc. 870 (2006) 202; J. Angle et al.\n[XENON Collaboration], arXiv:0706.0039 [astro-ph].\n14\n"}
{"id":"oai:arXiv.org:hep-ph/0610379","text":"arXiv:hep-ph/0612309v1  22 Dec 2006\nProbing the octant of ?23 with very long baseline neutrino\noscillation experiments: a global look\nGuey-Lin Lina,b? and Yoshiaki Umedaa?\naInstitute of Physics, National Chiao-Tung University, Hsinchu 300, Taiwan\nbPhysics Division, National Center for Theoretical Sciences, Hsinchu 300, Taiwan\n(Dated: February 7, 2008)\nAbstract\nWe investigate the baseline range in which the ?23 degeneracy in neutrino oscillation probabilities\nis absent for fixed values of ?13 and CP violation phase ?CP. We begin by studying sensitivities\nof neutrino oscillation probabilities to ?13, ?23 and ?CP for very-long-baseline neutrino oscillations.\nWe show contour graphs of the muon-neutrino survival probability P(?? ? ??) and the appearance\nprobability P(?e ? ??) on the cos2?23?sin2?13 plane for baseline lengths L = 1000, 5000, 10000,\nand 12000 km. For each baseline length, it is found that P(?? ? ??) is more sensitive to sin2?13 at\nenergies around its local maximum while it is more sensitive to cos2?23 at energies around its local\nminimum. On the other hand, the appearance probability P(?e ? ??) is sensitive to sin2?13 and\ncos2?23 only near its local maximum. We observe that the ?23 degeneracy in P(?? ? ??) is absent\nat energies around the local maximum of this probability, provided ?13 is sufficiently large. The\n?23 degeneracy is also absent in general near the local maximum of P(?e ? ??). Using analytic\napproximations for neutrino oscillation probabilities, we demonstrate that the above observations\nfor L = 1000, 5000, 10000, and 12000 km are in fact valid for all distances. The implications of\nthese results on probing the octant of ?23 are discussed in details.\nPACS numbers: 14.60.Pq, 13.15.+g, 14.60.Lm\n? E-mail: glin@cc.nctu.edu.tw\n? E-mail: umeda@faculty.nctu.edu.tw\n1\nI. INTRODUCTION\nThe understanding of neutrino masses and mixing matrix is crucial to unveil the mystery\nof lepton flavor structures. The updated SK analysis of the atmospheric neutrino data gives\n[1]\n1.5?10?3 eV2 < |?m231| < 3.4?10?3 eV2, sin2 2?23 > 0.92. (1)\nThis is a 90%C.L. range with the best fit values given by sin2 2?23 = 1 and ?m231 =\n2.1?10?3 eV2 respectively. An earlier result based upon L/E analysis gives [2]\n1.9?10?3 eV2 < |?m231| < 3.0?10?3 eV2, sin2 2?23 > 0.9. (2)\nat 90%C.L. where the best fit values are given by sin2 2?23 = 1 and ?m231 = 2.4?10?3 eV2\nrespectively. The scenario of ?? ? ?? oscillation for atmospheric neutrinos has been con-\nfirmed by the K2K experiment [3, 4]. Furthermore the results in the solar neutrino oscillation\nmeasurements are also confirmed by KamLAND reactor measurements [5, 6]. Combining\nthese measurements, the LMA solution of the solar neutrino problem is established and the\nupdated 2? parameter ranges are given by [7]\n7.21?10?5 eV2 < ?m221 < 8.63?10?5 eV2, 0.267 < sin2 ?12 < 0.371, (3)\nwith the best fit values ?m221 = 7.92?10?5 eV2 and sin2 ?12 = 0.314.\nDespite the achievements so far in measuring the neutrino mixing parameters, the sign\nof ?m231, the mixing angle ?13 and the CP violating parameter ?CP in the mixing matrix\nremain to be determined. Furthermore, one is keen to resolve the octant degeneracy of ?23\n[8].\nThe mixing angle ?13 is constrained by the reactor experiments [9, 10]. The CHOOZ\nexperiment [9] gives a more stringent constraint on ?13 with sin2 2?13 < 0.1 for a large\n?m231 (90% C.L.). A recent global fit based upon three-flavor neutrino oscillation gives the\n2? upper bound, sin2 2?13 < 0.124 [7]. It is well known that the mixing angle ?13 can be\nenhanced by the matter effect in Earth. The appearance oscillations ?? ? ?e, ?e ? ??,\nand the survival mode ?? ? ?? performed in a very-long baseline have been proposed\n[11] to probe the angle ?13 and the sign of ?m231. Furthermore, the aforementioned very\nlong baseline neutrino experiments as well as future atmospheric neutrino experiments are\nproposed to determine the deviation of ?23 to maximality [12]. In this work, we focus on\n2\nthe mixing angle ?23. We shall provide a global survey on ideal neutrino energies in the\nGeV range and baseline lengths from 103 km to 104 km for probing the octant of the mixing\nangle ?23. The muon neutrino survival probability P(?? ? ??) ? P?? and electron neutrino\nappearance probability P(?e ? ??) ? Pe? are both studied for this purpose. We observe\nthat the muon neutrino survival probability P?? has complementary dependencies on mixing\nangles ?13 and ?23 as the neutrino energy varies. This property is established by studying\nthe dependencies of P?? on cos2?23 and sin2?13 while keeping other parameters fixed. The\nchoice of the parameter cos2?23 is appropriate as\n1\n2 cos2?23 =\n1\n2 ?sin\n2 ?23, (4)\nwhich is a probe to the deviation of ?23 to the best-fit value pi/4. We find that the de-\npendencies of P?? on cos2?23 and sin2?13 at energies near local maxima of this probability\ndiffer drastically from those at energies near local maxima of the same probability. In the\nformer case, the probability P?? is always more sensitive to sin2?13. Furthermore, the ?23\ndegeneracy is absent in this case. In the latter case, the probability P?? is more sensitive to\ncos2?23 while the ?23 degeneracy is generally present. Such information is useful for probing\nthe octant of ?23. We also study sensitivities of the probability Pe? to cos2?23 and sin2?13\nwith other parameters fixed. We only focus on energies near the local maximum of Pe? as\nthis probability is not sensitive to mixing parameters for energies near its local minimum.\nThis paper is organized as follows. In Section II, we compare results on the oscillation\nprobability Pe? obtained by the full calculation with those obtained by various analytic\napproximations. This comparison is essential since analytic approximations will be employed\nfor discussions in later sessions. To set up the analytic approximation, we introduce the\nconcept of average density which varies with the total neutrino path-length inside the Earth.\nApplying full calculations and the two-layer analytic approximations [13], we identify the\nenergy values for local maxima and local minima of neutrino oscillation probabilities P?? and\nPe? for baseline lengths 1000 ? L/km ? 12000. It is found that the two-layer approximation\nis quite satisfactory compared to the full calculation for computing these energy values. In\nSection III, we first present the dependencies of P?? and Pe? on the CP violation phase\n?CP. It will be shown that, unlike Pe?, P?? is not sensitive to the CP violation phase ?CP.\nWe study numerically the effect of CP violation phase to the appearance probability Pe?.\nThe result confirms the so-called magic baseline [14, 15, 16] at L ? 7600 km where Pe? is\n3\nrather insensitive to the CP violation phase. After discussions on the CP violation phase,\nwe present the contour graphs of probabilities P?? and Pe? on cos2?23 ?sin2?13 plane for\nbaseline lengths L = 1000, 5000, 10000, and 12000 km. At all these baseline lengths, we\nshall see that P?? is more sensitive to sin2?13 at energies around its local maximum while\nit is more sensitive to cos2?23 at energies around its local minimum. Such observations\nare then justified by using the two-layer analytic approximations for neutrino oscillation\nprobabilities. With this approximation, the baseline lengths and neutrino energies allowing\nan unambiguous determination of ?23 through measuring P?? are identified. In Section IV,\nwe discuss the prospects of probing the ?23 octant via measuring Pe? and P??. We then\nconclude in the same section.\nII. THE COMPARISON OF FULL CALCULATIONSAND ANALYTICAPPROX-\nIMATIONS\nWe begin the discussions with the relation connecting flavor and mass eigenstates of\nneutrinos, ?? =summationtexti U?i?i, with U the Maki-Nakagawa-Sakata mixing matrix [17] given by\nU =\n?\n??\n??\nc12c13 s12c13 s13e?i?CP\n?s12c23 ?c12s13s23ei?CP c12c23 ?s12s13s23ei?CP c13s23\ns12s23 ?c12s13c23ei?CP ?c12s23 ?s12s13c23ei?CP c13c23\n?\n??\n?? , (5)\nwhere sij and cij denote sin?ij and cos?ij, respectively. The value for the Dirac type CP-\nphase ?CP ranges from 0 to 2pi. The evolutions of neutrino flavor eigenstates are governed\nby the equation\ni ddt|?(t)? =\n?\n????\n????\n1\n2E?U\n?\n??\n??\n0 0 0\n0 ?m221 0\n0 0 ?m231\n?\n??\n??U? +\n?\n??\n??\nV 0 0\n0 0 0\n0 0 0\n?\n??\n??\n?\n????\n????|?(t)?, (6)\nwhere |?(t)? = (?e(t),??(t),??(t))T, ?m2ij ? m2i ?m2j is the mass-squared difference between\nthe i-th and j-th mass eigenstates, and V ? ?2GFNe is the effegtive potential arising\nfrom the charged current interaction between ?e and electrons in the medium with Ne the\nelectron number density. Numerically V = 7.56?10?14 (?/[g/cm3])Ye [eV] with Ye denoting\nthe number of electrons per nucleon. We take Ye ? 0.5 in our calculations. One solves\nEq. (6) by diagonalizing the Hamiltonian on its right hand side. This amounts to writing\n4\n0 5000 10000\nbaseline length L[km]\n0\n5\n10\n? [g/cm\n3 ]\naverage density\ndensity in the mantle\ndensity in the core\naverage density\nFIG. 1: The average Earth density along the path traversed by the neutrino as a function of the\npath length L.\nthe right hand side of Eq. (6) as U?H?U??|?(t)? with U? the neutrino mixing matrix in the\nmatter and H? ? diag(E1,E2,E3) the Hamiltonian after diagonalization. To obtain various\noscillation probabilities described later, we have used the parametrization in [18] for the\nEarth density profile.\nFor analytic calculations, we employ the two-layer approximation for the Earth density\nprofile [13]. Given a path-length L for a neutrino traversing the Earth medium, one can\ndivide L into the sum L = L1 + L2 + ???Ln with each Li corresponding to a region with\na specific matter density. The average density for this path-length is then given by ? =\n(?1L1 + ?2L2 + ????nLn)/L. The Earth medium can be categorized as the Earth mantle\nand the Earth core. If a neutrino only traverses the Earth mantle, we shall use the one-\ndensity approximation for the analytic calculation with the density defined by the above\nprescription. However, if a neutrino traverses both the Earth mantle and the Earth core,\none should write the total neutrino path-length as L = 2Lm + Lc with\nLm = R\nparenleftBigg\ncos?n ?\nradicalbigg\nr2c\nR2 ?sin\n2 ?n\nparenrightBigg\n,\nLc = 2R\nradicalbigg\nr2c\nR2 ?sin\n2 ?n, (7)\n5\nwhere R = 6371 km and rc = 3480 km are the radii of the entire Earth and the Earth core\nrespectively while ?n is the incident Nadir angle of the neutrino. We note that the critical\nNadir angle for a neutrino to pass the Earth core is 33.17? corresponding to L = 10674 km.\nFor L > 10674 km, one separately defines average densities within the path-length Lm and\nthe path-length Lc respectively. The average densities as functions of the neutrino path-\nlength is shown in Fig. 1. For L ? 10674 km, there is only one curve for the average density,\nwhich is represented by the solid line in the figure. Beyond this distance, one can define the\naverage density in the core and the average density in the mantle, which are represented\nby dashed and dotted lines respectively. Alternatively, one can also define single average\ndensity for L > 10674 km by ignoring the distinction between the mantle and the core. This\nis seen from the solid line for L > 10674 km. However, in our analytic calculations, we shall\nadopt the two-density approach for L > 10674 km.\nFor analytic calculations, we only compute oscillation probabilities up to the lowest order\nin ? ? ?m221/?m231. In other words, we set ?m221=0 in analytic calculations and conse-\nquently the mixing angle ?12 and the CP phase ?CP dropout fromthe oscillation probabilities.\nThe probabilities P?? and Pe? in the two-layer approximations are given by[19, 20, 21, 22, 23]:\nP?? = cos4 ?23 +parenleftbigu2 + v2parenrightbigsin4 ?23 + 2cos2 ?23 sin2 ?23 (ucost+ vsint),\nPe? = sin2 ?23parenleftbig1?u2 ?v2parenrightbig. (8)\nThe quantities u, v and t are defined as\nu = cos(2?m)cos(?c)?cos(2?c13 ?2?m13)sin(2?m)sin(?c),\nv = ?cos(2?m13)[sin(?c)cos(2?m)cos(2?c13 ?2?m13) + cos(?c)sin(2?m)]\n+sin(2?m13)sin(?c)sin(2?c13 ?2?m13),\nt = (M\n2\n13)\nm + (m2\n13)\nm\n4E ?2L\nm + (M\n2\n13)\nc + (m2\n13)\nc\n4E ?L\nc, (9)\nwhere\n?m(c) = ?\nm(c)\n31\n4E L\nm(c),\n(M213)m(c) = (?m231 + Am(c)e + ?m(c)31 )/2,\n(m213)m(c) = (?m231 + Am(c)e ??m(c)31 )/2, (10)\nwith\n?m(c)31 =\nradicalBig\n(?m231 sin2?13)2 + (Am(c)e ??m231 cos2?13)2. (11)\n6\n0 5 10\nE [GeV]\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nP e?\nFull\nTwo-Layer\nOne-Layer\n(First order)\nOne-Layer\n(Second order)\nFull (?m212 =0)\nPe? for L=11400 km, sin2?13=0.3, cos2?23=0\nFIG. 2: A comparison of Pe? obtained by the full numerical calculation and various approximations.\nThe thick solid curve denotes the result by the full numerical calculation. The dotted-dashed\ncurve denotes the result by setting ?m221 = 0 in the full numerical calculation. The dashed\ncurve represents the result obtained by the two-layer approximation in the leading order of ? ?\n?m221/?m231. The dotted curve denotes the result obtained by one-density approximation in the\nleading order of ? while the thin solid curve is that obtained by the one-density approximation in\nthe next-to-leading order of ?.\nThe superscripts m and c denote quantities defined in the Earth mantle and the Earth\ncore respectively. For neutrinos traversing only the Earth mantle, one simply sets Lc =\n0, 2Lm = L in the above equations and recovers well known expressions for P?? and Pe? in\nthe one-density approximation [24].\nThe accuracy of two-layer approximation is shown in Fig. 2 with a comparison of this\napproximation to the full numerical calculation and other approximations. In the calcula-\ntions, we have assumed the normal mass hierarchy and taken sin2?13 = 0.3, cos2?23 = 0,\n?CP = 0, ?m231 = 2.4?10?3 eV2, ?m221 = 8.2?10?5 eV2, and tan2 ?12 = 0.39 [25]. This\nset of parameters will be adopted for later calculations unless specific mentioning of other\nchoices. This set of parameters differ from the most updated best-fit values quoted right\nafter Eq. (3). However, both set of parameters give undistinguishable results on Pe? and P??\n7\n0 5000 10000\nbaseline length L[km]\n0\n5\n10\n15\nenergy [GeV]\nFull calculation\nTwo-Layer\nThe energy at local maximum of Pe?\nmax1\nmax2\n0 5000 10000\nbaseline length L[km]\n0\n5\n10\n15\n20\nenergy [GeV]\nFull calculation\nTwo-Layer calculation\nThe energies at local maximum and local minimum of P??\nmin2\nmax1\nmin1\nmax2\nFIG. 3: Left panel: the energy at the local maximum of Pe?, as a function of L. Right panel:\nenergies at local maxima and local minima of P??, as functions of L.\nin the energy range concerned here. A comparison made at L = 11400 km has two purposes.\nFirst of all, it is known that the series expansion in the parameter ? is valid for L/E? ? 104\n(km/GeV) [24, 26]. Hence analytic calculations performed at this baseline length test the\nmarginal region of the condition L/E? ? 104 (km/GeV). Secondly this path-length implies\nthat the neutrino traverses both the Earth mantle and the Earth core. Therefore it is also\na good test to the two-layer approximation. It is seen that the two-layer approximation,\nunlike the one-layer approximation, reproduces well the peak energies of Pe?, while it gives\npeak probabilities deviating from those obtained from the full calculation by 15% ?20%.\nWe also see that the two-layer approximation agrees well with the full calculation in the\nlimit ?m221 = 0.\nFor later analysis, we compute energies at local maxima of Pe? and those at local maxima\nand local minima of P?? for the baseline range 1000 ? L/km ? 12000. The results are\ndepicted in Fig. 3. We do not study local minima of Pe? since their values are not sensitive\nto mixing angles ?13 and ?23. It is seen that the analytic approximation is satisfactory for\ncomputing energies at local maxima and local minima of neutrino oscillation probabilities.\nWe point out that the energy curves in Fig. 3 are calculated with sin2?13 = 0.3 and cos2?23 =\n0. It is found that these curves are not sensitive to the values of sin2?13 and cos2?23.\n8\n0 1 2 3 4 5\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n(P ??\n)\n?CP=0\n?CP=0.5pi\n?CP=pi\n?CP=1.5pi\nP?? and Pe? for L=1000 km, sin2?13=0.3, cos2?23=0\nPe?P??\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=5000 km, sin2?13=0.3, cos2?23=0\n0 5 10 15 20\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=10000 km, sin2?13=0.3, cos2?23=0\n0 5 10 15 20\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=12000 km, sin2?13=0.3, cos2?23=0\nFIG. 4: The CP phase dependencies of P?? and Pe? for L = 1000 km, 5000 km, 10000 km and\n12000 km respectively. The probability P?? is described by the thick curve while Pe? is described\nby the thin curve.\nIII. CONDITIONS FOR THE ABSENCE OF ?23 DEGENERACY IN P?? AND Pe?\nAT DIFFERENT ENERGIES\nA. The dependencies of P?? and Pe? on ?CP\nBefore concentrating on ?13 and ?23 dependencies of neutrino oscillation probabilities,\nwe first study the CP phase dependencies with the full numerical calculations. It is easily\nseen from Fig. 4 that P?? is not sensitive to the CP phase for all distances displayed. On\nthe other hand, Pe? is rather sensitive to the CP phase for L = 1000 km and 5000 km.\nIn order to quantify the CP phase dependence of Pe?, we study peak values of Pe?, which\noccur at energies described by the curve max1 in Fig. 3 for different baseline lengths. This\npeak value for a specific baseline length depends on the CP violation phase ?CP and we\n9\n0 2000 4000 6000 8000 10000\nbaseline length L [km]\n0\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\nP e?max\n?  P\ne?min\nPe?max ?  Pe?min,  sin2?13=0.3, cos2?23=0\n0 2000 4000 6000 8000 10000\nbaseline length L [km]\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nP e?min\n/  P\ne?max\nPe?min /  Pe?max,  sin2?13=0.3, cos2?23=0\nFIG. 5: The difference and the ratio of Pmaxe? and Pmine? as functions of the baseline length.\ndenote the maximum and the minimum of this value as Pmaxe? and Pmine? respectively. The\ndifference and the ratio of these two values as functions of the baseline length L are shown\nin Fig. 5. It is interesting to note that the ratio Pmine? /Pmaxe? increases monotonically with the\nbaseline length until L = 7600 km. The ratio begins to decrease for a larger baseline but\nremains larger than 90%. In fact, one can see that Pmaxe? and Pmine? differ by less than 10%\nfor L ? 6500 km. We point out that 1?Pmine? /Pmaxe? reaching to minimum at L = 7600 km\nconfirms the so-called magic baseline for the probability Pe? [14, 15, 16].\nB. The dependencies of P?? and Pe? on mixing angles ?13 and ?23\nHaving studied CP phase dependencies of oscillation probabilities, we now focus on ?13\nand ?23 dependencies. In this study we set the CP phase ?CP equal to zero. The results\nare presented in Fig. 6. It is easily seen that the values of P?? at its local maximum and\nlocal minimum depend on mixing angles ?13 and ?23 while only the local maximum of Pe?\ndepends on these parameters. This confirms our earlier comments concerning the left panel\nof Fig. 3. We point out that the differences between solid and dotted curves in Fig. 6 reflect\nthe effect of sin2?13; while the differences between solid and dashed curves there reflect the\neffect of cos2?23.\nWe now present contour graphs of P?? and Pe? on the cos2?23 ? sin2?13 plane. The\nrange for cos2?23 is chosen such that sin2?23 > 0.9 [2], i.e., ?0.316 < cos2?23 < 0.316; while\nsin2 2?13 is chosen to be less than 0.1, i.e., sin2?13 < 0.316. The contour graphs of P?? at\n10\n0 1 2 3 4 5\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nsin2?13=0.3,   cos2?23=0\nsin2?13=0.15, cos2?23=0\nsin2?13=0.3,   cos2?23=0.3\nsin2?13=0.3,   cos2?23=?0.3\nP?? and Pe? for L=1000 km\nPe?P??\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=5000 km\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=10000 km\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=12000 km\nFIG. 6: The ?13 and ?23 dependencies of P?? and Pe? for L = 1000 km, 5000 km, 10000 km and\n12000 km respectively. The probability P?? is described by the thick curve while Pe? is described\nby the thin curve.\ndifferent baseline lengths are presented in Fig. 7. Except for L = 1000 km, we have shown\ncontours of P?? for energies in the vicinity of both local maximum and local minimum of\nthis probability. The contour for the local maximum of P?? at L = 1000 km is not shown\nsince P?? at this energy and baseline length is not sensitive to mixing angles ?13 and ?23. For\nL = 5000 km, 10000 km and 12000 km, it is seen that the contours at local maxima of P??\nand those at local minima of P?? behave rather differently. The former are in general more\nparallel to the cos2?23-axis while the latter are generally more parallel to the sin2?13-axis.\nWe note that the local maximum (max2) of P?? at L = 12000 km can vary from 0.9 to a\nmuch smaller value, 0.45, which is a result of significant matter effects. Similarly, due to\nlarge matter effects, the local minimum (min2) of P?? at L = 10000 km can vary from 0\nto a much larger value, 0.4. We also notice that, at this baseline length, the ?23 degeneracy\n11\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=1.39-2.39 GeV (min1), L=1000 km\n0.065\n0.08\n0.08\n0.1\n0.1\n0.13\n0.13\n0.16\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=4.25-5.25 GeV (max1, solid)\nand E=8.74-9.74 GeV (min1, dashed), L= 5000 km\n0.005\n0.02\n0.02\n0.05\n0.05\n0.08\n0.08\n0.12\n0.96 0.93 0.9 0.85\n0.8\n0.75\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=8.71-9.71 GeV (max1, solid)\nand E=5.74-6.74 GeV (min2, dashed), L=10000 km\n0.06\n0.05\n0.3\n0.04\n0.1\n0.1\n0.15 0.40.2\n0.93\n0.982 0.97\n0.95\n0.9\n0.87\n0.84\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=5.00-6.00 GeV (max2, solid)\nand E=6.65-7.65 GeV (min2, dashed), L=12000 km\n0.12\n0.09\n0.450.15\n0.15\n0.6\n0.18\n0.7\n0.86\n0.86\n0.8\n0.06\n0.03\n0.18\nFIG. 7: The contour graphs of the muon neutrino survival probability P?? on the cos2?23?sin2?13\nplane. At L = 1000 km, the local minimum of P?? on the curve min1 occurs at E = 1.89 GeV. We\nplot the contour graph of P?? by averaging this probability over an 1 GeV energy range centered\nat the above local minimum. At L = 5000 km, the local maximum of P?? on the curve max1\noccurs at E = 4.75 GeV while the local minimum of this probability on the curve min1 occurs at\nE = 9.24 GeV. We plot the contour graphs of P?? in the energy range 4.25 ? E/GeV ? 5.25 for\nthe former case and 8.74 ? E/GeV ? 9.74. The same type of convention applies to L = 10000 km\nand 12000 km.\nis absent for P?? > 0.1. In general, such a degeneracy is also absent for energies near local\nmaxima of P??. However, the probabilities are not sensitive to cos2?23 in those cases. For\ncomparisons, we also present contour graphs for the appearance probability Pe? at different\nbaseline lengths. It is clearly seen that Pe? is only sensitive to sin2?13 for most cases. The\nsensitivity to cos2?23 only occurs at very long baseline lengths and large values of sin2?13.\n12\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=1.39-2.39 GeV (max1), L=1000 km\n0.002\n0.01 0.02\n0.03 0.04\n0.06\n0.08\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=5.31-6.31 GeV (max1), L=5000 km\n0.01 0.05\n0.1\n0.15\n0.2\n0.25\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=5.49-6.49 GeV (max1), L=10000 km\n0.03 0.1 0.2\n0.4\n0.5\n0.3\n0.6\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=2.64-3.64 GeV (max1), L=12000 km\n0.01 0.1 0.2\n0.4\n0.5\n0.3\nFIG. 8: The contour graphs for the oscillation probability Pe? on the cos2?23 ?sin2?13 plane. We\nplot contours of Pe? at energies near the local maximum (max1) of this probability.\nFor example, at L = 10000 km, Pe? becomes sensitive to cos2?23 as sin2?13 approaches 0.3.\nAt L = 12000 km, Pe? becomes sensitive to cos2?23 when sin2?13 is greater than 0.2.\nC. A global look at the absence of ?23 degeneracy\nIn this subsection, we focus on ?23 dependencies of P?? and Pe? for general baseline\nlengths. The two-layer analytic approximations for P?? and Pe? will be employed for our\ndiscussions, and observations in the previous subsection shall be justified. It is instructive\nto rewrite Eq. (8) in polynomials of cos2?23:\nf(y,z) = ??y2 + (? + ?)y + (1??),\ng(y,z) = ??(y ?1), (12)\n13\n2000 4000 6000 8000 10000 12000\nbaseline length L [km]\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n?+?\nsin2?13=0.1\nsin2?13=0.2\nsin2?13=0.3\nFIG. 9: The coefficient ?(z) + ?(z) calculated along the energy curve max1 in the left panel of\nFig. 3. The values of sin2?13 are taken to be 0.1, 0.2 and 0.3 respectively.\nwith f(y,z) ? P??, g(y,z) ? Pe?, y ? cos2?23 and z ? sin2?13. Furthermore,\n? = ?14bracketleftbig(u?cost)2 + (v?sint)2bracketrightbig,\n? = 12parenleftbig1?u2 ?v2parenrightbig+ 14bracketleftbig(u?cost)2 + (v ?sint)2bracketrightbig,\n? = 12parenleftbig1?u2 ?v2parenrightbig. (13)\nWe note that the sin2?13 dependencies of P?? and Pe? reside in quantities u, v, cost and\nsint. These quantities also depend on the baseline length L and the neutrino energy E.\nHence the coefficients ?, ? and ? also depend on the baseline length L and the neutrino\nenergy E. It is interesting to note that ? + ? = ?. Therefore we have\nP?? = ?parenleftbigy2 ?1parenrightbig, (14)\nusing P?e +P?? +P?? = 1 and P?e = Pe? with our choice of ?CP = 0. The contour structure\nof Pe? is straightforward as g(y,z) is only a linear function of y. Hence no ?23 degeneracy\npresents in the contour graphs depicted in Fig. 8. Additionally, the sensitivity of Pe? to\ncos2?23 is dg(y,z)/dy = ?(?(z) + ?(z)). The coefficient ? + ? evaluated along the energy\ncurve max1 in the left panel of Fig. 3 are plotted in Fig. 9 for sin2?13 = 0.1, 0.2 and 0.3. For\nsin2?13 = 0.3, ?+? reaches to the maximal value, 0.5, for L ? 10500 km. For sin2?13 = 0.1\n14\n0 5000 100000\n0.2\n0.4\n0.6\n0.8\n1\nmin1\nmax1\nmin2\nmax2\nbaseline length L [km]\n-? and ?+?, sin2?13=0.2, cos2?23=0\n-? and ?+?, sin2?13=0.2, cos2?23=0\n?? ?+?\n0 5000 10000\nbaseline length L [km]\n0\n0.2\n0.4\n0.6\n0.8\n1\nmin1\nmax1\nmin2\nmax2\n?? and ?+?, sin2?13=0.3, cos2?23=0\n?+???\nFIG. 10: The coefficients ?? and ?+? evaluated along energy curves in the right panel of Fig. 3.\nThe coefficients are calculated with sin2?13 = 0.2 and 0.3 on the left and right panels respectively.\nThe thick curves denote values of ?? while thin curves denote those of ?+?. For solid and dotted\ncurves, the thick curves generally dominate over the corresponding thin ones. For dashed and\ndotted-dashed curves, the thin curves generally dominate over the thick ones.\nand 0.2, ?+? rises quickly as the baseline length L surpasses 10674 km. We note that the\nvalue of Pe? is proportional to ?+?. Hence ?+? shown in Fig. 9 is its own maximal value\nfor each baseline length L.\nThe contour structure of P?? can be analyzed through the quadratic polynomial f(y,z)\nin y. If ?? ? ?+?, generally there are two solution curves for f(y,z) = p compatible with\nthe ranges of y and z where p is a given value for P??. Let us suppose that z ? sin2?13\nis measured in the future [27, 28] with a central value z0. The two solution curves for the\nequation f(y,z) = p then intersect with the straight line z ? sin2?13 = z0 at two points\n(y1,z0) and (y2,z0). This is actually what we have seen in Fig. 7 for local minima of P??. If,\non the other hand, ?? ? ? + ? or even ?? ? ? + ?, there exists only one solution curve\nfor the equation f(y,z) = p. This is because that the two points (y1,z0) and (y2,z0) can not\nsimultaneously satisfy the constraint ?0.316 < y < 0.316 since |y1 +y2| = ?(?+?)/? ? 1.\nThis is actually what we have seen in Fig. 7 for local maxima of P??. To justify this\nobservation, it remains to show that the coefficient ?? dominates over ? + ? at energies\ncorresponding to local minima of P?? while the latter dominates over the former at energies\ncorresponding to local maxima of P??. This is clearly demonstrated in Fig. 10 where the\n15\ncoefficients ?? and ? + ? are evaluated along energy curves in the right panel of Fig. 3.\nWe have calculated the coefficients with cos2?23 = 0 and sin2?13 = 0.2, 0.3 respectively.\nWe remark that other choices for cos2?23 do not produce noticeable changes on the energy\ncurves where ?? and ? + ? are evaluated.\nIt is easily seen that ?+? always dominates over ?? when these coefficients are evaluated\natenergies alongmax1 ormax2inthe right panelofFig.3. Insuch cases, the ?23 degeneracy\nis absent in the solutions of f(y,z) = p. Namely there exists only one solution curve for\nthe above equation. Reversely, ?? always dominates over ?+? when these coefficients are\nevaluated at energies along min1. The situation is slightly more complicated when these\ncoefficients are evaluated at energies along min2. In this case ?? no longer dominates\nover ? + ? for baseline lengths around 104 km. In fact, with sin2?13 = 0.3, ? + ? is even\nlarger than ?? for 9000 ? L/km ? 10500. This explains the contour structure of P??\nat L = 10000 km (see Fig. 7) where the straight line z = 0.3 only intersects one equal\nprobability curve f(y,z = 0.3) = p. The straight line z = 0.2 also behaves the same except\nfor a very small p. We reiterate that the range for y ? cos2?23 is ?0.316 < y < 0.316 due\nto the constraint sin2 2?23 > 0.9 [2]. Therefore, given z = z0, the equation f(y,z0) = p could\nhave only one solution for y if ?(?(z0) +?(z0))/?(z0) > 0.632. In other words, such values\nof ?(?(z0) + ?(z0))/?(z0) lead to the absence of ?23 degeneracy. In fact, the condition for\nthe absence of ?23 degeneracy is even more relaxed. To see this, let us divide our discussions\naccording to the true octant of ?23.\n1. min2, ?23 < pi/4\nSince ? < 0 and ? + ? > 0, the two solutions for y in f(y,z0) = p are both negative for\n1??(z0)?p > 0 while they have opposite signs for 1??(z0)?p < 0. If the true value of\n?23 is less than pi/4, i.e., the true value of y is positive, then the experimental measurement\nshould give 1??(z0)?p < 0 so that a positive solution for y exists. With 1??(z0)?p <\n0, the two solutions for f(y,z0) = p have opposite signs and the negative solution has\na larger absolute value. The negative solution will violate the constraint ?0.316 < y if\n?(?(z0) + ?(z0))/?(z0) > 0.316. For z0 = 0.2, ?(?(z0) + ?(z0))/?(z0) > 0.316 is valid\nfor 8300 ? L/km ? 10770. For z = 0.3, the above baseline range is extended to 7410 ?\nL/km ? 10790.\n16\n2. min2, ?23 > pi/4\nWith a true value of ?23 greater than pi/4, i.e., the true value of y less than zero, the\nvalue of 1 ? ?(z0) ? p can either be positive or negative. The condition 1 ? ?(z0) ? p >\n(<)0 is equivalent to the condition |y| < (>)(?(z0) +?(z0))/(??(z0)). For ?(?(z0) +\n?(z0))/?(z0) > 0.316, one must have 1 ? ?(z0) ? p > 0. Hence there exist two negative\nsolutions for y. In this case, the corresponding solutions for ?23 are both located in the same\noctant. For 0.316 < ?(?(z0)+?(z0))/?(z0) < 0.632, the spurious solution for y may or may\nnot violate the constraint y > ?0.316. For ?(?(z0) + ?(z0))/?(z0) > 0.632, the spurious\nsolution for y must violate the constraint y > ?0.316, hence the ?23 degeneracy is surely\nabsent. For sin2?13 = 0.2, the condition ?(?(z0)+?(z0))/?(z0) > 0.632 can not be achieved\nalong min2. For sin2?13 = 0.3, the above condition is satisfied for 8270 ? L/km ? 10720.\nFor ?(?(z0) + ?(z0))/?(z0 < 0.316, 1 ? ?(z0) ?p can either be positive or negative. For\n1??(z0)?p > 0, both solutions for y are negative and satisfying the constraint y > ?0.316.\nFor 1 ? ?(z0) ? p < 0, both solutions for y satisfy the constraint ?0.316 < y < 0.316.\nHowever their corresponding ?23 angles are situated in different octants.\nLet us summarize the results obtained in this subsection. The coefficient ?+? dominates\nover ?? for energy values along curves max1 and max2 for all baseline lengths. Hence the\n?23 degeneracy is absent along these energy curves for all baseline lengths. The situation\nalong the curve min1 is just the opposite, the coefficient ?? dominates over ? + ? for all\nbaseline lengths. Hence the ?23 degeneracy is present for all baseline lengths in this case.\nThe issue of ?23 degeneracy becomes more complicated along min2, which we have discussed\naccording to the true octant of ?23. Along the energy curve min2, the non-degeneracy\nbaseline range is larger for the ?23 < pi/4 case.\nIV. DISCUSSIONS AND CONCLUSIONS\nWe have presented the baselines and energies ideal for probing the octant of ?23 through\nneutrino oscillations. The appearance mode ?e ? ?? can be studied in a very long baseline\nwith the facility of neutrino factory [29] or the more recent proposed ? beam [30]. As said,\nthe sensitivity of Pe? to ?23 is dg(y,z)/dy = ?(?(z) + ?(z)) where g(y,z) represents Pe? in\nthe analytic approximation given by Eq. (12). The maximal value of ?+? for each baseline\n17\nlength is shown in Fig. 9. At the magic baseline, L = 7600 km, ?+? = 0.06, 0.21 and 0.38\nfor sin2?13 = 0.1, 0.2 and 0.3 respectively. For a sufficiently large sin2?13 and a baseline\nlength close to the magic value [14, 15, 16], Pe? is ideal for probing the octant of ?23.\nThe probability P?? is also relevant in neutrino oscillation experiments with neutrino\nfactories. The sensitivity of this probability to ?23 is determined by the derivative\nr ? dP??dcos2?\n23\n= ?2?cos2?23 + (? + ?). (15)\nSince ? is negative, the sensitivity r is larger for cos2?23 > 0, i.e., ?23 < pi/4. For a\nmeasurement performed around a local maximum of P??, the sensitivity to ?23 is completely\ndetermined by the coefficient ?+?, since the coefficient ? is generally rather suppressed in\nthis case. Along the energy curve denoted by max1, ?+? peaks at 7480 km for sin2?13 = 0.2\nand it peaks at L = 7350 km for sin2?13 = 0.3. The values of ?+? at those peaks are 0.17\nand 0.32 respectively. Along the curve max2, ? + ? peaks around L = 10750 km for both\nsin2?13 = 0.2 and 0.3 with values 0.43 and 0.48 respectively.\nFor a measurement performed around a local minimum of P??, the sensitivity to ?23 is\ndetermined by both coefficients ?? and ? + ?. Along the energy curve denoted by min1,\nthe coefficient ?? is always close to unity while the coefficient ? + ? is always suppressed\nfor all baseline lengths. It is understood that the magnitude of ? + ? determines the size\nof matter effects. Hence the matter effect is small at energies along the curve min1. The\nsuppression of ? + ? compared to ?? leads to the ?23 degeneracy as discussed before. The\nbehavior of P?? along the energy curve min2 is more interesting. If the true value of ?23\nis less than pi/4, the ?23 degeneracy from the measurement of P?? is absent in the baseline\nrange 8300 ? L/km ? 10770 for sin2?13 = 0.2. The above non-degeneracy baseline range\nextends to 7410 ? L/km ? 10790 for sin2?13 = 0.3. On the other hand, if the true ?23\nis greater than pi/4, the non-degeneracy baseline range does not exist along the energy\ncurve min2 for sin2?13 = 0.2. For sin2?13 = 0.3, the non-degeneracy baseline range is\n8270 ? L/km ? 10720.\nThe existence of non-degeneracy baseline range along the energy curve min2 has impor-\ntant implications. It can be seen from Fig. 3 that the curve min2 lies in between curves\nmax1 and max2. Since the degeneracy of ?23 is absent on both max1 and max2 for all\nbaselines, it is possible that there exists a non-degeneracy region spanned by ranges of the\nbaseline length and the neutrino energy. For example, with sin2?13 = 0.2 and a true value of\n18\nTABLE I: The baseline range in which the ?23 degeneracy is absent in the probability P?? for all\nenergy values between the curves max2 and max1. The entry corresponding to ?23 > pi/4 and\nsin2?13 = 0.2 is left blank since, with such set of parameters, there exists no baseline length where\nthe condition for the absence of ?23 degeneracy can be satisfied.\n?23 octant sin2?13 = 0.2 sin2?13 = 0.3\n?23 < pi/4 8550 ? L/km ? 10680 7950 ? L/km ? 10700\n?23 > pi/4 8450 ? L/km ? 10680\n?23 less than pi/4, the ?23 degeneracy is absent for 8300 ? L/km ? 10770 for energies along\ncurves max2, min2 and max1. It is of great interest to investigate if the ?23 degeneracy is\nalso absent for any neutrino energy larger than the value on max2 and smaller than that on\nmax1. By taking all these energies into account, we find that the ?23 degeneracy is absent\nfor 8550 ? L/km ? 10680. For a true value of ?23 greater than pi/4 and sin2?13 = 0.3,\nthe ?23 degeneracy is absent for 8270 ? L/km ? 10720 for energies along curves max2,\nmin2 and max1. However, with all energies between curves max2 and max1 considered,\nwe find that the ?23 degeneracy is absent for 8450 ? L/km ? 10680. The non-degeneracy\nbaseline range corresponding to different combinations of ?23 and ?13 values are summarized\nin Table I.\nIt is interesting to compare measurements on Pe? and P?? since both oscillations appear\nin experiments with neutrino factories [29]. The main issue for comparison is on the deter-\nmination of the true ?23 value under the assumption that both the sign of ?m231 and the\nvalue of sin2?13 are known. Let us begin the discussion with a true value of ?23 less than pi/4\nand sin2?13 = 0.2. For L < 8550 km, the appearance mode ?e ? ?? is useful for probing the\noctant of ?23, in particular for L close to the magic value, 7600 km. However, the survival\nmode ?? ? ?? is not as useful since the ?23 degeneracy is absent only at energies near max1\nand max2. Concerning the sensitivity to ?23, we note that the differentiation of Pe? with\nrespect to cos2?23 is ?(?+?). The value of ?+? increases with L as shown in Fig. 9. It is\n0.21 at L = 7600 km, and 0.26 at L = 8550 km. For 8550 ? L/km ? 10680, both ?e ? ??\nand ?? ? ?? are useful for probing the octant of ?23. We note that peak positions of Pe?\nare mostly around 6 GeV. Hence they overlap with the non-degeneracy energy range of P??.\nFrom Eq. (15) and our assumption of ?23 < pi/4, we find that P?? is more sensitive to ?23\n19\nas compared to Pe? for the same neutrino energy. For L > 10680 km, ?e ? ??, is again the\nonly useful mode for probing the octant of ?23.\nLet us turn to the case where the true value of ?23 is greater than pi/4 and sin2?13 = 0.2.\nIn such a case, the value for Pe? is enhanced compared to that with y > 0. Furthermore\nPe? is always more sensitive to cos2?23 as compared to P?? for the same neutrino energy.\nIt is clear that the ?e ? ?? appearance mode is more useful for probing ?23 regardless the\nbaseline length. Although there exists a baseline range where the ?23 degeneracy is absent\nin P?? for neutrino energies between curves max2 and max1. However this requires a large\nvalue of sin2?13, such as sin2?13 = 0.3.\nIt is essential to remark that the above non-degeneracy baseline range is not sensitive to\nthe value of ?m231, which we have so far taken to be 2.4 ? 10?3 eV2. Changing the value\nof ?m231 only shifts the probability curves in Fig. 4 and Fig. 6 so that positions for local\nmaxima and local minima of these probabilities shift accordingly. However, the maximal or\nminimal values of these probabilities remain unchanged. In other words, although the energy\ncurves in Fig. 3 are shifted, the coefficients ?? and ?+? plotted in Fig. 10, which combine\nto form Pe? and P?? (see Eq. (12)), remain the same. The values of these coefficients as\nfunctions of the baseline length L then determine the non-degeneracy baseline range.\nInconclusion, we have studied theprobabilities Pe? andP?? forvery longbaseline neutrino\noscillations. We focus on sensitivities of these probabilities to mixing angles ?13, ?23 and the\nCP violation phase ?CP. Taking ?CP = 0 as an example, we presented contour graphs of\nPe? and P?? in the sin2?13 ? cos2?23 plane for baseline lengths L = 1000 km, 5000 km,\n10000 km and 12000 km. The energy values chosen for such studies are in the vicinities of\neither local minima or local maxima of neutrino oscillation probabilities. For each baseline\nlength, we have found that P?? is more sensitive to sin2?13 at energies around its local\nmaxima while it is more sensitive to cos2?23 at energies around its local minima. On the\nother hand, the appearance probability Pe? is sensitive to sin2?13 and cos2?23 only near its\nlocal maximum. Such findings have been applied to probe the octant of mixing angle ?23\nassuming that the angle ?13 and the sign of ?m231 are known. The appearance probability\nPe? is non-degenerate in ?23. The sensitivity of Pe? to cos2?23 is studied for baseline lengths\nfrom 1000 km to 12000 km. We also studied the sensitivity of P?? to cos2?23 for the same\nrange of baseline length. We have identified the ranges of neutrino energy and baseline\nlengths where the ?23 degeneracy is absent. We have pointed out that, for a true value of ?23\n20\nless than pi/4 and a baseline length between 8000 and 10000 km, the survival mode ?? ? ??\nis equally good as the appearance mode ?e ? ?? for probing the octant of ?23.\nAcknowledgements\nG.L.L likes to thank D. Indumathi for informative discussions. This work is supported\nby National Science Council of Taiwan under the grant number NSC 94-2112-M-009-026.\n[1] Y. Ashie et al. [Super-Kamiokande Collaboration], Phys. Rev. D 71, 112005 (2005)\n[arXiv:hep-ex/0501064].\n[2] Y. Ashie et al. [Super-Kamiokande Collaboration], Phys. Rev. Lett. 93 (2004) 101801\n[arXiv:hep-ex/0404034].\n[3] E. Aliu et al. [K2K Collaboration], Phys. Rev. Lett. 94 (2005) 081802 [arXiv:hep-ex/0411038].\n[4] M. H. Ahn et al. [K2K Collaboration], Phys. Rev. D74, 072003 (2006) [arXiv:hep-ex/0606032].\n[5] K. Eguchi et al. [KamLAND Collaboration], Phys. Rev. Lett. 90 (2003) 021802\n[arXiv:hep-ex/0212021].\n[6] T. Araki et al. [KamLAND Collaboration], Phys. Rev. Lett. 94 (2005) 081801\n[arXiv:hep-ex/0406035].\n[7] See G. L. Fogli, E. Lisi, A. Marrone and A. Palazzo, Prog. Part. Nucl. Phys. 57, 742 (2006)\n[arXiv:hep-ph/0506083], which contains a list of original references on solar neutrino oscilla-\ntions.\n[8] G. L. Fogli and E. Lisi, Phys. Rev. D 54, 3667 (1996) [arXiv:hep-ph/9604415].\n[9] M. Apollonio et al. [CHOOZ Collaboration], Phys. Lett. B 466, 415 (1999)\n[arXiv:hep-ex/9907037].\n[10] F. Boehm et al., Phys. Rev. D 64, 112001 (2001) [arXiv:hep-ex/0107009].\n[11] I. Mocioiu and R. Shrock, Phys. Rev. D 62, 053017 (2000) [arXiv:hep-ph/0002149];\nV. D. Barger, S. Geer, R. Raja and K. Whisnant, Phys. Lett. B 485, 379 (2000)\n[arXiv:hep-ph/0004208]; V. D. Barger, S. Geer, R. Raja and K. Whisnant, Phys. Rev. D\n62, 013004 (2000) [arXiv:hep-ph/9911524]; M. Freund, M. Lindner, S. T. Petcov and A. Ro-\nmanino, Nucl. Phys. B 578, 27 (2000) [arXiv:hep-ph/9912457]; M. Freund, P. Huber and\n21\nM. Lindner, Nucl. Phys. B 585, 105 (2000) [arXiv:hep-ph/0004085]; A. Cervera, A. Donini,\nM. B. Gavela, J. J. Gomez Cadenas, P. Hernandez, O. Mena and S. Rigolin, Nucl. Phys. B\n579, 17 (2000) [Erratum-ibid. B 593, 731 (2001)] [arXiv:hep-ph/0002108].\n[12] D. Choudhury and A. Datta, JHEP 0507, 058 (2005) [arXiv:hep-ph/0410266]; D. Indu-\nmathi and M. V. N. Murthy, Phys. Rev. D 71, 013001 (2005) [arXiv:hep-ph/0407336];\nS. Choubey and P. Roy, Phys. Rev. D 73, 013006 (2006) [arXiv:hep-ph/0509197]. D. In-\ndumathi, M. V. N. Murthy, G. Rajasekaran and N. Sinha, Phys. Rev. D 74, 053004 (2006)\n[arXiv:hep-ph/0603264].\n[13] We adopt the approach of M. Freund and T. Ohlsson, Mod. Phys. Lett. A 15, 867 (2000)\n[arXiv:hep-ph/9909501], by dividing the Earth density regions into the Earth mantle and the\nEarth core. However we have further introduced the concept of average density to be discussed\nin details later.\n[14] V. Barger, D. Marfatia and K. Whisnant, Phys. Rev. D 65, 073023 (2002)\n[arXiv:hep-ph/0112119].\n[15] P. Huber and W. Winter, Phys. Rev. D 68, 037301 (2003) [arXiv:hep-ph/0301257].\n[16] A. Y. Smirnov, arXiv:hep-ph/0610198.\n[17] Z. Maki, M. Nakagawa and S. Sakata, Prog. Theor. Phys. 28, 870 (1962); see also , B. Pon-\ntecorvo, Zh. Eksp. Teor. Fiz. 53, 1717 (1967) [Sov. Phys. JETP 26, 984 (1968)].\n[18] A. Dziewonski, Earth Structure, Global, in: The Encyclopedia of Solid Earth Geophysics,\nDavid E. James, ed. (Van Nostrand Reinhold, New York 1989) p. 331.\n[19] M. V. Chizhov and S. T. Petcov, Phys. Rev. D 63, 073003 (2001) [arXiv:hep-ph/9903424];\nM. V. Chizhov and S. T. Petcov, Phys. Rev. Lett. 83, 1096 (1999) [arXiv:hep-ph/9903399].\n[20] E. K. Akhmedov, Nucl. Phys. B 538, 25 (1999) [arXiv:hep-ph/9805272].\n[21] S. T. Petcov, Phys. Lett. B 214, 259 (1988).\n[22] J. Bernabeu, S. Palomares-Ruiz, A. Perez and S. T. Petcov, Phys. Lett. B 531, 90 (2002)\n[arXiv:hep-ph/0110071].\n[23] Y. C. Hsu, Master Thesis, NCTU (2005).\n[24] See E. K. Akhmedov, R. Johansson, M. Lindner, T. Ohlsson and T. Schwetz, JHEP 0404,\n078 (2004) [arXiv:hep-ph/0402175] and earlier works cited in this paper.\n[25] J. N. Bahcall, M. C. Gonzalez-Garcia and C. Pena-Garay, JHEP 0408 (2004) 016\n[arXiv:hep-ph/0406294].\n22\n[26] I. Mocioiu and R. Shrock, JHEP 0111, 050 (2001) [arXiv:hep-ph/0106139].\n[27] F. Ardellier et al. [Double Chooz Collaboration], arXiv:hep-ex/0606025.\n[28] Y. Wang, arXiv:hep-ex/0610024.\n[29] S. Geer, Phys. Rev. D 57, 6989 (1998) [Erratum-ibid. D 59, 039903 (1999)]\n[arXiv:hep-ph/9712290]; A. De Rujula, M. B. Gavela and P. Hernandez, Nucl. Phys. B 547,\n21 (1999) [arXiv:hep-ph/9811390]; V. D. Barger, S. Geer and K. Whisnant, Phys. Rev. D 61,\n053004 (2000) [arXiv:hep-ph/9906487].\n[30] P. Zucchelli, Phys. Lett. B 532, 166 (2002).\n23\n"}
{"id":"oai:arXiv.org:hep-ph/0612309","text":"arXiv:q-bio/0601020v1  [q-bio.BM]  14 Jan 2006\nComputation of protein geometry and its applications: Packing and\nfunction prediction\nJie Liang\nFebruary 9, 2008\nContents\n6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n6.2 Theory and Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n6.2.1 The idealized ball model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\n6.2.2 Surface models: Lee-Richards and Connolly?s surfaces . . . . . . . . . . . . . . . . . . 2\n6.2.3 Geometric constructs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n6.2.4 Topological structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n6.2.5 Metric measurement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n6.3 Computation and software . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n6.4 Applications: Packing analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n6.5 Applications: Protein function prediction from structures. . . . . . . . . . . . . . . . . . . . . 13\n6.6 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n6.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n6.8 Further reading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n6.9 Acknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n6.1 Introduction\nThree-dimensional atomic structures of protein molecules provide rich information for understanding how\nthese working molecules of a cell carry out their biological functions. With the amount of solved protein\nstructures rapidly accumulating, computation of geometric properties of protein structure becomes an indis-\npensable component in studies of modern biochemistry and molecular biology. Before we discuss methods for\ncomputing the geometry of protein molecules, we first briefly describe how protein structures are obtained\nexperimentally.\nThereareprimarilythree experimentaltechniques for obtainingprotein structures: X-raycrystallography,\nsolution nuclear magnetic resonance (NMR), and recently freeze-sample electron microscopy (cryo-EM). In\nX-ray crystallography, the diffraction patterns of X-ray irradiation of a high quality crystal of the protein\nmolecule are measured. Since the diffraction is due to the scattering of X-rayby the electrons of the molecules\nin the crystal, the position, the intensity, and the phase of each recorded diffraction spot provide information\nfor the reconstruction of an electron density map of atoms in the protein molecule. Based on independent\ninformation of the amino acid sequence, a model of the protein conformation is then derived by fitting model\nconformations of residues to the electron density map. An iterative process called refinement is then applied\nto improve the quality of the fit of the electron density map. The final model of the protein conformation\nconsists of the coordinates of each of the non-hydrogen atoms [1].\nThe solution NMR technique for solving protein structure is based on measuring the tumbling and\nvibrating motion of the molecule in solution. By assessing the chemical shifts of atomic nuclei with spins due\nto interactions with other atoms in the vicinity, a set of estimated distances between specific pairs of atoms\ncan be derived from NOSEY spectra. When a large number of such distances are obtained, one can derive\na set of conformations of the protein molecule, each is consistent with all of the distance constraints [2].\nAlthough determining conformations from either X-ray diffraction patterns or NMR spectra is equivalent to\nsolving an ill-posed inverse problem, technique such as Bayesian Markov chain Monte Carlo with parallel\n1\ntempering has been shown to be effective in obtaining protein structures from NMR spectra [3]. The cryo-EM\ntechnique for obtaining protein structure is described in more details in Chapter 11.\n6.2 Theory and Model\n6.2.1 The idealized ball model\nThe shape of a protein molecule is complex. The chemical properties of atoms in a molecule are determined\nby their electron charge distribution. It is this distribution that generates the scattering patterns of the\nX-ray diffraction. Chemical bonds between atoms lead to transfer of electronic charges from one atom to\nanother, and the resulting isosurfaces of the electron density distribution depend not only on the location of\nindividual nuclei but also on interactions between atoms. This results in an overall complicated isosurface\nof electron density [4].\nThe geometric model of macromolecule amenable to convenient computation is an idealized model, where\nthe shapes of atoms are approximated by three-dimensional balls. The shape of a protein or a DNA molecule\nconsisting of many atoms is then the space-filling shape taken by a set of atom balls. This model is often\ncalled the interlocking hard-sphere model, the fused ball model, the space filling model [5?8], or the union\nof ball model [9]. In this model, details in the distribution of electron density, e.g., the differences between\nregions of covalent bonds and non-covalent bonds, are ignored. This idealization is quite reasonable, as it\nreflects the fact that the electron density reaches maximum at a nucleus, and its magnitude decays almost\nspherically away from the point of the nucleus. Despite possible inaccuracy, this idealized model has found\nwide acceptance, because it enables quantitative measurement of important geometric properties (such as\narea and volume) of molecules. Insights gained from these measurements correlate well with experimental\nobservations [5,8,10?13].\nIn this idealization, the shape of each atom is that of a ball, and its size parameter is the ball radius.\nThere are many possible choices for the parameter set of atomic radii [14,15]. Frequently, atomic radii are\nassigned the values of their van der Waals radii [16]. Among all these atoms, hydrogen atom has the smallest\nmass, and has a much smaller radius than those of other atoms. For simplification, the model of united\natom is often employed to approximate the union of a heavy atom and the hydrogen atoms connected by a\ncovalent bond. In this case, the radius of the heavy atom is increased to approximate the size of the union of\nthe two atoms. This practice significantly reduces the total number of atom balls in the molecule. However,\nthis approach has been questioned for possible inadequacy [17].\nThe mathematical model of this idealized model is that of the union of balls [9]. For a molecule M of n\natoms, the i-th atom is modeled as a ball bi, whose center is located at zi ? R3, and the radius of this ball\nis ri ? R, namely, we have bi ? {x|x ? R3,||x?zi|| ? ri} parameterized by (zi,ri). The molecule M is\nformed by the union of a finite number n of such balls defining the set B:\nM =\nuniondisplay\nB =\nnuniondisplay\ni=1\n{bi}.\nIt creates a space-filling body corresponding to the union of the excluded volumes vol(uniontextni=1 bi) [9]. When\nthe atoms are assigned the van der Waals radii, the boundary surface ?uniontextB of the union of balls is called\nthe van der Waals surface.\n6.2.2 Surface models: Lee-Richards and Connolly?s surfaces\nProtein folds into native three-dimensional shape to carry out its biological functional roles. The interac-\ntions of a protein molecule with other molecules (such as ligand, substrate, or other protein) determine its\nfunctional roles. Such interactions occur physically on the surfaces of the protein molecule.\nThe importance of protein surface was recognized very early on. Lee and Richards developed the widely\nused solvent accessible surface (SA) model, which is also often called the Lee-Richards surface model [5].\n2\nba c\nFigure 6.1: Geometric models of protein surfaces. (a) The solvent accessible surface (SA surface) is shown\nin the front. The van der Waals surface (beneath the SA surface) can be regarded as a shrunken version\nof the SA surface by reducing all atomic radii uniformly by the amount of the radius of the solvent probe\nrs = 1.4?A. The elementary pieces of the solvent accessible surface are the three convex spherical surface\npieces, the three arcs, and the vertex where the three arcs meet. (b) The molecular surface (MS, beneath\nthe SA surface) also has three types of elementary pieces: the convex spheric pieces, which are shrunken\nversion of the corresponding pieces in the solvent accessible surface, the concave toroidal pieces, and concave\nspheric surface. The latter two are also called the re-entrant surface. (c) The toroidal surface pieces in the\nmolecular surface, correspond to the arcs in the solvent accessible surface, and the concave spheric surface\nto the vertex. The set of elements in one surface can be continuously deformed to the set of elements in the\nother surface.\nIntuitively, this surface is obtained by rolling a ball of radius rs everywhere along the van der Waals surface of\nthe molecule. The center of the solvent ball will then sweep out the solvent accessible surface. Equivalently,\nthe solvent accessible surface can be viewed as the boundary surface ?uniontextBrs of the union of a set of inflated\nballs Brs, where each ball takes the position of an atom, but with an inflated radius ri + rs (Fig. 6.1a).\nThe solvent accessible surface in general has many sharp crevices and sharp corners. In hope of obtaining\na smoother surface, one can take the surface swept out by the front instead of the center of the solvent ball.\nThis surface is the molecular surface (MS model), which is often called the Connolly?s surface after Michael\nConnolly who developed the first algorithm for computing molecular surface [11]. Both solvent accessible\nsurface and molecular surface are formed by elementary pieces of simpler shape.\nElementary pieces. For the solvent accessible surface model, the boundary surface of a molecule consists\nof three types of elements: the convex spherical surface pieces, arcs or curved line segments (possibly a\nfull circle) formed by two intersecting spheres, and a vertex that is the intersection point of three atom\nspheres. The whole boundary surface of the molecules can be thought of as a surface formed by stitching\nthese elements together.\nSimilarly, the molecular surface swept out by the front of the solvent ball can also be thought of as being\nformed by elementary surface pieces. In this case, they are the convex spherical surface pieces, the toroidal\nsurface pieces, and the concave or inverse spherical surface pieces (Fig. 6.1b) . The latter two types of surface\npieces are often called the ?re-entrant surfaces? [8,11].\nThe surface elements of the solvent accessible surface and the molecular surface are closely related.\nImagine a process where atom balls are shrunk or expanded. The vertices in solvent accessible surface\nbecomes the concave spherical surface pieces, the arcs becomes the toroidal surfaces, and the convex surface\npieces become smaller convex surface pieces (Fig. 6.1c). Because of this mapping, these two type of surfaces\nare combinatorically equivalent and have similar topological properties, i.e., they are homotopy equivalent.\nHowever, the SA surface and the MS surface differ in their metric measurement. In concave regions of a\nmolecule, often the front of the solvent ball can sweep out a larger volume than the center of the solvent ball.\nA void of size close to zero in solvent accessible surface model will correspond to a void of the size of a solvent\nball (4pir3s/3). It is therefore important to distinguish these two types of measurement when interpreting the\nresults of volume calculations of protein molecules. The intrinsic structures of these fundamental elementary\n3\nvoid\na cb\nFigure 6.2: Geometry of a simplified two dimensional model molecule, to illustrate the geometric constructs\nand the procedure mapping the Voronoi diagram to the Delaunay triangulation. (a) The molecule formed by\nthe union of atom disks of uniform size. Voronoi diagram is in dashed lines. (b) The shape enclosed by the\nboundary polygon is the convex hull. It is tessellated by the Delaunay triangulation. (c) The alpha shape of\nthe molecule is formed by removing those Delaunay edges and triangles whose corresponding Voronoi edges\nand Voronoi vertices do not intersect with the body of the molecule. A molecular void is represented in the\nalpha shape by two empty triangles.\npieces are closely related to several geometric constructs we describe below.\n6.2.3 Geometric constructs\nVoronoi diagram. Voronoi diagram (Fig 6.2a), also known as Voronoi tessellation, is a geometric construct\nthat has been used for analyzing protein packing in the early days of protein crystallography [6,18,19]. For\ntwo dimensional Voronoi diagram, we consider the following analogy. Imagine a vast forset containing a\nnumber of fire observation towers. Each fire ranger is responsible for putting out any fire closer to his/her\ntower than to any other tower. The set of all trees for which a ranger is responsible constitutes the Voronoi\ncell associated with his/hertower, and the map of rangerresponsibilities, with towersand boundariesmarked,\nconstitutes the Voronoi diagram.\nWe formalize this for three dimensional space. Consider the point set S of atom centers in three dimen-\nsional space R3. The Voronoi region or Voronoi cell Vi of an atom bi with atom center zi ? R3 is the set of\nall points that are at least as close to zi than to any other atom centers in S:\nVi = {x ?R3|||x?zi|| ? ||x?zj||,zj ? S}. (6.1)\nWe can have an alternative view of the Voronoi cell of an atom bi. Considering the distance relationship of\natom center zi with the atom center zk of another atom bk. The plane bisecting the line segment connecting\npoints zi and zk divides the full R3 space into two half spaces, where points in one half space is closer to\nzi than to zk, and points in the other allspice is closer to zk than to zi. If we repeat this process and take\nzk in turn from the set of all atom centers other than zi, we will have a number of halfspaces where points\nare closer to zi than to each of the atom center zk. The Voronoi region Vi is then the common intersections\nof these half spaces, which is convex. When we consider atoms of different radii, we replace the Euclidean\ndistance ||x?zi|| with the power distance defined as: pii(x) ? ||x?zi||2 ?r2i .\nDelaunay tetrahedrization. Delaunay triangulation in R2 or Delaunay tetrahedrization in R3 is a geo-\nmetric construct that is closely related to the Voronoi diagram (Fig 6.2b). In general, it uniquely tessellates\nor tile up the space of the convex hull of the atom centers in R3 with tetrahedra. Convex hull for a point\n4\nset is the smallest convex body that contains the point set 1. The Delaunay tetrahedrization of a molecule\ncan be obtained from the Voronoi diagram. Consider that the Delaunay tetrahedrization is formed by gluing\nfour types of primitive elements together: vertices, edges, triangles, and tetrahedra. Here vertices are just\nthe atom centers. We obtain a Delaunay edge by connecting atom centers zi and zj if and only if the\nVoronoi regions Vi and Vj have a common intersection, which is a planar piece that may be either bounded\nor extend to infinity. We obtain a Delaunay triangle connecting atom centers zi, zj, and zk if the common\nintersection of Voronoi regions Vi,Vj and Vk exists, which is either a line segment, or a half-line, or a line\nin the Voronoi diagram. We obtain a Delaunay tetrahedra connecting atom centers zi,zj,zk and zl if and\nonly if the Voronoi regions Vi,Vj,Vk and Vl intersect at a point.\n6.2.4 Topological structures\nDelaunay complex. The structures in both Voronoi diagram and Delaunay tetrahedrization are better\ndescribed with concepts from algebraic topology. We focus on the intersection relationship in the Voronoi\ndiagram and introduce concepts formalizing the primitive elements. In R3, between two to four Voronoi re-\ngions may have common intersections. We use simplices of various dimensions to record these intersection or\noverlap relationships. We have vertices ?0 as 0-simplices, edges ?1 as 1-simplices, triangles ?2 as 2-simplices,\nand tetrahedra ?3 as 3-simplices. Each of the Voronoi plane, Voronoi edge, and Voronoi vertices corresponds\nto a 1-simplex (Delaunay edge), 2-simplex (Delaunay triangle), and 3-simplex (Delaunay tetrahedron), re-\nspectively. If we use 0-simplices to represent the Voronoi cells, and add them to the simplices induced by\nthe intersection relationship, we can think of the Delaunay tetrahedrization as the structure obtained by\n?glueing? these simplices properly together. Formally, these simplices form a simplicial complex K:\nK = {?|I|?1|\nintersectiondisplay\ni?I\nVi negationslash= ?}, (6.2)\nwhere I is an index set for the vertices representing atoms whose Voronoi cells overlap, and |I|? 1 is the\ndimension of the simplex.\nAlpha shape and protein surfaces. Imagine we can turn a knob to increase or decrease the size of all\natoms simultaneously. We can then have a model of growing balls and obtain further information from the\nDelaunay complex about the shape of a protein structure. Formally, we use a parameter ? ? R to control\nthe size of the atom balls. For an atom ball bi of radius ri, we modified its radius ri at a particular ? value\nto ri(?) = (r2i +?)1/2. When ?ri < ? < 0, the size of an atom is shrunk. The atom could even disappear if\n? < 0 and |?| > ri. We start to collect the simplices at different ? value as we increase ? from ?? to +?\n(see Fig 6.3 for a two-dimensional example). At the beginning, we only have vertices. When ? is increased\nsuch that two atoms are close enough to intersect, we collect the corresponding Delaunay edge that connects\nthese two atom centers. When three atoms intersect, we collect the correspondingDelaunay triangle spanning\nthese three atom centers. When four atoms intersect, we collect the corresponding Delaunay tetrahedron.\nAt any specific ? value, we have a dual simplicial complex or alpha complex K? formed by the collected\nsimplices. If all atoms take the incremented radius of ri +rs and ? = 0, we have the dual simplicial complex\nK0 of the protein molecule. When ? is sufficiently large, we have collected all simplices and we get the full\nDelaunay complex. This series of simplicial complexes at different ? value form a family of shapes (Fig 6.3),\ncalled alpha shapes, each faithfully represents the geometric and topological property of the protein molecule\nat a particular resolution parametrized by the ? value.\nAn equivalent way to obtain the alpha shape at ? = 0 is to take a subset of the simplices, with the\nrequirement that the corresponding intersections of Voronoi cells must overlap with the body of the union\n1For a two dimensional toy molecule, we can imagine that we put nails at the locations of the atom centers, and tightly wrap\na rubber band around these nails. The rubber band will trace out a polygon. This polygon and the region enclosed within\nis the convex hull of the set of points corresponding to the atom centers. Similarly, imagine if we can tightly wrap a tin-foil\naround a set of points in three dimensional space, the resulting convex body formed by the tin-foil and space enclosed within\nis the convex hull of this set of points in R3.\n5\na b c\nd e f\nFigure 6.3: The family of alpha shapes or dual simplicial complexes for a two-dimensional toy molecule.\n(a) We collect simplices from the Delaunay triangulation as atoms grow by increasing the ? value. At the\nbeginning as ? grows from ??, atoms are in isolation and we only have vertices in the alpha shape. (b) and\n(c) When ? is increased such that some atom pairs start to intersect, we collect the corresponding Delaunay\nedges. (d) When three atoms intersect as ? increases, we collect the corresponding Delaunay triangles.\nWhen ? = 0, the collection of vertices, edges, and triangles form the dual simplicial complex K0, which\nreflecting the topological structure of the protein molecule. (e) More edges and triangles from the Delaunay\ntriangulation are now collected as atoms continue to grow. (d) Finally, all vertices, edges, and triangles are\nnow collected as atoms are grown to large enough size. We get back the full original Delaunay complex.\nof the balls. We obtain the dual complex or alpha shape K0 of the molecule at ? = 0 (Fig 6.2c):\nK0 = {?|I|?1|\nintersectiondisplay\ni?I\nVi ?\nuniondisplay\nB negationslash= ?}. (6.3)\nAlpha shape provides a guide map for computing geometric properties of the structures of biomolecules.\nTake the molecular surface as an example, the re-entrant surfaces are formed by the concave spherical patch\nand the toroidal surface. These can be mapped from the boundary triangles and boundary edges of the\nalpha shape, respectively [20]. Recall that a triangle in the Delaunay tetrahedrization corresponds to the\nintersection of three Voronoi regions, i.e., a Voronoi edge. For a triangle on the boundary of the alpha shape,\nthe corresponding Voronoi edge intersects with the body of the union of balls by definition. In this case,\nit intersects with the solvent accessible surface at the common intersecting vertex when the three atoms\noverlap. This vertex corresponds to a concave spherical surface patch in the molecular surface. For an\nedge on the boundary of the alpha shape, the corresponding Voronoi plane coincides with the intersecting\nplane when two atoms meet, which intersect with the surface of the union of balls on an arc. This line\nsegment corresponds to a toroidal surface patch. The remaining part of the surface are convex pieces, which\ncorrespond to the vertices, namely, the atoms on the boundary of the alpha shape.\nThe numbers of toroidal pieces and concave spherical pieces are exactly the numbers of boundary edges\nand boundary triangles in the alpha shape, respectively. Because of the restriction of bond length and the\nexcluded volume effects, the number of edges and triangles in molecules are roughly in the order of O(n)\n[21].\n6.2.5 Metric measurement\nWe have described the relationship between the simplices and the surface elements of the molecule. Based\non this type of relationship, we can compute efficiently size properties of the molecule. We take the problem\n6\nof volume computation as an example.\nConsider a grossly incorrect way to compute the volume of a protein molecule using the solvent accessible\nsurface model. We could define that the volume of the molecule is the summation of the volumes of individual\natoms, whose radii are inflated to account for solvent probe. By doing so we would have significantly inflated\nthe value of the true volume, because we neglected to consider volume overlaps. We can explicitly correct\nthis by following the inclusion-exclusion formula: when two atoms overlap, we subtract the overlap; when\nthree atoms overlap, we first subtract the pair overlaps, we then add back the triple overlap, etc. This\ncontinues when there are four, five, or more atoms intersecting. At the combinatorial level, the principle\nof inclusion-exclusion is related to the Gauss-Bonnet theorem used by Connolly [11]. The corrected volume\nV (B) for a set of atom balls B can then be written as:\nV (B) =\nsummationdisplay\nvol(intersectiontext T)>0\nT?B\n(?1)dim(T)?1 vol(\nintersectiondisplay\nT), (6.4)\nwhere vol(intersectiontextT) represents volume overlap of various degree, T ? B is a subset of the balls with non-zero\nvolume overlap: vol(intersectiontextT) > 0.\nHowever, the straightforward application of this inclusion-exclusion formula does not work. The degree\nof overlap can be very high: theoretical and simulation studies showed that the volume overlap can be up\nto 7-8 degrees [22,23]. It is difficult to keep track of these high degree of volume overlaps correctly during\ncomputation, and it is also difficult to compute the volume of these overlaps because there are many different\ncombinatorial situations, i.e., to quantify how large is the k-volume overlap of which one of the parenleftbig7kparenrightbig or parenleftbig8kparenrightbig\noverlapping atoms for all of k = 2,??? ,7 [23]. It turns out that for three-dimensional molecules, overlaps\nof five or more atoms at a time can always be reduced to a ?+? or a ??? signed combination of overlaps\nof four or fewer atom balls [9]. This requires that the 2-body, 3-body, and 4-body terms in Eqn 6.4 enter\nthe formula if and only if the corresponding edge ?ij connecting the two balls (1-simplex), triangles ?ijk\nspanning the three balls (2-simplex), and tetrahedron ?ijkl cornered on the four balls (3-simplex) all exist in\nthe dual simplicial complex K0 of the molecule [9,21]. Atoms corresponding to these simplices will all have\nvolume overlaps. In this case, we have the simplified exact expansion:\nV (B) =\nsummationdisplay\n?i?K\nvol(bi)?\nsummationdisplay\n?ij?K\nvol(bi ?bj)\n+\nsummationdisplay\n?ijk?K\nvol(bi ?bj ?bk)?\nsummationdisplay\n?ijkl?K\nvol(bi ?bj ?bk ?bl).\nThe same idea is applicable for the calculation of surface area of molecules.\nAn example. An example of area computation by alpha shape is shown in Fig 6.4. Let b1,b2,b3,b4 be the\nfour disks. To simplify the notation we write Ai for the area of bi, Aij for the area of bi ?bj, and Aijk for\nthe area of bi ?bj ?bk. The total area of the union, b1 ?b2 ?b3 ?b4, is\nAtotal = (A1 + A2 + A3 + A4)\n? (A12 + A23 + A24 + A34)\n+ A234.\nWe add the area of bi if the corresponding vertex belongs to the alpha complex (Fig 6.4), we subtract the\narea of bi ?bj if the corresponding edge belongs to the alpha complex, and we add the area of bi ?bj ?bk if\nthe corresponding triangle belongs to the alpha complex. Note without the guidance of the alpha complex,\nthe inclusion-exclusion formula may be written as:\nAtotal = (A1 + A2 + A3 + A4)\n? (A12 + A13 + A14 + A23 + A24 + A34)\n+ (A123 + A124 + A134 + A234)\n? A1234.\n7\nb1\nb2\nb3\nb4\nA\nb1\nb2\nb3\nb4\nB\nFigure 6.4: An example of analytical area calculation. (a) Area can be computed using the direct inclusion-\nexclusion. (b) The formula is simplified without any redundant terms when using alpha shape.\nThis contains 6 canceling redundant terms: A13 = A123, A14 = A124, and A134 = A1234. Computing these\nterms would be wasteful. Such redundancy does not occur when we use the alpha complex: the part of the\nVoronoi regions contained in the respective atom balls for the redundant terms do not intersect. Therefore,\nthe corresponding edges and triangles do not enter the alpha complex. In two dimensions, we have terms of at\nmost three disk intersections, corresponding to triangles in the alpha complex. Similarly, in three dimensions\nthe most complicated terms are intersections of four spherical balls, and they correspond to tetrahedra in\nthe alpha complex.\nVoids and pockets. Voids and pockets represent the concave regions of a protein surface. Because shape-\ncomplementarity is the basis of many molecular recognition processes, binding and other activities frequently\noccur in pocket or void regions of protein structures. For example, the majority of enzyme reactions take\nplace in surface pockets or interior voids.\nThe topological structure of the alpha shape also offers an effective method for computing voids and\npockets in proteins. Consider the Delaunay tetrahedra that are not included in the alpha shape. If we\nrepeatedly merge any two such tetrahedra on the condition that they share a 2-simplex triangle, we will\nend up with discrete sets of tetrahedra. Some of them will be completely isolated from the outside, and\nsome of them are connected to the outside by triangle(s) on the boundary of the alpha shape. The former\ncorresponds to voids (or cavities) in proteins, the latter corresponds to pockets and depressions in proteins.\nA pocket differs from a depression in that it must have an opening that is at least narrower than one\ninterior cross-section. Formally, the discrete flow [24] explains the distinction between a depression and a\npocket. In a two dimensional Delaunay triangulation, the empty triangles that are not part of the alpha\nshape can be classified into obtuse triangles and acute triangles. The largest angle of an obtuse triangle is\nmore than 90 degrees, and the largest angle of an acute triangle is less than 90 degrees. An empty obtuse\ntriangle can be regarded as a ?source? of empty space that ?flows? to its neighbor, and an empty acute\ntriangle a ?sink? that collects flow from its obtuse empty neighboring triangle(s). In Figure 6.5a, obtuse\ntriangles 1, 3, 4 and 5 flow to the acute triangle 2, which is a sink. Each of the discrete empty spaces on\nthe surface of protein can be organized by the flow systems of the corresponding empty triangles: Those\nthat flow together belong to the same discrete empty space. For a pocket, there is at least one sink among\nthe empty triangles. For a depression, all triangles are obtuse, and the discrete flow goes from one obtuse\ntriangle to another, from the innermost region to outside the convex hull. The discrete flow of a depression\ntherefore goes to infinity. Figure 6.5b gives an example of a depression formed by a set of obtuse triangles.\nOnce voids and pockets are identified, we can apply the inclusion-exclusion principle based on the sim-\nplices to compute the exact size measurement (e.g., volume and area) of each void and pocket [24,25].\nThe distinction between voids and pockets depends on the specific set of atomic radii and the solvent\n8\n1\n2 34\n5\n1\n345\nInfinity\n2\na b\nFigure 6.5: Discrete flow of empty space illustrated for two dimensional disks. (a) Discrete flow of a pocket.\nTriangles 1, 3, 4 and 5 are obtuse. The free volume flows to the ?sink? triangle 2, which is acute. (b) In a\ndepression, the flow is from obtuse triangles to the outside.\nradius. When a larger solvent ball is used, the radii of all atoms will be inflated by a larger amount. This\ncould lead to two different outcomes. A void or pocket may become completely filled and disappear. On the\nother hand, the inflated atoms may not fill the space of a pocket, but may close off the opening of the pocket.\nIn this case, a pocket becomes a void. A widely used practice in the past was to adjust the solvent ball\nand repeatedly compute voids, in the hope that some pockets will become voids and hence be identified by\nmethods designed for cavity/void computation. The pocket algorithm [24] and tools such as CastP [26,27]\noften makes this unnecessary.\n6.3 Computation and software\nComputing Delaunay tetrahedrization and Voronoi diagram. It is easier to discuss the computation\nof tetrahedrization first. The incremental algorithm developed in [28] can be used to compute the weighted\ntetrahedrization for a set of atoms of different radii. For simplicity, we sketch the outline of the algorithm\nbelow for two dimensional unweighted Delaunay triangulation.\nThe intuitive idea of the algorithm can be traced back to the original observation of Delaunay. For the\nDelaunay triangulation of a point set, the circumcircle of an edge and a third point forming a Delaunay\ntriangle must not contain a fourth point. Delaunay showed that if all edges in a particular triangulation\nsatisfy this condition, the triangulation is a Delaunay triangulation. It is easy to come up with an arbitrary\ntriangulation for a point set. A simple algorithm to covert this triangulation to the Delaunay triangulation is\ntherefore to go through each of the triangles, and make corrections using ?flips? discussed below if a specific\ntriangle contains an edge violating the above condition. The basic ingredients for computing Delaunay\ntetrahedrization are generalizations of these observations. We discuss the concept of locally Delaunay edge\nand the edge-flip primitive operation below.\nLocally Delaunay edge. We say an edge ab is locally Delaunay if either it is on the boundary of the convex\nhull of the point set, or if it belongs to two triangles abc and abd, and the circumcircle of abc does not contain\nd (e.g., edge cd in Fig 6.6a).\nEdge-flip. If ab is not locally Delaunay (edge ab in Fig 6.6a), then the union of the two triangles abc?abd\nis a convex quadrangle acbd, and edge cd is locally Delaunay. We can replace edge ab by edge cd. We call\nthis an edge-flip or 2-to-2 flip, as two old triangles are replaced by two new triangles.\nWe recursively check each boundary edge of the quadrangle abcd to see if it is also locally Delaunay after\nreplacing ab by cd. If not, we recursively edge-flip it.\nIncremental algorithm for Delaunay triangulation. Assume we have a finite set of points (namely, atom\ncenters) S = {z1,z2,??? ,zi,??? ,zn}. We start with a large auxiliary triangle that contains all these points.\nWe insert the points one by one. At all times, we maintain a Delaunay triangulation Di upto insertion of\n9\n1?to?3 flip\nb\n2?to?2 flip\na\nb\nc\nd\na\nb\nc\nd\na\nFigure 6.6: An illustration of locally Delaunay edge and flips. (a) For the quadrilateral abcd, edge ab is not\nlocally Delaunay, as the circumcircle passing through edge ab and a third point c contains a fourth point d.\nEdge cd is locally Delaunay, as b is outside the circumcircle adc. An edge-flip or 2-to-2 flip replaces edge ab\nby edge cd, and replace the original two triangles abc and adb with two new triangles acd and bcd. (b) When\na new vertex is inserted, we replace the old triangle containing this new vertex with three new triangles.\nThis is called 1-to3 flips.\npoint zi.\nAfter inserting point zi, we search for the triangle ?i?1 that contains this new point. We then add zi to\nthe triangulation and split the original triangle ?i?1 into three smaller triangles. This split is called 1-to-3\nflip, as it replaces one old triangle with three new triangles. We then check if each of the three edges in ?i?1\nstill satisfies the locally Delaunay requirement. If not, we perform a recursive edge-flip. This algorithm is\nsummarized in Algorithm 1.\nAlgorithm 1 Delaunay triangulation\nObtain random ordering of points {z1,??? ,zn};\nfor i = 1 to n do\nfind ?i?1 such zi ? ?i?1;\nadd zi, and split ?i?1 into three triangles (1-to-3 flip);\nwhile any edge ab not locally Delaunay do\nflip ab to other diagonal cd (2-to-2 edge flip);\nend while\nend for\nIn R3, the algorithm of tetrahedrization becomes more complex, but the same basic ideas apply. In this\ncase, we need to locate a tetrahedron instead of a triangle that contains the newly inserted point. The\nconcept of locally Delaunay is replaced by the concept of locally convex, and there are flips different than the\n2-to-2 flip in R3 [28]. Although an incremental approach, i.e., sequentially adding points, is not necessary\nfor Delaunay triangulation in R2, it is necessary in R3 to avoid non-flippable cases and to guarantee that\nthe algorithm will terminate. This incremental algorithm has excellent expected performance [28].\nThe computation of Voronoi diagram is conceptually easy once the Delaunay triangulation is available.\nWe can take advantage of the mathematical duality and compute all of the Voronoi vertices, edges, and\nplanar faces from the Delaunay tetrahedra, triangles, and edges. Because one point zi may be an vertex of\nmany Delaunay tetrahedra, the Voronoi region of zi therefore may contain many Voronoi vertices, edges,\nand planar faces. The efficient quad-edge data structure can be used for software implementation [29].\nVolume and area computation. Let V and A denote the volume and area of the molecule, respectively,\nK? for the alpha complex, ? for a simplex in K, i for a vertex, ij for an edge, ijk for a triangle, and ijkl for\na tetrahedron. The algorithm for volume and area computation can be written as Algorithm 2. Additional\ndetails of volume and area computation can be found in [20,21].\nSoftware. The software package Delcx for computing weighted Delaunay tetrahedrization, Mkalf for\ncomputing the alpha shape, Volbl for computing volume and area of both molecules and interior voids\n10\nAlgorithm 2 Volume and area measurement\nV := A := 0.0;\nfor all ? ? K do\nif ? is a vertex i then\nV := V +vol(bi); A := A+area(bi);\nend if\nif ? is an edge ij then\nV := V ?vol(bi ?bj); A := A?area(bi ?bj);\nend if\nif ? is a triangle ijk then\nV := V +vol(bi ?bj ?bk); A := A +area(bi ?bj ?bk);\nend if\nif ? is a tetrahedron ijkl then\nV := V ?vol(bi ?bj ?bk ?bl); A := A?area(bi ?bj ?bk ?bl);\nend if\nend for\nand be found at www.alphashape.org. The CastP webserver for pocket computation can be found at\ncast.engr.uic.edu. There are other studies that compute or use Voronoi diagrams of protein structures\n[30?32], although not all computes the weighted version which allows atoms to have different radii.\nIn this short description of algorithm, we have neglected many details important for geometric compu-\ntation. For example, the problem of how to handle geometric degeneracy, namely, when three points are\nco-linear, or when four points are co-planar. Interested readers should consult the excellent monograph by\nEdelsbrunner for a detailed treatise of these and other important topics in computational geometry [33].\n6.4 Applications: Packing analysis.\nAn important application of the Voronoi diagram and volume calculation is the measurement of protein\npacking. Tight packing is an important feature of protein structure [6,10], and is thought to play important\nroles in protein stability and folding dynamics [34]. The packing density of a protein is measured by the\nratio of its van der Waals volume and the volume of the space it occupies. One approach is to calculate the\npacking density of buried residues and atoms using Voronoi diagram [6,10]. This approach was also used to\nderive radii parameters of atoms [15].\nBased on the computation of voids and pockets in proteins, a detailed study surveying major represen-\ntatives of all known protein structural folds showed that there is a substantial amount of voids and pockets\nin proteins [35]. On average, every 15 residues introduces a void or a pocket (Fig 6.7a). For a perfectly\nsolid three-dimensional sphere of radius r, the relationship between volume V = 4pir3/3 and surface area\nA = 4pir2 is: V ? A3/2. In contrast, Figure 6.7b shows that the van der Waals volume scales linearly with\nthe van der Waals surface areas of proteins. The same linear relationship holds irrespective of whether we\nrelate molecular surface volume and molecular surface area, or solvent accessible volume and solvent acces-\nsible surface area. This and other scaling behavior point out that protein interior is not packed as tight as\nsolid [35]. Rather, packing defects in the form of voids and pockets are common in proteins.\nIf voids and pockets are prevalent in proteins, an interesting question is what is then the origin of the\nexistence of these voids and pockets. This question was studied by examining the scaling behavior of packing\ndensity and coordination number of residues through the computation of voids, pockets, and edge simplices\nin the alpha shapes of random compact chain polymers [36]. For this purpose, a 32-state discrete state\nmodel was used to generate a large ensemble of compact self-avoiding walks. This is a difficult task, as it is\nvery challenging to generate a large number of independent conformations of very compact chains that are\nself-avoiding. The results in [36] showed that it is easy for compact random chain polymers to have similar\nscaling behavior of packing density and coordination number with chain length. This suggests that proteins\n11\nNumber of Residues\nNum of Voids and Pockets\n0 200 600 1000\n0\n50\n100\n150\nA x 1000\nV x 1000\n0 200 400 600 800\n0\n100\n300\n500\nFigure 6.7: Voids and pockets for a set of 636 proteins representing most of the known protein folds, and\nthe scaling behavior of the geometric properties of proteins. (a) The number of voids and pockets detected\nwith a 1.4 ?A probe is linearly correlated with the number of residues in a protein. Only proteins with\nless than 1,000 residues are shown. Solid triangles and empty circles represent the pockets and the voids,\nrespectively. (b) The van der Waals (vdw) volume and van der Waals area of proteins scale linearly with\neach other. Similarly, molecular surface (ms) volume also scales linearly with molecular surface area using\na probe radius of 1.4?A. (Data not shown. Figure adapted after [35])\n12\nare not optimized by evolution to eliminate voids and pockets, and the existence of many pockets and voids is\nrandom in nature, and is due to the generic requirement of compact chain polymers. The frequent occurrence\nand the origin of voids and pockets in protein structures raise a challenging question: How can we distinguish\nvoids and pockets that perform biological functions such as binding from those formed by random chance?\nThis question is related to the general problem of protein function prediction.\n6.5 Applications: Protein function prediction from structures.\nConservation of protein structures often reveals very distant evolutionary relationship, which are otherwise\ndifficult to detect by sequence analysis [37]. Comparing protein structures can provide insightful ideas about\nthe biochemical functions of proteins (e.g., active sites, catalytic residues, and substrate interactions) [38?40].\nA fundamental challenge in inferring protein function from structure is that the functional surface of\na protein often involves only a small number of key residues. These interacting residues are dispersed in\ndiverse regions of the primary sequences and are difficult to detect if the only information available is the\nprimary sequence. Discovery of local spatial motifs from structures that are functionally relevant has been\nthe focus of many studies.\nGraph based methods for spatial patterns in proteins. To analyze local spatial patterns in proteins.\nArtymiuk et al developed an algorithm based on subgraph isomorphism detection [41]. By representing\nresidue side-chains as simplified pseudo-atoms, a molecular graph is constructed to represent the patterns of\nside-chain pseudo-atoms and their inter-atomic distances. A user defined query pattern can then be searched\nrapidly against the Protein Data Bank for similarity relationship. Another widely used approach is the\nmethod of geometric hashing. By examining spatial patterns of atoms, Fischer et al developed an algorithm\nthat can detect surface similarity of proteins [42,43]. This method has also been applied by Wallace et al for\nthe derivation and matching of spatial templates [44]. Russell developed a different algorithm that detects\nside-chain geometric patterns common to two protein structures [45]. With the evaluation of statistical\nsignificance of measured root mean square distance, several new examples of convergent evolution were\ndiscovered, where common patterns of side-chains were found to reside on different tertiary folds.\nThese methods have a number of limitations. Most require a user-defined template motif, restricting their\nutility for automated database-wide search. In addition, the size of the spatial pattern related to protein\nfunction is also often restricted.\nPredicting protein functions by matching pocket surfaces. Protein functional surfaces are frequently\nassociated with surface regions of prominent concavity [26,46]. These include pockets and voids, which can\nbe accurately computed as we have discussed. Computationally, one wishes to automatically identify voids\nand pockets on protein structures where interactions exist with other molecules such as substrate, ions,\nligands, or other proteins.\nBinkowski et al. developed a method for predicting protein function by matching a surface pocket or void\non a protein of unknown or undetermined function to the pocket or void of a protein of known function\n[47,48]. Initially, the Delaunay tetrahedrization and alpha shapes for almost all of the structures in the\nPDB databank are computed [27]. All surface pockets and interior voids for each of the protein structure\nare then exhaustively computed [24,25]. For each pocket and void, the residues forming the wall are then\nconcatenated to form a short sequence fragment of amino acid residues, while ignoring all intervening residues\nthat do not participate in the formation of the wall of the pocket or void. Two sequence fragments, one\nfrom the query protein and another from one of the proteins in the database, both derived from pocket or\nvoid surface residues, are then compared using dynamic programming. The similarity score for any observed\nmatch is assessed for statistical significance using an empirical randomization model constructed for short\nsequence patterns.\nFor promising matches of pocket/void surfaces showing significant sequence similarity, we can further\nevaluate their similarity in shape and in relative orientation. The former can be obtained by measuring\nthe coordinate root mean square distance (rmsd) between the two surfaces. The latter is measured by\n13\nfirst placing a unit sphere at the geometric center z0 ? R3 of a pocket/void. The location of each residue\nz = (x,y,z)T is then projected onto the unit sphere along the direction of the vector from the geometric\ncenter: u = (z ?z0)/||z ?z0||. The projected pocket is represented by a collection of unit vectors located\non the unit sphere, and the original orientation of residues in the pocket is preserved. The rmsd distance of\nthe two sets of unit vectors derived from the two pockets are then measured, which is called the ormsd for\norientation rmsd [47]. This allows similar pockets with only minor conformational changes to be detected\n[47].\nThe advantage of the method of Binkowski et al is that it does not assume prior knowledge of functional\nsite residues, and does not require a priori any similarity in either the full primary sequence or the backbone\nfold structures. It has no limitation in the size of the spatially derived motif and can successfully detect\npatterns small and large. This method has been successfully applied to detect similar functional surfaces\namong proteins of the same fold but low sequence identities, and among proteins of different fold [47,49].\nFunction prediction through models of protein surface evolution. To match local surfaces such as\npockets and voids and to assess their sequence similarity, an effective scoring matrix is critically important.\nIn the original study of Binkowski et al, Blosum matrix was used. However, this is problematic, as Blosum\nmatrices were derivedfrom analysisof precomputed large quantities of sequences, while the information of the\nparticular protein of interest has limited or no influence. In addition, these precomputed sequences include\nburied residues in protein core, whose conservation reflects the need to maintain protein stability rather\nthan to maintain protein function. In reference [50,51], a continuous time Markov process was developed\nto explicitly model the substitution rates of residues in binding pockets. Using a Bayesian Markov chain\nMonte Carlo method, the residue substitution rates at functional pocket are estimated. The substitution\nrates are found to be very different for residues in the binding site and residues on the remaining surface of\nproteins. In addition, substitution rates are also very different for residues in the buried core and residues\non the solvent exposed surfaces.\nThese rates are then used to generate a set of scoring matrices of different time intervals for residues\nlocated in the functional pocket. Application of protein-specific and region-specific scoring matrices in\nmatching protein surfaces result in significantly improved sensitivity and specificity in protein function\nprediction [50,51].\nIn a large scale study of predicting protein functions from structures, a subset of 100 enzyme families are\ncollected from the total of 286 enzyme families containing between 10?50 member protein structures with\nknown Enzyme Classification (E.C.) labels. By estimating the substitution rate matrix for residues on the\nactive site pocket of a query protein, a series of scoring matrices of different evolutionary time is derived. By\nsearching for similar pocket surfaces from a database of 770,466 pockets derived from the CastP database\n(with the criterion that each must contain at least 8 residues), this method can recover active site surfaces\non enzymes similar to that on the query structure at an accuracy of > 92%. Fig 6.8 shows the Receiver\nOperating Characteristic Curve of this study. An example of identifying human amylase using template\nsurfaces from B. subtilis and from barley is shown in Fig 6.9.\nThe method of surface matching based on evolutionary model is also especially effective in solving the\nchallenging problems of protein function prediction of orphan structures of unknown function (such as those\nobtained in structural genomics projects), which have only sequence homologs that are themselves hypothet-\nical proteins with unknown functions.\n6.6 Discussion\nA major challenge in studying protein geometry is to understand our intuitive notions of various geometric\naspects of molecular shapes, and to quantify these notions with mathematical models that are amenable to\nfast computation. The advent of the union of ball model of protein structures enabled rigorous definition\nof important geometric concepts such as solvent accessible surface and molecular surface. It also led to\nthe development of algorithms for area and volume calculations of proteins. Deep understanding of the\ntopological structure of molecular shapes is also based on the idealized union of ball model [9]. A success\n14\n0.0 0.2 0.4 0.6 0.8 1.0\n0.75\n0.80\n0.85\n0.90\nnewy\nTrue Positive Rate(sensitivity)\nFalse Positve Rate(1?specificity)\nFigure 6.8: A large scale study of protein function prediction from structures by matching similar func-\ntional surfaces for 100 protein families. A correct prediction is made if the matched surface comes from a\nprotein structure with the same Enzyme Classification (E.C.) number (upto the 4-th digit) as that of the\nquery protein. The x-axis of the Receiver Operating Characteristics curve reflects the false positive rate\n(1?specificity) at different statistical significance p-value by cRMSD measurement, and the y-axis reflects\nthe true positive rate (sensitivity).\nin approaching these problems is exemplified in the development of the pocket algorithm [24]. Another\nexample is the recent development of a rigorous definition of protein-protein binding or interaction interface\nand algorithm for its computation [52].\nPerhaps a more fundamental problem we face is to identify important structural and chemical features\nthat are the determinants of biological problems of interest. For example, we would like to know what are the\nshape features that has significant influences on protein solvation, protein stability, ligand specific binding,\nand protein conformational changes. It is not clear whether our current geometric intuitions are sufficient,\nor are the correct or the most relevant ones. There may still be important unknown shape properties of\nmolecules that elude us at the moment.\nAn important application of geometric computation of protein structures is to detect patterns important\nfor protein function. The shape of local surface regions on a protein structure and their chemical texture are\nthe basis of its binding interactions with other molecules. Proteins fold into specific native structure to form\nthese local regions for carrying out various biochemical functions. The geometric shape and chemical pattern\nof the local surface regions, and how they change dynamically are therefore of fundamental importance in\ncomputational studies of proteins.\nAnother important application is the development of geometric potential functions. Potential functions\nare important for generating conformations, for distinguishing native and near native conformations from\nother decoy conformations in protein structure predictions [53?56] and in protein-protein docking [57]. They\nare also important for peptide and protein design [57,58]. Chapter 4 describes in details the development of\ngeometric potential and applications in decoy discrimination and in protein-protein docking prediction.\nWe havenot described in detail the approachof studying protein geometryusing graphtheory. In addition\nto side-chain pattern analysis briefly discussed earlier, graph based protein geometric model also has lead to\na number of important insights, including the optimal design of model proteins formed by hydrophobic and\npolar residues [59], and methods for optimal design of side-chain packing [60,61]. Another important topic\nwe did not touch upon is the analysis of the topology of protein backbones. Based on concepts from knot\ntheory, R?gen and Bohr developed a family of global geometric measures for protein structure classification\n[62]. These measures originate from integral formulas of Vassiliev knot invariants. With these measures,\nR?gen and Fain further constructed a system that can automatically classify protein chains into folds [63].\n15\nFigure 6.9: Protein function prediction as illustrated by the example of alpha amylases. Two template\nbinding surfaces are used to search database of protein surfaces to identify protein structures that are of\nsimilar functions. (a) The phylogenetic tree for the template Pdb structure 1bag from B. subtilis. (b)\nThe template binding pocket of alpha amylase on 1bag. (c) A matched binding surface on a different\nprotein structure (1b2y from human, full sequence identity 22%) obtained by querying with 1bag. (d) The\nphylogenetic tree for the template structure 1bg9 from H. vulgare. (e) The template binding pocket on 1bg9.\n(f) A matched binding surface on a different protein structure (1u2y from human, full sequence identity\n23%) obtained by querying with 1bg9 (Adapted from [51]).\nThis system can reproduce the Cath classification system that requires explicit structural alignment as well\nas human curation.\nFurther development of descriptions of geometric shape and topological structure, as well as algorithms\nfor their computation will provide a solid foundation for studying many important biological problems. The\nother important tasks are then to show how these descriptors may be effectively used to deepen our biological\ninsights and to develop accurate predictive models of biological phenomena. For example, in computing\nprotein-protein interfaces, a challenging task is to discriminate surfaces that are involved in protein binding\nfrom other non-binding surface regions, and to understand in what fashion this depends on the properties\nof the binding partner protein.\nUndoubtedly, evolution plays central roles in shaping up the function and stability of protein molecules.\nThe method of analyzing residue substitution rates using a continuous time Markov models [50,51], and\nthe method of surface mapping of conservation entropy and phylogeny [64,65] only scratches the surface of\n16\nthis important issue. Much remains to be done in incorporating evolutionary information in protein shape\nanalysis for understanding biological functions.\n6.7 Summary\nThe accumulation of experimentally solved molecular structures of proteins provides a wealth of information\nfor studying many important biological problems. With the development of a rigorous model of the structure\nof protein molecules, various shape properties, including surfaces, voids, and pockets, and measurements of\ntheir metric properties can be computed. Geometric algorithms have found important applications in protein\npacking analysis, in developing potential functions, in docking, and in protein function prediction. It is\nlikely further development of geometric models and algorithms will find important applications in answering\nadditional biological questions.\n6.8 Further reading\nThe original work of Lee and Richards surface can be found in [5], where they also formulated the molecular\nsurface model [8]. Michael Connolly developed the first method for the computation of the molecular surface\n[11]. Tsai et al. described a method for obtaining atomic radii parameter [15]. The mathematical theory of\nthe union of balls and alpha shape was developed by Herbert Edelsbrunner and colleague [9,66]. Algorithm\nfor computing weighted Delaunay tetrahedrization can be found in [28], or in a concise monograph with\nin-depth discussion of geometric computing [33]. Details of area and volume calculations can be found in\n[20,21,25]. The theory of pocket computation and applications can be found in [24,26]. Richards and Lim\noffered a comprehensive review on protein packing and protein folding [12]. A detailed packing analysis of\nproteins can be found in [35]. The study on inferring protein function by matching surfaces is described in\n[47]. The study of the evolutionary model of protein binding pocket and its application in protein function\nprediction can be found in [51].\n6.9 Acknowledgments\nThis work is supported by grants from the National Science Foundation (CAREER DBI0133856), the Na-\ntional Institute of Health (GM68958), the Office of Naval Research (N000140310329), and the Whitaker\nFoundation (TF-04-0023). The author thanks Jeffrey Tseng for help in preparing this chapter.\n17\nBibliography\n[1] G. Rhodes. Crystallography Made Crystal Clear: A Guide for Users of Macromolecular Models. Aca-\ndemic Press, 1999.\n[2] G. M. Crippen and T. F. Havel. Distance Geometry and Molecular Conformation. J. Wiley & Sons,\n1988.\n[3] W. Rieping, M. Habeck, and M. Nilges. Inferential structure determination. Science, 309(5732):303?6,\n2005.\n[4] R.F.W. Bader. Atoms in Molecules: A Quantum Theory. The international series of mongraphs on\nchemistry, No. 22. Oxford University Press, 1994.\n[5] B. Lee and F. M. Richards. The interpretation of protein structures: estimation of static accessibility.\nJ. Mol. Biol., 55:379?400, 1971.\n[6] F. M. Richards. The interpretation of protein structures: total volume, group volume distributions and\npacking density. J. Mol. Biol., 82:1?14, 1974.\n[7] T. J. Richmond. Solvent accessible surface area and excluded volume in proteins: analytical equations\nfor overlapping spheres and implications for the hydrophobic effect. J. Mol. Biol., 178:63?89, 1984.\n[8] F. M. Richards. Calculation of molecular volumes and areas for structures of known geometries. Methods\nin Enzymology, 115:440?464, 1985.\n[9] H. Edelsbrunner. The union of balls and its dual shape. Discrete Comput. Geom., 13:415?440, 1995.\n[10] F. M. Richards. Areas, volumes, packing, and proteinstructures. Ann. Rev. Biophys. Bioeng., 6:151?176,\n1977.\n[11] M. L. Connolly. Analytical molecular surface calculation. J. Appl. Cryst., 16:548?558, 1983.\n[12] F. M. Richards and W. A. Lim. An analysis of packing in the protein folding problem. Q. Rev. Biophys.,\n26:423?498, 1994.\n[13] M. Gerstein and F. M Richards. Protein Geometry: Distances, Areas, and Volumes, volume F, chap-\nter 22. International Union of Crystallography, 1999.\n[14] F. M. Richards. The interpretation of protein structures: total volume, group volume distributions and\npacking density. J. Mol. Biol., 82:1?14, 1974.\n[15] J. Tsai, R. Taylor, C. Chothia, and M. Gerstein. The packing density in proteins: standard radii and\nvolumes. J Mol Biol, 290(1):253?66, 1999.\n[16] A. Bondi. VDW volumes and radii. J. Phys. Chem., 68:441?451, 1964.\n[17] J.M. Word, S.C. Lovell, J.S. Richardson, and D.C. Richardson. Asparagine and glutamine: using\nhydrogen atom contacts in the choice of side-chain amide orientation. J Mol Biol, 285(4):1735?47, 1999.\n18\n[18] J. L. Finney. Volume occupation, environment and accessibility in proteins. The problem of the protein\nsurface. J. Mol. Biol., 96:721?732, 1975.\n[19] B. J. Gellatly and J.L. Finney. Calculation of protein volumes: an alternative to the Voronoi procedure.\nJ. Mol. Biol., 161:305?322, 1982.\n[20] H. Edelsbrunner, M. Facello, P. Fu, and J. Liang. Measuring proteins and voids in proteins. In Proc.\n28th Ann. Hawaii Int?l Conf. System Sciences, volume 5, pages 256?264, Los Alamitos, California, 1995.\nIEEE Computer Scociety Press.\n[21] J. Liang, H. Edelsbrunner, P. Fu, P. V. Sudhakar, and S. Subramaniam. Analytical shape computing\nof macromolecules I: Molecular area and volume through alpha-shape. Proteins, 33:1?17, 1998.\n[22] K. W. Kratky. Intersecting disks (and spheres) and statistical mechanics. I. mathematical basis. J. Stat.\nPhys., 25:619?634, 1981.\n[23] M. Petitjean. On the analytical calculation of van der waals surfaces and volumes: some numerical\naspects. J. Comput. Chem., 15:507?523, 1994.\n[24] H. Edeslbrunner, M. Facello, and J. Liang. On the definition and the construction of pockets in macro-\nmolecules. Disc. Appl. Math., 88:18?29, 1998.\n[25] J. Liang, H. Edelsbrunner, P. Fu, P. V. Sudhakar, and S. Subramaniam. Analytical shape computing\nof macromolecules II: Identification and computation of inaccessible cavities inside proteins. Proteins,\n33:18?29, 1998.\n[26] J. Liang, H. Edelsbrunner, and C. Woodward. Anatomy of protein pockets and cavities: Measurement\nof binding site geometry and implications for ligand design. Protein Sci, 7:1884?1897, 1998.\n[27] T. A. Binkowski, S. Naghibzadeh, and J. Liang. CASTp: Computed atlas of surface topography of\nproteins. Nucleic Acids Res., 31:3352?3355, 2003.\n[28] H. Edelsbrunner and N.R. Shah. Incremental topological flipping works for regular triangulations.\nAlgorithmica, 15:223?241, 1996.\n[29] L. Guibas and J. Stolfi. Primitives for the manipulation of general subdivisions and the computation of\nVoronoi diagrams. ACM Transactions on Graphiques, 4:74?123, 1985.\n[30] S. Chakravarty, A. Bhinge, and R. Varadarajan. A procedure for detection and quantitation of cavity\nvolumes proteins. application to measure the strength of the hydrophobic driving force in protein folding.\nJ Biol Chem, 277(35):31345?53, 2002.\n[31] A. Goede, R. Preissner, and C. Frommel. Voronoi cell: New method for allocation of space among\natoms: Elimination of avoidable errors in calculation of atomic volume and density. J. Comput. Chem.,\n18:1113?1123, 1997.\n[32] Y. Harpaz, M. Gerstein, and C. Chothia. Volume changes on protein folding. Structure, 2(7):641?9,\n1994.\n[33] H. Edelsbrunner. Geometry and Topology for Mesh Generation. Cambridge University Press, 2001.\n[34] M. Levitt, M. Gerstein, E. Huang, S. Subbiah, and J. Tsai. Protein folding: the endgame. Annu Rev\nBiochem, 66:549?579, 1997.\n[35] J. Liang and K. A. Dill. Are proteins well-packed? Biophys. J., 81:751?766, 2001.\n[36] J. Zhang, R. Chen, C. Tang, and J. Liang. Origin of scaling behavior of protein packing density: A\nsequential monte carlo study of compact long chain polymers. J. Chem. Phys., 118:6102?6109, 2003.\n19\n[37] A. E. Todd, C. A. Orengo, and J. M. Thornton. Evolution of function in protein superfamilies, from a\nstructural perspective. J. Mol. Biol., 307:1113?1143, 2001.\n[38] L. Holm and C. Sander. New structure: Novel fold? Structure, 5:165?171, 1997.\n[39] A. C. R. Martin, C. A. Orengo, E. G. Hutchinson, A. D. Michie, A. C. Wallace, M. L. Jones, and J. M.\nThornton. Protein folds and functions. Structure, 6:875?884, 1998.\n[40] C. A. Orengo, A. E. Todd, and J. M. Thornton. From protein structure to function. Curr. Opinion\nStructural Biology, 9(4):374?382, 1999.\n[41] P. J. Artymiuk, A. R. Poirrette, H. M. Grindley, D.W. Rice, and P. Willett. A graph-theoretic approach\nto the identification of three-dimensional patterns of amino acid side-chains in protein structure. J. Mol.\nBiol., 243:327?344, 1994.\n[42] D. Fischer, R. Norel, H. Wolfson, and R. Nussinov. Surface motifs by a computer vision technique:\nsearches, detection, and implications for protein- ligand recognition. Proteins: Structure, Function and\nGenetics, 16:278?292, 1993.\n[43] R. Norel, D. Fischer, H. J. Wolfson, and R. Nussinov. Molecualr surface recognition by computer\nvision-based technique. Protein Eng., 1994.\n[44] A. C. Wallace, N. Borkakoti, and J. M. Thornton. TESS: a geometric hashing algorithm for deriving\n3d coordinate templates for searching structural databases. Application to enzyme active sites. Protein\nSci., 6:2308?2323, 1997.\n[45] R. Russell. Detection of protein three-dimensional side-chain patterns: New examples of convergent\nevolution. J. Mol. Biol., 279:1211?1227, 1998.\n[46] R. A. Laskowski, N. M. Luscombe, M. B. Swindells, and J. M. Thornton. Protein clefts in molecular\nrecognition and function. Protein Sci., 5:2438?2452, 1996.\n[47] T. A. Binkowski, L. Adamian, and J. Liang. Inferring functional relationship of proteins from local\nsequence and spatial surface patterns. J. Mol. Biol., 332:505?526, 2003.\n[48] T.A. Binkowski, A. Joachimiak, and J. Liang. Protein surface analysis for function annotation in\nhigh-throughput structural genomics pipeline. Protein Sci, 14(12):2972?81, 2005.\n[49] T.A. Binkowski, P. Freeman, and J. Liang. pvSOAR: Detecting similar surface patterns of pocket and\nvoid surfaces of amino acid residues on proteins. Nucleic Acid Research, 32:W555?W558, 2004.\n[50] Y.Y. Tseng and J. Liang. Estimating evolutionary rate of local protein binding surfaces: a bayesian\nmonte carlo approach. Proceedings of 2005 IEEE-EMBC Conference, 2005.\n[51] Y.Y. Tseng and J. Liang. Estimation of amino acid residue substitution rates at local spatial regions\nand application in protein function inference: A Bayesian Monte Carlo approach. Mol. Biol. Evol.,\n23:421?436, 2006.\n[52] Y. Ban, H. Edelsbrunner, and J. Rudolph. Interface surfaces for protein-protein complexes. In RE-\nCOMB, pages 205?212, 2004.\n[53] R. K.Singh, A. Tropsha, and I. I. Vaisman. Delaunaytessellationof proteins: fourbody nearest-neighbor\npropensities of amino-acid residues. J. Comp. Bio., 3:213?221, 1996.\n[54] W. Zheng, S. J. Cho, I. I. Vaisman, and A. Tropsha. A new approach to protein fold recognition based\non Delaunay tessellation of protein structure. In R.B. Altman, A.K. Dunker, L. Hunter, and T.E. Klein,\neditors, Pacific Symposium on Biocomputing?97, pages 486?497, Singapore, 1997. World Scientific.\n20\n[55] X. Li, C. Hu, and J. Liang. Simplicial edge representation of protein structures and alpha contact\npotential with confidence measure. Proteins, 53:792?805, 2003.\n[56] X. Li and J. Liang. Geometric cooperativity and anticooperativity of three-body interactions in native\nproteins. Proteins, 60(1):46?65, 2005.\n[57] X. Li and J. Liang. Computational design of combinatorial peptide library for modulating protein-\nprotein interactions. Pac Symp Biocomput, pages 28?39, 2005.\n[58] C. Hu, X. Li, and J. Liang. Developing optimal nonlinear scoring function for protein design. Bioinfor-\nmatics, 20:3080?3098, 2004.\n[59] J. Kleinberg. Efficient algorithms for protein sequence design and the analysis of certain evolutionary\nfitness landscapes. In RECOMB, pages 205?212, 2004.\n[60] J. Xu. Rapid protein side-chain packing via tree decomposition. In RECOMB, pages 423?439, 2005.\n[61] A. Leaver-Fay, B. Kuhlman, and J. Snoeyink. An adaptive dynamic programming algorithm for the\nside chain placement problem. In Pacific Symposium on Biocomputing, pages 17?28, 2005.\n[62] P. R?gen and H. Bohr. A new family of global protein shape descriptors. Math Biosci, 182(2):167?81,\n2003.\n[63] P. R?gen and B. Fain. Automatic classification of protein structure by using gauss in tegrals. Proc Natl\nAcad Sci U S A, 100(1):119?24, 2003.\n[64] O. Lichtarge, H.R. Bourne, and F.E. Cohen. An evolutionary trace method defines binding surfaces\ncommon to protein families. J Mol Biol, 257(2):342?58, 1996.\n[65] F. Glaser, T. Pupko, I. Paz, R.E. Bell, D. Shental, E. Martz, and N. Ben-Tal. Consurf: identifica-\ntion of functional regions in proteins by surface-mapping of phylogenetic information. Bioinformatics,\n19(1):163?4, 2003.\n[66] H. Edelsbrunner and E.P. M?ucke. Three-dimensional alpha shapes. ACM Trans. Graphics, 13:43?72,\n1994.\n21\n"}
{"id":"oai:arXiv.org:hep-ph/0612309","text":"arXiv:quant-ph/0610192v1  23 Oct 2006\nICMPA-MPA/2006/20\nCP3-06-13\n(p,q)-Deformations and (p,q)-Vector Coherent States\nof the Jaynes-Cummings Model\nin the Rotating Wave Approximation\nJoseph Ben Geloun?, Jan Govaerts?,?,1 and M. Norbert Hounkonnou?\n?International Chair in Mathematical Physics and Applications (ICMPA-UNESCO)\n072 B.P. 50 Cotonou, Republic of Benin\nE-mail: jobengeloun@yahoo.fr, norbert?hounkonnou@cipma.net\n?Department of Theoretical Physics, School of Physics\nThe University of New South Wales, Sydney NSW 2052, Australia\nE-mail: Jan.Govaerts@fynu.ucl.ac.be\nFebruary 1, 2008\nAbstract\nClasses of (p,q)-deformations of the Jaynes-Cummings model in the rotating wave ap-\nproximation are considered. Diagonalization of the Hamiltonian is performed exactly, leading\nto useful spectral decompositions of a series of relevant operators. The latter include ladder\noperators acting between adjacent energy eigenstates within two separate infinite discrete\ntowers, except for a singleton state. These ladder operators allow for the construction of\n(p,q)-deformed vector coherent states. Using (p,q)-arithmetics, explicit and exact solutions\nto the associated moment problem are displayed, providing new classes of coherent states\nfor such models. Finally, in the limit of decoupled spin sectors, our analysis translates into\n(p,q)-deformations of the supersymmetric harmonic oscillator, such that the two supersym-\nmetric sectors get intertwined through the action of the ladder operators as well as in the\nassociated coherent states.\n1On sabbatical leave from the Center for Particle Physics and Phenomenology (CP3), Institute of Nuclear\nPhysics, Catholic University of Louvain, 2, Chemin du Cyclotron, B-1348 Louvain-la-Neuve, Belgium.\n1 Introduction\nIn recent years, quantum algebras and groups [1] which appear as a generalization of the sym-\nmetry concept [2] and the basics of so-called noncommutative theories, have been the subject of\nintensive research interest in both mathematics and physics. The q- and more generally (p,q)-\ndeformation of a pre-defined algebraic structure [3, 4, 5] proves to be a powerful tool widely used\nin the representation theory of quantum groups. The field of ?q-mathematics? has a long history\n[6, 7] dating back to over 150 years, and includes several famous names such as Cauchy, Jacobi\nand Heine to mention just a few. Its possible relation to physics has been considerably reinforced\nduring the last thirty years [3, 8]. In particular, great attention has been devoted to deformations\nof the bosonic Fock-Heisenberg algebra. The most commonly studied deformed bosons, with\nannihilation and creation operators a and a?, respectively, satisfy the q-commutation relation\n[3] (also called quommutation)\naa??qa?a = I, (1)\nor some variant forms of such a relation [4, 9]. Still more general deformations, which include in\nspecific limits the above standard q-deformed case and which also provides consistent extensions\nof the harmonic oscillator algebra, proceed from the two parameter deformation of the Fock\nalgebra introduced by Chakrabarty and Jagannathan [5], namely the so-called (p,q)-oscillator\nquantum algebras generated by three operators a, a? and N which obey [5, 10]\n[N,a] =?a, [N,a?] = a?, aa??qa?a = p?N, aa??p?1a?a = qN. (2)\nHere, p and q are free parameters, which henceforth are chosen to be both real and such that\np > 1, 0 < q < 1 and pq < 1. Clearly, one recovers the ordinary Fock algebra of the harmonic\noscillator algebra in the double limit p,q?1, with then [a,a?] = I and N = a?a. Furthermore,\nthese q- and (p,q)-deformed algebras have found a number of relevant applications and provide\nalgebraic interpretations of various q- and (p,q)-special functions [9, 10, 11].\nThe harmonic oscillator algebra is central in the construction of a number of models in\nphysics, among which the Jaynes?Cummings model (JCm) plays a significant role. Indeed ever\nsince Jaynes and Cummings? historical work [12], the JCm has been at the basis of many in-\nvestigations. This system belongs to a class of physically relevant models widely used in atomic\nphysics and quantum optics. As far as we know, a great deal of analytically solvable models of\nthis type have been studied in the rotating wave approximation (r.w.a.) within the framework\nof non-deformed commutative theories (see [12]?[17] and references therein). TheJCm has also\nbeen considered in the context of generalized intensity dependent oscillator algebras including\nnonlinear dynamical supersymmetry[18] or using shapeinvariance techniques [19, 20]. Compara-\ntively, much fewer papers have dealt with generalizations of these models including deformations.\nAmong the latter and mainly based on the generalized intensity-dependent coupling of Buck and\nSukumar [21], one may mention, on the one hand, the work by Chaichan et al. [22], and on the\nother hand, that by Chang [23], both dealing with a generalized q-deformed intensity-dependent\ninteraction Hamiltonian of theJCm given by the Holstein-Primakoff suq(1,1) or suq(2) quantum\nalgebra realizations of the Hamiltonian field operators and the related Peremolov, Glauber or\nBarut-Girardello group theoretical construction of coherent states. In the same vein, the paper\nby Naderi et al. considers the dynamical properties of a two-level atom in three variants of the\ntwo-photon q-deformedJCm [24]. In this latter work, the authors focused their attention onto\nthe time evolution of atomic properties including population inversion and quantum fluctuations\nof the atomic dipole variables. However, it is not clear to us how the main issues related to the\nmoment problem as well as the mathematical foundation of the coherent and squeezed states\nwhich they use and on which a great part of their analysis rests in a crucial way, are solved.\n1\nIn a recent publication [14], Hussin and Nieto have performed an interesting systematic\nsearch of different types of ladder operators for theJCm model in the r.w.a. and constructed\nassociated coherent states. In the present work, and in line with that investigation, we provide\na generalization of that analysis to (p,q)-deformations of the same model.\nThe outline of the paper is the following. In Section 2, we briefly recall the main results\nrelevant to theJCm in the r.w.a. in the non-deformed situation [14]. Section 3 then introduces\n(p,q)-deformations of the same model. By providing an explicit diagonalization of the (p,q)-\ndeformed Hamiltonian, the spectrum and its eigenstates are exactly identified. As in the non-\ndeformed case [14], except for a singleton state, all other energy eigenstates are organized into\ntwo separate discrete towers, for which ladder operators transforming states into one another\nwithin each tower separately may be introduced. Using properties of these ladder operators, in\nSection 4 we introduce general classes of (p,q)-deformed vector coherent states. The freedom\nafforded in their construction is fixed from two alternative points of view, discussed in Section 5,\nwhich in the ordinary case of the non-deformed Fock algebra coincide. However at all stages of\nour discussion, the double limit p,q?1 reproduces the corresponding results of [14]. Section 5\nalso briefly considers the situation in the uncoupled limit of theJCm, while Section 6 presents\nsome concluding remarks. An Appendix collects useful facts in connection with properties of\n(p,q)-deformed algebras and related functions.\n2 The Ordinary JCm in the Rotating Wave Approximation\nThe JCm describes the interaction between one mode of the quantized electromagnetic field\nand a two-level model of an atomic system [12, 14]?[16]. It has proved to be a theoretical\nlaboratory of great relevance to many topics in atomic physics and quantum optics, as well\nas in the study of ion traps, cavity QED theory and quantum information processing [13, 14].\nFurthermore, the spin-orbit interaction term which appears in the JCm is essentially the so-\ncalled Dresselhaus spin-orbit term [25]. The model is thus also widely used in condensed matter\nphysics for its relevance in spintronics [26] which exploits the electron spin rather than its charge\nto develop a new generation of electronic devices [27, 28]. The solution of the completeJCm is\nnot yet known in a closed form [14]. However, in the r.w.a., although the Hamiltonian remains\nnonlinear, the model becomes exactly solvable in closed form with explicit expressions for its\neigenenergy states. In this Section, we briefly recall, in a streamlined presentation, the main\nresults in the non-deformed case (see [14, 15] and references therein) of relevance to our analysis\nof (p,q)-deformations hereafter.\nIn the r.w.a., the reduced dimensionlessJCm Hamiltonian reads [15]\nHred = 1planckover2pi1?\n0\nH= (1+?)\nparenleftbigg\na?a+ 12\nparenrightbigg\n+ 12?3 +?\nparenleftBig\na??? +a?+\nparenrightBig\n, (3)\nwhere a and a? are the usual photon annihilation and creation operators, respectively, obeying\nthe ordinary Fock algebra, and (?1,?2,?3) are the Pauli matrices with ?? = ?1?i?2. The r.w.a.\nis related to the detuning parameter ? which is such that|?|?1, with ?0 being the fixed atomic\nfrequency and ? = ?0(1 + ?) the actual field mode frequency. The r.w.a. is reliable provided\n|???0|??,?0. Finally, ? is the reduced spin-orbit coupling modelling the interaction strength\nbetween the radiation field and the atom.\n2\nThe Hilbert spaceV of the system is the tensor product of the Fock space representation\nof the Fock algebra (a,a?) and the 2-dimensional representation of the SU(2) algebra associated\nto the Pauli matrices. A basis of the former is provided by the number operator, N = a?a,\northonormalized eigenstates |n? = (1/?n!)(a?)n|0? (n = 0,1,2,???), with a|n? = ?n|n?1?,\na?|n?=?n+ 1|n + 1?and N|n?= n|n?, while a basis of the latter spin sector is the orthonor-\nmalized set {|+?,|??} such that ?3|??=?|??. The tensor product space is thus spanned by\nthe states|n,??=|n??|??.\nThe diagonalization of the Hamiltonian (3) is readily achieved. The orthonormalized\nenergy eigenspectrum consists of a ?singleton? state|E??,\nHred|E??= E?|E??, (4)\nwith\nE? = 12?, |E??=|0,??, (5)\nand two infinite discrete towers of states |E?n? such that Hred|E?n? = E?n|E?n? for all n =\n0,1,2,???, expressed as [14]\n|E+n? = sin?(n)|n,+?+ cos?(n)|n+ 1,??, (6)\n|E?n? = cos?(n)|n,+??sin?(n)|n+ 1,??, (7)\nwhere, given Q(n+ 1) =radicalbig?2/4 +?2(n+ 1), the mixing angle ?(n) is such that\nsin?(n) = sign(?)\nradicalBigg\nQ(n+ 1)??/2\n2Q(n + 1) , cos?(n) =\nradicalBigg\nQ(n+ 1) +?/2\n2Q(n+ 1) , (8)\nwhile the energy eigenvalues are\nE?n = (1 +?)(n+ 1)?Q(n+ 1). (9)\nConsequently, one has the spectral decomposition of the reduced Hamiltonian (3),\nHred =|E??E??E?| +\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|. (10)\nIt proves useful to introduce the following notations. Let V0 be the (complex) one-\ndimensional subspace of the Hilbert space V spanned by the state |0,?? = |E??, and V be\nits complement in the Hilbert spaceV, spanned by{|E?n?,n?N}. We thus haveV=V0?V.\nFurthermore let us introduce [14] operatorsU andU? defined through their action on the\nabove two sets of basis vectors, for all n?N,\nU|n,??=|E?n?; U?|E??= 0, U?|E?n?=|n,??, (11)\nnamely\nU =\n?summationdisplay\nn=0,?\n|E?n??n,?|, U? =\n?summationdisplay\nn=0,?\n|n,???E?n|. (12)\nClearly we have\nUV =V; U?V =V, U?V=V. (13)\n3\nNote that even though neither U nor U? is unitary on the full Hilbert space V, they are the\nadjoint of one another, hence the notation.\nIt is of interest to apply these operators onto the quantum Hamiltonian (3). One obtains\nHred =U?HredU =\n?summationdisplay\nn=0,?\n|n,??E?n ?n,?|, (14)\nand conversely,\nUHredU? =\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|=Hred ?|E??E??E?|. (15)\nThe energy eigenstates spanning V may be organized into two subspaces referred to as\n?towers?, namely {|E+n?,n?N} and {|E?n?,n?N}. The states in the tower {|E+n?,n?N}\nare associated to strictly increasing eigenvalues so that they constitute a nondegenerate set\nof eigenstates. The second group does not necessarily possess the same feature depending\non the values for the parameters ? and ?. It is possible [16] to identify a range of values\nfor these parameters such that {|E?n?,n?N} only contains nondegenerate states of strictly\nincreasing eigenvalues with n. Some of the considerations discussed hereafter may require a\nnondegenerate spectrum, which may always be achieved by properly ?detuning? the parameters\n? and ? away from a degenerate case, but not necessarily a strictly increasing spectrum in the\nlabel n?N. Whatever the case may be though, bounded from below spectra such that E?n > E?0\nfor n = 1,2,???are always assumed implicitly.\nIt is possible to consider ladder operators acting between successive energy eigenstates\nwithin each of the above two towers, irrespective of whether the spectral values are strictly\nincreasing or not1. Namely, let us first consider operators M? and M+ given as\nM? =\n?summationdisplay\nn=0,?\n|n?1,??K?(n)?n,?|; M+ =\n?summationdisplay\nn=0,?\n|n+ 1,??K??(n+ 1)?n,?|, (16)\nwhere K?(n) are, at this stage, arbitrary complex coefficients such that K?(0) = 0. Then,\nintroduce the ladder operators\nM? =UM?U? =\n?summationdisplay\nn=0,?\n|E?n?1?K?(n)?E?n|; M+ =UM+U? =\n?summationdisplay\nn=0,?\n|E?n+1?K??(n+ 1)?E?n|,\n(17)\nwhich are thus such that, for all n = 0,1,2,???,\nM?|E??= 0, M?|E?n?= K?(n)|E?n?1?; M+|E??= 0, M+|E?n?= K??(n+ 1)|E?n+1?.\n(18)\nNote thatM? andM+ are adjoint of one another but in effect only act on the subspaceV.\nGeneral vector coherent states (VCS) may then be introduced [29]?[32] on the space V\nas eigenstates of the lowering operator M? with as eigenvalue an arbitrary complex number\nz?C. Furthermore, these VCS are also parametrized by two real quantities ?? which account\nfor their stability under time evolution generated by the operator expbraceleftbig?i?0tHredbracerightbig, as well as\nthe two spherical coordinates (?,?)?[0,?]?[0,2?[ parametrizing a unit vector in the 2-sphere\n1We differ on this point with [14], where strictly increasing energy spectra in each tower are required.\n4\nS2 (hence the name of ?vector? coherent states). Explicitly, one has [14]\n|z;??;?,?? = N+(|z|)cos?\n?summationdisplay\nn=0\nzn\nK+(n)!e\n?i?0?+E+n |E+\nn?\n+ N?(|z|)ei? sin?\n?summationdisplay\nn=0\nzn\nK?(n)!e\n?i?0??E?n |E?\nn?, (19)\nwhere K?(n)! =producttextnk=1 K?(k) (with, by convention, K?(0)! = 1), while the normalization factors\nare defined as\nN?(|z|) =\nbracketleftBigg ?summationdisplay\nn=0\n|z|2n\n|K?(n)!|2\nbracketrightBigg?1/2\n(20)\nin order that the VCS be of unit norm. The smallest value, R, of the two convergence radii of\nthese two series in |z| also defines the disk DR in z ?C for which these VCS are well defined.\nThese states are clearly such that\nM?|z;??;?,??= z|z;??;?,??, e?i?0tHred|z;??;?,??=|z;t +??;?,??. (21)\nFurther restrictions are necessary to finally specify in a unique fashion the factors K?(n),\nand then solve the moment problem implied by the requirement of overcompleteness overV for\nthe VCS (19) given a choice of a SU(2) matrix-valued integration measure over C?S2 [30]-[32].\nDifferent choices are available [14], each leading to a different set of VCS. Furthermore, taking\nthe limit case ??0 or the zero-detuning limit (resonance case) ??0, different models arise\nwith their associated VCS.\nFor the sake of illustration, let us consider one such choice explicitly [14]. The factors\nK?(n) may be restricted for example by requiring that the ladder operatorsM? andM+ obey\nthe usual Fock algebra of annihilation and creation operators on the spaceV,\nbracketleftbigM?,M+bracketrightbig=M?M+ ?M+M? = I\nV =\n?summationdisplay\nn=0,?\n|E?n??E?n|. (22)\nFrom the expressions in (18) and the initial conditions K?(0) = 0, it follows that the quantities\nK?(n) are now determined up to arbitrary phase factors ??(n) as\nK?(n) = ei??(n)?n, n = 0,1,2,???. (23)\nConsequently, one has N?(|z|) = e?|z|2/2, which is well-defined for all z?C. Hence so are then\nall the VCS|z;??;?,??.\n3 The (p,q)-Deformed JCm in the Rotating Wave Approxima-\ntion\nLet us now introduce a (p,q)-deformation of the JCm Hamiltonian (3), namely (p,q)-JCm\nmodels. The eigenstates and spectrum are first identified, before considering the construction\nof ladder operators following the same rationale as in Section 2. A study of the associated VCS\nand examples of exactly solvable reduced models is differed to Section 4.\n5\n3.1 Energy spectrum and eigenstates\nGiven the (p,q)-deformation (2) of the ordinary Fock algebra (see the Appendix for further\ndetails and identities pertaining to such deformations), we now consider (p,q)-deformations of\nthe Hamiltonian (3) of the form2\nHred = (1 +?)\nbraceleftbigg\nh(p,q)[N] + 12\nbracerightbigg\n+ 12?3 +?\nparenleftBig\na??? +a?+\nparenrightBig\n, (24)\nwhere [N] = (p?N ?qN)/(p?1?q), and h(p,q) is some arbitrary positive function of the real\nparameters p > 1 and 0 < q < 1 (with pq < 1) such that limp,q?1 h(p,q) = 1 in order to recover\n(3) in the non-deformed case.\nThe Hilbert space V of quantum states of the model is again the tensor product of the\n(p,q)-deformed Fock space spanned by the states3 |n?(n?N) such as a|n?= radicalbig[n]|n?1?and\na?|n?=radicalbig[n+ 1]|n+1?(see the Appendix), with the 2-dimensional representation of the SU(2)\nalgebra associated to the Pauli matrices ?i (i = 1,2,3). Hence the diagonalization of (24) is\nreadily achieved in the same way as in the non-deformed case, on the basis|n,??=|n??|??of\nV.\nFor any n?N, let us introduce the following quantities,\nE([n+1]) = (1+?)h(p,q)\nparenleftBig\n[n+1]?[n]\nparenrightBig\n?1, Q([n+1]) =\nradicalbigg\n1\n4E\n2([n +1]) + ?2 [n+1], (25)\nas well as the mixing angles ?([n]) defined by\nsin?([n]) = sign(?)\nradicalBigg\nQ([n+ 1])?E([n + 1])/2\n2Q([n + 1]) , cos?([n]) =\nradicalBigg\nQ([n + 1]) +E([n+ 1])/2\n2Q([n +1]) .\n(26)\nThe energy eigenspectrum of (24) is then obtained as follows. First, there exists a singleton\nstate|E??=|0,??such that\nHred|E??= E?|E??, E? = 12?, (27)\nwith an eigenvalue which is thus independent of the deformation parameters p and q. Next, one\nalso finds two infinite discrete towers of states for all n?N such that\n|E+n? = sin?([n])|n,+? + cos?([n])|n + 1,??, (28)\n|E?n? = cos?([n])|n,+?? sin?([n])|n + 1,??, (29)\nwith\nHred|E?n?= E?n |E?n?, E?n = 12 (1 +?)\nbraceleftBig\nh(p,q)\nparenleftBig\n[n+ 1] + [n]\nparenrightBig\n+1\nbracerightBig\n? Q([n+ 1]). (30)\nNote that the energy spectrum of these states is deformed by the parameters p and q as compared\nto the ordinary case. In particular, the Zeeman spin splitting ?En = E+n ?E?n = 2Q([n + 1]),\n2Make no mistake that henceforth, all quantities correspond to the (p,q)-deformed analysis even though the\nnotations used coincide with those of Section 2 and do not make explicit the fact that all expressions correspond\nnow to the deformed case. When wanting to make the difference explicit, notations such as for instance [N] ?\n[N](p,q) = (p?N ?qN)/(p?1 ?q) and [n] ? [n](p,q) = (p?n ?qn)/(p?1 ?q) are used.\n3Once again, the states |n? = |n?(p,q) are not to be confused with the number operator eigenstates of the\nordinary Fock algebra as in Section 2, in spite of an identical notation.\n6\nproportional to the Rabi frequency, is function of the values for p and q. In terms of these\nresults, the reduced Hamiltonian (24) possesses the spectral resolution\nHred =|E??E??E?| +\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|. (31)\nLet us again introduce the following notations and operators. LetV0 denote the subspace\nof the Hilbert space V spanned by the singleton state |E??= |0,??, and V its complement in\nV, namely the subspace spanned by{|E?n?,n?N}, with of courseV=V0?V. Acting on these\nspaces, let us consider the operators\nU =\n?summationdisplay\nn=0,?\n|E?n??n,?|; U? =\n?summationdisplay\nn=0,?\n|n,???E?n|, (32)\nsuch that, for all n = 0,1,2,???,\nU|n,??=|E?n?; U?|E??= 0, U?|E?n?=|n,??, (33)\nand thus\nUV=V; U?V=V, U?V =V. (34)\nHence once again the operators U and U?, even though non unitary on V, are adjoint of one\nanother. More specifically, one has\nU?U =\n?summationdisplay\nn=0,?\n|n,???n,?|= IV, UU? =\n?summationdisplay\nn=0,?\n|E?n??E?n|= IV. (35)\nApplying these operators to the reduced Hamiltonian, one finds\nHred =U?HredU =\n?summationdisplay\nn=0,?\n|n,??E?n ?n,?|, (36)\nand conversely,\nUHredU? =\n?summationdisplay\nn=0,?\n|E?n?E?n ?E?n|=Hred ?|E??E??E?|. (37)\nSome remarks on the spectrum are in order. First, as in the ordinary JCm, except\nfor the singleton state |E?? = |0,??, the spectrum is the direct sum of two towers of states\n{|E?n?,n?N}. However, in contradistinction to the non-deformed case or even the q-deformation\nwith p = 1, the (p,q)-basic numbers [n] = [n](p,q) are not strictly increasing as a function of\nn?N when p > 1, 0 < q < 1 and pq < 1. There always exists a finite positive value n0 ?N\nsuch that [n] decreases once n > n0. Hence, depending on the values for the parameters ? and ?\nas well as the positive function h(p,q), parts of the spectrum E?n may turn negative or present\nsome degeneracies (as in [16]). Without exploring this issue any further in the present work,\nhenceforth we shall assume that parameter values are such that no degeneracies occur and that\nthe spectrum E?n remains bounded from below (E+n is obviously positive). The definition of the\nladder operators to be considered next does not require a strictly increasing spectrum, while it\nis only for one of possible choices leading to vector coherent states to be discussed hereafter that\nthe condition of non degeneracy in E?n > E?0 , for n?1, becomes relevant. Since it has been\n7\nshown [16] that such conditions may be met in the non-deformed case for appropriate ranges\nof values for the available parameters, through an argument of continuity in the deformation\nparameters p and q, similar ranges ought to exist also for the (p,q)-deformed realizations of the\nJCm model.\nAnother feature of potential interest related to these facts, and which will also not be\npursued here, is the possibility that through the (p,q)-deformation of theJCm, the levels E+n\nand E?n+1 cross one another. Such a property may lead to effects similar to the phenomenon\nof resonant spin-Hall conductance at the Fermi level recently observed in spintronics [27, 28].\nNote that this (p,q)-dependent crossing phenomenon is expected since the Zeeman splitting\n?En is also modified as a function of p and q. This remark is also in line with the recent\nsuggestion [33, 34, 35] that (p,q)-deformed or space noncommutative realizations of exactly\nsolvable systems may provide useful model approximations to more realistic complex interacting\ndynamics of collective phenomena.\n3.2 Ladder operators\nIn order to construct ladder operators mapping each of the successive states |E?n? into one\nanother separately within each of the towers, let us first introduce the following operators acting\nonV,\nA? =\n?summationdisplay\nn=0,?\n|n?1,??K?([n])?n,?|; A+ =\n?summationdisplay\nn=0,?\n|n+ 1,??K??([n +1])?n,?|, (38)\nwhere K?([n]) are arbitrary complex quantities such that K?([0]) = K?(0) = 0. Note that A?\nand A+ are adjoint of one another onV.\nThen the relevant ladder operators are obtained as\nA? =UA?U? =\n?summationdisplay\nn=0,?\n|E?n?1?K?([n])?E?n|; A+ =UA+U? =\n?summationdisplay\nn=0,?\n|E?n+1?K??([n+ 1])?E?n|.\n(39)\nConsequently, we have indeed, for all n?N,\nA?|E??= 0, A?|E?n?= K?([n])|E?n?1?; A+|E??= 0, A+|E?n?= K??([n+ 1])|E?n+1?.\n(40)\nNote thatA? andA+ are adjoint of one another, but that in effect they act only on the subspace\nV.\nIt is of course possible to express these ladder operators in the|n,??basis. In the case of\nthe lowering operator, one finds\nA? = summationtext?n=0 |n,+?A?++(n)?n+ 1,+| + summationtext?n=0 |n,+?A?+?(n)?n+ 2,?|\n+ summationtext?n=0 |n,??A??+(n)?n,+| + summationtext?n=0 |n,??A???(n)?n+ 1,?|\n(41)\nwhere\nA?++(n) = sin?([n]) sin?([n+ 1])K+([n + 1]) + cos?([n]) cos?([n+ 1])K?([n + 1]),\nA?+?(n) = sin?([n]) cos?([n+ 1])K+([n + 1]) ? cos?([n]) sin?([n+ 1])K?([n + 1]),\n8\nA??+(n) = cos?([n?1]) sin?([n])K+([n]) ? sin?([n?1]) cos?([n])K?([n]),\nA???(n) = cos?([n?1]) cos?([n])K+([n]) + sin?([n?1]) sin?([n])K?([n]). (42)\nLikewise for the raising operator,\nA+ = summationtext?n=0 |n+ 1,+?parenleftbigA?++(n)parenrightbig? ?n,+| + summationtext?n=0 |n,+?parenleftbigA??+(n)parenrightbig? ?n,?|\n+ summationtext?n=0 |n+ 2,??parenleftbigA?+?(n)parenrightbig? ?n,+| + summationtext?n=0 |n+ 1,??parenleftbigA???(n)parenrightbig? ?n,?|.\n(43)\nNote that we haveA??+(0) = 0 =A???(0), since K?([0]) = 0.\nThe quantities K?([n]) parametrize the freedom available in the choice of such ladder\noperators. Further restrictions arise when considering first the possible existence of vector\ncoherent states meeting a series of general conditions charateristic of such states [30]-[32], starting\nwith one involving the lowering operatorA? itself.\n4 (p,q)-Vector Coherent States for the (p,q)-JCm\nBy considering the action of the lowering operatorA?, we are able to construct an overcomplete\nset of vectors in V, so-called vector coherent states [30]-[32] for the (p,q)-JCm. Since these\nstates are associated to unit vectors in the 2-sphere S2 [29], they are referred to as (p,q)-vector\ncoherent states ((p,q)-VCS). As in Section 2, these (p,q)-VCS are parametrized by a complex\nvariable z ?C, two real parameters ?? to track a stable time evolution of the (p,q)-VCS, and\nfinally the spherical angle coordinates (?,?) on S2,|z;??;?,??. In the double limit that p,q?1,\nthese (p,q)-VCS reduce to those of [14] discussed in Section 2. The dependence of the (p,q)-VCS\non all these quantities is introduced as follows, according to the discussion in [30].\n4.1 Identifying (p,q)-VCS\nAs a slight extension of the analysis so far, given two real parameters ? and ?, let us consider\nthe operator\nQV =|E???E?| +\n?summationdisplay\nn=0,?\n|E?n?\nparenleftbiggq?\np?\nparenrightbiggn\n?E?n|. (44)\nHence, the energy eigenstates of the (p,q)-JCm are also eigenstates of this operator QV, with\neigenvalues given through the above spectral decomposition.\nWe are now in a position to successively identify the dependence of the (p,q)-VCS to be\nconstructed on each of the parameters of which they are functions, first z, then ??, and finally,\n? and ?. Having defined both the operatorsA? and QV, let us consider the following eigenvalue\nproblem in z for the (p,q)-VCS,\nA?|z;??;?,??= zQV|z;??;?,?? (45)\nwhich generalizes to a two-level system the definition of coherent states as advocated in [30]-\n[32]. The particular case ? = 0 = ? yields also a consistent definition of (p,q)-VCS viewed as\nthe limit ?,? ?0 of the present definition (note that their domain of definition in z, required\n9\nfor the convergence of the infinite series to be considered hereafter, may have to be adapted\naccordingly).\nBy expanding the (p,q)-VCS in the Hamiltonian eigenstate basis as\n|z;??;?,??= C?(z)|E??+\n?summationdisplay\nn=0,?\nC?n (z)|E?n?, (46)\nwhere C?(z) and C?n (z) are complex continuous functions of z to be specified presently, the\ncondition (45) then requires, for all n?N,\nC?(z) = 0, C?n+1(z)K?([n+ 1]) = z q\n?n\np?n C\n?\nn (z), (47)\nof which the solution is\nC?n (z) =\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK?([n])! C\n?\n0 (z), (48)\nwhere C?0 (z) are arbitrary complex functions of z, while we defined K?([n])! = producttextnk=1 K?([k])\nwith, by convention, K?([0])! = 1. Hence, the general solution to (45) defines states lying only\nwithin the subspaceV, of the form\n|z;??;?,??=\n?summationdisplay\nn=0,?\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK?([n])! C\n?\n0 (z)|E\n?\nn?. (49)\nNote that the eigenvalue problem (45) is singular at the particular value z = 0, since its solution\nis an arbitrary superposition of the three states|E??and|E?0 ?. Nevertheless, we shall consider\nthe (p,q)-VCS associated to z = 0, |z = 0;??;?,??, as being defined through the continuous\nlimit in z?0 of the construction in (49), namely|z = 0;??;?,??= C+0 (0)|E+0 ?+C?0 (0)|E?0 ?.\nLet us now turn to the issue of the stability of the (p,q)-VCS under time evolution gener-\nated by the Hamiltonian (24). Namely, we now require furthermore that (p,q)-VCS are trans-\nformed into one another under time evolution according to the following dependence on the real\nparameters ??, for all t?R,\ne?i?0tHred|z;??;?,??=|z;t +??;?,??. (50)\nSince one has, for all n?N,\ne?i?0tHred|E?n?= e?i?0tE?n |E?n?, (51)\none needs to factor out their complex phases from the quantities K?([n]),\nK?([n]) = ei??([n])K0?([n]), (52)\nwhere K0?([n]) > 0 are now real positive scalars. The stability condition (50) is then solved by\nchoosing, for all n = 1,2,???,\n??([n]) = ?0??bracketleftbigE?n ?E?n?1bracketrightbig, (53)\nand redefining\nC?0 (z) =C?0 (z)e?i?0??E?0 , (54)\n10\nwhereC?0 (z) are new complex functions of z. Hence,\n|z;??;?,??=\n?summationdisplay\nn=0,?\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK0?([n])!C\n?\n0 (z)e\n?i?0??E?n |E?\nn?. (55)\nHaving identified both the z and ?? dependences of the coherent states, finally let us\naccount for their (?,?) dependence and S2 vector character implicit so far through the two\nfunctionsC?0 (z). The latter are now chosen to be given as\nC+0 (z) = N+(|z|) cos?, C?0 (z) = N?(|z|)ei? sin?, (56)\nN?(|z|) being factors such that the constructed (p,q)-VCS be of unit norm,\nN?(|z|) =\nbraceleftBigg ?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2\nbracerightBigg?1/2\n. (57)\nThe convergence radii R? of these two series in z,\nR? = limn??\nbraceleftBig\n(q?p??)?(n?1) K0?([n])\nbracerightBig\n, (58)\ndepend on the choice of functions K0?([n]) as well as on (?,?) possibly. Specific cases are\nconsidered hereafter.\nConsequently, the (p,q)-VCS constructed here are properlydefined provided z?DR where\nDR denotes the disk in the complex plane centered at z = 0 and of radius R = min(R+,R?).\nTheir general structure is thus of the form\n|z;??;?,?? = N+(|z|) cos?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK0+([n])! e\n?i?0?+ E+n |E+\nn?\n+ N?(|z|)ei? sin?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1)/2 zn\nK0?([n])! e\n?i?0??E?n |E?\nn?. (59)\nOnly the real positive functions K0?([n]) still need to be specified. They parametrize the remain-\ning freedom in the construction. Particular examples will be considered hereafter by imposing\nfurther requirements on these (p,q)-VCS. Note that the double limit p,q?1 yields the VCS of\nthe non-deformedJCm as obtained by Hussin and Nieto [14], briefly described in Section 2.\n4.2 Some expectation values\nBefore dealing with further requirements on the family of (p,q)-VCS, among which their over-\ncompleteness in the space V, let us consider some relevant expectation values for these states.\nGiven (59), the mean value ofHred for any of the (p,q)-VCS is simply\n?Hred? = |N+(|z|)|2 cos2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n+([n])!\nparenrightbig2 E+n\n+|N?(|z|)|2 sin2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2 E?n . (60)\n11\nLikewise for the ?number? operator associated to the ladder operators A? and A+, one finds\nthe expectation value\n?A+A?? = |z|2\nbraceleftBigg\n|N+(|z|)|2 cos2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n+1) |z|2n\nparenleftbigK0\n+([n])!\nparenrightbig2\n+|N?(|z|)|2 sin2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n+1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2\nbracerightBigg\n. (61)\nFinally, the average atomic spin time evolution ??3(t)? = ?U?1(t)?3U(t)?, with U(t) =\nexp{?i?0tHred}being the time evolution operator, has the form\n??3(t)?= 12\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1)\n|z|2nE([n+ 1])Q([n+ 1])\nbraceleftBigg\n?|N\n+(|z|)|2\nparenleftbigK0\n+([n])!\nparenrightbig2 cos2 ? + |N\n?(|z|)|2\nparenleftbigK0\n?([n])!\nparenrightbig2 sin2 ?\nbracerightBigg\n+?N+(|z|)N?(|z|)sin2?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nK0+([n])!K0?([n])!\n[n+ 1]\nQ([n+ 1]) cos?n(t), (62)\nwith\n?n(t) = ?0bracketleftbig(t+?+)E+n ? (t +??)E?nbracketrightbig + ? = ?0?En t + ?0bracketleftbig?+E+n ???E?nbracketrightbig+?. (63)\nAs is the case in the non-deformed model, the explicit time dependence which arises for the\natomic inversion ??3(t)? is due to the mixed state sector, namely the fact that the mixed-spin\nmatrix elements of the Heisenberg picture operator ?3(t) do not vanish when ? negationslash= 0. Hence,\nthe proposition which states that the time dependence of atomic inversion consists of Rabi\noscillations when a system is prepared in a coherent state of the radiation field [17] extends to\n(p,q)-VCS. However, in the limit where ??0, no such oscillations occur. Let us also point out\nthat the time dependence of??3(t)?diplays chaotic behaviour for appropriate values of the model\nparameters, as was previously mentioned for the q-deformation of the model, with 0 < q < 1, in\nthe work by Naderi et al. [24].\n4.3 Overcompleteness and the moment problem\nAn important property that coherent states ought to meet is that of overcompleteness in the\nspace over which they are defined [30]. In the present case, this means that the (p,q)-VCS in\n(59) must also provide a resolution of the identity operator over the subspaceV, namely\nIV = IV0 + IV =|E???E?| + IV, (64)\nwhile\nIV =\n?summationdisplay\nn=0,?\n|E?n??E?n|=\nintegraldisplay\nDR?S2\nd?(z;?,?)|z;??;?,???z;??;?,?|, (65)\nwhere d?(z;?,?) is some SU(2) matrix-valued integration measure over DR?S2 to be determined\nfrom the above requirement.\nLet us thus consider the following parametrization of that measure,\nd?(z;?,?) = d2zd? sin?d?\nbraceleftBigg\nW+(|z|)\n?summationdisplay\nn=0\n|E+n??E+n| + W?(|z|)\n?summationdisplay\nn=0\n|E?n??E?n|\nbracerightBigg\n, (66)\n12\nin terms of real weight functions W?(|z|) to be identified. Using the radial parametrization\nz = rei? and d2z = drrd? where r ? [0,?[ and ? ? [0,2?[, a direct substitution in (65)\nleads to the moment problem associated to the overcompleteness relation (65). In terms of the\nfunctions h?(r2) defined through\nh+(r2) = 4?\n2\n3 |N\n+(r)|2W+(r), h?(r2) = 8?2\n3 |N\n?(r)|2W?(r), (67)\nthe following two infinite sets of moment identities must be met, for all n?N,\nintegraldisplay R2\n0\nduun h?(u) =\nparenleftbiggq?\np?\nparenrightbigg?n(n?1) parenleftbig\nK0?([n])!parenrightbig2 . (68)\nIn conclusion, the resolution of the identity operator over V in terms of the (p,q)-VCS\nis achieved provided the Stieljes moment problem (68) can be solved [36, 37]. This requires a\nchoice of functions K0?([n]) > 0 such that not only the conditions (68) may all be met, but also\nsuch that the normalization factors N?(|z|) converge in a non-empty disc of the complex plane.\nAs a result of this analysis, a priori there may exist a large number of sets of (p,q)-VCS\nwhich fulfill all the above properties, namely continuity in the complex parameter z, temporal\nstability through a simple additive time dependence in the real parameters ??, a unit vector\nvalued characterization on the sphere S2 in terms of the spherical coordinates ? and ?, and the\ncompleteness propertyof a resolution of the unit operator with a SU(2) matrix-valued integration\nmeasure over these spaces. These sets of (p,q)-VCS are distinguished from one another by\ndifferent choices of real positive weight factors K0?([n]), in agreement with the considerations\ndeveloped in [30, 38]. The above construction of (p,q)-VCS is general, but can admit explicit\nexact solutions to the moment problem(68) for particular cases. Concrete examples are discussed\nin Section 5..\n4.4 Action-angle variables\nOne of the useful properties that general coherent states constructed according to the arguments\nof [38] possess, is that action-angle variables are readily identified in relation to the continuous\nparameters ensuring stability of the coherent states under time evolution. In the present case,\ncanonical reduced action-angle variables (J?(t),??(t)) are such that for the previously evaluated\nexpectation values of the reduced Hamiltonian (24) in the (p,q)-VCS, one has\n?Hred?= J+ ?+ + J? ?? =\nsummationdisplay\n?\nJ? ??, (69)\nin relation to the action-angle variational principle of the form\nintegraldisplay\ndt\nsummationdisplay\n?\nbracketleftbiggd?\n?\ndt J? ? ??J?\nbracketrightbigg\n??\nintegraldisplay\ndt\nbracketleftbigg\n? i?\n0\nd\ndt???H\nred?\nbracketrightbigg\n, (70)\nwhere ?? are two constant factors to be chosen appropriately. Consequently\nd??\ndt =\n??Hred?\n?J? = ??,\ndJ?\ndt =?\n??Hred?\n??? = 0. (71)\n13\nGiven the time evolution, ??(t) = t + ??(0), one simply finds ?? = 1. From the expression in\n(60), one then has the identifications\nJ+ = |N+(|z|)|2 cos2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n+([n])!\nparenrightbig2 E+n ,\nJ? = |N?(|z|)|2 sin2 ?\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\nparenleftbigK0\n?([n])!\nparenrightbig2 E?n . (72)\nAs a final remark, let us mention that the saturated Heisenberg uncertainty relations\nwhich are obeyed by q- and (p,q)-coherent states are also well-known in q-mechanics (see for\ninstance [39]). Such minimal uncertainties may be characterized through small corrections to\ncanonical commutation relations defined in [39, 40]. Such properties in the case of the (p,q)-VCS\nconstructed here are deferred to a later study.\n5 Explicit Solutions\nIn order to completely specify the quantities K0?([n]), one last set of conditions needs to be\nimplemented. In the present Section, two such choices are discussed, one of which allows for an\nexact and explicit solution to the moment problem, hence the construction of a set of (p,q)-VCS.\nFirst, in line with the illustrative example of Section 2, we consider restricting the algebra of the\nladder operatorsA?. Then as a second and independent possibility, we apply a final additional\ncriterion developed in [30] in order to uniquely characterize a set of coherent states which meet\nalready all the requirements considered heretofore and having led to the representation (59),\neven though the moment problem remains unsolved for that choice.\n5.1 Constraining the ladder operator algebra\nIn order to uniquely identify the set of functions K0?([n]) > 0, let us consider the possibility\nthat this may be achieved by restricting the algebraic properties of the ladder operators. In line\nwith the general (p,q)-deformations of the Fock algebra in (2), let us constrain the algebra of\nthe operators A? acting onV to be such that\nA?A+ ? q0A+A? = p?N0 =\n?summationdisplay\nn=0,?\n|n,??p?n0 ?n,?|,\nA?A+ ? p?10 A+A? = qN0 =\n?summationdisplay\nn=0,?\n|n,??qn0 ?n,?|, (73)\nwhere p0 and q0 are again two real parameters such that p0 > 1, 0 < q0 < 1 and p0q0 < 1, which\nmay or may not be identical to p and q. For instance, we could have p0 = 1 and q0 = 1 thus\ncorresponding to an ordinary Fock algebra, or else p0 = p and q0 = q, but also more generally\np0 = p? and q0 = q?, ? being some real constant. As a matter of fact, exact solutions to the\nmoment problem are presented hereafter in all these situations.\nIn terms of the ladder operatorsA? =UA?U? acting on the subspaceV, the associated\nalgebraic constraint reads\nA?A+ ? q0A+A? =\n?summationdisplay\nn=0,?\n|E?n?p?n0 ?E?n|,\n14\nA?A+ ? p?10 A+A? =\n?summationdisplay\nn=0,?\n|E?n?qn0 ?E?n|. (74)\nWhether in terms of (73) or (74), these algebraic constraints translate into the following identi-\nties, for all n?N,\nparenleftbigK0\n?([n+ 1])\nparenrightbig2 ? q\n0\nparenleftbigK0\n?([n])\nparenrightbig2 = p?n\n0 ,\nparenleftbigK0\n?([n+ 1])\nparenrightbig2 ? p?1\n0\nparenleftbigK0\n?([n])\nparenrightbig2 = qn\n0. (75)\nGiven the initial values K0?([0]) = 0, the solution to these recursion relations is simply\nK0?([n]) =\nradicalBig\n[n](p0,q0) =\nradicalBig\n[n](q?1\n0 ,p\n?1\n0 )\n, (76)\nwhere4\n[n](p0,q0) = p\n?n\n0 ?qn0\np?10 ?q0 =\nparenleftbigq?1\n0\nparenrightbig?n?parenleftbigp?1\n0\nparenrightbign\nparenleftbigq?1\n0\nparenrightbig?1?parenleftbigp?1\n0\nparenrightbig = [n](q?10 ,p?10 ). (77)\nGiven this solution, the normalization factors are defined by the series\n|N?(|z|)|?2 =\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn(n?1) |z|2n\n[n](p0,q0)!, (78)\nof which the convergence radius is\nR = limn??\nbracketleftBiggparenleftbigg\nq?\np?\nparenrightbigg?2(n?1) p?n\n0 ?qn0\np?10 ?q0\nbracketrightBigg1/2\n= limn??\nbracketleftbiggparenleftbig\np0p?2?q2?parenrightbig?(n?1) 1?(p0q0)\nn\n1?(p0q0)\nbracketrightbigg1/2\n. (79)\nProvided p0p?2?q2? < 1, a condition which we shall henceforth assume to be satisfied5, this\nradius of convergence is infinite, R =?, and the moment problem (68) then becomes, for all\nn?N, integraldisplay\n?\n0\nduun h?(u) =\nparenleftbiggq?\np?\nparenrightbigg?n(n?1) parenleftbig\n[n](p0,q0)!parenrightbig. (80)\nIn order to solve these equations, the Ramanujan integral (121) discussed in the Appendix\nsuggests itself quite naturally, through a simple but appropriate rescaling of its arguments in\nthe form of (123).\nAfter a little moment?s thought one comes to the conclusion that a solution to (80) based\non (123) is possible for the following choice of parameters,\n? = 12, ? = 0, p0 = p, q0 = q, (81)\nin which case p0p?2?q2? = pq < 1, hence corresponding indeed to an infinite radius of conver-\ngence. For this choice, one has (for definitions of the (p,q)-exponential functions appearing in\nthese expressions, see the Appendix),\nh?parenleftbig|z|2parenrightbig=\nparenleftbigp?1?qparenrightbig\nqlog(1/pq) e(p,q)\nparenleftBig\n?|z|2 p?1/2q?1parenleftbigp?1?qparenrightbig\nparenrightBig\n, (82)\n4Incidentally, it is because of this identity, corresponding to the exchange p0 ? q?1\n0 , that the two solutions to\nthe above two recursion relations are consistent, as are the two algebraic restrictions in (73) and (74).\n5If p0p?2?q2? = 1, the radius of convergence is finite with R = (1?p0q0)?1/2, while when p0p?2?q2? > 1 the\nradius of convergence vanishes, implying that (p,q)-VCS cannot be constructed in such a case.\n15\nas well as6\nparenleftbigK0\n?([n])\nparenrightbig2 = [n], |N?(|z|)|?2 =E(1/2,0)\n(p,q)\nparenleftBig\n|z|2q?1/2parenleftbigp?1?qparenrightbig\nparenrightBig\n, (83)\nwith for the weight functions W?(|z|) in the integration measure (66) of the overcompleteness\nrelation (65),\nW+ (|z|) = 34?2 |N+ (|z|)|?2 h+parenleftbig|z|2parenrightbig, W?(|z|) = 38?2 |N?(|z|)|?2 h?parenleftbig|z|2parenrightbig. (84)\nExplicit expressions for all previously computed quantities readily follow, beginning with the\ndefinition of the associated (p,q)-VCS which then meet all thenecessary requirements expected of\ncoherent states. Note that up to the coefficients 3/(2?) and 3/(4?), the reduced weights obtained\nare compatible with that of the q-shape invariant harmonic oscillator [20]. Furthermore, (82)\nis a (p,q)-generalization of the q-harmonic oscillator coherent state moment problem solution\nconstructed in [41]. Finally, in the double limit p,q?1, the results of [14] are recovered.\nThe functions (82) thus provide a complete and explicit solution to the moment problem of\nthe (p,q)-VCS for the (p,q)-JCm such that the ladder operatorsA? obey the same (p,q)-Fock\nalgebra as the original modes a and a? of the initial Hamiltonian (24), namely with the choice\np0 = p and q0 = q. It is also possible to construct an explicit solution when the ladder operators\nA? are constrained to rather obey the ordinary non-deformed Fock algebra onV, corresponding\nto the choice p0 = 1 and q0 = 1. One then has to consider7, for all n?N,\nK0?([n]) =?n,\nintegraldisplay ?\n0\nduun h?(u) =\nparenleftbiggq?\np?\nparenrightbigg?n(n?1)\n(n!), p??q??1. (85)\nAn obvious solution to this moment problem is obtained when ? = 0 = ?, in which case the\ncondition for an infinite radius of convergence is saturated. One then has\nh?parenleftbig|z|2parenrightbig= e?|z|2, |N? (|z|)|?2 = e|z|2, W+ (|z|) = 34?2, W?(|z|) = 38?2. (86)\nIn fact, the above two explicit solutions belong to a general class of solutions obtained\nby taking (p0,q0) = (p?,q?) with ? a positive real parameter, ? > 0, such that p??2?q2? < 1\nin order to ensure an infinite radius of convergence8 in z ?C. Once again based on (123), an\nexplicit solution to the moment problem (80) is achieved for the following choice of parameters,\n? = 12?, ? = 0, p0 = p?, q0 = q?, (87)\nfor which the radius of convergence is indeed infinite, p??2?q2? = (pq)? < 1. One then has\nh?parenleftbig|z|2parenrightbig= (p\n???q?)\nq? log(1/p?q?) e(p?,q?)\nparenleftBig\n?|z|2 p??/2q??parenleftbigp???q?parenrightbig\nparenrightBig\n, (88)\nwith\n|N?(|z|)|?2 =E(1/2,0)(p?,q?)\nparenleftBig\n|z|2q??/2parenleftbigp???q?parenrightbig\nparenrightBig\n, (89)\nleading finally to the weight functionsW?(|z|) given in terms of the latter two quantities through\nthe same relations as in (84). In the limits that ? ? 1 or ? ? 0, the previous two explicit\nsolutions are then recovered as particular cases.\n6Restricting to p0 = p and q0 = q but keeping ? and ? arbitrary such that p1?2?q2? < 1 in order to retain an\ninfinite radius of convergence, one has parenleftbigK0?([n])parenrightbig2 = [n] and |N? (|z|)|?2 = E(?,?)(p,q) parenleftbig|z|2 p? q??parenleftbigp?1 ?qparenrightbigparenrightbig, hence\nalso all other previous expressions given accordingly.\n7Leading to |N? (|z|)|?2 = e(?,?)\n(p,q)\nparenleftbig|z|2 p? q??parenrightbig, which converges for all |z| < ? provided p??q? ? 1.\n8Leading to |N? (|z|)|?2 = E(?/?,?/?)\n(p?,q?)\nparenleftbig|z|2p?q??(p?? ?q?)parenrightbig.\n16\n5.2 The action identity constraint\nAn alternative to fixingthe factors K0?([n]) through conditions on the algebra ofladder operators,\nis to consider the action identity constraint discussed in [30] as the one last requirement which\nsingles out coherent states uniquely. In the case of the ordinary Fock algebra, this action\nidentity constraint is equivalent to requiring that the ladder operators obey themselves the Fock\nalgebra as well. We shall establish that this is not the case for the (p,q)-VCS of the (p,q)-JCm\nconstructed above.\nGiven the relations (72), in the present model the action identity constraint is of the form\nJ+ = cos2 ?parenleftbig|z|2 +E+0 parenrightbig, J? = sin2 ?parenleftbig|z|2 +E?0 parenrightbig. (90)\nBy direct substitution into these constraints of the relations (72), the identification of the suc-\ncessive powers in|z|2 leads to the following solution for the factors K0?([n]),\nK0?([n]) =\nparenleftbiggq?\np?\nparenrightbigg(n?1) radicalBig\nE?n ? E?0 . (91)\nThese positive real quantities are thus well-defined provided one has E?n > E?0 for all n ? 1,\nas is implicitly assumed. It is noteworthy that, as (p,q) ? (1+,1?), these factors reduce to\nexactly those obtained in [16] by the factorization method. On the other hand, since the present\nsolution for K0?([n]) cannot be brought into the form of (76) for some choice of constants p0 and\nq0 meeting our assumptions for these quantities, it follows indeed that for the (p,q)-JCm the\naction identity constraint is not equivalent to requiring an algebraic constraint on the ladder\noperators of the (p0,q0)-deformed Fock algebra type.\nThis choice also allows for the factorization of the Hamiltonian in (36) in the form\nHred = A+\nparenleftbiggq?\np?\nparenrightbigg?2N\nA +\n?summationdisplay\nn=0,?\n|n,??E?0 ?n,?|, (92)\nextending a similar expression in [14].\nGiven this solution for the factors K0?([n]), the general moment problem (68) reduces to\nthe following conditions,\nintegraldisplay R2\n0\ndu h?(u) = 1;\nintegraldisplay R2\n0\nduun h?(u) =\nnproductdisplay\nk=1\nparenleftbigE?\nk ?E\n?\n0\nparenrightbig, n = 1,2,3,???, (93)\nwhere the radius of convergence R is given as\nR = min (R+,R?), R? = limn?+?\nradicalBig\nE?n ?E?0 . (94)\nIn the absence of a detailed analysis of the energy spectra E?n as functions of the parameters p,\nq, ? and ? and the function h(p,q), nothing more explicit may be said concerning this moment\nproblem. Since when p > 1 the quantities [n] always possess a turn-around behaviour as func-\ntions of n for n sufficiently large, it is to be expected generally that the radius of convergence\nR, hence the moment problem as well, are associated to a finite disk DR in the complex plane.\nNevertheless, one conclusion of the present discussion is that indeed for the (p,q)-VCS consid-\nered in this work, the action identity constraint leads to coherent states different from those\nconstructed in Section 5.1 and for which explicit solutions to the moment problem have been\ngiven.\n17\n5.3 The spin decoupled limit ? = 0\nIn the limit that ? = 0, the two spin sectors of the model are decoupled, and the (p,q)-JCm\nreduces to the supersymmetric harmonic oscillator [43, 44, 18] with a (p,q)-deformation. Diago-\nnalization of the reduced Hamiltonian (24) is then of course straightforward in the ?3-eigenbasis,\nwith, for n = 0,1,2,???,\nHred?=0|n,??= ??n |n,??, ??n = (1 +?)h(p,q)[n] + 12(1 +?)?12. (95)\nFrom that point of view, one thus has two decoupled (p,q)-deformed Fock bases, for which\none could consider the usual (p,q)-coherent states in each spin sector separately. However, such\ncoherent states do not coincide with any of those constructed in this paper and obtained in the\nlimit ? = 0, because of the distinguished role played by the singleton state |E?? = |0,?? and\nthe S2 unit vector character of the (p,q)-VCS. In particular the ladder operators A? acting\nwithin each of the towers |E?n? do not coincide with the annihilation and creation operators a\nand a? defining the Hamiltonian (24), even in the decoupled limit ? = 0. As a matter of fact,\nthe action of the ladder operatorsA? may switch between the two spin sectors as a function of\nn depending on the sign of the quantityE([n+ 1]).\nMore specifically, let us introduce the notation\nsn = signE([n+ 1]), n?N. (96)\nIn the limit that ? = 0, one has Q([n + 1]) =|E([n + 1])|/2, so that the mixing angle ?([n]) is\nnow such that, for all n?N,\n? = 0 : sin?([n]) = 12(1?sn)(sign?), cos?([n]) = 12(1 +sn). (97)\nConsequently, the towers of energy eigenstates|E?n?are then given as follows, for all n?N,\nIf sn = +1 : |E+n??=0 =|n+1,??, |E?n??=0 =|n,+?;\nIf sn =?1 : |E+n??=0 = (sign?)|n,+?, |E?n??=0 =?(sign?)|n + 1,??,\n(98)\nwhile the energy eigenvalues are given as\nIf sn = +1 : E+n (? = 0) = (1 +?)h(p,q)[n +1] + 12(1 +?) ? 12,\nE?n (? = 0) = (1 +?)h(p,q)[n] + 12(1 +?) + 12;\nIf sn =?1 : E+n (? = 0) = (1 +?)h(p,q)[n] + 12(1 +?) + 12,\nE?n (? = 0) = (1 +?)h(p,q)[n +1] + 12(1 +?) ? 12.\n(99)\nThese spectra do indeed coincide with those in (95), once the singleton state|E??=|0,??with\nE? = ?/2 is included as well.\nThese expressions show how, even in the decoupled spin limit ? = 0, the (p,q)-VCS\nconstructed here are not simply the juxtaposition of two separate (p,q)-coherent states of the\n(p,q)-deformed Fock algebra in each of the two spin sectors. Since the spectrum of the system\nis discrete infinite, by leaving aside the singleton state|0,??, all the remaining states still allow\nfor similar types of constructions of coherent states, but in such a way that different spin sectors\nare getting superposed, leading to the SU(2) vector coherent states of the type studied here. All\nthe expressions detailed in the previous sections for the (p,q)-VCS may readily be particularized\nto the limit ??0.\n18\n6 Conclusion\nIn this work, we considered (p,q)-deformations of the Jaynes-Cummings model in the rotating\nwave approximation, extending recent developments on this topic in the non-deformed case [14].\nHaving introduced (p,q)-deformed versions of the model, first its energy eigenspectrum has been\nidentified, enabling the definition of different relevant operators acting on Hilbert space and the\ncharacterization of the spectrum in terms of two separate infinite discrete towers and a singleton\nstate. Among these operators, ladder operators acting within each of the two towers separately\nmay be considered, defined up to some arbitrary normalization factors.\nSuch a structure sets the stage for the introduction of vector coherent states for the (p,q)-\ndeformed Jaynes-Cummings model, following the approach of [14] and the rationale outlined\nin [30]. These (p,q)-VCS are parametrized by elements of C?S2, and enjoy temporal sta-\nbility through a further action-angle identification. The moment problem associated to the\novercompleteness property of these (p,q)-VCS involves SU(2)-valued matrix weight functions.\nUsing (p,q)-arithmetic techniques, some explicit and exact solutions to the moment problem\nhave been displayed, hence characterizing specific classes of such (p,q)-VCS. All these solutions\nprovide (p,q)-extensions to the non-deformed vector coherent states of theJCm considered in\n[14]. These explicit solutions are obtained by requiring that specific algebraic constraints of the\n(p,q)-deformed Fock algebra type be obeyed by the ladder operators. However, in contradis-\ntinction to [14], we have not been able to display an explicit and exact solution to the moment\nproblem in the generic case by imposing an action identity constraint.\nFinally, the spin decoupled limit of these models was considered, corresponding to a (p,q)-\nsupersymmetric oscillator of which the two sectors are intertwined in a manner depending on\nthe sign of the energy level spacing between the two decoupled spin sectors as function of the\nexcitation level. In the non-deformed limit (p,q) = (1,1), this feature disappears, reproducing\nthe ordinary supersymmetric oscillator. Our results thus provide new classes of generalized\nversions of theJCm in the rotating wave approximation [20, 18]. Finally, the (p,q)-VCS built\nhere extend the q-coherent states obtained by other techniques involving supersymmetric shape\ninvariance and self-similar potential formalisms applied to the harmonic oscillator [20, 45].\nAcknowledgements\nJ. B. G. is grateful to the Abdus Salam International Centre for Theoretical Physics (ICTP,\nTrieste, Italy) for a Ph.D. fellowship under the grant Prj-15. M. N. H. is particularly indebted\nto V. Hussin for discussions relating to the JCm as well as for provided references during his\nstay at the Centre de Recherches Math?ematiques, Universit?e de Montr?eal, Canada. The ICMPA\nis in partnership with the Daniel Iagoniltzer Foundation (DIF), France.\nJ. G. acknowledges a visiting appointment as Visiting Professor in the School of Physics\n(Faculty of Science) at the University of New South Wales. He is grateful to Prof. Chris Hamer\nand the School of Physics for their hospitality during his sabbatical leave, and for financial sup-\nport through a Fellowship of the Gordon Godfrey Fund. His stay in Australia is also supported\nin part by the Belgian National Fund for Scientific Research (F.N.R.S.) through a travel grant.\nJ. G. acknowledges the Abdus Salam International Centre for Theoretical Physics (ICTP,\nTrieste, Italy) Visiting Scholar Programme in support of a Visiting Professorship at the ICMPA.\nHis work is also supported by the Belgian Federal Office for Scientific, Technical and Cultural\nAffairs through the Interuniversity Attraction Pole (IAP) P5/27.\n19\nAppendix\nThis appendix lists some useful facts related to the (p,q)-boson algebra and associated functions.\nThe (p,q)-deformed oscillator algebra introduced in [5] is generated by operators a, a? and N\nobeying the relations\n[N,a] =?a, [N,a?] = a?,\naa??qa?a = p?N, aa??p?1a?a = qN. (100)\nThroughout the text, we assume the real parameters p and q are such that p > 1, 0 < q < 1\nand pq < 1. The limit p ? 1+ yields the q-oscillator of Arik and Coon [3] while p = q gives\nthe q-deformed oscillator algebra of Biedenharn and MacFarlane [4]. Finally, the algebra (100)\nreduces to the ordinary harmonic oscillator Fock algebra as q ? 1 for p = 1+ or p = q. At\nany stage of the discussion, the (p,q)-deformed model readily reduces to its usual counterpart\nas (p,q)?(1,1).\nThe associated (p,q)-deformed Fock-Hilbert space representation is spanned by the vac-\nuum|0?annihilated by a and the orthonormalized states|n?, such that\na|0?= 0, ?0|0?= 1, |n?= 1radicalBig\n[n](p,q)!\nparenleftBig\na?\nparenrightBign\n|0?,\na|n?=\nradicalBig\n[n](p,q)|n?1?, a?|n?=\nradicalBig\n[n+ 1](p,q)|n+ 1?, N|n?= n|n?, (101)\nwhere the symbol [n](p,q) = (p?n?qn)/parenleftbigp?1?qparenrightbigis called (p,q)-basic number with, by conven-\ntion, [0](p,q) = 0, and its (p,q)-factorial is defined through [n](p,q)! = [n](p,q)parenleftbig[n?1](p,q)!parenrightbig and\nthe convention [0](p,q)! = 1. There exists a formal (p,q)-number operator denoted by [N](p,q), or\nsimply by [N] when no confusion arises. As a matter of fact, from the second pair of relations\nin (100), it follows that [N] = a?a as well as [N + 1] = aa?. One has of course [N]|n?= [n]|n?.\nHence, (101) provides a well defined Fock-Hilbert representation space of the algebra (100).\nThe following relations hold for any function f ?f(N) and consequently for any function\nof [N],\naf(N?1) = f(N)a, a?f(N) = f(N?1)a?. (102)\nLet us define q-shifted products and factorials and their (p,q)-analogues. Using the nota-\ntions of [46], for any quantity x, (x;q)? is constructed as follows,\n(x;q)0 = 1, (x;q)? = (x;q)?(xq?;q)\n?\n, (x;q)? =\n?productdisplay\nn=0\n(1?xqn). (103)\nFurthermore, in the notations of [10], (p,q)-shifted products and factorials are defined as follows,\nfor any real quantities a and b such that anegationslash= 0,\n[a,b;p,q]0 = 1, [a,b;p,q]? = [a,b;p,q]?[ap?,bq?;p,q]\n?\n, [a,b;p,q]? =\n?productdisplay\nn=0\nparenleftbigg 1\napn ?bq\nn\nparenrightbigg\n. (104)\nFor ? = n?N, we have\n[p?,q?;p,q]n =\nparenleftbigg 1\np? ?q\n?\nparenrightbiggparenleftbigg 1\np?+1 ?q\n?+1\nparenrightbigg\n...\nparenleftbigg 1\np?+n?1 ?q\n?+n?1\nparenrightbigg\n20\n= p??n?n(n?1)/2(p?q?;pq)n. (105)\nThis identity is a central formula since it defines a bridge between q- and (p,q)-analogue quan-\ntities and functions.\nLet us now introduce q-analogues of the ordinary exponential funtion. There exist many\ntypes of q-deformations of the exponential function ez, z ?C (see, for instance, [9]). For any\n(z,?)?C?R, the (?,q)-exponential is the complex function [9]\nE(?)q (z) =\n?summationdisplay\nn=0\nq?n2\n(q;q)nz\nn. (106)\nThis series has an infinite radius of convergence for ? > 0. For ? = 0 its domain of definition\nreduces to the unit disk, |z| < 1, while it is nowhere convergent in C for ? < 0. Rescaling\nz?z(1?q) and taking the limit limq?1 E?q (z(1?q)), one recovers ez. For some specific values\nof ?, (106) reproduces some standard q-exponentials [9, 11],\nE(0)q (z) = eq(z) = 1(z;q)\n?\n=\n?summationdisplay\nn=0\nzn\n(q;q)n, |z|< 1, (107)\nE(1/2)q (z) = Eq(q1/2z) = (?q1/2z;q)?, z?C, (108)\nwhere\nEq(z) =\n?summationdisplay\nn=0\nqn(n?1)/2zn\n(q;q)n , z?C, (109)\nis known as the Jackson q-exponential [6]. Note that whereas E(?)q (z) is defined in the entire\ncomplex plane, |z| < ?, for any ? > 0, its reduction eq(z) is only defined on the unit disc.\nFinally, it is also well established that [11]\nEq(?z)eq(z) = 1. (110)\n(p,q)-analogues of the usual exponential function ez, z?C may also be introduced (see,\nfor instance, [10]). Given any (z,?,?)?C?R?R, consider the (?,?,p,q)-exponential function\nE(?,?)(p,q) (z) =\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn2 zn\n[p,q;p,q]n. (111)\nKeeping in mind the condition pq < 1, the radius of convergence R of this series is such that\nR1 =\n?\n?\n?\n?, if q2?p1?2? < 1;\np??1q??, if q2?p1?2? = 1;\n0, if q2?p1?2? > 1.\n(112)\nThus the functionE(?,?)(p,q) (z) exists only provided q2?p1?2? ?1.\nIn order to recover the usual exponential function, one has to rescale z?z(p?1?q), for\nexample, and then take the limit lim(p,q)?(1,1)E?,?(p,q)(z(p?1?q)) = ez. For particular values of\nthe parameters ? and ?, (111) reproduces known (p,q)-exponentials,\nE(1/2,1/2)(p,q) (z) = E(p,q)\nparenleftBiggparenleftbigg\nq\np\nparenrightbigg1/2\nz\nparenrightBigg\n=\n?summationdisplay\nn=0\nparenleftbiggq\np\nparenrightbiggn2/2 zn\n[p,q;p,q]n, (113)\n21\nwhere\nE(p,q)(z) =\n?summationdisplay\nn=0\nparenleftbiggq\np\nparenrightbiggn(n?1)/2 zn\n[p,q;p,q]n. (114)\nThe function E(p,q) may be found in [10]. Note that (114) coincides with (109) as p?1. In the\nsame limit, (111) reproduces the (?,q)-deformed exponential map E(?)q (z) [9]. If ? = 0 = ? the\nseries (111) is not defined since then R = 0, unless one has taken p = 1 in which case the radius\nof convergence is unity. A (p,q)-analogue of (107) is given by\ne(p,q)(z) =\n?summationdisplay\nn=0\n1\npn2/2\nzn\n[p,q;p,q]n, |z|< p\n?1/2, (115)\nwhich reproduces exactly eq(z) converging in the unit disc as p ? 1+. Furthermore, we have\nfrom (105)\ne(p,q)(z) =\n?summationdisplay\nn=0\n(p1/2z)n\n(pq;pq)n = epq(p\n1/2z). (116)\nUsing (105) and (109), we may also write\nE(p,q)(z) =\n?summationdisplay\nn=0\nparenleftbiggq\np\nparenrightbiggn(n?1)/2 zn\np?n(n+1)/2(pq;pq)n\n=\n?summationdisplay\nn=0\nqn(n?1)/2 (zp)\nn\n(pq;pq)n = Epq(pz). (117)\nThen taking into account (110), (116) and (117), a (p,q)-analogue of (110) is given by\nEpq(?pz)epq(pz) = E(p,q)(?z)e(p,q)(p1/2z) = 1. (118)\nFinally, consider\ne(?,?)(p,q)(z) =\n?summationdisplay\nn=0\nparenleftbiggq?\np?\nparenrightbiggn2 zn\nn!. (119)\nTherefore, e(?,?)(p,q)(z), which converges to ez as (p,q) ? (1,1), provides a (p,q)-deformed ex-\nponential analogue to the q-function used by Penson and Solomon [42] which coincides with\ne(1,?)(1,q)(q?1/2z). The radius of convergence of (119) is given as\nR2 =\nbraceleftbigg ?, if q?p?? ?1;\n0, if q?p?? > 1. (120)\nFinally, consider the Ramanujan integral [7, 19], valid for any integer n?N,\nintegraldisplay ?\n0\ndttn eq(?t) =? (q;q)nqn(n+1)/2 logq. (121)\nThrough the change of variables\nq?pq, t??0 p?1/2 t, ?0 > 0, (122)\nand using once again (105), the following identity is obtained, for any n?N,\nintegraldisplay ?\n0\ndttn e(p,q)\nparenleftBig\n??0p?1/2t\nparenrightBig\n= [p,q;p,q]n?n+1\n0 qn(n+1)/2\nlog\nparenleftbigg 1\npq\nparenrightbigg\n. (123)\nThis result is indeed a (p,q)-analogue of the Ramanujan integral (121).\n22\nReferences\n[1] S. Majid, Quantum Groups (Cambridge Univ. Press, Cambridge, 1995);\nV. G. Drinfeld, Quantum Groups, Lecture Notes in Mathematics, Ed. P. P. Kulish (Springer,\nBerlin, 1992).\n[2] See for example,\nJ. Wess and B. Zumino, Nucl. Phys. B (Proceedings Supplements) 18, 302-312 (1991);\nA. Lorek and J. Wess, Z. Phys. C 67, 671-680 (1995).\n[3] M. Arik and D. D. Coon, J. Math. Phys. 17, 524-527 (1976).\n[4] A. J. Macfarlane, J. Phys. A: Math. Gen. 22, 4581-4588 (1989);\nL. C. Biedenharn, J. Phys A: Math. Gen. 22, L873-L878 (1989).\n[5] R. Chakrabarti and R. Jagannathan, J. Phys. A: Math. Gen. 26, L711-L719 (1991).\n[6] F. Jackson, Mess. Math. 38, 57 (1909).\n[7] S. Ramanujan, Mess. Math. 44, 10-18 (1915).\n[8] H. Exton, q-Hypergeometric Functions and Application (John Wiley and Sons, New York,\n1983).\n[9] F. Floreanini and L. Vinet, Lett. Math. Phys. 22, 45-54 (1991);\nF. Floreanini, J. LeTourneux and L. Vinet, J. Phys. A: Math. Gen. 28, L287-L239 (1995).\n[10] R. Floreanini, L. Lapointe and L. Vinet, J. Phys. A: Math. Gen. 26, L611-L614 (1993).\n[11] R. Koekoek and R. F. Swarttouw, The Askey-scheme of hypergeometric orthogonal polyno-\nmials and its q-analogue, Delft University Technology, Report 94-05 (1994).\n[12] E. T. Jaynes and F. Cummings, FW Proc. IEEE 51, 89-109 (1963).\n[13] P. Meystre and E. M. Wright, Phys. Rev. A 37, 2524 (1988).\n[14] V. Hussin and L. M. Nieto, J. Math. Phys. 46, 122102 (2005).\n[15] Y. B?erub?e-Lauziere, V. Hussin and L. M. Nieto, Phys. Rev. A 50, 1725 (1994).\n[16] L. Dello Sbarba and V. Hussin, in Group of Theoretical Methods in Physics: Proceeding\nof the XXV International Colloqium on Group Theoretical Methods in Physics, Institute\nof Physics Conferences Series, Vol. 185, Eds. G. S. Pogosyan, L. E. Vincent and K. B. Wolf\n(IOP, Bristol, 2005).\n[17] M. Daoud and V. Hussin, J. Phys. A: Math. Gen. 35, 7381-7402 (2002).\n[18] M. Daoud and J. Douari, Int. J. Mod. Phys. B 17, 2473-2486 (2003).\n[19] A. B. Balantekin, To be published in the Proceedings of ?Computational And Group The-\noretical Methods In Nuclear Physics: Symposium In Honor Of Jerry P. Draayer?s 60th\nBirthday, 18-21 Feb 2003, Playa del Carmen, Mexico?; e-print arXiv:nucl-th/0309038.\n23\n[20] A. N. F. Aleixo, A. B. Balantekin and M. A. Candido Ribeiro, J. Phys. A: Math. Gen. 35,\n9063-9070 (2002);\nA. N. F. Aleixo, A. B. Balantekin and M. A. Candido Ribeiro, J. Phys. A: Math. Gen. 36,\n11631-11642 (2003);\nA. N. F. Aleixo and A. B. Balantekin, J. Phys. G 30, 1225-1230 (2004).\n[21] B. Buck and C. V. Sukumar, Phys. Lett. A 81, 132 (1981).\n[22] M. Chaichan, D. Ellinas and P. Kulish, Phys. Rev. Lett. 65, 980-983 (1990).\n[23] Z. Chan, Phys. Rev. A 47, 5017-5023 (1993).\n[24] M. H. Naderi, M. Soltanolkotabi and R. Roknizadeh, Journal of the Physical Society of\nJapan 73, 2413-2423 (2004).\n[25] G. Dresselhaus, Phys. Rev. 100, 580 (1955).\n[26] For a recent review on spintronics, see\nJ. Schliemann, e-print arXiv:cond-mat/0602330.\n[27] S-Q. Shen, Y-J Bao, M. Ma, X. C. Xie and F. C. Zhang, Phys. Rev. B 71, 155316 (2005).\n[28] S-Q. Shen, M. Ma, X. C. Xie and F. C. Zhang, Phys. Rev. Lett. 92, 256603 (2004).\n[29] S. T. Ali and F. Bagarello, J. Math. Phys. 46, 053518 (2004).\n[30] J-P. Gazeau and J. R. Klauder, J. Phys. A: Math. Gen. 32, 123 (1999).\n[31] J-P. Antoine, J-P. Gazeau, P. Monceau, J. R. Klauder and K. A. Penson, J. Math. Phys.\n42, 2349 (2001).\n[32] S. T. Ali, J-P. Antoine and J-P. Gazeau, Coherent States, Wavelets and their Generaliza-\ntions (Springer-Verlag, Berlin, 2000).\n[33] F. G. Scholtz, B. Chakraborty, S. Gangopadhyay and J. Govaerts, J. Phys. A: Math. Gen.\n38, 9849-9858 (2005).\n[34] F. G. Scholtz, B. Chakraborty, S. Gangopadhyay and A. Ghosh Hazra, Phys. Rev. D 71,\n085005 (2005).\n[35] J. Ben Geloun, J. Govaerts and M. N. Hounkonnou, A (p,q)-deformed Landau problem\nin a spherical harmonic well: spectrum and noncommuting coordinates, preprint ICMPA-\nMPA/2006/22, CP3-06-12, e-print arXiv:hep-th/0609120, submitted to J. Phys. A: Math.\nGen.\n[36] M. N. Hounkonnou and K. Sodoga, J. Phys. A: Math. Gen. 38, 7851-7862 (2005).\n[37] For an exhaustive dicussion on the moment problem, see for instance\nB. Simon, Adv. Math. 137, 82-203 (1998).\n[38] J. R. Klauder, Contribution to the 7th ICSSUR Conference, June 2001, e-print\narXiv:quant-ph/0110108.\n[39] A. Kempf, J. Math. Phys. 35, 4483 (1994);\nH. Hinrichsen and A. Kempf, J. Math. Phys. 37, 2121 (1996).\n24\n[40] C. Quesne, K. A. Penson and V. M. Tkachuk, Phys. Lett. A 313, 29-36 (2003).\n[41] C. Quesne, J. Phys. A: Math. Gen. 35, 9213-9226 (2002).\n[42] K. A. Penson and A. I. Solomon, J. Math. Phys. 40, 2354 (1999).\n[43] C. Aragone and F. Zypman, J. Phys. A: Math. Gen. 19, 2267-2279 (1986).\n[44] M. Orszag and S. Salamo, J. Phys. A: Math. Gen. 21, L1059-L1064 (1988).\n[45] F. Cooper, A. Khare and U. Sukhatme, Supersymmetry in Quantum Mechanics 2nd Ed.\n(World Scientific, Singapore, 2004).\n[46] G. Gasper and M. Rahman, Basic Hypergeometric Series (Cambridge Univ. Press, Cam-\nbridge, 1990).\n25\n"}
{"id":"oai:arXiv.org:hep-ph/0612309","text":"arXiv:quant-ph/0602178v2  17 May 2006\nDuality, Phase Structures and Dilemmas in Symmetric Quantum Games\nTsubasa Ichikawa and Izumi Tsutsui\nHigh Energy Accelerator Research Organization (KEK), Tsukuba, Ibaraki 305-0801, Japan\n(Dated: February 22, 2006)\nSymmetric quantum games for 2-player, 2-qubit strategies are analyzed in detail by using a scheme\nin which all pure states in the 2-qubit Hilbert space are utilized for strategies. We consider two\ndifferent types of symmetric games exemplified by the familiar games, the Battle of the Sexes (BoS)\nand the Prisoners? Dilemma (PD). These two types of symmetric games are shown to be related by a\nduality map, which ensures that they share common phase structures with respect to the equilibria\nof the strategies. We find eight distinct phase structures possible for the symmetric games, which\nare determined by the classical payoff matrices from which the quantum games are defined. We\nalso discuss the possibility of resolving the dilemmas in the classical BoS, PD and the Stag Hunt\n(SH) game based on the phase structures obtained in the quantum games. It is observed that\nquantization cannot resolve the dilemma fully for the BoS, while it generically can for the PD and\nSH if appropriate correlations for the strategies of the players are provided.\nPACS numbers: 02.50.Le, 03.67.-a, 87.23.Ge\nKeywords: quantum mechanics, game theory, entanglement\nI. INTRODUCTION\nQuantum game theory has attracted much attention\nin recent years as an interesting attempt to expand the\nscope of the conventional (classical) game theory, which\nis now a standard tool in various fields, most notably in\neconomics, for analyzing decision making processes. The\nmain thrust in the investigation of quantum game has\ncome from the remarkable observation by Eisert et al. [1]\nthat the famous dilemma in the Prisoners?Dilemma (PD)\ngame can be resolved if the players resort to strategies\navailable in quantum theory. Subsequently, Marinatto\nand Weber [2] examined the dilemma in the Battle of\nthe Sexes (BoS) game, another typical dilemma in game\ntheory, and observed that this, too, could be resolved\nby adopting a quantum strategy involving a maximally\nentangled state. Application of quantum strategies to\nvarious other games, such as the Stag Hunt (SH) or the\nSamaritan?s Dilemma game, has also been discussed in\n[3].\nThese studies of the quantum games presented in [1, 3]\nand [2] employ different schemes of quantum strategies,\nand it has turned out that the outcome of the analysis is\nhighly dependent on the scheme used. In fact, it has been\npointed out in [4, 5, 6] that in the scheme used in [1, 3]\nthe dilemma in PD can be resolved only if the strategic\nspace is restricted artificially, while a more recent study\n[7] shows that there exists a new scheme in which the\ndilemma can be resolved even with a full strategic space.\nSimilarly, the resolution of the dilemma in the BoS has\nbeen argued using different reasonings depending on the\nschemes [3, 8, 9] (for a generalized scheme, with no analy-\nsis on dilemmas, see [10]), casting a doubt on the genuine\nnature of the resolution and, more importantly, the uni-\nversality of the outcomes of quantum game in general.\nThe distinction among these schemes can be found in\nthe definitions of quantum strategy, the strategic space\nwhich the players can exploit, and the way the quan-\ntum correlation (entanglement) is furnished. These dif-\nferences are crucial, because (as observed in [4, 5, 6])\ndifferent strategic spaces admit different stable solutions,\nand moreover the amount of entanglement required to\nresolve the dilemma will depend on the stage in the pro-\ncess it is measured. Despite of this scheme-dependence,\nwe have found in [7] an intriguing phase structure for the\nquantum PD game, which is reminiscent of the ?phase\ntransition? of equilibrium solutions discovered earlier in\n[11] in a different scheme. This suggests that the phase\nstructures may exhibit a scheme-independent, intrinsic\nfeatures of quantum games under consideration.\nThe aim of the present paper is to support this idea by\nproviding a convenient tool to analyze quantum games\nin general terms. We consider 2-player, 2-qubit strategy\ngames, which are the simplest nontrivial and yet have not\nbeen fully analyzed. Using the scheme introduced in [7],\nwe study in detail two types of ?symmetric games?, exem-\nplified by the BoS and PD games, respectively. We show\nthat these two types of games are actually related by a\nduality map, which brings a game in one symmetric type\ninto a game in the other symmetric type without chang-\ning the payoff in effect. This is convenient because then\nwe can use the outcome of the analysis of the BoS for the\nstudy of the PD, for instance. A quantum game may be\nregarded as a family of games provided by quantum cor-\nrelations which are absent in classical settings, and our\ngeometric picture used to portray the correlation-family\nin this paper turns out to be quite convenient, espe-\ncially for analyzing the phase structures of the game. We\nshall then see that symmetric games admit eight differ-\nent types of phase structures with regard to the possible\nstable strategies (related to classical strategies) preferred\nby the players, and that these types are determined by\nthe original classical games. With these phase structures,\nwe find that the dilemma in the BoS cannot be resolved\nfully in our scheme, albeit alleviated to some extent [2],\nirrespective of the amount of entanglement provided. In\n2\ncontrast, the dilemma of the PD game can be resolved if\na certain amount of correlationsare introduced. An anal-\nogous conclusion will also be drawn for the SH game, for\nwhich we find rather intricate phase structures for the full\nstable strategies compared to the BoS and PD games.\nThe plan of the paper is as follows. We first introduce\nour scheme of quantum gamein section II and present the\nduality map between the two types of symmetric games.\nThe phase structures of the symmetric games are studied\nin section III. Section IV is devoted to the analysis of the\nBoS, PD and SH games, where we examine the resolution\nof the dilemmas based on the results obtained in section\nIII. Finally, we give our conclusion and discussions in\nsection V.\nII. QUANTUM GAME AND DUALITY FOR\nSYMMETRIC GAMES\nTo begin with, we first recapitulate the classical 2-\nplayer, 2-strategy game and then introduce its quantum\nversion following [7]. Let i = 0,1, j = 0,1 be the la-\nbels of the strategies available for the players, Alice and\nBob, respectively, and let also Aij and Bij be their pay-\noffs when their joint strategy is (i,j). In classical game\ntheory, the game is said to be ?symmetric? if Bji = Aij,\nthat is, if their payoffs coincide when their strategies are\nswapped (i,j) ? (j,i). To make a distinction from the\nother symmetry discussed shortly, we call such a game\nS-symmetric in this paper. The PD and other famil-\niar games such as the SH and the Chicken game (see,\ne.g., [3, 12]) are S-symmetric games. Similarly, we call\nthe game T-symmetric if B1?j,1?i = Aij, that is, if the\npayoff matrices coincide when the strategies of the two\nplayers are ?twisted? as (i,j) ? (1 ? j,1 ? i). The BoS\nis an example of T-symmetric games with the additional\nproperty A01 = A10. The payoffs in these S-symmetric\nand T-symmetric games are displayed in the form of the\nbi-matrix (Aij,Bij) in Table I.\nGiven a payoff matrix, each player tries to maximize\nhis/her payoff by choosing the best possible strategy, and\nif there exists a pair of strategies in which no player can\nbring him/her in a better position by deviating from it\nunilaterally, we call it a Nash equilibrium (NE) of the\ngame. The players will be happy if the NE is unique\nand fulfills certain conditions attached to the game (e.g.,\nPareto-optimality or risk-dominance as mentioned later).\nEven when there are more than one NE, the players will\nstill be satisfied if a particular NE can be selected over\nthe other upon using some reasonings. Otherwise, the\nplayers may face a dilemma, as they do in the case of the\nBoS and the PD.\nTo introduce a quantum version of the classical game,\nwe first regard Alice?s strategies i as vectors in a Hilbert\nspace HA of a qubit. Namely, corresponding to the clas-\nsical strategies i we consider vectors |i?A for i = 0 and 1\nwhich are orthonormal in HA. A general quantum strat-\negyavailablefor Alice is then representedbya normalized\nS-symmetric:\nstrategy Bob 0 Bob 1\nAlice 0 (A00,A00) (A01,A10)\nAlice 1 (A10,A01) (A11,A11)\nT-symmetric:\nstrategy Bob 0 Bob 1\nAlice 0 (A00,A11) (A01,A01)\nAlice 1 (A10,A10) (A11,A00)\nTABLE I: Payoff bi-matrices (Aij,Bij) of the S-symmetric\ngame (above) and the T-symmetric game (below).\nvector |??A (with the overall phase ignored, i.e., a unit\nray) in HA. Bob?s strategy is similarly represented by\na normalized vector |??B in another qubit Hilbert space\nHB spanned by orthonormal vectors |j?B for j = 0 and\n1 in HB. The strategies of the players can thus be ex-\npressed in the linear combinations,\n|??A =\nsummationdisplay\ni\n?i(?)|i?A ,\n|??B =\nsummationdisplay\nj\n?j(?)|j?B ,\n(2.1)\nusing the bases |i?A, |j?B which correspond to the clas-\nsical strategies, with complex coefficients ?i(?), ?j(?)\nwhich are functions of the parameters ? and ? normal-\nized as summationtexti|?i|2 = summationtextj |?j|2 = 1. The strategies of the\nindividual players are, therefore, realized by local actions\nimplemented by the players independently.\nThe joint strategy of the players, on the other hand,\nis given by a vector in the direct product Hilbert space\nH = HA ?HB. Here lies one of the crucial differences\nbetween the classical and quantum games: in quantum\ngame theory, the joint strategy is specified not just by the\nchoice of the strategies of the players but also by furnish-\ning the quantum correlation (essentially the entangle-\nment) between the individual strategies. Consequently,\nthe outcome of a quantum game rests also on a third\nparty (or referee) that determines the correlation. To be\nmore explicit, using the product vector|?,?? = |??A|??B\nwhich is uniquely specified by the individual strategies,\na vector in the total strategy space H is written as\n|?,?;?? = J(?)|?,?? = J(?)|??A|??B , (2.2)\nwhere J(?) is a unitary operator providing the quantum\ncorrelation between the individual strategies. The corre-\nlation factor J(?) with the parameter set ? is designed to\nexhaust all possible joint strategies available in H. The\npayoffs for Alice and Bob are then given by the expecta-\ntion values of some appropriate self-adjoint operators A\nand B, respectively:\n?A(?,?;?) = ??,?;?|A|?,?;??,\n?B(?,?;?) = ??,?;?|B|?,?;??. (2.3)\nTo sum up, a quantum game is defined formally by the\ntriplet {H,A,B}.\n3\nTo choose the payoff operators A and B, we require\nthat, in the absence of quantum correlations J(?) = I\n(I is the identity operator in H), the payoff values re-\nduce to the classical ones when the players choose the\n?semiclassical (pure) strategies? |i,j? = |i?A|j?B,\n?i?,j?|A|i,j? = Aij?i?i?j?j,\n?i?,j?|B|i,j? = Bij?i?i?j?j. (2.4)\nAdopting, for simplicity, the value ? = 0 for the refer-\nence point at which J(?) = I holds, we find that, for\nthe uncorrelated product strategies |?,?;0? = |?,??, the\npayoffs (2.3) become\n?A(?,?;0) = ??,?;0|A|?,?;0? =\nsummationdisplay\ni,j\nxiAijyj,\n?B(?,?;0) = ??,?;0|B|?,?;0? =\nsummationdisplay\ni,j\nxiBijyj,\n(2.5)\nwhere xi = |?i|2, yj = |?j|2 represent the probability\nof realizing the strategies |i?A, |j?B under the general\nchoice |??A, |??B (see (2.1)). This ensures the exis-\ntence of a classical limit at which the quantum game\nreduces to the classical game defined by the payoff ma-\ntrix Aij, where now Alice and Bob are allowed to adopt\nmixed strategies (see, e.g., [13]) with probability distri-\nbutions xi, yj (summationtextxi = summationtextyj = 1) for strategies i, j.\nWe thus see that the quantum game is an extension of\nthe classical game, in which the correlation parameter ?\nplays a role similar to the Planck constant planckover2pi1 in quantum\nphysics in the technical sense that the classical limit is\nobtained by their vanishing limit. Note that, since the set\n{|i,j?, i,j = 0,1} forms a basis set in the entire Hilbert\nspace H, the payoff operators A and B are uniquely de-\ntermined from the classical payoff matrices by (2.4); in\nother words, our quantization is unique.\nThe aforementioned symmetries in classical game can\nalso be incorporated into quantum game by using cor-\nresponding appropriate symmetry operators. Indeed, by\nintroducing the swap operator\nS|i,j? = |j,i?, (2.6)\nwe see immediately that in the classical limit the game\nis S-symmetric, ?B(?,?;0) = ?A(?,?;0), provided that\nthe payoff operators A and B fulfill\nB = SAS. (2.7)\nAnalogously, if we introduce the notation ?i = 1 ? i for\ni = 0,1 (i.e., ?0 = 1 and ?1 = 0) and thereby the twist\noperator,\nT|i,j? = |?j,?i?, (2.8)\nand the twisted states,\nvextendsinglevextendsingle??, ??angbracketrightbig := T |?,?? = summationdisplay\ni,j\n?i(?)?j(?)|?j,?i?, (2.9)\nwe find that in the classial limit the game is T-symmetric,\n?B(??, ??;0) = ?A(?,?;0), provided that the operators\nfulfill\nB = T AT. (2.10)\nThe symmetries can be elevated to the full quantum\nlevel if we adopt the correlation factor in the form [7],\nJ(?) = ei?1S/2ei?2T/2, (2.11)\nwith real parameters ?i ? [0,2pi) for i = 1,2 [17]. In fact,\none can readily confirm, using [S,T] = ST ? TS = 0,\nthat under (2.10) the game is S-symmetric\n?B(?,?;?) = ?A(?,?;?), (2.12)\neven in the presence of the correlation (2.11). Similarly,\nthe game is T-symmetric\n?B(??, ??;?) = ?A(?,?;?), (2.13)\nif (2.10) is fulfilled. Since the correlation parameters in\n? are arbitrary, the properties (2.12), (2.13) imply that\na symmetric quantum game consists of a (?-parameter)\nfamily of games with the (S or T) symmetry exhibited\nfor each ?.\nIt is interesting to observe that these two types of sym-\nmetric games are actually related by unitary transforma-\ntions. To see this, let us introduce the operator CA which\nimplements the conversion for Alice?s strategies,\nCA|i,j? = |?i,j?. (2.14)\nNote that CA satisfies\nCA SCA = T, CA T CA = S. (2.15)\nConsider then the transformation of strategy by unilat-\neral conversion by Alice,\n|?,?;??? CA|?,?;??. (2.16)\nOn account of the relation (2.14) and the form of the\ncorrelation (2.11), we find\nCA|?,?;?? = |??,?;???, (2.17)\nwith ?? given by\n(??1,??2) = (?2,?1). (2.18)\nIn addition, one may also consider the transformation\non the payoff operators,\nA ? ?A = CA ACA, B ? ?B = CA BCA. (2.19)\nOne then observesthat, if the game is S-symmetricfulfill-\ning (2.7), the game defined by the transformed operators\nbecomes T-symmetric,\n?B = T ?AT. (2.20)\n4\nAnalogously, if the game is T-symmetric fulfilling (2.10),\nthen the transformed operators define an S-symmetric\ngame,\n?B = S ?AS. (2.21)\nThis shows that the conversion CA in (2.14) provides\na one-to-one correspondence, or duality, between an S-\nsymmetric game and a T-symmetric game. Some quan-\ntities in quantum game are invariant under the duality\nmap while other are not. For instance, the trace of the\npayoff,\nTrA =\nsummationdisplay\ni,j\nAij = A00 +A01 +A10 +A11, (2.22)\nremains invariant TrA ? Tr ?A = TrA, whereas the al-\nternate trace defined by\n?(A) =\nsummationdisplay\ni,j\n(?)i+jAij = A00 ?A01 ?A10 +A11, (2.23)\nchanges the sign ?(A) ? ?( ?A) = ??(A).\nIn formal terms, the two games given by {H,A,B}and\n{H, ?A, ?B} are dual to each other in the sense that the\npayoff under the strategy |?,?;?? in one game is equiva-\nlent to the payoff under the dual strategy CA|?,?;?? =\n|??,?;??? in the other. In particular, if the former\ngame happens to be S-symmetric, then the latter is T-\nsymmetric, and vice versa. This allows us to regard any\ntwo games as ?identical? if their payoff operators are re-\nlated by the duality map (2.19).\nEvidently, the other conversionofthe strategiesby Bob\nCB|i,j? = |i,1?j? can also be used to provide a similar\nbut different duality. Besides, their combination,\nC = CA ?CB, (2.24)\nimplements the renaming of the strategies 0 ? 1 for both\nof the players, and yields a duality map which does not\nalter the type of symmetries of the game. These dual-\nity maps CA, CB and C are used later to identify games\ndefined from different classical payoff matrices. We men-\ntion that these dualities are actually a special case of the\nmore general ?gauge symmetry? in quantum game the-\nory, which is that the two games defined by {H,A,B}\nand {H,UAU?,UBU?} with some unitary operator U\nare dual to each other under the corresponding strategies\n|?,?;?? and U|?,?;??. Thus the identification of games\ncan be extended to those which are unitarily equivalent.\nIII. CLASSIFICATION OF T-SYMMETRIC\nGAMES\nThe foregoing argument suggeststhat in order to study\nthe two types of symmetric games it is sufficient to con-\nsider either one of the two. Moreover, even if the two\ngames are of the same symmetric type, a further identi-\nfication may be possible using the full conversion C. In\nview of this, in the following we choose the T-symmetric\ngames and analyze the pattern of the allowed equilibria\nthere. To start with, we furnish the definition of an equi-\nlibrium which corresponds to the NE in classical game\n[18]. A joint strategy |??,??? is called quantum Nash\nequilibrium (QNE), if it satisfies\n?A(??,??;?) ? ?A(?,??;?), (3.1)\nfor all ?, and also\n?B(??,??;?) ? ?B(??,?;?), (3.2)\nfor all ?. Note that the QNE is defined for a given ?\ntreated as a set of external parameters. Below, we study\nthe conditions for ? under which a QNE appears.\nTo evaluate the payoffs explicitly, we write the strate-\ngies as\n|??A = cos(?1/2)|0?A + sin(?1/2)ei?2|1?A,\n|??B = cos(?1/2)|0?B + sin(?1/2)ei?2|1?B, (3.3)\nwith angle parameters ?1,?1 ? [0,pi] and ?2,?2 ? [0,2pi).\nFor convenience, we henceforth adopt both of the ket\nnotations |?? and |i? with the convention that |0? and |1?\nrefer always to the latter notations. Using (3.3) we find\nthat, for a T-symmetric game fulfilling (2.10), the payoff\nfor Alice reads\n?A(?,?;?) = 14{TrA+?(A)cos?1 cos?1\n+I?+(?)cos?1 +I??(?)cos?1\n?I+(?)sin?1 sin?1 sin?2 cos?2\n?I?(?)sin?1 sin?1 cos?2 sin?2},\n(3.4)\nwhere we have defined\nI?(?) = G+(?)?G?(?),\nI??(?) = G?+(?)?G??(?), (3.5)\nwith\nG+(?) = (A00 ?A11)sin?2,\nG?+(?) = (A00 ?A11)cos?2,\nG?(?) = (A01 ?A10)sin?1,\nG??(?) = (A01 ?A10)cos?1.\n(3.6)\nThe payoff ?B(?,?;?) for Bob is readily obtained from\n(3.4) using the relation (2.13). The conditions for QNE\n(3.1) and (3.2) imply\n??i?A(?,??;?)|?? = 0,\n??i?B(??,?;?)|?? = 0, (3.7)\nfor i = 1,2. Besides, the Hessian matrices PA and PB\ngiven by\nPA(?,?;?)ij = ??i??j?A(?,?;?),\nPB(?,?;?)ij = ??i??j?B(?,?;?), (3.8)\n5\n|??,??? Hessian conditions ?A(??,??;?)\n|0,0? H+ > 0, H? > 0 [TrA+?(A)+ 2G?+]/4\n|0,1? H? < 0 [TrA??(A)+ 2G??]/4\n|1,0? H+ < 0 [TrA??(A)? 2G??]/4\n|1,1? H+ > 0, H? > 0 [TrA+?(A)? 2G?+]/4\nTABLE II: Hessian conditions and Alice?s payoffs for edge\nstrategies in T-symmetric games. Bob?s payoffs can be ob-\ntained from ?B(??,??;?) = ?A(???, ???;?).\nmust be both negative semi-deifinite,\nPA(??,??;?) ? 0, PB(??,??;?) ? 0. (3.9)\nUsing (3.4) we obtain, for example,\n??2?A(?,??;?)|?? = ???2?B(??,?;?)|??\n= 14 sin??1 sin??1 [I?(?)sin??2 sin??2\n?I+(?)cos??2 cos??2]. (3.10)\nThese conditions (3.7) and (3.9) will now be analyzed in\ndetail.\nA. Edge strategies\nFrom (3.10) we see that an obvious set of solutions for\n(3.7) are obtained if\nsin??1 = sin??1 = 0. (3.11)\nThese have solutions given by the semiclassical pure\nstrategies |i,j? for i,j = 0,1, i.e., the four ?edge? strate-\ngies,\n|0,0?, |1,1?, |0,1?, |1,0?, (3.12)\nwhich correspond to classical pure strategies (i,j). Note,\nhowever, that these quantum edge strategies differ from\nthe classical counterparts because the joint strategy is\ndetermined with the additional correlation factor J(?).\nNote also that on the edge strategies the unitary opera-\ntion J(?) yields only a one-parameter family of correla-\ntions for joint states |i,j;?? in (2.2), since one of the two\nfactors in (2.11) gives merely an overall phase.\nFor the edge states to become QNE, they also need to\nobey the Hessian conditions (3.9), which pose different\nrequirements for the states as\n|0,0? : H+(?) > 0, H?(?) > 0,\n|0,1? : H?(?) < 0,\n|1,0? : H+(?) < 0,\n|1,1? : H+(?) > 0, H?(?) > 0,\n(3.13)\nwhere we have used\nH?(?) = ?(A)?I?+(?), (3.14)\nlabel QNE characteristics\nBoS |0,0? and |1,1? none\nPD |1,0? or |0,1? not Pareto optimal\nSH |1,0? and |0,1? either payoff or risk dominant\nTABLE III: QNE and their characteristics in the domains\non the G?+-G?? plane classified by the labels of the classi-\ncal games. Both PD and SH games are mapped to their T-\nsymmetric dual versions.\nand ignored the cases of equalities for brevity. These con-\nditions and the payoffs for the edge solutions are sum-\nmarized in Table II. To see when these conditions are\nfulfilled for different ?, it is convenient to consider the\nplane coordinated by (G?+,G??) with G?? given in (3.6).\nOne then sees that, as shown in Figure 1, the entire pa-\nrameter region of ? is mapped to a rectangular area in\nthe centre of the G?+-G?? plane with the horizontal length\nLh and the vertical length Lv given by\nLh = 2|A00 ?A11|, Lv = 2|A01 ?A10|. (3.15)\nIt is worth noting that, at each of the midpoints of\nthe four edges, the operation J(?) can yield a maximally\nentangled joint strategy state. For instance, for A01 >\nA10 the midpoint (G?+,G??) = (0,Lv/2) corresponds\nto J(pi/2,0) under which the edge state |01? becomes\n(|01? + i|10?)/?2. Similarly, for A00 > A11 the mid-\npoint (G?+,G??) = (Lh/2,0) corresponds to J(0,pi/2) un-\nder which the edge state |00? becomes (|00?+i|11?)/?2.\nThe four corners of the rectangle, on the other hand, cor-\nrespond to J(mpi,npi) for m,n = 0,1, which are S, T, C,\nand I operations, and hence the resultant joint strategies\nare all unentangled. On the G?+-G?? plane, the Hessian\nconditions determine the domains of allowed edge QNE\nwhich are separated by the parallel lines H?(?) = 0 (see\nFigure 1). Observe that the allowed edge QNE are differ-\nent depending onthe domains, and that the combinations\nof the QNE change when the sign of ?(A) is reversed.\nNote that for ?(A) > 0 all edge strategies in (3.12) could\narise as a QNE for some ?, whereas for ?(A) < 0 only\n|0,1? and/or |1,0? become QNE.\nAs will be seen shortly, as long as the edge strategies\nareconcerned our quantum gameis simulated by classical\ngames possessing the corresponding NE. In view of this,\nwe may characterize the domains on the G?+-G?? plane\nby the typical classical games sharing the same NE. We\ndo this by using the BoS, PD and SH as the representa-\ntives (see Table III). Here, the label ?BoS? is chosen to\ndesignate the domain of games possessing two edge QNE\nat |0,0? and |1,1?, which is an obvious choice because\nthe classical BoS game is T-symmetric and has the cor-\nresponding NE at (i,j) = (0,0) and (1,1). None of these\nNE admits better payoffs to both of the players, simulta-\nneously, leading to the dilemma that they cannot decide\non which strategy the should choose. The domain ?BoS?\narises only for ?(A) > 0 and the required conditions are\nBoS : H+ < 0, H? < 0. (3.16)\n6\nG?+\nG??\n? > 0\nH? = 0H+ = 0\n|0,1?\n|1,0?\nBoS\nPD\nPD\nG?+\nG??\n? < 0\nH+ = 0H? = 0\n|0,1?\n|1,0?\nSH\nSH\nPD\nPD\nFIG. 1: Phase structures of QNE in terms of edge strategies: ?(A) > 0 (above), ?(A) < 0 (below). The names of the domains\nare borrowed from the classical games sharing the same characteristic dilemmas (see Table III). Games in the domains without\nnames are free from dilemmas within edge strategies and possess a single stable strategy |1,0? or |0,1? among at most two QNE.\nThe correlation family of a quantum game forms a rectangle on the plane, as shown by the dotted line for the case ?(A) > 0.\nThe domain fulfilling these forms a diagonal strip be-\ntween the parallel lines H? = 0 on the G?+-G?? plane\n(see Figure 1).\nTo justify the assignment of the other labels, recall\nthat the classical PD game is an S-symmetric game and\nhas a NE at (1,1) which is unique. The problem of the\ngame is that the NE is not Pareto optimal, i.e., there\nexists another strategy which improves the payoffs for\nthe two players, simultaneously, and this constitutes the\ndilemma. Upon quantization, the quantum PD, in the\nclassical limit, will have one edge QNE at |1,1?, which\nturns into |0,1? by the duality map (2.14) when it is\nemployed to convert the PD into the T-symmetric dual\nversion. For this reason, we use ?PD? to label the do-\nmain of those T-symmetric games possessing the edge\nQNE at |0,1? which is not Pareto optimal. The Pareto\noptimality can be examined by comparing the payoff val-\nues with other strategies, and in the present case this\nis done essentially by comparing the payoffs between the\ntwo strategies|1,0? and |0,1?. From Table II, we see that\nthis situation occurs when\nPD : H+ > 0, H? < 0, G?? < 0. (3.17)\nWe also use the same label ?PD? for the domain of games\npossessing a QNE at |1,0? which is not Pareto optimal,\nsince thoseareidentified bythe full conversionC in (2.24)\nwith the standard quantum PD. This is the case when\nwe have\nPD : H+ < 0, H? > 0, G?? > 0. (3.18)\nAs shown in Figure 1, the domains of PD appear both\nfor ?(A) > 0 and ?(A) < 0.\nThe classical SH game, on the other hand, is an S-\nsymmetric game which has two NE at (0,0) and (1,1),\nin which (0,0) is payoff dominant (i.e., better than (1,1)\nin the payoff) and (1,1)is risk dominant (i.e., better than\n(0,0) in the ?average? over the choice of the other player).\nThe dilemma is that, while (0,0) is Pareto optimal, (1,1)\nis preferable for the minimal risk, which makes the play-\ners uncertain to decide which to choose. Now, after the\nquantization and the application of the duality map to\nget the T-symmetric quantum version of the game, we\nwill have two edge QNE at |1,0? and |0,1? in the classi-\ncal limit, with payoff dominant |1,0? and risk dominant\n|0,1?. We therefore use the label ?SH? to name the do-\nmain in which the games possess the same QNE with the\nabove property. In the presence of correlations, we find\nfrom Table II that the payoff dominance of |1,0? requires\nG?? < 0. The risk dominance of |0,1? demands that the\naverage payoff Alice receives under the choice |0?A be\nlarger than that obtained under the choice |1?A, which\nis ensured if G?+ + G?? > 0. As in the case of the PD,\nthe label ?SH? is also used for the domain of games pos-\nsessing the two QNE with payoff dominant |0,1? and risk\ndominant |1,0? for Alice, which are possible if G?? > 0\nand G?+ + G?? < 0. These domains ?SH? are allowed\nonly for ?(A) < 0 where |1,0? and |0,1? arise as QNE\nbetween the two parallel lines H? = 0 on the G?+-G??\nplane. Combined with the above additional conditions,\nthe SH domains are characterized by\nSH : H+ > 0, H? > 0, G??(G?+ +G??) < 0. (3.19)\nAs shown in Figure 1, the classification of the games\nleavesunlabeled domains on the G?+-G?? plane for each of\nthe cases ?(A) > 0 and ?(A) < 0. For ?(A) > 0, we find\ntwo separate domains which contain games possessing a\nunique QNE, either at |0,1? or |1,0?. These QNE are\nPareto optimal, and hence the games are free from the\ndilemma of the PD type. For ?(A) < 0, we have two ad-\nditional domains of games possessing QNE at |0,1? and\n|1,0?, which are free from the dilemma of the SH. This\nresult suggests that, if the game under consideration can\nbe driven to lie in these unlabeled domains by adjusting\nthe correlations appropriately, then the original dilemma\nmay be resolved under these correlations, at least within\nthe realm of edge strategies. In this respect, the phase\ndiagram given by Figure 1 provides a convenient basis to\nexamine the problem of optimality of strategies in quan-\ntum games.\nSince the correlation-family of a symmetric quantum\ngame is mapped to a rectangle on the G?+-G?? plane, we\ncan classify quantum games in terms of the patterns of\nthe rectangle formed on the plane. As shown in Figure\n7\nFIG. 2: Four patterns of rectangles which are possible in re-\nlation to the parallel lines H? = 0 provide distinct phase\nstructures for symmetric quantum games. The rectangle may\nreduce to a line as we see in the case of the BoS later.\n2, there are four types of rectangles, determined from\nthe values of Lh and Lv in (3.15), which are different\nin position with respect to the parallel lines H?(?) = 0\nappearing in Figure 1. Combining the two cases ?(A) > 0\nand?(A) < 0 whichoffer different structuresfor domains,\nwe find that there are altogether eight classes of quantum\ngames which have distinct phase structures of QNE in\nterms of edge strategies.\nOne of the advantages of the present quantization\nscheme is that it allows us to establish the connection\nbetween the classical and quantum games in a simple\nmanner and thereby examine how ?quantum? the game\nactually is. To see this, let us introduce the correlated\npayoff matrices\nA(?) = J?(?)AJ(?), B(?) = J?(?)BJ(?). (3.20)\nWith these, the payoffs (2.3) are expressed in terms of\nseparable (uncorrelated) states\n?A(?,?;?) = ??,?|A(?)|?,??,\n?B(?,?;?) = ??,?|B(?)|?,??. (3.21)\nOne may decompose each of the correlated payoffs into\n?pseudo-classical? and ?interference? terms as\nA(?) = Apc(?)+Ain(?), (3.22)\nwith\nApc(?) = cos2 ?12 A+ (cos2 ?22 ?cos2 ?12 )SAS\n+ sin2 ?22 C AC,\n(3.23)\nwhere C is given in (2.24) and\nAin(?) = i2 sin?1 [A,S] + i2 sin?2[A,T]. (3.24)\nThe pointis thatthe pseudo-classicalpartApc isdiagonal\nand hence for separable strategies it can be interpreted\nas a classical payoff matrix. In contrast, the interference\npart Apc is non-diagonal and represents a non-classical\ncontribution. Accordingly, the payoff for Alice in a T-\nsymmetric game is decomposed into the sum ?A = ?pcA +\n?inA, where we have\n?inA(?,?;?) = 0, (3.25)\nfor edge strategies. This observation confirms that our\nquantum game with edge strategies are, in effect, equiv-\nalent to the classical game with the payoff matrices Apc\nand Bpc (the latter can be defined analogously for the\ncorrelated payoff B(?)). Possible game theoretical inter-\npretations of the pseudo-classical payoff based on altru-\nism and value-conversion have been noted in Ref.[7].\nB. Non-edge strategies\nTo discuss QNE beyond the edge strategies (3.12), we\nrecall (2.13) and seek solutions which are T-symmetric,\n|??,??? = |???, ????. In the representation (3.3) of the\nstate (which is defined up to an overall phase), this trans-\nlates into\n??1 ???1 = pi, ??2 +??2 = pi. (3.26)\nUnder the T-symmetric ansatz and the non-edge require-\nment sin??1 negationslash= 0, the conditions in (3.7) imply\ncos??1 [?(A)?G?(?)sin2??2]?I?+(?) = 0,\nG?(?)cos2??2 +G+(?) = 0. (3.27)\nBesides, the Hessian condition (3.9) implies\nG? sin2??2 ? 0. (3.28)\nBefore analyzing the solutions in detail, we observe\nthat at the classical limit ? = 0 the above conditions are\nsimplified to the single condition,\ncos??1 = ?+(A)?(A) , (3.29)\nwith ?+(A) defined as\n??(A) = (A00 ?A11)?(A01 ?A10). (3.30)\nThe condition (3.29) has a solution when |?(A)| ?\n|?+(A)|, which is equivalent to\nA00 ? A10 and A11 ? A01, or\nA00 ? A10 and A11 ? A01. (3.31)\nThe solution for (3.29) corresponds to the NE for mixed\nstrategies in classical games with x?1 = y?1 = cos2(??1/2),\nand (3.31) agrees precisely with the conditions for such\nnontrivial NE to arise. It is important to note, how-\never, that the non-edge QNE in quantum game and the\nmixed NE in classical game are completely different in\nthe meaning of strategies. Namely, the NE in classical\ngame is relevant only for the situation where the games\n8\nFIG. 3: Possible patterns of allowed regions by (3.33) in the\nrectangle of the game under Lh < Lv (left), Lh = Lv (middle)\nand Lh > Lv (right). These regions are shaded, and the dot\nin the centre represents the origin of the G?+-G?? plane.\nare repeated many times in which the players can con-\nsider probability distributions in choosing their strategies\n? the mixed NE and pure NE belong to different cate-\ngories conceptually. In contrast, the non-edge QNE in\nquantum game is a pure strategy and meaningful with-\nout repeating the game ? it belongs to the same category\nas the edge QNE.\nTo discuss solutions for generic ?, we notice first that\nthe second condition in (3.27) determines ??2, which can\nbe used to determine ??1 in the first condition. In terms\nof ?(?) :=\nradicalBig\nG2? ?G2+ for which we have\n?2 = (G?+)2 ?(G??)2 ??+ ??, (3.32)\nthe condition for the existence of ??2 reads\n? ? 0. (3.33)\nNotice that ?+ ?? = (L2h ?L2v)/4 measures the squared\ndifference in length between the two edges of the rectan-\ngle of the game. It follows that the regions allowed by\n(3.33) are those enclosed by the two hyperbolae ?2 = 0\nand the edges of the rectangle, which vary depending on\nthe types of the rectangle (see Figure 3).\nOn the other hand, by combining the two conditions\nin (3.27) and (3.28) we see that the solution for ??1 exists\nif\n(H+ + ?)(H? + ?) ? 0. (3.34)\nUsing (3.32), one can readily depict the regions where\n(3.34) is fulfilled on the G?+-G?? plane. The games be-\nlonging to the overlapped areas of the above two regions\nadmit non-edge QNE, and this is indeed possible if the\npayoff A meets certain conditions, as illustrated by the\nSH game later. When this happens, the non-edge QNE,\nwhich we denote by |??,??;?? = |?ne,?ne;??, offers the\nsame payoff (as ensured by the T-symmetry) for Alice\nand Bob,\n?A(?ne,?ne;?) = ?B(?ne,?ne;?)\n= 14\nbracketleftbigg\nTrA+ ?(A)?(?)??+(A)??(A)?(A) + ?(?)\nbracketrightbigg\n. (3.35)\nIn particular, at the classical limit the payoff becomes\n?A(?ne,?ne;0) = A00A11 ?A01A10A\n00 +A11 ?A01 ?A10\n, (3.36)\nwhich is the familiar payoff expression for the mixed NE\nin classicalT-symmetricgames. This showsthat the non-\nedge QNE are actually an extension of the classicalmixed\nNE. In fact, at the classical limit, we find from ?(0) = 0\nthat the condition (3.33) is trivially fulfilled, and that\n(3.34) reduces to\nH+(0)H?(0) = 4(A00 ?A10)(A11 ?A01) ? 0, (3.37)\nwhich is exactly the condition for mixed NE (3.31). In\nother words, if the classical game admits a mixed NE,\nthen the quantum game defined from the classical game\nadmits a QNE for a certain range of correlations includ-\ning the classical limit.\nTo summarize, non-edge QNE may exist as an exten-\nsion of mixed NE under various correlations in quantum\ngame theory, and their existence can be examined from\nthe rectangle of the game specified from the classical pay-\noff matrix Aij. Game theoretical analysis, including the\nresolution of dilemma in classical game, should be made\nbased on the combination of edge and non-edge QNE.\nIV. DILEMMAS IN BOS, PD AND SH\nHaving obtained the phase structures of symmetric\nquantum games for edge QNE as well as the conditions\nfor non-edgeQNE,we nowexamineif andhowthe typical\ndilemmas familiar in classical game theory ? the dilem-\nmas in the BoS, the PD and the SH game ? can be re-\nsolved in quantum game theory. All of the dilemmas\nin these cases are intrinsically different, and there is no\nunique criterion for the resolution. We thus consider the\nresolution based on the conventional requirements which\nare attached to the respective classical games, and find\nthat the quantization of the games lead to considerably\ndifferent outcomes for the three cases.\nA. Battle of the Sexes\nThe BoS game is a special case of the T-symmetric\ngame specified by the payoff matrix,\nA00 > A11 > A01 = A10. (4.1)\nThe degeneracy A01 = A10 provides the T-symmetric\ngame with an extra symmetry between the payoff matri-\nces, that is,\nB = T AT = C AC. (4.2)\nOnaccountofthe degeneracy,we haveG?(?) = G??(?) =\n0, which implies that the parameter ?1 drops out from\nour consideration of QNE. Notice that the BoS defined\nby (4.1) has ?(A) > 0 and that, as shown in Figure 4, the\nrectangle of the game in the G?+-G?? plane is smashed to\na line on the G?+-axis with length Lh. Notice also from\nA00 > A11 that the classical limit is found at the right\n9\nend of the line. Now, an important point to observe is\nthat since\n?(A)?(A00 ?A11) = 2(A11 ?A01) > 0, (4.3)\nthe line segment of the game lies entirely within the BoS\ndomain (see Figure 4). This shows that, so far as the edge\nstrategies are concerned, even in the presence of the cor-\nrelation J(?), the dilemma in the BoS does not disappear\nin quantum game. Using (3.21) and (3.23), Alice finds\nher payoff ?A(i,i;?) at the edge QNE |??,??? = |i,i? for\ni = 0,1 as\n?A(i,i;?) = cos2 ?22 Aii + sin2 ?22 A?i?i. (4.4)\nNote that the correlationinterpolates between the largest\ntwo payoff values A00 and A11, and hence ?A(i,i;?) ?\nA11 for both of the edge QNE, i = 0,1.\nTo see if the dilemma can be resolved by taking non-\nedge QNE into account, we first observe that for BoS the\nconditions (3.27) are fulfilled for ?2 = 0, pi with arbitrary\n?1. For that non-edge QNE, the payoff ?A(?ne,?ne;?) in\n(3.35) reduces to (3.36) with A01 = A10. At ?1 = 0 this\nnon-edge QNE corresponds to the known mixed strategy\nNE in classical BoS, which cannot resolve the dilemma\nsince the payoffs are strictly less than those obtained un-\nder the two edge QNE for both of the players. The situa-\ntion doesnot improveevenfor?1 negationslash= 0, because the payoffs\nare independent of ?1 for all strategies. Moreover, on the\ngeneral basis of the assignments (4.1) (i.e., without mak-\ning use of the ansatz (3.26)), one can confirm by looking\nat the Hessian condition (3.9) that there is no non-edge\nQNE for BoS except for the one mentioned above. Thus\nwe find that under any correlations ? for the non-edge\nQNE we have ?A(?ne,?ne;?) < A11 and hence\n?A(i,i;?) > ?A(?ne,?ne;?), for i = 0,1. (4.5)\nAlthough the dilemma does not disappear even in\nquantum BoS, one may argue that the problem is some-\nwhat mitigated at?2 = pi/2 wherethe joint strategystate\nis maximally entangled. Indeed, under this correlation\nthe payoffs for the two edge QNE (4.18) for i = 0,1 coin-\ncide and hence the choice of strategies becomes irrelevant\nfor the players. The dilemma still remains in essence [16],\nhowever, because the players, who cannot communicate,\nmay inadvertently end up with a wrong strategy, |0,1? or\n|1,0?, yielding the worst payoff ?A = ?B = A01 (for all\n?). A similar conclusion has been drawn for BoS in [2, 8]\nusing a different quantization scheme with mixed quan-\ntum states, while a way out is suggested in an extended\nscheme [9]. The analysis [3] made in the scheme of [1]\nyields a considerably different outcome, with infinitely\nmany QNE with the payoffs lower than those of our edge\nQNE, indicating that the dilemma is unresolved unless\nsome subtle reasoning (focal point effect) is invoked.\nG?+\nG??\nCL\nME\nFIG. 4: Phase structure of edge QNE in the BoS game. The\nrectangle of the game is smashed to a line segment lying at the\ncentre as shown by the dotted line, which is entirely contained\nin the BoS domain. The right end point CL is the classical\nlimit and the middle point ME represents the point where the\nmaximally entangled correlation is realized.\nB. Prisoners? Dilemma\nThe PD game can also be analyzed in our scheme by\nconverting it to a dual T-symmetric game using the map\n(2.19). The general S-symmetric PD in classical game\ntheory may be defined by the payoff matrix for Alice Aij\nsatisfying\nA10 > A00 > A11 > A01, (4.6)\ntogether with Bob?s payoff given by Bij = Aji. Supple-\nmental conditions (which is inessential for the following\nargument),\n2A00 > A01 +A10 > 2A11, (4.7)\nmay also be imposed in order to render the strategies\n(i,j) = (0,0) and (1,1) the best and the worst of all\npossible strategies with respect to the sum of the payoffs\n[13]. The quantum PD is obtained by considering the\nself-adjointoperatorsA, B fulfilling (2.4), and the duality\nmap (2.19) yieldsthe T-symmetricversionof the PD with\nthe payoff operator ?A possessing the diagonal (classical)\nvalues\n( ?A00, ?A01, ?A10, ?A11) = (A10,A11,A00,A01). (4.8)\nIn terms of the converted payoff values, the conditions\n(4.6) and (4.7) turn out to be\n?A00 > ?A10 > ?A01 > ?A11, (4.9)\nand\n2 ?A10 > ?A00 + ?A11 > 2 ?A01. (4.10)\nNote that under the duality map for strategies (2.16) the\nparameters of the states (3.3) acquire the change\n(??1, ??2) = (?1 +pi, pi ??2). (4.11)\nIn addition, the duality relation in the correlation (2.18)\namounts to ?1 ? ?2 in G? and G??. To accommodate\nthese changes caused by the duality map, we use nota-\ntions such as\n?G? = G?|A? ?A,????, ?H? = H?|A? ?A,????, (4.12)\n10\nG?+\nG??\nCL\nG?+\nG??\nCL\nFIG. 5: Phase structure of edge QNE in the (T-symmetrized)\nPD game for the cases ?( ?A) > 0 (left) and ?( ?A) < 0 (right).\nFor both of the cases, the rectangle of the game, whose edges\nare shown by dotted lines, extends to domains of no dilemmas.\nfor our discussion of T-symmetric games.\nTo examine the possible phase structures of the game,\nwe observe that neither of the conditions (4.9) and (4.10)\ndetermines the sign of ?( ?A). However, since (4.9) implies\nthat the classical limit ? = 0 locates at the lower right\ncorner of the rectangle of the game, the inequalities\n?H+(0) = 2( ?A00 ? ?A10) > 0,\n?H?(0) = 2( ?A11 ? ?A10) < 0, (4.13)\nobtained at the classical limit ? = 0 from (4.9) are suf-\nficient to specify where the corner lies on the G?+-G??\nplane. The phase structures of the quantum PD game\nare then determined from the patterns of the rectangle\nin both of the cases ?( ?A) > 0 and ?( ?A) < 0, as illustrated\nin Figure 5. The outcome indicates that the correlation-\nfamily given by the rectangle does extend to domains of\nno dilemmas. It follows that, as long as edge QNE are\nconcerned, the quantum PD can be made dilemma-free\nwhen the correlations are furnished appropriately.\nFor a full resolution of the dilemma, we need to see\nwhether a non-edge QNE, if any, alters our conclusion\ndrawn from the edge QNE. This can be examined from\nthe analysis given in the previous section. We then learn\nthat, since the condition (3.31) is violated for (4.9), there\nis no non-edge QNE at the classical limit. We also re-\nalize that, for generic ?, the existence of non-edge QNE\nis dependent on the actual classical values of Aij, and\nthat for a wide range of payoff values centered at the\nstandard ones (A10,A00,A11,A01) = (5,3,1,0) used in\nthe literature (e.g., [1]), there exists no region fulfilling\n(3.33) and (3.34) simultaneously, and hence no non-edge\nQNE. Thus, our conclusion concerning the resolution of\nthe dilemma does not change in these standard settings\nof the PD game.\nC. Stag Hunt\nThe classical SH game is an S-symmetric game in\nwhich the payoff matrix for Alice fulfills the conditions,\nA00 > A10 ? A11 > A01, (4.14)\nwhich ensure that the strategies (0,0) and (1,1) are clas-\nsical NE. Among them, (0,0) is payoff dominant while\nG?+\nG??\nCL\nH+ + ? = 0\nH? + ? = 0\nFIG. 6: Phase structures of edge QNE (left) and non-edge\nQNE (right) in the (T-symmetrized) SH game. For edge\nQNE, the rectangle of the game extends to domains of no\ndilemmas. For non-edge QNE, the allowed regions by (3.33)\nare of the third type in Figure 3, and the two narrow regions\noverlapped with (3.34) shown in thick gray indicate the do-\nmains where a non-edge QNE appears.\nthe other (1,1) becomes risk dominant if\nA10 +A11 > A00 +A01. (4.15)\nAnalogously to the PD, we quantize the SH according to\n(2.4) and then T-symmetrizeit by the duality map (2.19).\nThis yields the payoffoperator ?A with the diagonalvalues\n(4.8) obeying\n?A10 > ?A00 ? ?A01 > ?A11, (4.16)\nand\n?A00 + ?A01 > ?A10 + ?A11. (4.17)\nNote that (4.16) implies ?( ?A) < 0. It also shows that\nthe classical limit is at the lower right corner of the rect-\nangle of the game, and that we have ?H?(0) < 0. From\nthis we can determine the position of the rectangle on the\nG?+-G?? plane as shown in Figure 6. The phase structure\nof the quantum SH game then suggests that, as in PD,\nthe correlation-family given by the rectangle extends to\ndomains without dilemmas. Within the edge strategies,\nthe dilemma of the SH can therefore be resolved in quan-\ntum game, if one adjusts the correlations appropriately.\nThe payoffs ?A(i,?i;?) at the edge QNE |??,??? = |i,?i?\nfor i = 0,1 read\n?A(i,?i;?) = cos2 ?12 ?Ai?i + sin2 ?12 ?A?ii, (4.18)\nwhich fall within the range of the payoffs of the two clas-\nsical NE, ?A10 ? ?A(i,?i;?) ? ?A01.\nThe classical SH game admits a mixed NE, and ac-\ncordingly the quantum SH admits a non-edge QNE for\na range of correlations including the classical limit, as\ncan be confirmed explicitly by examining the condition\n(3.37). To see where such correlations occur on the G?+-\nG?? plane, we consider the lines of equality H? + ? = 0\ndetermined by the condition (3.34), which are rewritten\nas\nG?+ = ?G?? ? ?\n2 +?+??\n2(G?? ??). (4.19)\n11\nCL:\nstrategy Bob |0? Bob |1? Bob |?ne?\nAlice |0? (3,0) (3,3) (3,3/4)\nAlice |1? (4,4) (0,3) (3,15/4)\nAlice |?ne? (15/4,3) (3/4,3) (3,3)\nME:\nstrategy Bob |0? Bob |1? Bob |?ne?\nAlice |0? (3,0) (7/2,7/2) (3,0)\nAlice |1? (7/2,7/2) (0,3) (7/2,7/2)\nAlice |?ne? (7/2,7/2) (0,3) (7/2,7/2)\nTABLE IV: Quantum payoff bi-matrices (?A,?B) of the SH\ngame for edge QNE and non-edge QNE. We used the values\n?A10 = 4, ?A00 = ?A01 = 3 and ?A11 = 0 (obtained from those\nmentioned in the text) to evaluate the payoffs at the classi-\ncal limit CL and the maximally entangled point ME, which\nare given by (G?+,G??) = (3,?1) and (3,0), respectively. The\npresence of the non-edge QNE worsens the risk balance be-\ntween the two edge QNE as we increase the amount of en-\ntanglement, but the dilemma disappears at ME where their\npayoffs become identical, for which the non-edge QNE does\nnot contribute.\nFor the SH we find ?2+?+?? > 0 from (4.16) and (4.17).\nThe domains where the non-edge QNE arise are then\nfound to be surrounded by the hyperbolae ? = 0 and\nthe curves (4.19), both of which come in contact at\n(G?+,G??) = ? 12? parenleftbig?2 +?+??,?2 ??+??parenrightbig. (4.20)\nAs illustrated in Figure 6, these domains are given by\ntwo narrow regions along the left and right edges of the\nrectangle of the game, indicating that under generic cor-\nrelations the non-edge QNE does not spoil the resolution\nof the dilemma in terms of edge QNE. It is, however,\nconceivable that the non-edge QNE, in the region where\nit is allowed, could alter the nature of the dilemmas, that\nis, the non-edge QNE could be both payoff and risk dom-\ninant under some particular correlations in the domains\nof SH, or it could pose a new dilemma in the domains\nwhere there was no dilemma originally. These possibili-\nties should be examined for the actual values of the payoff\nmatrix (4.16), but the analysis with the standard values\n(A00,A10,A11,A01) = (4,3,3,0) given in Table IV sug-\ngests that these are not likely to occur unless the payoff\nvalues are fine-tuned.\nV. CONCLUSION AND DISCUSSIONS\nIn this paper, we studied the phase structures of sym-\nmetric quantum games with respect to the stable strate-\ngies (QNE) available by pure states in quantum mechan-\nics. For quantization of classical games we adopted the\nscheme [7] which defines a unique correlation-family of\nquantum games from a classical game, allowing for all\npossible strategies realized by pure states, entangled or\nnot. The correlation-family is projected onto a rectangu-\nlar area in the G?+-G?? plane, where the phase structures\nof both the edge and non-edge QNE in the game can\nreadily be recognized. We have found that for symmet-\nric games there arise altogether eight different classes of\nphase structures for edge QNE depending on the payoff\nmatrices of the classical game we started with. This re-\nsult gives a more detailed account of the phase structures\nmentioned in [1] and discussed later in [5, 11].\nThe symmetric games considered in this paper consist\nof two types, T-symmetric and S-symmetric. We have\npresented a unified framework to treat them by means\nof a duality map, which enables us to use the results\nof the analysis of T-symmetric games for studying S-\nsymmetric games and vice versa. As an example of the\nT-symmetric game, we studied the BoS which is known\nto be a?icted with a dilemma classically. We have found\nthat the dilemma in the BoS cannot be resolved fully\n(albeit it can be alleviated) with strategies given by pure\nstates, even if we go over to quantum game where arbi-\ntrarily entangled states are utilized. Thus, the previous\nobservation made in [2, 8] remains essentially unchanged\neven in our enlarged scheme of quantum game, while the\noutcome is considerably different from those obtained in\nother schemes [3, 9]. As for the S-symmetric game, we\nexamined the PD and the SH to observe that for both of\nthe games the correlation-family contains a phase which\nis free from dilemmas under edge QNE. Since the stan-\ndard PD does not admit non-edge QNE, we concluded\nthat for the PD the classical dilemma disappears after\nquantization. For the SH, on the other hand, there ex-\nists a non-edge QNE which does not affect the resolution\nrealized by the edge QNE, generically. In short, quantum\nentanglement can resolve classical dilemmas for certain\ngames, and the games for which this is possible can be\njudged from the classical payoff matrices. We remark\nthat entanglement is necessary for the resolution of the\ndilemmas in our scheme, and that this is so in any other\nschemes of quantum games in which the resolution is pos-\nsible and the classical games are recovered in the limit\nwhere the joint strategies become separable as in (2.5).\nHowever, the actual amount of entanglement required de-\npends on the scheme used (because the class of families\nconsidered may be scheme-dependent) as well as on the\nvalues of the classical payoffs.\nCompared to most other schemes proposed so far, our\nscheme of quantum game is distinguished in the specifica-\ntion of strategies and correlations which are expressed in\nthe ordering of operations implementing them. Namely,\nin our scheme the players first make their choice of strate-\ngies independently, by performing the corresponding lo-\ncal unitary transformations on a fixed separable state,\nbefore a third party furnishes a correlation for the local\nstates. The player?s strategy is represented by a quantum\nstate, not by the local unitary transformation as consid-\nered in [1]. The advantage for this is that different pure\nstates used to specify the strategies yield different out-\ncomes of the payoff in general, while this is not ensured\nif unitary transformations are regarded as strategies. In\n12\nfact, it has been pointed out [6] that unitary transfor-\nmations become redundant (i.e., different unitary oper-\nations give the same quantum states) when the strate-\ngies are maximally entangled. Obviously, the choice of\nquantization scheme is directly related to the question of\nthe role of the third party which provides the quantum\ncorrelation in the game, and this has not been fully ex-\nplored yet. In this regard, we have found here a number\nof interesting features of quantum games which are com-\nmonly observed in various different schemes, in the phase\nstructures of the QNE and the resolution of dilemmas in\nsome of the familiar games. We hope that these findings\nwill help uncover the core elements ? independent of the\nscheme employed ? in quantum games, which are crucial\nfor laying a solid foundation of quantum game theory.\nAcknowledgments\nWe thank T. Cheon for helpful discussions. This work\nis supported by the Grant-in-Aid for Scientific Research,\nNo.13135206and No.16540354,ofthe JapaneseMinistry\nof Education, Science, Sports and Culture.\n[1] J. Eisert, M. Wilkens and M. Lewenstein, Quantum\ngames and quantum strategies, Phys. Rev. Lett. 83\n(1999) 3077-3080.\n[2] L. Marinatto and T. Weber, A quantum approach to\nstatic games of complete information, Phys. Lett. A272\n(2000) 291-303.\n[3] J. Shimamura, S. K. ?Ozdemir, F. Morikoshi and N.\nImoto, Quantum and classical correlations between play-\ners in game theory, Int.Journ. Quant.Inf.2(2004) 79-89.\n[4] J. Eisert and M. Wilkens, Quantum Games, J. Mod. Opt.\n47 (2000) 2543-2556.\n[5] J. Du, X. Xu, H. Li, X. Zhou and R. Han, Playing Pris-\noner?s Dilemma with Quantum Rules, Fluct. and Noise\nLett. 2 (2002) 189-203.\n[6] S. C. Benjamin and P. M. Hayden, Comment on ?Quan-\ntum Games and Quantum Strategies?, Phys. Rev. Lett.\n87 (2001) 069801.\n[7] T. Cheon and I. Tsutsui, Classical and Quantum Con-\ntents of Solvable Game Theory on Hilbert Space, Phys.\nLett. A348 (2006) 147-152\n[8] L. Marinatto and T. Weber, Reply to ?Comment on: A\nQuantum Approach to Static Games of Complete Infor-\nmation?, Phys. Lett. A277 (2000) 183-184.\n[9] A. Nawaz and A. H. Toor, Dilemma and Quantum Battle\nof Sexes, J. Phys. A: Math. Gen. 37 (2004) 4437-4443.\n[10] A. Nawaz and A. H. Toor, Generalized Quantization\nScheme for Two-Person Non-Zero-Sum Games, J. Phys.\nA: Math. Gen. 37 (2004) 11457-11463.\n[11] J. Du, X. Xu, H. Li, X. Zhou and R. Han, Experimental\nrealization of quantum games on a quantum computer,\nPhys. Rev. Lett. 88 (2002) 137902.\n[12] A. P. Flitney and D. Abbott, Advantage of a quantum\nplayer over a classical one in 2x2 quantum games, Poc\n.R. Soc. (London) A459 (2003) 2463-2474.\n[13] E. Rasmusen, An Introduction to Game Theory, Cam-\nbridge Univ. Press, Cambridge, 1989.\n[14] J. F. Nash, Equilibrium points in N-person games, Proc.\nNat. Acad. Sci. U.S.A. 36 (1950) 48-49.\n[15] C. F. Lee and N. Johnson, Quantum Game Theory, Phys.\nRev. A67 (2003) 022311.\n[16] S. C. Benjamin, Comment on ?A quantum approach to\nstatic games of complete information?, Phys. Lett. A277\n(2000) 180-182.\n[17] Apart from the irrelevant freedoms concerning the over-\nall phase and the normalization, the dimensionality of the\njoint strategy space is dimH ? 2 = 6 in real variables.\nSince the individual strategies |??A and |??B are specified\nby 2 + 2 = 4 parameters (e.g., see (3.3)), the correlation\nfactor must have another 2 parameters to cover the full\njoint strategy space. The actual construction of the cor-\nrelation factor is far from unique, and our form (2.11) is\nadopted based on the convenience for the duality map.\n[18] In the present paper, we consider quantum joint strate-\ngies given by pure states only. The space of pure states is\nnot convex, and hence the Nash theorem [14], which en-\nsures the existence of NE for a classical game with mixed\nstrategies, is no longer available. The existence of QNE\nin quantum game is, therefore, non-trivial [15].\n"}
{"id":"oai:arXiv.org:hep-ph/0612309","text":"arXiv:hep-ph/0610379v2  12 Jul 2007\nDirect detection of neutralino dark matter in non-standard\ncosmologies\nGraciela B. Gelmini,1, ? Paolo Gondolo,2, ? Adrian Soldatenko,1, ? and Carlos E. Yaguna1, ?\n1Department of Physics and Astronomy, UCLA,\n475 Portola Plaza, Los Angeles, CA 90095, USA\n2Department of Physics, University of Utah,\n115 S 1400 E # 201, Salt Lake City, UT 84112, USA\nAbstract\nWe compute the neutralino direct detection rate in non-standard cosmological scenarios where\nneutralinos account for the dark matter of the Universe. Significant differences are found when\nsuch rates are compared with those predicted by the standard cosmological model. For bino-\nlike neutralinos, the main feature is the presence of additional light (m? lessorsimilar 40 GeV) and heavy\n(m? greaterorsimilar 600 GeV) neutralinos with detection rates within the sensitivity of future dark matter\nexperiments. For higgsino- and wino-like neutralinos lighter than m? ? 1 TeV, enhancements of\nmore than two orders of magnitude in the largest detection rates are observed. Thus, if dark matter\nis made up of neutralinos, the prospects for their direct detection are in general more promising\nthan in the standard cosmology.\n?Electronic address: gelmini@physics.ucla.edu\n?Electronic address: paolo@physics.utah.edu\n?Electronic address: asold@physics.ucla.edu\n?Electronic address: yaguna@physics.ucla.edu\n1\nI. INTRODUCTION\nThe Large Hadron Collider is now in its final preparation stages and may soon be search-\ning for supersymmetric particles. Among them, the lightest neutralino in the minimal su-\npersymmetric standard model plays a distinctive role as a dark matter candidate [1]. It is\nneutral, weakly interacting, and stable (provided it is the lightest supersymmetric particle).\nIf evidence for low energy supersymmetry is found, it will strongly support the idea that\nneutralinos constitute the dark matter of the Universe. A logical next step would then be\nthe use of neutralinos as cosmological probes of the early Universe. Neutralinos could, in\nparticular, test the standard cosmological model well before big bang nucleosynthesis. Being\nan observable sensitive to the conditions in the early Universe, the neutralino direct detec-\ntion rate provides a plausible way of discriminating between different cosmological models,\nand therefore an indirect way of testing the standard scenario. Most studies on the direct\ndetection of neutralinos already assume the standard cosmology so it is not known what to\nexpect in a more general cosmological framework.\nThe vastness of the supersymmetric parameter space is the most compelling reason to\nassume the standard cosmological model. In a general setup, neither the neutralino mass\nor gauge composition nor its interaction rate, for example, can be determined a priori. To\nreduce such uncertainties, the dark matter constraint is usually imposed on supersymmetric\nmodels. That is, the neutralino relic density is computed within the standard cosmological\nmodel and only models with ?std < ?DM are considered (here ?std is the neutralino density\nin the standard cosmological model, and ?DM is the cold dark matter density, both in units\nof the critical density). This bound, it turns out, is very effective in restricting the parameter\nspace of supersymmetric models. In minimal supergravity models (mSUGRA), for instance,\nthe neutralino typically has a small annihilation rate in the early Universe, thus its relic\ndensity tends to be larger than observed. At the end, the requirement ?std < ?DM is found\nto be satisfied only along four narrow regions: the ?bulk? (with a light neutralino and tight\naccelerator constraints), the ?coannihilation region? (where the stau is almost degenerate\nwith the neutralino and coannihilation effects suppress the relic density), the ?funnel region?\n(where m? ?mA/2 and resonance effects enhance the ?-? annihilation rate) and the ?focus\npoint region? (where the neutralino acquires a non-negligible higgsino fraction). Accounting\nfor the dark matter provides, in fact, the most stringent constraint on supersymmetric\n2\nmodels, well over precision data or accelerator searches (see e.g. [2]).\nThough useful in reducing the supersymmetric parameter space, the dark matter con-\nstraint should not be taken for granted, as it relies on untested assumptions about the early\nUniverse. In particular, it postulates that the entropy of matter and radiation is conserved\nand that the Universe is radiation dominated at high temperatures (T ? m?). Several sce-\nnarios where such assumptions do not hold and, more generally, where the evolution of the\nUniverse before big bang nucleosynthesis deviates from the standard cosmological model,\nhave been studied in the literature. They are generically known as non-standard cosmolo-\ngies and include models with gravitino [3], moduli [4] or Q-ball decay [5], thermal inflation\n[6], the Brans-Dicke-Jordan [7] cosmological model, models with anisotropic expansion [8]\nor quintessence domination [9]. Non-standard cosmological models are viable alternatives\nagainst which the predictions of the standard scenario may be compared.\nIn non-standard cosmological scenarios, the neutralino relic density ?? may be larger or\nsmaller than ?std [11]-[20]. Smaller densities are usually the result of an episode of entropy\nproduction that dilutes the neutralino abundance. Larger densities are due either to ad-\nditional contributions to the expansion rate of the Universe, or to non-thermal neutralino\nproduction mechanisms. Usually these scenarios contain additional parameters that can be\nadjusted to modify the neutralino relic density. A distinctive feature of non-standard\ncosmologies is that the new physics they incorporate does not manifest in ac-\ncelerator or detection experiments. That is certainly the case, for instance, for\nthe several models mentioned above. Neutralino scattering rates, therefore, are\nnot affected by the cosmological model.\nA prototype non-standard cosmological model is that of a scalar field ? with\ncouplings of gravitational strength whose late decay reheats the Universe to\na low reheating temperature. The reheating temperature in this scenario can\nbe lower than the standard neutralino freeze-out temperature without spoiling\nprimordial nucleosynthesis [10]. Such scalar fields are common in superstring\nmodels where they appear as moduli fields. In these models, the decay of ?\ninto radiation increases the entropy, diluting the neutralino number density.\nInstead, the decay of ? into supersymmetric particles, which eventually decay\ninto neutralinos, increases the neutralino number density. In this non-standard\ncosmological model it has been shown that practically all neutralinos can have\n3\nthe density of the dark matter, provided the right combination of two parameters\ncan be achieved in the high energy theory: the reheating temperature, and\nthe ratio of the number of neutralinos produced per ? decay over the ? field\nmass [19, 20].\nIn this paper, we compute the neutralino direct detection rate in generic cosmological\nscenarios where neutralinos constitute the dark matter of the Universe. That is, we assume\nthat, independently of the supersymmetric spectrum, the parameters of the non-standard\ncosmological model can always be chosen so that ?? = ?DM. By randomly scanning the\nsupersymmetric parameter space, we obtain a large sample of models and compute their\ndetection rates in non-standard cosmologies. These predictions are then compared with\nthose obtained within the standard cosmological model. Our goal is twofold. First, we\nexplore the possibility of using the neutralino direct detection rate as a test of the standard\ncosmological model. Second, we establish the potential of future dark matter detectors in\nprobing the parameter space of supersymmetric models in a cosmology-independent setup.\nII. THE SUPERSYMMETRIC MODELS\nIn the MSSM, neutralinos are linear combinations of the fermionic partners of the neutral\nelectroweak bosons, called bino ( ?B0) and wino ( ?W03), and of the fermionic partners of the\nneutral Higgs bosons, called higgsinos ( ?H0u, ?H0d). We assume that the lightest neutralino, ?,\nis the dark matter candidate. Its composition can be parameterized as\n? = N11 ?B0 +N12 ?W03 +N13 ?H0d +N14 ?H0u . (1)\nBecause the neutralino interactions are determined by its gauge content, it is useful to\ndistinguish between bino-like (N211 > N212, N213 + N214), wino-like (N212 > N211, N213 + N214),\nand higgsino-like (N213 + N214 > N211, N212) neutralinos according to the hierarchy of terms\nin (1). This classification implies that even so-called mixed neutralinos, those with two or\nmore comparable components, are considered as either binos, winos or higgsinos.\nBino-like neutralinos annihilate mainly into fermion-antifermion pairs through sfermion\nexchange. Such annihilation cross-section is helicity suppressed and gives rise to a standard\nrelic density that is usually larger than observed. Agreement with the observed dark matter\nabundance can still be achieved in standard cosmological scenarios but only in restricted\n4\nregions of the parameter space where special mechanisms such as coannihilations or resonant\nannihilations help reduce the relic density. Owing to the gaugino unification condition, bino-\nlike neutralinos are a generic prediction of minimal supergravity models.\nWino-like andhiggsino-like neutralinos annihilate mostly into gaugebosons (W+W?, ZZ,\nif kinematically allowed) through neutralino or chargino exchange; otherwise they annihilate\ninto fermions. Due to coannihilations with the lightest chargino (and, for higgsinos, with the\nnext-to-lightest neutralino), their standard relic density is rather small. Neutralino masses\nas large as 1 TeV for higgsinos or 2 TeV for winos are required to bring their thermal density\nwithin the observed range. Wino-like and higgsino-like neutralinos can be obtained in models\nwith non-universal gaugino masses; models with anomaly mediated supersymmetry breaking\n(AMSB) [21], for instance, feature a wino-like neutralino.\nWe consider a general class of MSSM models defined in terms of the parameter set M3,\nM2, M1, mA, ?, tan?, m?q, m?? At, and Ab. Here Mi are the three gaugino masses, mA\nis the mass of the pseudoscalar higgs boson, and tan? denotes the ratio v2/v1. The soft\nbreaking scalar masses are defined through the simplifying ansatz MQ = MU = MD = m?q\nand ME = ML = m??, whereas the trilinear couplings are given by AU = diag(0,0,At),\nAD = diag(0,0,Ab), and AE = 0. All these parameters are defined at the weak scale.\nSpecific realizations of supersymmetry breaking such as mSUGRA, mAMSB [21] or split-\nSUSY [22] are similar to - though not necessarily coincide with - particular examples of these\nmodels.\nWe performed a random scan of such parameter space within the following ranges\n10 GeV < M1,M2,M3 < 50 TeV (2)\n40 GeV < mA,?,m?q,m?? < 50 TeV (3)\n?3m0 < At,Ab < 3m0 (4)\n1 < tan? < 60 (5)\nA logarithmic distribution was used for Mi, mA, ?, m?q and m??, and a linear one for At, Ab,\nand tan?; the sign of ? was randomly chosen. After imposing accelerator constraints, as\ncontained in DarkSUSY version 4.1 [23], a sample of about 105 viable models was obtained.\nThe following analysis is based on such a sample of supersymmetric models.\n5\n10 100 1000 10000\nNeutralino mass (GeV)\n0.0001\n0.01\n1\n100\n10000\n1e+06\n?h\n2\nBinos\nWinos\nHiggsinos\nFIG. 1: The standard neutralino relic density as a function of the neutralino mass for our sample\nof models. The models are differentiated according to the bino, wino, or higgsino character of the\nlightest neutralino. The horizontal band indicates the dark matter range.\nIII. RESULTS\nFigure 1 shows the standard relic density as a function of the neutralino mass for our\nsample of models. Each cell -triangle, circle or dot- represents a small region around which at\nleast one model was found. The models are classified as binos, winos, or higgsinos, according\nto the gauge composition of the lightest neutralino. The horizontal band corresponds to\nthe observed dark matter density ?stdh2 = ?dmh2 = 0.109+0.003?0.006, obtained for a ?CDM\nmodel with scale-invariant primordial perturbation spectrum through a global fit of cosmic\nmicrowave background, supernovae, and large scale structure data [24]. Several observations\ncan be made from this figure. Models with bino-like neutralinos are spread over a wide area\nand usually give a rather large relic density. Models with wino- and higgsino-like neutralinos,\non the contrary, are concentrated over narrow bands and their relic density exceeds the dark\nmatter density only for large masses, m? greaterorsimilar 1 TeV. Finally, notice that in our sample the\n6\nneutralino relic density varies between 106 and 10?4.\nWe now want to compute, for our set of models, the neutralino interaction rates in generic\ncosmologies where the neutralino accounts for the dark matter and compare them with those\nobtained in the standard cosmology. Since spin-dependent searches are harder than spin-\nindependent ones, we will focus on the latter. The neutralino interaction rate in direct\ndark matter detection experiments is proportional to the product of the spin-independent\nneutralino-nucleus cross section ?SI and the number density of neutralinos passing through\nthe detector, f. We assume that, as expected for collisionless cold dark matter, f = ??/?dm.\n?SI is determined only by the supersymmetric spectrum but ?? is sensitive to the cosmo-\nlogical setup. Thus, the neutralino detection rate depends on the cosmology only through\nf.\nIf the standard cosmological model is assumed, then all models above the horizontal band\nin figure 1 are rejected. They have a standard relic density larger than the observed dark\nmatter density (?std > ?DM) and therefore are considered incompatible with cosmological\nobservations. Models with a relic density below the dark matter density are still viable,\nthough neutralinos make up only a fraction of the dark matter. They have f < 1, so their\ndetection rate is typically suppressed. Finally, those models with a neutralino relic density\nwithin the observed dark matter range are viable and have f = 1. They have been the focus\nof the large majority of studies on neutralino direct detection.\nIn non-standard cosmologies, ?? = ?DM may be ensured and the previous picture is\nmodified in two important ways. On the one hand, the viable parameter space is different. In\nfact, overdense models, those with ?std > ?DM, canno longer be rejected. On theother hand,\nunderdense models, those with ?std < ?DM, no longer will have the f < 1 suppression factor\nin the detection rate. Hence, in non-standard cosmologies, we expect more viable models\nand larger detection rates. A priori, however, it is not possible to predict the detection rate\nfor the new viable models or to know whether the enhanced detection rates are within the\nsensitivity of future dark matter detection experiments. Thus, a careful analysis is required\nto establish the implications of non-standard cosmologies for dark matter searches. In the\nfollowing, such an analysis will be carried out.\nFigure 2 displays the detection rate in standard and non-standard cosmologies for bino-\nlike neutralinos as a function of the neutralino mass. As before, the figure has been divided\ninto a rectangular grid and each occupied cell denotes the existence of at least one model\n7\n10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 2: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM for bino-like neutralinos in the standard and non-standard cosmological\nmodels. The solid line indicates the CDMS II present limit [25]. The dashed lines show sensitivity\nlimits for -from top to bottom on the right- CDMS II,ZEPLINIV , XENON-1Ton, and SuperCDMS\nphase C [26].\naround it. For comparison, we also show the current limit from the CDMS II experiment [25]\naswell asthe expected sensitivity of CDMS II, ZEPLIN IV , XENON-1Ton, andSuperCDMS\nphase C [26]. In the standard scenario, both the lower and the upper limit on the bino\nmass are set by the relic density constraint. That is why the range of neutralino masses\nextends to lower and higher values in non-standard cosmologies. They yield many more\nviable models, though most of them have rather small detection rates. This fact is not\nentirely surprising. Small annihilation rates, as those associated with bino-like neutralinos,\nare generically correlated with small scattering rates. Regarding dark matter searches, the\nmost remarkable difference observed in the figure is the existence of new viable models with\nneutralino masses not allowed in the standard cosmology and detection rates within the\nreach of future experiments. Such models feature either m? lessorsimilar 40 GeV or m? greaterorsimilar 600 GeV\n8\n10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 3: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM for higgsino-like neutralinos in the standard and non-standard cosmological\nmodels. The solid line indicates the CDMS II present limit [25]. The dashed lines show sensitivity\nlimits for -from top to bottom on the right- CDMS II,ZEPLINIV , XENON-1Ton, and SuperCDMS\nphase C [26].\nand may be detected in ZEPLIN IV, XENON-1Ton, or SuperCDMS phase C.\nThe detection rate for higgsino-like neutralinos is shown in figure 3 as a function of\nthe neutralino mass in standard and non-standard cosmologies. The lower limit on the\nhiggsino mass is now set by the experimental constraint on the chargino mass and is therefore\nindependent of the cosmological scenario. Two features clearly distinguish the standard and\nthe non-standard cosmologies. One of them is the existence of viable models with heavy\nneutralinos, m? greaterorsimilar 1 TeV. A sizable fraction of them has detection rates large enough\nto be observed in ZEPLINIV, XENON-1Ton, or SuperCDMS phase C. The other feature\nis the significant enhancement in the detection rate of neutralinos lighter than lessorsimilar 1 TeV.\nIn the standard scenario, such neutralinos are usually underdense (see figure 1) and have\nsuppressed detection rates. From the figure we see that non-standard cosmologies yield an\n9\n10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 4: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM for wino-like neutralinos in the standard and non-standard cosmological\nmodels. The solid line indicates the CDMS II present limit [25]. The dashed lines show sensitivity\nlimits for -from top to bottom on the right- CDMS II,ZEPLINIV , XENON-1Ton, and SuperCDMS\nphase C [26].\nenhancement of up to two orders of magnitude for the neutralinos with the largest detection\nrates. Some of them are already ruled out by the present limit and many more will be within\nthe expected sensitivity of the CDMSII experiment.\nA compelling signature of non-standard cosmologies would be the detection of a wino-\nlike neutralino by the CDMSII experiment, as revealed in figure 4. Indeed, in the standard\nscenario, winos with m? lessorsimilar 1-2 TeV are usually underdense and therefore their detection rate\nis suppressed by the factor f = ?std/?DM. In non-standard cosmologies, such suppression\nis nonexistent and light winos have larger detection rates. The enhancement in the largest\ndetection rates are typically larger than for higgsinos, amounting in some cases to three\norders of magnitude. As for higgsinos, the lower bound on m? is not set by the dark matter\nbound but rather by the experimental constraint on the chargino mass, so no additional\n10\n1 10 100 1000 10000\nNeutralino Mass (GeV)\n1e-20\n1e-18\n1e-16\n1e-14\n1e-12\n1e-10\n1e-08\n1e-06\n0.0001\nf?\nSI\n(pb)\nGeneric\nStandard\nFIG. 5: Spin-independent neutralino-proton cross section ?SI multiplied by the neutralino halo\nfraction f = ?std/?DM in the standard cosmological model and in the late decaying scalar field\nmodel. Here the lower limit of M1 in Eq. (2) has been lowered to 0.1 MeV The solid upper line\nindicates the CDMS II present limit [25] and the lower solid line the XENON limit [27]. The\ndashed lines show sensitivity limits for -from top to bottom on the right- CDMS II, ZEPLIN IV ,\nXENON-1Ton, and SuperCDMS phase C [26].\nmodels are found at low neutralino masses. For m? greaterorsimilar 2 TeV we do find new viable models\ncorresponding to overdense neutralinos in the standard cosmology. Most of them, however,\nhave small scattering rates, lying below the sensitivity of future detection experiments.\nFigure 5 summarizes the potential increase in neutralino candidates in the\nmodels studied in references [19] and [20]. For this figure the lower limit on M1 in\nEq. (2) has been lowered to 0.1 GeV (which is compatible with all experimental\nlimits (while no assumption is made on the relation between M1 and M2). In the\nlate decaying scalar field scenario most neutrinos can be brought to have the\ndark matter density (provided the value of the two relevant parameters of the\nphysics at the high scale can be suitably arranged). One exception is that of\n11\nvery light neutralinos which would be very overdense in the standard cosmology.\nRequiring the reheating temperature to be above 4 MeV [10], in order not to\nmodify nucleosynthesis, from the equations of reference [19] it is immediate to\nsee that neutralinos of mass m? should have a standard density smaller than\nthe dark matter density times (m?/120MeV)4 for it to be possible to bring their\ndensity to be that of the dark matter in the late decaying scalar field scenario.\nThis constraint is included in figure 5 where it is clearly shown the increase\nin potential neutralino candidates in the particular non-standard cosmological\nmodel considered with respect to the standard cosmological model.\nIV. CONCLUSION\nTo summarize, in this paper we computed the direct detection rate of MSSM neutralinos\nin generic cosmological scenarios where they constitute the dark matter of the Universe.\nWhen compared with the predictions of the standard cosmology, considerable differences\nwere encountered. If the neutralino is bino-like, as in msugra models, additional light m? lessorsimilar\n40 GeV and heavy m? greaterorsimilar 600 GeV neutralinos with non-negligible detection rates were found.\nThey could be detected in a variety of dark matter experiments such as ZEPLINIV, XENON-\n1Ton, or SuperCDMS phase C. For higgsino-like neutralinos, we found enhancements of up\nto two orders of magnitude in the largest detection rates as well as new viable models with\nheavy m? greaterorsimilar 1 TeV neutralinos. Both effects yielding detection rates within the sensitivity\nof future experiments. Wino-like neutralinos provide the clearest signature of non-standard\ncosmologies. Their detection rates may be enhanced by up to three orders of magnitude and\nthey could be detected in CDMSII. Thus, the prospects for the direct detection of neutralinos\nin non-standard cosmologies are significantly more promising than in the standard scenario.\nAcknowledgments\nWe thank Oleg Kalashev for allowing us to use the graphreader program. G.G., A.S. and\nC.Y. were supported in part by the US Department of Energy Grant DE-FG03-91ER40662,\nTask C and G.G. also by NASA grants NAG5-13399 and ATP03-0000-0057 at UCLA. P.G.\n12\nwas supported in part by the NFS grant PHY-0456825 at the University of Utah.\n[1] K. Griest and M. Kamionkowski, Phys. Rept. 333 (2000) 167.\n[2] J. R. Ellis, K. A. Olive, Y. Santoso and V. C. Spanos, Phys. Lett. B 565, 176 (2003).\n[3] T. Moroi, M. Yamaguchi and T. Yanagida, Phys. Lett.B 342,105 (1995); M Kawasaki, T.\nMoroi and T. Yanagida, Phys. Lett.B 370,52 (1996).\n[4] T. Moroi and L. Randall, Nucl. Phys. B570, 455 (2000).\n[5] M. Fujii, K. Hamaguchi, Phys. Rev. D 66, 083501 (2002); M. Fujii, M. Ibe, Phys. Rev. D 69,\n035006 (2004).\n[6] D. H. Lyth, E.D. Stewart, Phys. Rev. D 53, 1784 (1996).\n[7] M. Kamionkowski and M. S. Turner, Phys. Rev. D 42, 3310 (1990).\n[8] J. D. Barrow, Nucl. Phys. B 208, 501 (1982).\n[9] P. Salati, Phys. Lett. B 571, 121 (2003) [arXiv:astro-ph/0207396]; S. Profumo and P. Ullio,\nJCAP 0311, 006 (2003) [arXiv:hep-ph/0309220]. S. Profumo and C. E. Yaguna,\nPhys. Rev. D 70, 095004 (2004)\n[arXiv:hep-ph/0407036].\n[10] M. Kawasaki, K. Kohri, and N. Sugiyama, Phys. Rev. Lett. 82, 4168 (1999); Phys. Rev. D\n62, 023506 (2000); S. Hannestad, Phys. Rev. D 70, 043506 (2004).\n[11] M. Kamionkowski, M. Turner, Phys. Rev. D 42 3310 (1990); R. Jeannerot, X. Zhang, R.\nBrandenberger, JHEP 12, 003 (1999); W. B. Lin, D. H. Huang, X. Zhang, R. Brandenberger,\nPhys. Rev. Lett. 86 954 (2001).\n[12] T. Moroi, M. Yamaguchi and T. Yanagida, Phys. Lett.B 342,105 (1995); M Kawasaki, T.\nMoroi and T. Yanagida, Phys. Lett.B 370,52 (1996).\n[13] D. J.H. Chung, E. W. Kolb and A. Riotto, Phys. Rev. D60, 063504 (1999).\n[14] G. F. Giudice, E. W. Kolb and A. Riotto, Phys. Rev. D64, 023508 (2001).\n[15] R. Allahverdi and M. Drees, Phys. Rev. Lett. 89, 091302 (2002) and Phys. Rev. D66, 063513\n(2002).\n[16] S. Khalil, C. Mu?noz and E. Torrente-Lujan, New Journal of Physics 4, 27 (2002); E. Torrente-\nLujan, hep-ph/0210036 (2002).\n[17] N. Fornengo, A. Riotto, and S. Scopel, Phys. Rev. D67, 023514 (2003).\n13\n[18] C. Pallis, Astrop. Phys. 21, 689 (2004).\n[19] G. B. Gelmini and P. Gondolo, Phys. Rev. D 74, 023510 (2006)\n[20] G. Gelmini, P. Gondolo, A. Soldatenko and C. E. Yaguna, Phys. Rev. D 74, 083514 (2006).\n[21] L. Randall and R. Sundrum, Nucl. Phys. B 557, 79 (1999) [arXiv:hep-th/9810155].\nG. F. Giudice, M. A. Luty, H. Murayama and R. Rattazzi, JHEP 9812, 027 (1998)\n[arXiv:hep-ph/9810442].\n[22] N. Arkani-Hamed, S. Dimopoulos, G. F. Giudice and A. Romanino, Nucl. Phys. B 709,\n3 (2005) [arXiv:hep-ph/0409232]. G. F. Giudice and A. Romanino, Nucl. Phys. B 699, 65\n(2004) [Erratum-ibid. B 706, 65 (2005)] [arXiv:hep-ph/0406088].\n[23] P. Gondolo, J. Edsjo, P. Ullio, L. Bergstrom, M. Schelke and E. A. Baltz, JCAP 0407, 008\n(2004).\n[24] D.N. Spergel et al. Astrophys. J., Suppl. Ser. 148, 175 (2003); D.N.\nSpergel it et al., astro-ph/0603449 (2006); http:// lambda.gsfc.nasa.gov/ prod-\nuct/map/current/parameters.cfm.\n[25] D. S. Akerib et al. [CDMS Collaboration], Phys. Rev. Lett. 96, 011302 (2006)\n[arXiv:astro-ph/0509259].\n[26] R. J. Gaitskell, Ann. Rev. Nucl. Part. Sci. 54, 315 (2004).\n[27] D. N. McKinsey [XENON Collaboration], AIP Conf. Proc. 870 (2006) 202; J. Angle et al.\n[XENON Collaboration], arXiv:0706.0039 [astro-ph].\n14\n"}
{"id":"oai:arXiv.org:hep-ph/0612309","text":"arXiv:hep-ph/0612309v1  22 Dec 2006\nProbing the octant of ?23 with very long baseline neutrino\noscillation experiments: a global look\nGuey-Lin Lina,b? and Yoshiaki Umedaa?\naInstitute of Physics, National Chiao-Tung University, Hsinchu 300, Taiwan\nbPhysics Division, National Center for Theoretical Sciences, Hsinchu 300, Taiwan\n(Dated: February 7, 2008)\nAbstract\nWe investigate the baseline range in which the ?23 degeneracy in neutrino oscillation probabilities\nis absent for fixed values of ?13 and CP violation phase ?CP. We begin by studying sensitivities\nof neutrino oscillation probabilities to ?13, ?23 and ?CP for very-long-baseline neutrino oscillations.\nWe show contour graphs of the muon-neutrino survival probability P(?? ? ??) and the appearance\nprobability P(?e ? ??) on the cos2?23?sin2?13 plane for baseline lengths L = 1000, 5000, 10000,\nand 12000 km. For each baseline length, it is found that P(?? ? ??) is more sensitive to sin2?13 at\nenergies around its local maximum while it is more sensitive to cos2?23 at energies around its local\nminimum. On the other hand, the appearance probability P(?e ? ??) is sensitive to sin2?13 and\ncos2?23 only near its local maximum. We observe that the ?23 degeneracy in P(?? ? ??) is absent\nat energies around the local maximum of this probability, provided ?13 is sufficiently large. The\n?23 degeneracy is also absent in general near the local maximum of P(?e ? ??). Using analytic\napproximations for neutrino oscillation probabilities, we demonstrate that the above observations\nfor L = 1000, 5000, 10000, and 12000 km are in fact valid for all distances. The implications of\nthese results on probing the octant of ?23 are discussed in details.\nPACS numbers: 14.60.Pq, 13.15.+g, 14.60.Lm\n? E-mail: glin@cc.nctu.edu.tw\n? E-mail: umeda@faculty.nctu.edu.tw\n1\nI. INTRODUCTION\nThe understanding of neutrino masses and mixing matrix is crucial to unveil the mystery\nof lepton flavor structures. The updated SK analysis of the atmospheric neutrino data gives\n[1]\n1.5?10?3 eV2 < |?m231| < 3.4?10?3 eV2, sin2 2?23 > 0.92. (1)\nThis is a 90%C.L. range with the best fit values given by sin2 2?23 = 1 and ?m231 =\n2.1?10?3 eV2 respectively. An earlier result based upon L/E analysis gives [2]\n1.9?10?3 eV2 < |?m231| < 3.0?10?3 eV2, sin2 2?23 > 0.9. (2)\nat 90%C.L. where the best fit values are given by sin2 2?23 = 1 and ?m231 = 2.4?10?3 eV2\nrespectively. The scenario of ?? ? ?? oscillation for atmospheric neutrinos has been con-\nfirmed by the K2K experiment [3, 4]. Furthermore the results in the solar neutrino oscillation\nmeasurements are also confirmed by KamLAND reactor measurements [5, 6]. Combining\nthese measurements, the LMA solution of the solar neutrino problem is established and the\nupdated 2? parameter ranges are given by [7]\n7.21?10?5 eV2 < ?m221 < 8.63?10?5 eV2, 0.267 < sin2 ?12 < 0.371, (3)\nwith the best fit values ?m221 = 7.92?10?5 eV2 and sin2 ?12 = 0.314.\nDespite the achievements so far in measuring the neutrino mixing parameters, the sign\nof ?m231, the mixing angle ?13 and the CP violating parameter ?CP in the mixing matrix\nremain to be determined. Furthermore, one is keen to resolve the octant degeneracy of ?23\n[8].\nThe mixing angle ?13 is constrained by the reactor experiments [9, 10]. The CHOOZ\nexperiment [9] gives a more stringent constraint on ?13 with sin2 2?13 < 0.1 for a large\n?m231 (90% C.L.). A recent global fit based upon three-flavor neutrino oscillation gives the\n2? upper bound, sin2 2?13 < 0.124 [7]. It is well known that the mixing angle ?13 can be\nenhanced by the matter effect in Earth. The appearance oscillations ?? ? ?e, ?e ? ??,\nand the survival mode ?? ? ?? performed in a very-long baseline have been proposed\n[11] to probe the angle ?13 and the sign of ?m231. Furthermore, the aforementioned very\nlong baseline neutrino experiments as well as future atmospheric neutrino experiments are\nproposed to determine the deviation of ?23 to maximality [12]. In this work, we focus on\n2\nthe mixing angle ?23. We shall provide a global survey on ideal neutrino energies in the\nGeV range and baseline lengths from 103 km to 104 km for probing the octant of the mixing\nangle ?23. The muon neutrino survival probability P(?? ? ??) ? P?? and electron neutrino\nappearance probability P(?e ? ??) ? Pe? are both studied for this purpose. We observe\nthat the muon neutrino survival probability P?? has complementary dependencies on mixing\nangles ?13 and ?23 as the neutrino energy varies. This property is established by studying\nthe dependencies of P?? on cos2?23 and sin2?13 while keeping other parameters fixed. The\nchoice of the parameter cos2?23 is appropriate as\n1\n2 cos2?23 =\n1\n2 ?sin\n2 ?23, (4)\nwhich is a probe to the deviation of ?23 to the best-fit value pi/4. We find that the de-\npendencies of P?? on cos2?23 and sin2?13 at energies near local maxima of this probability\ndiffer drastically from those at energies near local maxima of the same probability. In the\nformer case, the probability P?? is always more sensitive to sin2?13. Furthermore, the ?23\ndegeneracy is absent in this case. In the latter case, the probability P?? is more sensitive to\ncos2?23 while the ?23 degeneracy is generally present. Such information is useful for probing\nthe octant of ?23. We also study sensitivities of the probability Pe? to cos2?23 and sin2?13\nwith other parameters fixed. We only focus on energies near the local maximum of Pe? as\nthis probability is not sensitive to mixing parameters for energies near its local minimum.\nThis paper is organized as follows. In Section II, we compare results on the oscillation\nprobability Pe? obtained by the full calculation with those obtained by various analytic\napproximations. This comparison is essential since analytic approximations will be employed\nfor discussions in later sessions. To set up the analytic approximation, we introduce the\nconcept of average density which varies with the total neutrino path-length inside the Earth.\nApplying full calculations and the two-layer analytic approximations [13], we identify the\nenergy values for local maxima and local minima of neutrino oscillation probabilities P?? and\nPe? for baseline lengths 1000 ? L/km ? 12000. It is found that the two-layer approximation\nis quite satisfactory compared to the full calculation for computing these energy values. In\nSection III, we first present the dependencies of P?? and Pe? on the CP violation phase\n?CP. It will be shown that, unlike Pe?, P?? is not sensitive to the CP violation phase ?CP.\nWe study numerically the effect of CP violation phase to the appearance probability Pe?.\nThe result confirms the so-called magic baseline [14, 15, 16] at L ? 7600 km where Pe? is\n3\nrather insensitive to the CP violation phase. After discussions on the CP violation phase,\nwe present the contour graphs of probabilities P?? and Pe? on cos2?23 ?sin2?13 plane for\nbaseline lengths L = 1000, 5000, 10000, and 12000 km. At all these baseline lengths, we\nshall see that P?? is more sensitive to sin2?13 at energies around its local maximum while\nit is more sensitive to cos2?23 at energies around its local minimum. Such observations\nare then justified by using the two-layer analytic approximations for neutrino oscillation\nprobabilities. With this approximation, the baseline lengths and neutrino energies allowing\nan unambiguous determination of ?23 through measuring P?? are identified. In Section IV,\nwe discuss the prospects of probing the ?23 octant via measuring Pe? and P??. We then\nconclude in the same section.\nII. THE COMPARISON OF FULL CALCULATIONSAND ANALYTICAPPROX-\nIMATIONS\nWe begin the discussions with the relation connecting flavor and mass eigenstates of\nneutrinos, ?? =summationtexti U?i?i, with U the Maki-Nakagawa-Sakata mixing matrix [17] given by\nU =\n?\n??\n??\nc12c13 s12c13 s13e?i?CP\n?s12c23 ?c12s13s23ei?CP c12c23 ?s12s13s23ei?CP c13s23\ns12s23 ?c12s13c23ei?CP ?c12s23 ?s12s13c23ei?CP c13c23\n?\n??\n?? , (5)\nwhere sij and cij denote sin?ij and cos?ij, respectively. The value for the Dirac type CP-\nphase ?CP ranges from 0 to 2pi. The evolutions of neutrino flavor eigenstates are governed\nby the equation\ni ddt|?(t)? =\n?\n????\n????\n1\n2E?U\n?\n??\n??\n0 0 0\n0 ?m221 0\n0 0 ?m231\n?\n??\n??U? +\n?\n??\n??\nV 0 0\n0 0 0\n0 0 0\n?\n??\n??\n?\n????\n????|?(t)?, (6)\nwhere |?(t)? = (?e(t),??(t),??(t))T, ?m2ij ? m2i ?m2j is the mass-squared difference between\nthe i-th and j-th mass eigenstates, and V ? ?2GFNe is the effegtive potential arising\nfrom the charged current interaction between ?e and electrons in the medium with Ne the\nelectron number density. Numerically V = 7.56?10?14 (?/[g/cm3])Ye [eV] with Ye denoting\nthe number of electrons per nucleon. We take Ye ? 0.5 in our calculations. One solves\nEq. (6) by diagonalizing the Hamiltonian on its right hand side. This amounts to writing\n4\n0 5000 10000\nbaseline length L[km]\n0\n5\n10\n? [g/cm\n3 ]\naverage density\ndensity in the mantle\ndensity in the core\naverage density\nFIG. 1: The average Earth density along the path traversed by the neutrino as a function of the\npath length L.\nthe right hand side of Eq. (6) as U?H?U??|?(t)? with U? the neutrino mixing matrix in the\nmatter and H? ? diag(E1,E2,E3) the Hamiltonian after diagonalization. To obtain various\noscillation probabilities described later, we have used the parametrization in [18] for the\nEarth density profile.\nFor analytic calculations, we employ the two-layer approximation for the Earth density\nprofile [13]. Given a path-length L for a neutrino traversing the Earth medium, one can\ndivide L into the sum L = L1 + L2 + ???Ln with each Li corresponding to a region with\na specific matter density. The average density for this path-length is then given by ? =\n(?1L1 + ?2L2 + ????nLn)/L. The Earth medium can be categorized as the Earth mantle\nand the Earth core. If a neutrino only traverses the Earth mantle, we shall use the one-\ndensity approximation for the analytic calculation with the density defined by the above\nprescription. However, if a neutrino traverses both the Earth mantle and the Earth core,\none should write the total neutrino path-length as L = 2Lm + Lc with\nLm = R\nparenleftBigg\ncos?n ?\nradicalbigg\nr2c\nR2 ?sin\n2 ?n\nparenrightBigg\n,\nLc = 2R\nradicalbigg\nr2c\nR2 ?sin\n2 ?n, (7)\n5\nwhere R = 6371 km and rc = 3480 km are the radii of the entire Earth and the Earth core\nrespectively while ?n is the incident Nadir angle of the neutrino. We note that the critical\nNadir angle for a neutrino to pass the Earth core is 33.17? corresponding to L = 10674 km.\nFor L > 10674 km, one separately defines average densities within the path-length Lm and\nthe path-length Lc respectively. The average densities as functions of the neutrino path-\nlength is shown in Fig. 1. For L ? 10674 km, there is only one curve for the average density,\nwhich is represented by the solid line in the figure. Beyond this distance, one can define the\naverage density in the core and the average density in the mantle, which are represented\nby dashed and dotted lines respectively. Alternatively, one can also define single average\ndensity for L > 10674 km by ignoring the distinction between the mantle and the core. This\nis seen from the solid line for L > 10674 km. However, in our analytic calculations, we shall\nadopt the two-density approach for L > 10674 km.\nFor analytic calculations, we only compute oscillation probabilities up to the lowest order\nin ? ? ?m221/?m231. In other words, we set ?m221=0 in analytic calculations and conse-\nquently the mixing angle ?12 and the CP phase ?CP dropout fromthe oscillation probabilities.\nThe probabilities P?? and Pe? in the two-layer approximations are given by[19, 20, 21, 22, 23]:\nP?? = cos4 ?23 +parenleftbigu2 + v2parenrightbigsin4 ?23 + 2cos2 ?23 sin2 ?23 (ucost+ vsint),\nPe? = sin2 ?23parenleftbig1?u2 ?v2parenrightbig. (8)\nThe quantities u, v and t are defined as\nu = cos(2?m)cos(?c)?cos(2?c13 ?2?m13)sin(2?m)sin(?c),\nv = ?cos(2?m13)[sin(?c)cos(2?m)cos(2?c13 ?2?m13) + cos(?c)sin(2?m)]\n+sin(2?m13)sin(?c)sin(2?c13 ?2?m13),\nt = (M\n2\n13)\nm + (m2\n13)\nm\n4E ?2L\nm + (M\n2\n13)\nc + (m2\n13)\nc\n4E ?L\nc, (9)\nwhere\n?m(c) = ?\nm(c)\n31\n4E L\nm(c),\n(M213)m(c) = (?m231 + Am(c)e + ?m(c)31 )/2,\n(m213)m(c) = (?m231 + Am(c)e ??m(c)31 )/2, (10)\nwith\n?m(c)31 =\nradicalBig\n(?m231 sin2?13)2 + (Am(c)e ??m231 cos2?13)2. (11)\n6\n0 5 10\nE [GeV]\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nP e?\nFull\nTwo-Layer\nOne-Layer\n(First order)\nOne-Layer\n(Second order)\nFull (?m212 =0)\nPe? for L=11400 km, sin2?13=0.3, cos2?23=0\nFIG. 2: A comparison of Pe? obtained by the full numerical calculation and various approximations.\nThe thick solid curve denotes the result by the full numerical calculation. The dotted-dashed\ncurve denotes the result by setting ?m221 = 0 in the full numerical calculation. The dashed\ncurve represents the result obtained by the two-layer approximation in the leading order of ? ?\n?m221/?m231. The dotted curve denotes the result obtained by one-density approximation in the\nleading order of ? while the thin solid curve is that obtained by the one-density approximation in\nthe next-to-leading order of ?.\nThe superscripts m and c denote quantities defined in the Earth mantle and the Earth\ncore respectively. For neutrinos traversing only the Earth mantle, one simply sets Lc =\n0, 2Lm = L in the above equations and recovers well known expressions for P?? and Pe? in\nthe one-density approximation [24].\nThe accuracy of two-layer approximation is shown in Fig. 2 with a comparison of this\napproximation to the full numerical calculation and other approximations. In the calcula-\ntions, we have assumed the normal mass hierarchy and taken sin2?13 = 0.3, cos2?23 = 0,\n?CP = 0, ?m231 = 2.4?10?3 eV2, ?m221 = 8.2?10?5 eV2, and tan2 ?12 = 0.39 [25]. This\nset of parameters will be adopted for later calculations unless specific mentioning of other\nchoices. This set of parameters differ from the most updated best-fit values quoted right\nafter Eq. (3). However, both set of parameters give undistinguishable results on Pe? and P??\n7\n0 5000 10000\nbaseline length L[km]\n0\n5\n10\n15\nenergy [GeV]\nFull calculation\nTwo-Layer\nThe energy at local maximum of Pe?\nmax1\nmax2\n0 5000 10000\nbaseline length L[km]\n0\n5\n10\n15\n20\nenergy [GeV]\nFull calculation\nTwo-Layer calculation\nThe energies at local maximum and local minimum of P??\nmin2\nmax1\nmin1\nmax2\nFIG. 3: Left panel: the energy at the local maximum of Pe?, as a function of L. Right panel:\nenergies at local maxima and local minima of P??, as functions of L.\nin the energy range concerned here. A comparison made at L = 11400 km has two purposes.\nFirst of all, it is known that the series expansion in the parameter ? is valid for L/E? ? 104\n(km/GeV) [24, 26]. Hence analytic calculations performed at this baseline length test the\nmarginal region of the condition L/E? ? 104 (km/GeV). Secondly this path-length implies\nthat the neutrino traverses both the Earth mantle and the Earth core. Therefore it is also\na good test to the two-layer approximation. It is seen that the two-layer approximation,\nunlike the one-layer approximation, reproduces well the peak energies of Pe?, while it gives\npeak probabilities deviating from those obtained from the full calculation by 15% ?20%.\nWe also see that the two-layer approximation agrees well with the full calculation in the\nlimit ?m221 = 0.\nFor later analysis, we compute energies at local maxima of Pe? and those at local maxima\nand local minima of P?? for the baseline range 1000 ? L/km ? 12000. The results are\ndepicted in Fig. 3. We do not study local minima of Pe? since their values are not sensitive\nto mixing angles ?13 and ?23. It is seen that the analytic approximation is satisfactory for\ncomputing energies at local maxima and local minima of neutrino oscillation probabilities.\nWe point out that the energy curves in Fig. 3 are calculated with sin2?13 = 0.3 and cos2?23 =\n0. It is found that these curves are not sensitive to the values of sin2?13 and cos2?23.\n8\n0 1 2 3 4 5\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n(P ??\n)\n?CP=0\n?CP=0.5pi\n?CP=pi\n?CP=1.5pi\nP?? and Pe? for L=1000 km, sin2?13=0.3, cos2?23=0\nPe?P??\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=5000 km, sin2?13=0.3, cos2?23=0\n0 5 10 15 20\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=10000 km, sin2?13=0.3, cos2?23=0\n0 5 10 15 20\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=12000 km, sin2?13=0.3, cos2?23=0\nFIG. 4: The CP phase dependencies of P?? and Pe? for L = 1000 km, 5000 km, 10000 km and\n12000 km respectively. The probability P?? is described by the thick curve while Pe? is described\nby the thin curve.\nIII. CONDITIONS FOR THE ABSENCE OF ?23 DEGENERACY IN P?? AND Pe?\nAT DIFFERENT ENERGIES\nA. The dependencies of P?? and Pe? on ?CP\nBefore concentrating on ?13 and ?23 dependencies of neutrino oscillation probabilities,\nwe first study the CP phase dependencies with the full numerical calculations. It is easily\nseen from Fig. 4 that P?? is not sensitive to the CP phase for all distances displayed. On\nthe other hand, Pe? is rather sensitive to the CP phase for L = 1000 km and 5000 km.\nIn order to quantify the CP phase dependence of Pe?, we study peak values of Pe?, which\noccur at energies described by the curve max1 in Fig. 3 for different baseline lengths. This\npeak value for a specific baseline length depends on the CP violation phase ?CP and we\n9\n0 2000 4000 6000 8000 10000\nbaseline length L [km]\n0\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\nP e?max\n?  P\ne?min\nPe?max ?  Pe?min,  sin2?13=0.3, cos2?23=0\n0 2000 4000 6000 8000 10000\nbaseline length L [km]\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nP e?min\n/  P\ne?max\nPe?min /  Pe?max,  sin2?13=0.3, cos2?23=0\nFIG. 5: The difference and the ratio of Pmaxe? and Pmine? as functions of the baseline length.\ndenote the maximum and the minimum of this value as Pmaxe? and Pmine? respectively. The\ndifference and the ratio of these two values as functions of the baseline length L are shown\nin Fig. 5. It is interesting to note that the ratio Pmine? /Pmaxe? increases monotonically with the\nbaseline length until L = 7600 km. The ratio begins to decrease for a larger baseline but\nremains larger than 90%. In fact, one can see that Pmaxe? and Pmine? differ by less than 10%\nfor L ? 6500 km. We point out that 1?Pmine? /Pmaxe? reaching to minimum at L = 7600 km\nconfirms the so-called magic baseline for the probability Pe? [14, 15, 16].\nB. The dependencies of P?? and Pe? on mixing angles ?13 and ?23\nHaving studied CP phase dependencies of oscillation probabilities, we now focus on ?13\nand ?23 dependencies. In this study we set the CP phase ?CP equal to zero. The results\nare presented in Fig. 6. It is easily seen that the values of P?? at its local maximum and\nlocal minimum depend on mixing angles ?13 and ?23 while only the local maximum of Pe?\ndepends on these parameters. This confirms our earlier comments concerning the left panel\nof Fig. 3. We point out that the differences between solid and dotted curves in Fig. 6 reflect\nthe effect of sin2?13; while the differences between solid and dashed curves there reflect the\neffect of cos2?23.\nWe now present contour graphs of P?? and Pe? on the cos2?23 ? sin2?13 plane. The\nrange for cos2?23 is chosen such that sin2?23 > 0.9 [2], i.e., ?0.316 < cos2?23 < 0.316; while\nsin2 2?13 is chosen to be less than 0.1, i.e., sin2?13 < 0.316. The contour graphs of P?? at\n10\n0 1 2 3 4 5\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nsin2?13=0.3,   cos2?23=0\nsin2?13=0.15, cos2?23=0\nsin2?13=0.3,   cos2?23=0.3\nsin2?13=0.3,   cos2?23=?0.3\nP?? and Pe? for L=1000 km\nPe?P??\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=5000 km\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=10000 km\n0 5 10 15\nE [GeV]\n0\n0.2\n0.4\n0.6\n0.8\n1\nP e? \n (P\n??\n)\nP?? and Pe? for L=12000 km\nFIG. 6: The ?13 and ?23 dependencies of P?? and Pe? for L = 1000 km, 5000 km, 10000 km and\n12000 km respectively. The probability P?? is described by the thick curve while Pe? is described\nby the thin curve.\ndifferent baseline lengths are presented in Fig. 7. Except for L = 1000 km, we have shown\ncontours of P?? for energies in the vicinity of both local maximum and local minimum of\nthis probability. The contour for the local maximum of P?? at L = 1000 km is not shown\nsince P?? at this energy and baseline length is not sensitive to mixing angles ?13 and ?23. For\nL = 5000 km, 10000 km and 12000 km, it is seen that the contours at local maxima of P??\nand those at local minima of P?? behave rather differently. The former are in general more\nparallel to the cos2?23-axis while the latter are generally more parallel to the sin2?13-axis.\nWe note that the local maximum (max2) of P?? at L = 12000 km can vary from 0.9 to a\nmuch smaller value, 0.45, which is a result of significant matter effects. Similarly, due to\nlarge matter effects, the local minimum (min2) of P?? at L = 10000 km can vary from 0\nto a much larger value, 0.4. We also notice that, at this baseline length, the ?23 degeneracy\n11\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=1.39-2.39 GeV (min1), L=1000 km\n0.065\n0.08\n0.08\n0.1\n0.1\n0.13\n0.13\n0.16\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=4.25-5.25 GeV (max1, solid)\nand E=8.74-9.74 GeV (min1, dashed), L= 5000 km\n0.005\n0.02\n0.02\n0.05\n0.05\n0.08\n0.08\n0.12\n0.96 0.93 0.9 0.85\n0.8\n0.75\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=8.71-9.71 GeV (max1, solid)\nand E=5.74-6.74 GeV (min2, dashed), L=10000 km\n0.06\n0.05\n0.3\n0.04\n0.1\n0.1\n0.15 0.40.2\n0.93\n0.982 0.97\n0.95\n0.9\n0.87\n0.84\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nP?? for E=5.00-6.00 GeV (max2, solid)\nand E=6.65-7.65 GeV (min2, dashed), L=12000 km\n0.12\n0.09\n0.450.15\n0.15\n0.6\n0.18\n0.7\n0.86\n0.86\n0.8\n0.06\n0.03\n0.18\nFIG. 7: The contour graphs of the muon neutrino survival probability P?? on the cos2?23?sin2?13\nplane. At L = 1000 km, the local minimum of P?? on the curve min1 occurs at E = 1.89 GeV. We\nplot the contour graph of P?? by averaging this probability over an 1 GeV energy range centered\nat the above local minimum. At L = 5000 km, the local maximum of P?? on the curve max1\noccurs at E = 4.75 GeV while the local minimum of this probability on the curve min1 occurs at\nE = 9.24 GeV. We plot the contour graphs of P?? in the energy range 4.25 ? E/GeV ? 5.25 for\nthe former case and 8.74 ? E/GeV ? 9.74. The same type of convention applies to L = 10000 km\nand 12000 km.\nis absent for P?? > 0.1. In general, such a degeneracy is also absent for energies near local\nmaxima of P??. However, the probabilities are not sensitive to cos2?23 in those cases. For\ncomparisons, we also present contour graphs for the appearance probability Pe? at different\nbaseline lengths. It is clearly seen that Pe? is only sensitive to sin2?13 for most cases. The\nsensitivity to cos2?23 only occurs at very long baseline lengths and large values of sin2?13.\n12\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=1.39-2.39 GeV (max1), L=1000 km\n0.002\n0.01 0.02\n0.03 0.04\n0.06\n0.08\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=5.31-6.31 GeV (max1), L=5000 km\n0.01 0.05\n0.1\n0.15\n0.2\n0.25\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=5.49-6.49 GeV (max1), L=10000 km\n0.03 0.1 0.2\n0.4\n0.5\n0.3\n0.6\n0 0.1 0.2 0.3\nsin2?13\n-0.2\n0\n0.2\ncos2\n? 23\nPe? for E=2.64-3.64 GeV (max1), L=12000 km\n0.01 0.1 0.2\n0.4\n0.5\n0.3\nFIG. 8: The contour graphs for the oscillation probability Pe? on the cos2?23 ?sin2?13 plane. We\nplot contours of Pe? at energies near the local maximum (max1) of this probability.\nFor example, at L = 10000 km, Pe? becomes sensitive to cos2?23 as sin2?13 approaches 0.3.\nAt L = 12000 km, Pe? becomes sensitive to cos2?23 when sin2?13 is greater than 0.2.\nC. A global look at the absence of ?23 degeneracy\nIn this subsection, we focus on ?23 dependencies of P?? and Pe? for general baseline\nlengths. The two-layer analytic approximations for P?? and Pe? will be employed for our\ndiscussions, and observations in the previous subsection shall be justified. It is instructive\nto rewrite Eq. (8) in polynomials of cos2?23:\nf(y,z) = ??y2 + (? + ?)y + (1??),\ng(y,z) = ??(y ?1), (12)\n13\n2000 4000 6000 8000 10000 12000\nbaseline length L [km]\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n?+?\nsin2?13=0.1\nsin2?13=0.2\nsin2?13=0.3\nFIG. 9: The coefficient ?(z) + ?(z) calculated along the energy curve max1 in the left panel of\nFig. 3. The values of sin2?13 are taken to be 0.1, 0.2 and 0.3 respectively.\nwith f(y,z) ? P??, g(y,z) ? Pe?, y ? cos2?23 and z ? sin2?13. Furthermore,\n? = ?14bracketleftbig(u?cost)2 + (v?sint)2bracketrightbig,\n? = 12parenleftbig1?u2 ?v2parenrightbig+ 14bracketleftbig(u?cost)2 + (v ?sint)2bracketrightbig,\n? = 12parenleftbig1?u2 ?v2parenrightbig. (13)\nWe note that the sin2?13 dependencies of P?? and Pe? reside in quantities u, v, cost and\nsint. These quantities also depend on the baseline length L and the neutrino energy E.\nHence the coefficients ?, ? and ? also depend on the baseline length L and the neutrino\nenergy E. It is interesting to note that ? + ? = ?. Therefore we have\nP?? = ?parenleftbigy2 ?1parenrightbig, (14)\nusing P?e +P?? +P?? = 1 and P?e = Pe? with our choice of ?CP = 0. The contour structure\nof Pe? is straightforward as g(y,z) is only a linear function of y. Hence no ?23 degeneracy\npresents in the contour graphs depicted in Fig. 8. Additionally, the sensitivity of Pe? to\ncos2?23 is dg(y,z)/dy = ?(?(z) + ?(z)). The coefficient ? + ? evaluated along the energy\ncurve max1 in the left panel of Fig. 3 are plotted in Fig. 9 for sin2?13 = 0.1, 0.2 and 0.3. For\nsin2?13 = 0.3, ?+? reaches to the maximal value, 0.5, for L ? 10500 km. For sin2?13 = 0.1\n14\n0 5000 100000\n0.2\n0.4\n0.6\n0.8\n1\nmin1\nmax1\nmin2\nmax2\nbaseline length L [km]\n-? and ?+?, sin2?13=0.2, cos2?23=0\n-? and ?+?, sin2?13=0.2, cos2?23=0\n?? ?+?\n0 5000 10000\nbaseline length L [km]\n0\n0.2\n0.4\n0.6\n0.8\n1\nmin1\nmax1\nmin2\nmax2\n?? and ?+?, sin2?13=0.3, cos2?23=0\n?+???\nFIG. 10: The coefficients ?? and ?+? evaluated along energy curves in the right panel of Fig. 3.\nThe coefficients are calculated with sin2?13 = 0.2 and 0.3 on the left and right panels respectively.\nThe thick curves denote values of ?? while thin curves denote those of ?+?. For solid and dotted\ncurves, the thick curves generally dominate over the corresponding thin ones. For dashed and\ndotted-dashed curves, the thin curves generally dominate over the thick ones.\nand 0.2, ?+? rises quickly as the baseline length L surpasses 10674 km. We note that the\nvalue of Pe? is proportional to ?+?. Hence ?+? shown in Fig. 9 is its own maximal value\nfor each baseline length L.\nThe contour structure of P?? can be analyzed through the quadratic polynomial f(y,z)\nin y. If ?? ? ?+?, generally there are two solution curves for f(y,z) = p compatible with\nthe ranges of y and z where p is a given value for P??. Let us suppose that z ? sin2?13\nis measured in the future [27, 28] with a central value z0. The two solution curves for the\nequation f(y,z) = p then intersect with the straight line z ? sin2?13 = z0 at two points\n(y1,z0) and (y2,z0). This is actually what we have seen in Fig. 7 for local minima of P??. If,\non the other hand, ?? ? ? + ? or even ?? ? ? + ?, there exists only one solution curve\nfor the equation f(y,z) = p. This is because that the two points (y1,z0) and (y2,z0) can not\nsimultaneously satisfy the constraint ?0.316 < y < 0.316 since |y1 +y2| = ?(?+?)/? ? 1.\nThis is actually what we have seen in Fig. 7 for local maxima of P??. To justify this\nobservation, it remains to show that the coefficient ?? dominates over ? + ? at energies\ncorresponding to local minima of P?? while the latter dominates over the former at energies\ncorresponding to local maxima of P??. This is clearly demonstrated in Fig. 10 where the\n15\ncoefficients ?? and ? + ? are evaluated along energy curves in the right panel of Fig. 3.\nWe have calculated the coefficients with cos2?23 = 0 and sin2?13 = 0.2, 0.3 respectively.\nWe remark that other choices for cos2?23 do not produce noticeable changes on the energy\ncurves where ?? and ? + ? are evaluated.\nIt is easily seen that ?+? always dominates over ?? when these coefficients are evaluated\natenergies alongmax1 ormax2inthe right panelofFig.3. Insuch cases, the ?23 degeneracy\nis absent in the solutions of f(y,z) = p. Namely there exists only one solution curve for\nthe above equation. Reversely, ?? always dominates over ?+? when these coefficients are\nevaluated at energies along min1. The situation is slightly more complicated when these\ncoefficients are evaluated at energies along min2. In this case ?? no longer dominates\nover ? + ? for baseline lengths around 104 km. In fact, with sin2?13 = 0.3, ? + ? is even\nlarger than ?? for 9000 ? L/km ? 10500. This explains the contour structure of P??\nat L = 10000 km (see Fig. 7) where the straight line z = 0.3 only intersects one equal\nprobability curve f(y,z = 0.3) = p. The straight line z = 0.2 also behaves the same except\nfor a very small p. We reiterate that the range for y ? cos2?23 is ?0.316 < y < 0.316 due\nto the constraint sin2 2?23 > 0.9 [2]. Therefore, given z = z0, the equation f(y,z0) = p could\nhave only one solution for y if ?(?(z0) +?(z0))/?(z0) > 0.632. In other words, such values\nof ?(?(z0) + ?(z0))/?(z0) lead to the absence of ?23 degeneracy. In fact, the condition for\nthe absence of ?23 degeneracy is even more relaxed. To see this, let us divide our discussions\naccording to the true octant of ?23.\n1. min2, ?23 < pi/4\nSince ? < 0 and ? + ? > 0, the two solutions for y in f(y,z0) = p are both negative for\n1??(z0)?p > 0 while they have opposite signs for 1??(z0)?p < 0. If the true value of\n?23 is less than pi/4, i.e., the true value of y is positive, then the experimental measurement\nshould give 1??(z0)?p < 0 so that a positive solution for y exists. With 1??(z0)?p <\n0, the two solutions for f(y,z0) = p have opposite signs and the negative solution has\na larger absolute value. The negative solution will violate the constraint ?0.316 < y if\n?(?(z0) + ?(z0))/?(z0) > 0.316. For z0 = 0.2, ?(?(z0) + ?(z0))/?(z0) > 0.316 is valid\nfor 8300 ? L/km ? 10770. For z = 0.3, the above baseline range is extended to 7410 ?\nL/km ? 10790.\n16\n2. min2, ?23 > pi/4\nWith a true value of ?23 greater than pi/4, i.e., the true value of y less than zero, the\nvalue of 1 ? ?(z0) ? p can either be positive or negative. The condition 1 ? ?(z0) ? p >\n(<)0 is equivalent to the condition |y| < (>)(?(z0) +?(z0))/(??(z0)). For ?(?(z0) +\n?(z0))/?(z0) > 0.316, one must have 1 ? ?(z0) ? p > 0. Hence there exist two negative\nsolutions for y. In this case, the corresponding solutions for ?23 are both located in the same\noctant. For 0.316 < ?(?(z0)+?(z0))/?(z0) < 0.632, the spurious solution for y may or may\nnot violate the constraint y > ?0.316. For ?(?(z0) + ?(z0))/?(z0) > 0.632, the spurious\nsolution for y must violate the constraint y > ?0.316, hence the ?23 degeneracy is surely\nabsent. For sin2?13 = 0.2, the condition ?(?(z0)+?(z0))/?(z0) > 0.632 can not be achieved\nalong min2. For sin2?13 = 0.3, the above condition is satisfied for 8270 ? L/km ? 10720.\nFor ?(?(z0) + ?(z0))/?(z0 < 0.316, 1 ? ?(z0) ?p can either be positive or negative. For\n1??(z0)?p > 0, both solutions for y are negative and satisfying the constraint y > ?0.316.\nFor 1 ? ?(z0) ? p < 0, both solutions for y satisfy the constraint ?0.316 < y < 0.316.\nHowever their corresponding ?23 angles are situated in different octants.\nLet us summarize the results obtained in this subsection. The coefficient ?+? dominates\nover ?? for energy values along curves max1 and max2 for all baseline lengths. Hence the\n?23 degeneracy is absent along these energy curves for all baseline lengths. The situation\nalong the curve min1 is just the opposite, the coefficient ?? dominates over ? + ? for all\nbaseline lengths. Hence the ?23 degeneracy is present for all baseline lengths in this case.\nThe issue of ?23 degeneracy becomes more complicated along min2, which we have discussed\naccording to the true octant of ?23. Along the energy curve min2, the non-degeneracy\nbaseline range is larger for the ?23 < pi/4 case.\nIV. DISCUSSIONS AND CONCLUSIONS\nWe have presented the baselines and energies ideal for probing the octant of ?23 through\nneutrino oscillations. The appearance mode ?e ? ?? can be studied in a very long baseline\nwith the facility of neutrino factory [29] or the more recent proposed ? beam [30]. As said,\nthe sensitivity of Pe? to ?23 is dg(y,z)/dy = ?(?(z) + ?(z)) where g(y,z) represents Pe? in\nthe analytic approximation given by Eq. (12). The maximal value of ?+? for each baseline\n17\nlength is shown in Fig. 9. At the magic baseline, L = 7600 km, ?+? = 0.06, 0.21 and 0.38\nfor sin2?13 = 0.1, 0.2 and 0.3 respectively. For a sufficiently large sin2?13 and a baseline\nlength close to the magic value [14, 15, 16], Pe? is ideal for probing the octant of ?23.\nThe probability P?? is also relevant in neutrino oscillation experiments with neutrino\nfactories. The sensitivity of this probability to ?23 is determined by the derivative\nr ? dP??dcos2?\n23\n= ?2?cos2?23 + (? + ?). (15)\nSince ? is negative, the sensitivity r is larger for cos2?23 > 0, i.e., ?23 < pi/4. For a\nmeasurement performed around a local maximum of P??, the sensitivity to ?23 is completely\ndetermined by the coefficient ?+?, since the coefficient ? is generally rather suppressed in\nthis case. Along the energy curve denoted by max1, ?+? peaks at 7480 km for sin2?13 = 0.2\nand it peaks at L = 7350 km for sin2?13 = 0.3. The values of ?+? at those peaks are 0.17\nand 0.32 respectively. Along the curve max2, ? + ? peaks around L = 10750 km for both\nsin2?13 = 0.2 and 0.3 with values 0.43 and 0.48 respectively.\nFor a measurement performed around a local minimum of P??, the sensitivity to ?23 is\ndetermined by both coefficients ?? and ? + ?. Along the energy curve denoted by min1,\nthe coefficient ?? is always close to unity while the coefficient ? + ? is always suppressed\nfor all baseline lengths. It is understood that the magnitude of ? + ? determines the size\nof matter effects. Hence the matter effect is small at energies along the curve min1. The\nsuppression of ? + ? compared to ?? leads to the ?23 degeneracy as discussed before. The\nbehavior of P?? along the energy curve min2 is more interesting. If the true value of ?23\nis less than pi/4, the ?23 degeneracy from the measurement of P?? is absent in the baseline\nrange 8300 ? L/km ? 10770 for sin2?13 = 0.2. The above non-degeneracy baseline range\nextends to 7410 ? L/km ? 10790 for sin2?13 = 0.3. On the other hand, if the true ?23\nis greater than pi/4, the non-degeneracy baseline range does not exist along the energy\ncurve min2 for sin2?13 = 0.2. For sin2?13 = 0.3, the non-degeneracy baseline range is\n8270 ? L/km ? 10720.\nThe existence of non-degeneracy baseline range along the energy curve min2 has impor-\ntant implications. It can be seen from Fig. 3 that the curve min2 lies in between curves\nmax1 and max2. Since the degeneracy of ?23 is absent on both max1 and max2 for all\nbaselines, it is possible that there exists a non-degeneracy region spanned by ranges of the\nbaseline length and the neutrino energy. For example, with sin2?13 = 0.2 and a true value of\n18\nTABLE I: The baseline range in which the ?23 degeneracy is absent in the probability P?? for all\nenergy values between the curves max2 and max1. The entry corresponding to ?23 > pi/4 and\nsin2?13 = 0.2 is left blank since, with such set of parameters, there exists no baseline length where\nthe condition for the absence of ?23 degeneracy can be satisfied.\n?23 octant sin2?13 = 0.2 sin2?13 = 0.3\n?23 < pi/4 8550 ? L/km ? 10680 7950 ? L/km ? 10700\n?23 > pi/4 8450 ? L/km ? 10680\n?23 less than pi/4, the ?23 degeneracy is absent for 8300 ? L/km ? 10770 for energies along\ncurves max2, min2 and max1. It is of great interest to investigate if the ?23 degeneracy is\nalso absent for any neutrino energy larger than the value on max2 and smaller than that on\nmax1. By taking all these energies into account, we find that the ?23 degeneracy is absent\nfor 8550 ? L/km ? 10680. For a true value of ?23 greater than pi/4 and sin2?13 = 0.3,\nthe ?23 degeneracy is absent for 8270 ? L/km ? 10720 for energies along curves max2,\nmin2 and max1. However, with all energies between curves max2 and max1 considered,\nwe find that the ?23 degeneracy is absent for 8450 ? L/km ? 10680. The non-degeneracy\nbaseline range corresponding to different combinations of ?23 and ?13 values are summarized\nin Table I.\nIt is interesting to compare measurements on Pe? and P?? since both oscillations appear\nin experiments with neutrino factories [29]. The main issue for comparison is on the deter-\nmination of the true ?23 value under the assumption that both the sign of ?m231 and the\nvalue of sin2?13 are known. Let us begin the discussion with a true value of ?23 less than pi/4\nand sin2?13 = 0.2. For L < 8550 km, the appearance mode ?e ? ?? is useful for probing the\noctant of ?23, in particular for L close to the magic value, 7600 km. However, the survival\nmode ?? ? ?? is not as useful since the ?23 degeneracy is absent only at energies near max1\nand max2. Concerning the sensitivity to ?23, we note that the differentiation of Pe? with\nrespect to cos2?23 is ?(?+?). The value of ?+? increases with L as shown in Fig. 9. It is\n0.21 at L = 7600 km, and 0.26 at L = 8550 km. For 8550 ? L/km ? 10680, both ?e ? ??\nand ?? ? ?? are useful for probing the octant of ?23. We note that peak positions of Pe?\nare mostly around 6 GeV. Hence they overlap with the non-degeneracy energy range of P??.\nFrom Eq. (15) and our assumption of ?23 < pi/4, we find that P?? is more sensitive to ?23\n19\nas compared to Pe? for the same neutrino energy. For L > 10680 km, ?e ? ??, is again the\nonly useful mode for probing the octant of ?23.\nLet us turn to the case where the true value of ?23 is greater than pi/4 and sin2?13 = 0.2.\nIn such a case, the value for Pe? is enhanced compared to that with y > 0. Furthermore\nPe? is always more sensitive to cos2?23 as compared to P?? for the same neutrino energy.\nIt is clear that the ?e ? ?? appearance mode is more useful for probing ?23 regardless the\nbaseline length. Although there exists a baseline range where the ?23 degeneracy is absent\nin P?? for neutrino energies between curves max2 and max1. However this requires a large\nvalue of sin2?13, such as sin2?13 = 0.3.\nIt is essential to remark that the above non-degeneracy baseline range is not sensitive to\nthe value of ?m231, which we have so far taken to be 2.4 ? 10?3 eV2. Changing the value\nof ?m231 only shifts the probability curves in Fig. 4 and Fig. 6 so that positions for local\nmaxima and local minima of these probabilities shift accordingly. However, the maximal or\nminimal values of these probabilities remain unchanged. In other words, although the energy\ncurves in Fig. 3 are shifted, the coefficients ?? and ?+? plotted in Fig. 10, which combine\nto form Pe? and P?? (see Eq. (12)), remain the same. The values of these coefficients as\nfunctions of the baseline length L then determine the non-degeneracy baseline range.\nInconclusion, we have studied theprobabilities Pe? andP?? forvery longbaseline neutrino\noscillations. We focus on sensitivities of these probabilities to mixing angles ?13, ?23 and the\nCP violation phase ?CP. Taking ?CP = 0 as an example, we presented contour graphs of\nPe? and P?? in the sin2?13 ? cos2?23 plane for baseline lengths L = 1000 km, 5000 km,\n10000 km and 12000 km. The energy values chosen for such studies are in the vicinities of\neither local minima or local maxima of neutrino oscillation probabilities. For each baseline\nlength, we have found that P?? is more sensitive to sin2?13 at energies around its local\nmaxima while it is more sensitive to cos2?23 at energies around its local minima. On the\nother hand, the appearance probability Pe? is sensitive to sin2?13 and cos2?23 only near its\nlocal maximum. Such findings have been applied to probe the octant of mixing angle ?23\nassuming that the angle ?13 and the sign of ?m231 are known. The appearance probability\nPe? is non-degenerate in ?23. The sensitivity of Pe? to cos2?23 is studied for baseline lengths\nfrom 1000 km to 12000 km. We also studied the sensitivity of P?? to cos2?23 for the same\nrange of baseline length. We have identified the ranges of neutrino energy and baseline\nlengths where the ?23 degeneracy is absent. We have pointed out that, for a true value of ?23\n20\nless than pi/4 and a baseline length between 8000 and 10000 km, the survival mode ?? ? ??\nis equally good as the appearance mode ?e ? ?? for probing the octant of ?23.\nAcknowledgements\nG.L.L likes to thank D. Indumathi for informative discussions. This work is supported\nby National Science Council of Taiwan under the grant number NSC 94-2112-M-009-026.\n[1] Y. Ashie et al. [Super-Kamiokande Collaboration], Phys. Rev. D 71, 112005 (2005)\n[arXiv:hep-ex/0501064].\n[2] Y. Ashie et al. [Super-Kamiokande Collaboration], Phys. Rev. Lett. 93 (2004) 101801\n[arXiv:hep-ex/0404034].\n[3] E. Aliu et al. [K2K Collaboration], Phys. Rev. Lett. 94 (2005) 081802 [arXiv:hep-ex/0411038].\n[4] M. H. Ahn et al. [K2K Collaboration], Phys. Rev. D74, 072003 (2006) [arXiv:hep-ex/0606032].\n[5] K. Eguchi et al. [KamLAND Collaboration], Phys. Rev. Lett. 90 (2003) 021802\n[arXiv:hep-ex/0212021].\n[6] T. Araki et al. [KamLAND Collaboration], Phys. Rev. Lett. 94 (2005) 081801\n[arXiv:hep-ex/0406035].\n[7] See G. L. Fogli, E. Lisi, A. Marrone and A. Palazzo, Prog. Part. Nucl. Phys. 57, 742 (2006)\n[arXiv:hep-ph/0506083], which contains a list of original references on solar neutrino oscilla-\ntions.\n[8] G. L. Fogli and E. Lisi, Phys. Rev. D 54, 3667 (1996) [arXiv:hep-ph/9604415].\n[9] M. Apollonio et al. [CHOOZ Collaboration], Phys. Lett. B 466, 415 (1999)\n[arXiv:hep-ex/9907037].\n[10] F. Boehm et al., Phys. Rev. D 64, 112001 (2001) [arXiv:hep-ex/0107009].\n[11] I. Mocioiu and R. Shrock, Phys. Rev. D 62, 053017 (2000) [arXiv:hep-ph/0002149];\nV. D. Barger, S. Geer, R. Raja and K. Whisnant, Phys. Lett. B 485, 379 (2000)\n[arXiv:hep-ph/0004208]; V. D. Barger, S. Geer, R. Raja and K. Whisnant, Phys. Rev. D\n62, 013004 (2000) [arXiv:hep-ph/9911524]; M. Freund, M. Lindner, S. T. Petcov and A. Ro-\nmanino, Nucl. Phys. B 578, 27 (2000) [arXiv:hep-ph/9912457]; M. Freund, P. Huber and\n21\nM. Lindner, Nucl. Phys. B 585, 105 (2000) [arXiv:hep-ph/0004085]; A. Cervera, A. Donini,\nM. B. Gavela, J. J. Gomez Cadenas, P. Hernandez, O. Mena and S. Rigolin, Nucl. Phys. B\n579, 17 (2000) [Erratum-ibid. B 593, 731 (2001)] [arXiv:hep-ph/0002108].\n[12] D. Choudhury and A. Datta, JHEP 0507, 058 (2005) [arXiv:hep-ph/0410266]; D. Indu-\nmathi and M. V. N. Murthy, Phys. Rev. D 71, 013001 (2005) [arXiv:hep-ph/0407336];\nS. Choubey and P. Roy, Phys. Rev. D 73, 013006 (2006) [arXiv:hep-ph/0509197]. D. In-\ndumathi, M. V. N. Murthy, G. Rajasekaran and N. Sinha, Phys. Rev. D 74, 053004 (2006)\n[arXiv:hep-ph/0603264].\n[13] We adopt the approach of M. Freund and T. Ohlsson, Mod. Phys. Lett. A 15, 867 (2000)\n[arXiv:hep-ph/9909501], by dividing the Earth density regions into the Earth mantle and the\nEarth core. However we have further introduced the concept of average density to be discussed\nin details later.\n[14] V. Barger, D. Marfatia and K. Whisnant, Phys. Rev. D 65, 073023 (2002)\n[arXiv:hep-ph/0112119].\n[15] P. Huber and W. Winter, Phys. Rev. D 68, 037301 (2003) [arXiv:hep-ph/0301257].\n[16] A. Y. Smirnov, arXiv:hep-ph/0610198.\n[17] Z. Maki, M. Nakagawa and S. Sakata, Prog. Theor. Phys. 28, 870 (1962); see also , B. Pon-\ntecorvo, Zh. Eksp. Teor. Fiz. 53, 1717 (1967) [Sov. Phys. JETP 26, 984 (1968)].\n[18] A. Dziewonski, Earth Structure, Global, in: The Encyclopedia of Solid Earth Geophysics,\nDavid E. James, ed. (Van Nostrand Reinhold, New York 1989) p. 331.\n[19] M. V. Chizhov and S. T. Petcov, Phys. Rev. D 63, 073003 (2001) [arXiv:hep-ph/9903424];\nM. V. Chizhov and S. T. Petcov, Phys. Rev. Lett. 83, 1096 (1999) [arXiv:hep-ph/9903399].\n[20] E. K. Akhmedov, Nucl. Phys. B 538, 25 (1999) [arXiv:hep-ph/9805272].\n[21] S. T. Petcov, Phys. Lett. B 214, 259 (1988).\n[22] J. Bernabeu, S. Palomares-Ruiz, A. Perez and S. T. Petcov, Phys. Lett. B 531, 90 (2002)\n[arXiv:hep-ph/0110071].\n[23] Y. C. Hsu, Master Thesis, NCTU (2005).\n[24] See E. K. Akhmedov, R. Johansson, M. Lindner, T. Ohlsson and T. Schwetz, JHEP 0404,\n078 (2004) [arXiv:hep-ph/0402175] and earlier works cited in this paper.\n[25] J. N. Bahcall, M. C. Gonzalez-Garcia and C. Pena-Garay, JHEP 0408 (2004) 016\n[arXiv:hep-ph/0406294].\n22\n[26] I. Mocioiu and R. Shrock, JHEP 0111, 050 (2001) [arXiv:hep-ph/0106139].\n[27] F. Ardellier et al. [Double Chooz Collaboration], arXiv:hep-ex/0606025.\n[28] Y. Wang, arXiv:hep-ex/0610024.\n[29] S. Geer, Phys. Rev. D 57, 6989 (1998) [Erratum-ibid. D 59, 039903 (1999)]\n[arXiv:hep-ph/9712290]; A. De Rujula, M. B. Gavela and P. Hernandez, Nucl. Phys. B 547,\n21 (1999) [arXiv:hep-ph/9811390]; V. D. Barger, S. Geer and K. Whisnant, Phys. Rev. D 61,\n053004 (2000) [arXiv:hep-ph/9906487].\n[30] P. Zucchelli, Phys. Lett. B 532, 166 (2002).\n23\n"}
